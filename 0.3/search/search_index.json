{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Copyright and other protections apply. Please see the accompanying LICENSE file for rights and restrictions governing use of this software. All rights not expressly waived or licensed are reserved. If that file is missing or appears to be modified from its original, then please contact the author before viewing or using this software in any capacity. dyce \u2013 simple Python tools for exploring dice outcomes and other discrete probabilities dyce is a pure-Python library for computing discrete probability distributions. It is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. If you find it lacking in any way, please consider contributing an issue to start a discussion. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Source code is available on GitHub . A taste dyce provides two key primitives. H objects represent histograms for modeling discrete outcomes, like individual dice. P objects objects represent pools (ordered sequences) of histograms. Both support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True Each can generate random rolls as desired. 1 2 3 >>> d6 = H ( 6 ) >>> d6 . roll () # doctest: +SKIP 4 1 2 3 4 >>> d10 = H ( 10 ) - 1 >>> p_6d10 = 6 @P ( d10 ) >>> p_6d10 . roll () # doctest: +SKIP ( 0 , 1 , 2 , 3 , 5 , 7 ) By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ( width = 65 )) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . style . use ( \"dark_background\" ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( 0 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v - 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Lowest\" , ... ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( - 1 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v + 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Highest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Taking the lowest or highest die of 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP See the tutorial and the API guide for a much more thorough treatment, including detailed examples. Design philosophy dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. That\u2019s a highfalutin way of saying it doesn\u2019t guess. It knows , even if knowing is harder. Which, if we\u2019re honest with ourselves, it often is. Or, at least, it should be. Quote \u201cIt\u2019s frightening to think that you might not know something, but more frightening to think that, by and large, the world is run by people who have faith that they know exactly what is going on.\u201d \u2014Amos Tversky Because dyce exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. 1 It can be installed and run anywhere 2 , and modified as desired. On its own, dyce is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter . In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods). Comparison to alternatives The following is a best-effort 3 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen python-dice Robson et al. AnyDice Flick d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clemens et al. dice-notation Garrido dyce Eyk Latest release 2021 N/A 2021 Unknown 2021 2016 2021 2021 2009 Actively maintained and documented \u2705 \u26a0\ufe0f 4 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Suitable as a dependency in other projects \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c \u274c Arbitrary expressions \u2705 \u26a0\ufe0f 6 \u2705 \u2705 \u2705 \u26a0\ufe0f 7 \u274c \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u26a0\ufe0f 8 \u274c \u26a0\ufe0f 8 \u2705 \u26a0\ufe0f 8 \u26a0\ufe0f 8 \u26a0\ufe0f 8 Open source (can inspect) \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 Permissive licensing (can use and extend) \u2705 \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705 \u2705 License dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub . Installation Installation can be performed via PyPI : 1 2 % pip install dycelib ... Alternately, you can download the source and run setup.py : 1 2 3 4 5 % git clone https://github.com/posita/dyce.git ... % cd dyce % python setup.py install ... Requirements dyce requires a relatively modern version of Python: cPython (3.8+) PyPy (Python 3.8+ compatible) dyce will make use the following optional libraries at runtime, if installed: matplotlib See the hacking quick-start for additional development and testing dependencies. You won\u2019t find any lexers, parsers, or tokenizers here, other than straight-up Python. That being said, if you really miss them, you can always roll your own and lean on dyce underneath to perform computations. It doesn\u2019t mind. It actually kind of likes it. \u21a9 Okay, maybe not literally anywhere, but you\u2019d be surprised . Void where prohibited. Certain restrictions apply. Do not taunt Happy Fun Ball . \u21a9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if you observe discrepancies. \u21a9 Actively maintained, but sparsely documented. The author has expressed a desire to release a more polished version. \u21a9 Source can be downloaded and incorporated directly, but there is no packaging, versioning, or dependency tracking. \u21a9 \u21a9 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u21a9 Limited arithmetic operations are available. The library also provides game-specific functions. \u21a9 Results only. Input is limited to specialized grammar. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Introduction"},{"location":"#dyce-simple-python-tools-for-exploring-dice-outcomes-and-other-discrete-probabilities","text":"dyce is a pure-Python library for computing discrete probability distributions. It is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. If you find it lacking in any way, please consider contributing an issue to start a discussion. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Source code is available on GitHub .","title":"dyce \u2013 simple Python tools for exploring dice outcomes and other discrete probabilities"},{"location":"#a-taste","text":"dyce provides two key primitives. H objects represent histograms for modeling discrete outcomes, like individual dice. P objects objects represent pools (ordered sequences) of histograms. Both support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True Each can generate random rolls as desired. 1 2 3 >>> d6 = H ( 6 ) >>> d6 . roll () # doctest: +SKIP 4 1 2 3 4 >>> d10 = H ( 10 ) - 1 >>> p_6d10 = 6 @P ( d10 ) >>> p_6d10 . roll () # doctest: +SKIP ( 0 , 1 , 2 , 3 , 5 , 7 ) By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ( width = 65 )) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . style . use ( \"dark_background\" ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( 0 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v - 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Lowest\" , ... ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( - 1 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v + 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Highest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Taking the lowest or highest die of 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP See the tutorial and the API guide for a much more thorough treatment, including detailed examples.","title":"A taste"},{"location":"#design-philosophy","text":"dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. That\u2019s a highfalutin way of saying it doesn\u2019t guess. It knows , even if knowing is harder. Which, if we\u2019re honest with ourselves, it often is. Or, at least, it should be. Quote \u201cIt\u2019s frightening to think that you might not know something, but more frightening to think that, by and large, the world is run by people who have faith that they know exactly what is going on.\u201d \u2014Amos Tversky Because dyce exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. 1 It can be installed and run anywhere 2 , and modified as desired. On its own, dyce is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter . In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods).","title":"Design philosophy"},{"location":"#comparison-to-alternatives","text":"The following is a best-effort 3 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen python-dice Robson et al. AnyDice Flick d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clemens et al. dice-notation Garrido dyce Eyk Latest release 2021 N/A 2021 Unknown 2021 2016 2021 2021 2009 Actively maintained and documented \u2705 \u26a0\ufe0f 4 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Suitable as a dependency in other projects \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c \u274c Arbitrary expressions \u2705 \u26a0\ufe0f 6 \u2705 \u2705 \u2705 \u26a0\ufe0f 7 \u274c \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u26a0\ufe0f 8 \u274c \u26a0\ufe0f 8 \u2705 \u26a0\ufe0f 8 \u26a0\ufe0f 8 \u26a0\ufe0f 8 Open source (can inspect) \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 Permissive licensing (can use and extend) \u2705 \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705 \u2705","title":"Comparison to alternatives"},{"location":"#license","text":"dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub .","title":"License"},{"location":"#installation","text":"Installation can be performed via PyPI : 1 2 % pip install dycelib ... Alternately, you can download the source and run setup.py : 1 2 3 4 5 % git clone https://github.com/posita/dyce.git ... % cd dyce % python setup.py install ...","title":"Installation"},{"location":"#requirements","text":"dyce requires a relatively modern version of Python: cPython (3.8+) PyPy (Python 3.8+ compatible) dyce will make use the following optional libraries at runtime, if installed: matplotlib See the hacking quick-start for additional development and testing dependencies. You won\u2019t find any lexers, parsers, or tokenizers here, other than straight-up Python. That being said, if you really miss them, you can always roll your own and lean on dyce underneath to perform computations. It doesn\u2019t mind. It actually kind of likes it. \u21a9 Okay, maybe not literally anywhere, but you\u2019d be surprised . Void where prohibited. Certain restrictions apply. Do not taunt Happy Fun Ball . \u21a9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if you observe discrepancies. \u21a9 Actively maintained, but sparsely documented. The author has expressed a desire to release a more polished version. \u21a9 Source can be downloaded and incorporated directly, but there is no packaging, versioning, or dependency tracking. \u21a9 \u21a9 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u21a9 Limited arithmetic operations are available. The library also provides game-specific functions. \u21a9 Results only. Input is limited to specialized grammar. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Requirements"},{"location":"contrib/","text":"Contributing to dyce There are many ways you can contribute. You have only but to try. Filing issues You can file new issues as you find them. Please try to avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful. Hacking quick-start A helper script is provided for bootstrapping an isolated development environment: 1 2 3 % [ PYTHON = \u2026/path/to/python ] helpers/venvsetup.sh \u2026 % . .venv/bin/activate The helper script is really only there to help folks get their feet wet who don\u2019t already manage their own virtual environments. The above is essentially equivalent to the following (with some additional checking): 1 2 3 4 5 % \u2026/path/to/python -m virtualenv .venv || \u2026/path/to/python -m venv .venv \u2026 % .venv/bin/pip install --upgrade --editable '.[dev]' \u2026 % . .venv/bin/activate The [dev] variant includes additional dependencies necessary for development and testing. See the extras_require parameter in setup.py . Unit tests are run with Tox (but can also be run with pytest directly, if installed): 1 2 3 4 5 6 % cd \u2026/path/to/dyce % . .venv/bin/activate % tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] \u2026 % pytest [ PYTEST_ARGS... ] \u2026 A bare bones example: 1 2 3 4 5 6 % git clone https://github.com/posita/dyce.git # or your fork % cd dyce % helpers/venvsetup.sh && . .venv/bin/activate \u2026 % tox \u2026 A virtualenvwrapper -based alternative: 1 2 3 4 5 6 7 % git clone https://github.com/posita/dyce.git # or your fork % mkvirtualenv [ --python = \u2026/path/to/python ] -a \" ${ PWD } /dyce\" dycelib \u2026 % pip install --upgrade --editable '.[dev]' \u2026 % tox \u2026 Submission guidelines If you are willing and able, consider submitting a pull request with a fix. See the docs if you\u2019re not already familiar with pull requests. dyce releases from master (although not always immediately), so a lot of these workflows are helpful. There are only a few additional guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file: 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub - [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Do your best to follow the source conventions as you observe them. If it\u2019s important to you, Existing comments are wrapped at 88 characters per line to match Black\u2019s default. (Don\u2019t spend too much effort on strict conformance, though. I can clean things up later if they really bother me.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in tests . If you want feedback on a work-in-progress, consider \u201cmentioning\u201d me ( @posita ), and describe specifically how I can help. Consider prefixing your pull request\u2019s title with something like, \u201c NEED FEEDBACK - \u201d. If your pull request is still in progress, but you are not blocked on anything, consider using the draft feature . Once you are ready for a merge, resolve any conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) If your pull request started out as a draft, promote it by requesting a review. Consider prefixing the pull request\u2019s title to something like, \u201c READY FOR MERGE - \u201d. I will try to get to it as soon as I can.","title":"Contributing"},{"location":"contrib/#contributing-to-dyce","text":"There are many ways you can contribute. You have only but to try.","title":"Contributing to dyce"},{"location":"contrib/#filing-issues","text":"You can file new issues as you find them. Please try to avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful.","title":"Filing issues"},{"location":"contrib/#hacking-quick-start","text":"A helper script is provided for bootstrapping an isolated development environment: 1 2 3 % [ PYTHON = \u2026/path/to/python ] helpers/venvsetup.sh \u2026 % . .venv/bin/activate The helper script is really only there to help folks get their feet wet who don\u2019t already manage their own virtual environments. The above is essentially equivalent to the following (with some additional checking): 1 2 3 4 5 % \u2026/path/to/python -m virtualenv .venv || \u2026/path/to/python -m venv .venv \u2026 % .venv/bin/pip install --upgrade --editable '.[dev]' \u2026 % . .venv/bin/activate The [dev] variant includes additional dependencies necessary for development and testing. See the extras_require parameter in setup.py . Unit tests are run with Tox (but can also be run with pytest directly, if installed): 1 2 3 4 5 6 % cd \u2026/path/to/dyce % . .venv/bin/activate % tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] \u2026 % pytest [ PYTEST_ARGS... ] \u2026 A bare bones example: 1 2 3 4 5 6 % git clone https://github.com/posita/dyce.git # or your fork % cd dyce % helpers/venvsetup.sh && . .venv/bin/activate \u2026 % tox \u2026 A virtualenvwrapper -based alternative: 1 2 3 4 5 6 7 % git clone https://github.com/posita/dyce.git # or your fork % mkvirtualenv [ --python = \u2026/path/to/python ] -a \" ${ PWD } /dyce\" dycelib \u2026 % pip install --upgrade --editable '.[dev]' \u2026 % tox \u2026","title":"Hacking quick-start"},{"location":"contrib/#submission-guidelines","text":"If you are willing and able, consider submitting a pull request with a fix. See the docs if you\u2019re not already familiar with pull requests. dyce releases from master (although not always immediately), so a lot of these workflows are helpful. There are only a few additional guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file: 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub - [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Do your best to follow the source conventions as you observe them. If it\u2019s important to you, Existing comments are wrapped at 88 characters per line to match Black\u2019s default. (Don\u2019t spend too much effort on strict conformance, though. I can clean things up later if they really bother me.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in tests . If you want feedback on a work-in-progress, consider \u201cmentioning\u201d me ( @posita ), and describe specifically how I can help. Consider prefixing your pull request\u2019s title with something like, \u201c NEED FEEDBACK - \u201d. If your pull request is still in progress, but you are not blocked on anything, consider using the draft feature . Once you are ready for a merge, resolve any conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) If your pull request started out as a draft, promote it by requesting a review. Consider prefixing the pull request\u2019s title to something like, \u201c READY FOR MERGE - \u201d. I will try to get to it as soon as I can.","title":"Submission guidelines"},{"location":"dyce/","text":"dyce package reference dyce special dyce provides two core primitives: H for histograms (outcomes or individual dice) P for collections of histograms (pools) H An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, it is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derives, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ): 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed: 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative): 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps: 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes: 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand: 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes: 1 2 >>> len ( 2 @d6 ) 11 The counts method can be used to compute the total number of combinations and each outcome\u2019s probability: 1 2 3 4 5 >>> from fractions import Fraction >>> total = sum (( 2 @d6 ) . counts ()) ; total 36 >>> [( outcome , Fraction ( count , total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ); d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [\u2026] : 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method : 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands: 1 2 >>> d6 . accumulate ( d6 ) == d6 . accumulate ( d6 ) . accumulate ( d6 ) True __hash__ ( self ) -> int special Return hash(self). Source code in dyce/h.py def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ())) __init__ ( self , items : _SourceT ) -> None special Initializer. Source code in dyce/h.py def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ OutcomeP ] = counter () if isinstance ( items , SupportsInt ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , OutcomeP ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HAbleT ): tmp . update ( items . h ()) elif isinstance ( items , ABCMapping ): tmp . update ( items ) elif isinstance ( items , ABCIterable ): # Items is either an Iterable[OutcomeP] or an Iterable[Tuple[OutcomeP, # SupportsInt]] (although this technically supports Iterable[Union[OutcomeP, # Tuple[OutcomeP, SupportsInt]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 } accumulate ( self , other : _SourceT ) -> 'H' Accumulates counts: 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py def accumulate ( self , other : _SourceT ) -> \"H\" : r \"\"\" Accumulates counts: ```python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , ABCMapping ): other = other . items () elif not isinstance ( other , ABCIterable ): other = cast ( Iterable [ OutcomeP ], ( other ,)) return H ( chain ( self . items (), cast ( Iterable , other ))) counts ( self ) -> ValuesView [ int ] More descriptive synonym for the values method . Source code in dyce/h.py def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . values () distribution ( self , fill_items : _MappingT = None , rational_t : _RationalP [ _T ] = < class ' fractions . Fraction '>) -> Iterator[Tuple[OutcomeP, _T]] Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: 1 2 3 4 5 >>> h = H (( 1 , 2 , 3 , 3 , 4 , 4 , 5 , 6 )) >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . ge ( 3 ) . distribution ()) [( False , Fraction ( 1 , 4 )), ( True , Fraction ( 3 , 4 ))] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes: 1 2 3 4 >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . distribution ( fill_items = { 0 : 0 , 7 : 0 })) [( 0 , Fraction ( 0 , 1 )), ( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 )), ( 7 , Fraction ( 0 , 1 ))] If provided, rational_t must be a callable that takes two int s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type: 1 2 3 4 5 6 7 8 9 10 >>> list ( h . distribution ( rational_t = lambda n , d : f \" { n } / { d } \" )) [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '2/8' ), ( 4 , '2/8' ), ( 5 , '1/8' ), ( 6 , '1/8' )] >>> import sympy >>> list ( h . distribution ( rational_t = sympy . Rational )) [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] >>> import sage.rings.rational # doctest: +SKIP >>> list ( h . distribution ( rational_t = lambda n , d : sage . rings . rational . Rational (( n , d )))) # doctest: +SKIP [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] Another way to accomplish something similar may be to leverage many number implementations\u2019 ability to convert from fractions.Fraction s (e.g., sage.rings.rational.Rational , sympy.core.numbers.Rational ): 1 2 3 4 5 6 7 >>> import sympy.abc >>> [( o , sympy . Rational ( c )) for o , c in ( h + sympy . abc . x ) . distribution ()] [( x + 1 , 1 / 8 ), ( x + 2 , 1 / 8 ), ( x + 3 , 1 / 4 ), ( x + 4 , 1 / 4 ), ( x + 5 , 1 / 8 ), ( x + 6 , 1 / 8 )] >>> import sage.rings.rational # doctest: +SKIP >>> [( o , sage . rings . rational . Rational ( c )) for o , c in h . distribution ()] # doctest: +SKIP [( 1 , 1 / 6 ), ( 2 , 1 / 6 ), ( 3 , 1 / 3 ), ( 4 , 1 / 3 ), ( 5 , 1 / 6 ), ( 6 , 1 / 6 )] Source code in dyce/h.py def distribution ( self , fill_items : _MappingT = None , # See <https://github.com/python/mypy/issues/10854> for context on all the # @overload work-around nonsense above rational_t : _RationalP [ _T ] = Fraction , ) -> Iterator [ Tuple [ OutcomeP , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: ```python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes: ```python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` If provided, *rational_t* must be a callable that takes two ``int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type: ```python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` Another way to accomplish something similar may be to leverage many number implementations\u2019 ability to convert from ``fractions.Fraction``s (e.g., [``sage.rings.rational.Rational``](https://doc.sagemath.org/html/en/reference/rings_standard/sage/rings/rational.html#sage.rings.rational.Rational), [``sympy.core.numbers.Rational``](https://docs.sympy.org/latest/modules/core.html#rational)): ```python >>> import sympy.abc >>> [(o, sympy.Rational(c)) for o, c in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] >>> import sage.rings.rational # doctest: +SKIP >>> [(o, sage.rings.rational.Rational(c)) for o, c in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) ) distribution_xy ( self , fill_items : _MappingT = None ) -> Tuple [ Tuple [ OutcomeP , ... ], Tuple [ float , ... ]] Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method and ensures the values are float s: 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , Fraction ( 1 , 6 )), ( 2 , Fraction ( 1 , 6 )), ( 3 , Fraction ( 1 , 6 )), ( 4 , Fraction ( 1 , 6 )), ( 5 , Fraction ( 1 , 6 )), ( 6 , Fraction ( 1 , 6 ))] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py def distribution_xy ( self , fill_items : _MappingT = None , ) -> Tuple [ Tuple [ OutcomeP , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``float``s: ```python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" return cast ( Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]], tuple ( zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) ), ) eq ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.eq, other) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map method . Source code in dyce/h.py def eq ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.eq, other)``. ```python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_eq , other ) even ( self ) -> 'H' Equivalent to self.umap(lambda outcome: outcome % 2 == 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py def even ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 == 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_even ( outcome : SupportsInt ) -> bool : return as_int ( outcome ) % 2 == 0 return self . umap ( is_even ) exactly_k_times_in_n ( self , outcome : OutcomeP , n : SupportsInt , k : SupportsInt ) -> int Experimental This method should be considered experimental and may disappear in future versions. Computes and returns the probability distribution where outcome appears exactly k times among n@self . 1 2 3 4 5 6 >>> H ( 6 ) . exactly_k_times_in_n ( outcome = 5 , n = 4 , k = 2 ) 150 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 2 , n = 3 , k = 3 ) 1 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 4 , n = 3 , k = 3 ) 8 Source code in dyce/h.py @experimental def exactly_k_times_in_n ( self , outcome : OutcomeP , n : SupportsInt , k : SupportsInt , ) -> int : \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``n@self``. ```python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) c_total = sum ( self . counts ()) return comb ( n , k ) * c_outcome ** k * ( c_total - c_outcome ) ** ( n - k ) explode ( self , max_depth : SupportsInt = 1 ) -> 'H' Shorthand for self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py def explode ( self , max_depth : SupportsInt = 1 ) -> \"H\" : r \"\"\" Shorthand for ``self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth)``. ```python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , op_add , max_depth , ) format ( self , fill_items : _MappingT = None , width : SupportsInt = 88 , scaled : bool = False , tick : str = '#' , sep : str = ' \\n ' ) -> str Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( \" {:->65} \" . format ( \" 65 chars wide -->|\" )) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py def format ( self , fill_items : _MappingT = None , width : SupportsInt = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ```python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ```python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``True``, horizontal bars are scaled to *width*: ```python >>> h = (2@H(6)).ge(7) >>> print(\"{:->65}\".format(\" 65 chars wide -->|\")) ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : Union [ float , OutcomeP ] = float ( self . mean ()) except TypeError : mu = self . mean () if width <= 0 : def _parts (): yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 def lines (): yield f \"avg | { mu : 7.2f } \" try : std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except TypeError : pass outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( lines ()) ge ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.ge, other) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map method . Source code in dyce/h.py def ge ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ge, other)``. ```python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ge , other ) gt ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.gt, other) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def gt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.gt, other)``. ```python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_gt , other ) items ( self ) -> ItemsView [ OutcomeP , int ] D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py def items ( self ) -> ItemsView [ OutcomeP , int ]: return cast ( ItemsView [ OutcomeP , int ], self . _h . items ()) keys ( self ) -> KeysView [ OutcomeP ] D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py def keys ( self ) -> KeysView [ OutcomeP ]: return cast ( KeysView [ OutcomeP ], self . _h . keys ()) le ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.le, other) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def le ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.le, other)``. ```python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_le , other ) lowest_terms ( self ) -> 'H' Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )); df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d6avg = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d6avg H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d6avg . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py def lowest_terms ( self ) -> \"H\" : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ```python >>> df = H((-1, -1, 0, 0, 1, 1)); df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ```python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return H ( self . _lowest_terms ()) lt ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.lt, other) : 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map method . Source code in dyce/h.py def lt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.lt, other)``: ```python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_lt , other ) map ( self , oper : _BinaryOperatorT , other : _OperandT ) -> 'H' Applies oper to each outcome of the histogram paired with other . Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . add , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . add , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . mul , - 1 ) H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 . map ( operator . mul , - 1 ) == d6 * - 1 True 1 2 3 4 >>> d6 . map ( operator . gt , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . gt , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py def map ( self , oper : _BinaryOperatorT , other : _OperandT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram paired with *other*. Shorthands exist for many arithmetic operators and comparators. ```python >>> import operator >>> d6 = H(6) >>> d6.map(operator.add, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.add, d6) == d6 + d6 True ``` ```python >>> d6.map(operator.mul, -1) H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> d6.map(operator.mul, -1) == d6 * -1 True ``` ```python >>> d6.map(operator.gt, 3) H({False: 3, True: 3}) >>> d6.map(operator.gt, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( other , HAbleT ): other = other . h () if isinstance ( other , H ): return H (( oper ( s , o ), self [ s ] * other [ o ]) for s , o in product ( self , other )) else : return H (( oper ( outcome , other ), count ) for outcome , count in self . items ()) mean ( self ) -> Union [ float , OutcomeP ] Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py def mean ( self ) -> Union [ float , OutcomeP ]: \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 ) ne ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.ne, other) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map method . Source code in dyce/h.py def ne ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ne, other)``. ```python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ne , other ) odd ( self ) -> 'H' Equivalent to self.umap(lambda outcome: outcome % 2 != 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py def odd ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 != 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_odd ( outcome : SupportsInt ) -> bool : return as_int ( outcome ) % 2 != 0 return self . umap ( is_odd ) order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> 'H' Experimental This method should be considered experimental and may disappear in future versions. Shorthand for self.order_stat_func_for_n(n)(pos) . Source code in dyce/h.py @experimental def order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> \"H\" : \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Shorthand for ``self.order_stat_func_for_n(n)(pos)``. \"\"\" return self . order_stat_func_for_n ( n )( pos ) order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], 'H' ] Experimental This method should be considered experimental and may disappear in future versions. Returns a function that takes a single argument ( pos ) and computes the probability distribution for each outcome appearing in that position among n@self . 1 2 3 4 >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> order_stat_for_5d6avg = d6avg . order_stat_func_for_n ( 5 ) >>> order_stat_for_5d6avg ( 3 ) # counts where outcome appears at index 3 H ({ 2 : 26 , 3 : 1432 , 4 : 4792 , 5 : 1526 }) The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where 2 appears at the fourth (index 3 ) position, 1432 ways where 3 appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria: 1 2 3 4 >>> from dyce import P >>> p_5d6avg = 5 @P ( d6avg ) >>> sum ( count for roll , count in p_5d6avg . rolls_with_counts () if roll [ 3 ] == 5 ) 1526 This method exists in addition to the H.order_stat_for_n_at_pos method because computing the betas for each outcome in n is unnecessary for each pos . Where different pos values are needed for the same n (e.g., in a loop) and where n is large, that overhead can be significant. The returned function caches those betas for n such that repeated querying or results at pos can be computed much faster: 1 2 3 4 5 6 7 In [ 2 ]: % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 100 , i ) for i in range ( 10 )] 1.61 s \u00b1 31.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 3 ]: %% timeit ... : order_stat_for_100d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 100 ) ... : [ order_stat_for_100d6_at_pos ( i ) for i in range ( 10 )] 170 ms \u00b1 3.41 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Source code in dyce/h.py @experimental def order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], \"H\" ]: \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``n@self``. ```python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``2`` appears at the fourth (index ``3``) position, 1432 ways where ``3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria: ```python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster: ```python In [2]: %timeit [H(6).order_stat_for_n_at_pos(100, i) for i in range(10)] 1.61 s \u00b1 31.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [3]: %%timeit ...: order_stat_for_100d6_at_pos = H(6).order_stat_func_for_n(100) ...: [order_stat_for_100d6_at_pos(i) for i in range(10)] 170 ms \u00b1 3.41 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) ``` \"\"\" betas_by_outcome : Dict [ OutcomeP , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ OutcomeP , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) def order_stat_for_n_at_pos ( pos : SupportsInt ) -> H : return H ( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos outcomes ( self ) -> KeysView [ OutcomeP ] More descriptive synonym for the keys method . Source code in dyce/h.py def outcomes ( self ) -> KeysView [ OutcomeP ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . keys () roll ( self ) -> OutcomeP Returns a (weighted) random outcome, sorted. On ordering This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. Source code in dyce/h.py def roll ( self ) -> OutcomeP : r \"\"\" Returns a (weighted) random outcome, sorted. !!! tip \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" if not self : return 0 return choices ( * self . distribution_xy ())[ 0 ] stdev ( self , mu : Union [ float , OutcomeP ] = None ) -> Union [ float , OutcomeP ] Shorthand for math.sqrt(self.variance(mu)) . Source code in dyce/h.py def stdev ( self , mu : Union [ float , OutcomeP ] = None ) -> Union [ float , OutcomeP ]: \"\"\" Shorthand for ``math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu )) substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = < function coalesce_replace at 0x10fd97a60 > , max_depth : SupportsInt = 1 ) -> 'H' Calls expand on each outcome, recursively up to max_depth times. If expand returns a number, it replaces the outcome. If it returns an H object , coalesce is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the lowest_terms method .) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: 1 2 3 4 5 6 7 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , outcome : - h if outcome == 4 else outcome ) ; sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( count for outcome , count in orig . items () if outcome == 4 ) / sum ( orig . counts ()) 0.4 >>> sum ( count for outcome , count in sub . items () if outcome < 0 ) / sum ( sub . counts ()) 0.4 An important exception If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: 1 2 >>> H ( 6 ) . substitute ( lambda h , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda h , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . add , max_depth = 6 ) >>> h_even = h . even () >>> print ( \" {:.3%} \" . format ( h_even [ 1 ] / sum ( h_even . counts ()))) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | Source code in dyce/h.py def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , ) -> \"H\" : r \"\"\" Calls *expand* on each outcome, recursively up to *max_depth* times. If *expand* returns a number, it replaces the outcome. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the [``lowest_terms`` method][dyce.h.H.lowest_terms].) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ```python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: ```python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, outcome: -h if outcome == 4 else outcome) ; sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(count for outcome, count in orig.items() if outcome == 4) / sum(orig.counts()) 0.4 >>> sum(count for outcome, count in sub.items() if outcome < 0) / sum(sub.counts()) 0.4 ``` !!! tip \"An important exception\" If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: ```python >>> H(6).substitute(lambda h, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda h, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ```python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.add, max_depth=6) >>> h_even = h.even() >>> print(\"{:.3%}\".format(h_even[1] / sum(h_even.counts()))) 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: ```python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=65, scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` \"\"\" max_depth = as_int ( max_depth ) def _substitute ( h : H , depth : int = 0 ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ OutcomeP , int , int ]] = [] for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , outcome ) # Account for the impact of expansion on peers expanded_scalar = sum ( expanded . counts ()) if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) else : items_for_reassembly . append (( expanded , count , 1 )) return H ( ( # Apply the total_scalar, but factor out this item's contribution ( outcome , count * total_scalar // s ) for outcome , count , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self ) umap ( self , oper : _UnaryOperatorT ) -> 'H' Applies oper to each outcome of the histogram: 1 2 >>> H ( 6 ) . umap ( lambda outcome : outcome * - 1 ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py def umap ( self , oper : _UnaryOperatorT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram: ```python >>> H(6).umap(lambda outcome: outcome * -1) H(-6) ``` ```python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = H (( oper ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : h_simple = H ( oper ( self . _simple_init )) if h_simple == h : return h_simple return h values ( self ) -> ValuesView [ int ] D.values() -> an object providing a view on D's values Source code in dyce/h.py def values ( self ) -> ValuesView [ int ]: return self . _h . values () variance ( self , mu : Union [ float , OutcomeP ] = None ) -> Union [ float , OutcomeP ] Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py def variance ( self , mu : Union [ float , OutcomeP ] = None ) -> Union [ float , OutcomeP ]: \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 ) vs ( self , other : _OperandT ) -> 'H' Compares this histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self.within(0, 0, other) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py def vs ( self , other : _OperandT ) -> \"H\" : r \"\"\" Compares this histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``self.within(0, 0, other)``. ```python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other ) within ( self , lo : OutcomeP , hi : OutcomeP , other : _OperandT = 0 ) -> 'H' Computes the difference between this histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py def within ( self , lo : OutcomeP , hi : OutcomeP , other : _OperandT = 0 ) -> \"H\" : r \"\"\" Computes the difference between this histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ```python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other ) P An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). This class implements the HAbleT protocol and derives from the HAbleOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using binary arithmetic operations. Note that this class also provides its own @ and unary operator implementations that result in new P objects, not flattened histograms. 1 2 3 4 5 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) >>> - p_d6 P ( - 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True Arithmetic operators involving a number or another P object produce an H object : 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) Comparisons with H objects work as expected: 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram: 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering: 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HAbleT protocol , the P.h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ### __init__ ( self , * args : Union [ SupportsInt , 'P' , H ]) -> None special Initializer. Source code in dyce/p.py def __init__ ( self , * args : Union [ SupportsInt , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs (): for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h else : yield H ( as_int ( a )) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs ) self . _homogeneous = len ( set ( self . _hs )) <= 1 appearances_in_rolls ( self , outcome : OutcomeP ) -> H Experimental This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being almost twice (about \\(\\frac{7}{4}\\) ) as efficient as the boolean accumulation technique for larger sets: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 In [ 3 ]: % timeit 3 @d4_eq3 + 2 @d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 4 ]: % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 402 \u00b5s \u00b1 5.59 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 5 ]: % timeit 9 @d4_eq3 + 6 @d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 6 ]: % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 597 \u00b5s \u00b1 9.46 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 7 ]: % timeit 90 @d4_eq3 + 60 @d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 8 ]: % timeit P ( 90 @P ( 4 ), 60 @P ( 6 )) . appearances_in_rolls ( 3 ) 7.5 ms \u00b1 84.6 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) In [ 9 ]: % timeit 900 @d4_eq3 + 600 @d6_eq3 3.34 s \u00b1 19.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 10 ]: % timeit P ( 900 @P ( 4 ), 600 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.93 s \u00b1 14.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py @experimental def appearances_in_rolls ( self , outcome : OutcomeP ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ```python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ```python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being almost twice (about $\\frac{7}{4}$) as efficient as the boolean accumulation technique for larger sets: ```python In [3]: %timeit 3@d4_eq3 + 2@d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [4]: %timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3) 402 \u00b5s \u00b1 5.59 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [5]: %timeit 9@d4_eq3 + 6@d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [6]: %timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3) 597 \u00b5s \u00b1 9.46 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [7]: %timeit 90@d4_eq3 + 60@d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [8]: %timeit P(90@P(4), 60@P(6)).appearances_in_rolls(3) 7.5 ms \u00b1 84.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) In [9]: %timeit 900@d4_eq3 + 600@d6_eq3 3.34 s \u00b1 19.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [10]: %timeit P(900@P(4), 600@P(6)).appearances_in_rolls(3) 1.93 s \u00b1 14.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" group_counters : List [ Counter [ OutcomeP ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ OutcomeP ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum (( H ( group_counter ) for group_counter in group_counters ), start = H ({})) h ( self , * which : _GetItemT ) -> H Roughly equivalent to H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) ) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HAbleT protocol : 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( width = 65 , scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d6avg + d6avg True Source code in dyce/p.py def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) )`` with some short-circuit optimizations. When provided no arguments, ``h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HAbleT`` protocol][dyce.h.HAbleT]: ```python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ```python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ```python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(width=65, scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ```python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum ( self , start = H ({})) roll ( self ) -> _RollT Returns (weighted) random outcomes from contained histograms. Source code in dyce/p.py def roll ( self ) -> _RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self )) rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ] Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, (1, 2) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d6avg + d6avg True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable: 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted: 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) : \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n@P(H(m)) . Enumerating combinations with replacements would yield all unique rolls: ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m)) To determine the count for a particular roll (a, b, \u2026, n) , we compute the multinomial coefficient for that roll and multiply by the scalar H(m)[a] * H(m)[b] * \u2026 * H(m)[n] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 In [ 1 ]: from dyce import H , P In [ 2 ]: for n in ( 6 , 8 ): ... : p = n @P ( 6 ) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 1.35 ms \u00b1 23.4 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 3.15 ms \u00b1 516 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.37 ms \u00b1 182 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 10.5 ms \u00b1 1.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.58 ms \u00b1 25.3 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 9.81 ms \u00b1 171 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 14.7 ms \u00b1 430 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 20.4 ms \u00b1 328 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 3 ]: for n in ( 3 , 4 ): ... : p = P ( n @P ( 6 ), * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 2 )): 16.1 ms \u00b1 1.09 ms per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 3 )): 39 ms \u00b1 602 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 4 )): 40.3 ms \u00b1 3.49 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 5 )): 46.2 ms \u00b1 7.43 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 538 ms \u00b1 9.46 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 534 ms \u00b1 30.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 536 ms \u00b1 13.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 604 ms \u00b1 52.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 4 ]: for n in ( 6 , 8 ): ... : p = P ( * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 2 )): 145 ms \u00b1 4.59 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 3 )): 147 ms \u00b1 3.6 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 158 ms \u00b1 1.38 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 147 ms \u00b1 691 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 6.09 s \u00b1 14.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 6.11 s \u00b1 36.9 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 6 )): 6.25 s \u00b1 47.5 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 7 )): 6.31 s \u00b1 42.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed for more flexible selections: ```python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: ```python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ```python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``(1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ```python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity: ```python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: ```python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable: ```python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted: ```python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ```python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$: $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls: ``((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``(a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ```ipython In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( _getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count umap ( self , oper : _UnaryOperatorT ) -> 'P' Shorthand for P(*(h.umap(oper) for h in self)) . See the H.umap method . Source code in dyce/p.py def umap ( self , oper : _UnaryOperatorT ) -> \"P\" : r \"\"\" Shorthand for ``P(*(h.umap(oper) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. \"\"\" return P ( * ( h . umap ( oper ) for h in self )) HAbleT A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users. h ( self ) -> H Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ... HAbleOpsMixin A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HAbleT protocol . The P class derives from this class. __add__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.add(self.h(), other) . See the h method . Source code in dyce/h.py def __add__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.add(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_add ( self . h (), other ) __and__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H special Shorthand for operator.and_(self.h(), other) . See the h method . Source code in dyce/h.py def __and__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H : r \"\"\" Shorthand for ``operator.and_(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_and ( self . h (), other ) __floordiv__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.floordiv(self.h(), other) . See the h method . Source code in dyce/h.py def __floordiv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.floordiv(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_floordiv ( self . h (), other ) __mod__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.mod(self.h(), other) . See the h method . Source code in dyce/h.py def __mod__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mod(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mod ( self . h (), other ) __mul__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.mul(self.h(), other) . See the h method . Source code in dyce/h.py def __mul__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mul(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mul ( self . h (), other ) __or__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H special Shorthand for operator.or_(self.h(), other) . See the h method . Source code in dyce/h.py def __or__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H : r \"\"\" Shorthand for ``operator.or_(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_or ( self . h (), other ) __pow__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.pow(self.h(), other) . See the h method . Source code in dyce/h.py def __pow__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.pow(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_pow ( self . h (), other ) __radd__ ( self : HAbleT , other : OutcomeP ) -> H special Shorthand for operator.add(other, self.h()) . See the h method . Source code in dyce/h.py def __radd__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.add(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_add ( other , self . h ()) __rand__ ( self : HAbleT , other : SupportsInt ) -> H special Shorthand for operator.and_(other, self.h()) . See the h method . Source code in dyce/h.py def __rand__ ( self : HAbleT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``operator.and_(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_and ( other , self . h ()) __rfloordiv__ ( self : HAbleT , other : OutcomeP ) -> H special Shorthand for operator.floordiv(other, self.h()) . See the h method . Source code in dyce/h.py def __rfloordiv__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.floordiv(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_floordiv ( other , self . h ()) __rmod__ ( self : HAbleT , other : OutcomeP ) -> H special Shorthand for operator.mod(other, self.h()) . See the h method . Source code in dyce/h.py def __rmod__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.mod(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mod ( other , self . h ()) __rmul__ ( self : HAbleT , other : OutcomeP ) -> H special Shorthand for operator.mul(other, self.h()) . See the h method . Source code in dyce/h.py def __rmul__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.mul(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mul ( other , self . h ()) __ror__ ( self : HAbleT , other : SupportsInt ) -> H special Shorthand for operator.or_(other, self.h()) . See the h method . Source code in dyce/h.py def __ror__ ( self : HAbleT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``operator.or_(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_or ( other , self . h ()) __rpow__ ( self : HAbleT , other : OutcomeP ) -> H special Shorthand for operator.pow(other, self.h()) . See the h method . Source code in dyce/h.py def __rpow__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.pow(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_pow ( other , self . h ()) __rsub__ ( self : HAbleT , other : OutcomeP ) -> H special Shorthand for operator.sub(other, self.h()) . See the h method . Source code in dyce/h.py def __rsub__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.sub(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_sub ( other , self . h ()) __rtruediv__ ( self : HAbleT , other : OutcomeP ) -> H special Shorthand for operator.truediv(other, self.h()) . See the h method . Source code in dyce/h.py def __rtruediv__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.truediv(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_truediv ( other , self . h ()) __rxor__ ( self : HAbleT , other : SupportsInt ) -> H special Shorthand for operator.xor(other, self.h()) . See the h method . Source code in dyce/h.py def __rxor__ ( self : HAbleT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``operator.xor(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_xor ( other , self . h ()) __sub__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.sub(self.h(), other) . See the h method . Source code in dyce/h.py def __sub__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.sub(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_sub ( self . h (), other ) __truediv__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.truediv(self.h(), other) . See the h method . Source code in dyce/h.py def __truediv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.truediv(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_truediv ( self . h (), other ) __xor__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H special Shorthand for operator.xor(self.h(), other) . See the h method . Source code in dyce/h.py def __xor__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H : r \"\"\" Shorthand for ``operator.xor(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_xor ( self . h (), other ) eq ( self : HAbleT , other : _OperandT ) -> H Shorthand for self.h().eq(other) . See the h method and H.eq . Source code in dyce/h.py def eq ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().eq(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other ) even ( self : HAbleT ) -> H Shorthand for self.h().even() . See the h method and H.even . Source code in dyce/h.py def even ( self : HAbleT ) -> H : r \"\"\" Shorthand for ``self.h().even()``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.even``][dyce.h.H.even]. \"\"\" return self . h () . even () explode ( self : HAbleT , max_depth : SupportsInt = 1 ) -> H Shorthand for self.h().explode(max_depth) . See the h method and H.explode . Source code in dyce/h.py def explode ( self : HAbleT , max_depth : SupportsInt = 1 ) -> H : r \"\"\" Shorthand for ``self.h().explode(max_depth)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth ) ge ( self : HAbleT , other : _OperandT ) -> H Shorthand for self.h().ge(other) . See the h method and H.ge . Source code in dyce/h.py def ge ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ge(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other ) gt ( self : HAbleT , other : _OperandT ) -> H Shorthand for self.h().gt(other) . See the h method and H.gt . Source code in dyce/h.py def gt ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().gt(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other ) le ( self : HAbleT , other : _OperandT ) -> H Shorthand for self.h().le(other) . See the h method and H.le . Source code in dyce/h.py def le ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().le(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other ) lt ( self : HAbleT , other : _OperandT ) -> H Shorthand for self.h().lt(other) . See the h method and H.lt . Source code in dyce/h.py def lt ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().lt(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other ) ne ( self : HAbleT , other : _OperandT ) -> H Shorthand for self.h().ne(other) . See the h method and H.ne . Source code in dyce/h.py def ne ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ne(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other ) odd ( self : HAbleT ) -> H Shorthand for self.h().odd() . See the h method and H.odd . Source code in dyce/h.py def odd ( self : HAbleT ) -> H : r \"\"\" Shorthand for ``self.h().odd()``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.odd``][dyce.h.H.odd]. \"\"\" return self . h () . odd () substitute ( self : HAbleT , expand : _ExpandT , coalesce : _CoalesceT = < function coalesce_replace at 0x10fd97a60 > , max_depth : SupportsInt = 1 ) -> H Shorthand for self.h().substitute(expand, coalesce, max_depth) . See the h method and H.substitute . Source code in dyce/h.py def substitute ( self : HAbleT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth ) within ( self : HAbleT , lo : OutcomeP , hi : OutcomeP , other : _OperandT = 0 ) -> H Shorthand for self.h().within(lo, hi, other) . See the h method and H.within . Source code in dyce/h.py def within ( self : HAbleT , lo : OutcomeP , hi : OutcomeP , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"<tt>dyce</tt>"},{"location":"dyce/#dyce-package-reference","text":"","title":"dyce package reference"},{"location":"dyce/#dyce","text":"dyce provides two core primitives: H for histograms (outcomes or individual dice) P for collections of histograms (pools)","title":"dyce"},{"location":"dyce/#dyce.h.H","text":"An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, it is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derives, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ): 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed: 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative): 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps: 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes: 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand: 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes: 1 2 >>> len ( 2 @d6 ) 11 The counts method can be used to compute the total number of combinations and each outcome\u2019s probability: 1 2 3 4 5 >>> from fractions import Fraction >>> total = sum (( 2 @d6 ) . counts ()) ; total 36 >>> [( outcome , Fraction ( count , total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ); d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [\u2026] : 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method : 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands: 1 2 >>> d6 . accumulate ( d6 ) == d6 . accumulate ( d6 ) . accumulate ( d6 ) True","title":"H"},{"location":"dyce/#dyce.h.H.__hash__","text":"Return hash(self). Source code in dyce/h.py def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ()))","title":"__hash__()"},{"location":"dyce/#dyce.h.H.__init__","text":"Initializer. Source code in dyce/h.py def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ OutcomeP ] = counter () if isinstance ( items , SupportsInt ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , OutcomeP ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HAbleT ): tmp . update ( items . h ()) elif isinstance ( items , ABCMapping ): tmp . update ( items ) elif isinstance ( items , ABCIterable ): # Items is either an Iterable[OutcomeP] or an Iterable[Tuple[OutcomeP, # SupportsInt]] (although this technically supports Iterable[Union[OutcomeP, # Tuple[OutcomeP, SupportsInt]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 }","title":"__init__()"},{"location":"dyce/#dyce.h.H.accumulate","text":"Accumulates counts: 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py def accumulate ( self , other : _SourceT ) -> \"H\" : r \"\"\" Accumulates counts: ```python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , ABCMapping ): other = other . items () elif not isinstance ( other , ABCIterable ): other = cast ( Iterable [ OutcomeP ], ( other ,)) return H ( chain ( self . items (), cast ( Iterable , other )))","title":"accumulate()"},{"location":"dyce/#dyce.h.H.counts","text":"More descriptive synonym for the values method . Source code in dyce/h.py def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . values ()","title":"counts()"},{"location":"dyce/#dyce.h.H.distribution","text":"Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: 1 2 3 4 5 >>> h = H (( 1 , 2 , 3 , 3 , 4 , 4 , 5 , 6 )) >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . ge ( 3 ) . distribution ()) [( False , Fraction ( 1 , 4 )), ( True , Fraction ( 3 , 4 ))] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes: 1 2 3 4 >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . distribution ( fill_items = { 0 : 0 , 7 : 0 })) [( 0 , Fraction ( 0 , 1 )), ( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 )), ( 7 , Fraction ( 0 , 1 ))] If provided, rational_t must be a callable that takes two int s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type: 1 2 3 4 5 6 7 8 9 10 >>> list ( h . distribution ( rational_t = lambda n , d : f \" { n } / { d } \" )) [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '2/8' ), ( 4 , '2/8' ), ( 5 , '1/8' ), ( 6 , '1/8' )] >>> import sympy >>> list ( h . distribution ( rational_t = sympy . Rational )) [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] >>> import sage.rings.rational # doctest: +SKIP >>> list ( h . distribution ( rational_t = lambda n , d : sage . rings . rational . Rational (( n , d )))) # doctest: +SKIP [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] Another way to accomplish something similar may be to leverage many number implementations\u2019 ability to convert from fractions.Fraction s (e.g., sage.rings.rational.Rational , sympy.core.numbers.Rational ): 1 2 3 4 5 6 7 >>> import sympy.abc >>> [( o , sympy . Rational ( c )) for o , c in ( h + sympy . abc . x ) . distribution ()] [( x + 1 , 1 / 8 ), ( x + 2 , 1 / 8 ), ( x + 3 , 1 / 4 ), ( x + 4 , 1 / 4 ), ( x + 5 , 1 / 8 ), ( x + 6 , 1 / 8 )] >>> import sage.rings.rational # doctest: +SKIP >>> [( o , sage . rings . rational . Rational ( c )) for o , c in h . distribution ()] # doctest: +SKIP [( 1 , 1 / 6 ), ( 2 , 1 / 6 ), ( 3 , 1 / 3 ), ( 4 , 1 / 3 ), ( 5 , 1 / 6 ), ( 6 , 1 / 6 )] Source code in dyce/h.py def distribution ( self , fill_items : _MappingT = None , # See <https://github.com/python/mypy/issues/10854> for context on all the # @overload work-around nonsense above rational_t : _RationalP [ _T ] = Fraction , ) -> Iterator [ Tuple [ OutcomeP , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: ```python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes: ```python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` If provided, *rational_t* must be a callable that takes two ``int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type: ```python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` Another way to accomplish something similar may be to leverage many number implementations\u2019 ability to convert from ``fractions.Fraction``s (e.g., [``sage.rings.rational.Rational``](https://doc.sagemath.org/html/en/reference/rings_standard/sage/rings/rational.html#sage.rings.rational.Rational), [``sympy.core.numbers.Rational``](https://docs.sympy.org/latest/modules/core.html#rational)): ```python >>> import sympy.abc >>> [(o, sympy.Rational(c)) for o, c in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] >>> import sage.rings.rational # doctest: +SKIP >>> [(o, sage.rings.rational.Rational(c)) for o, c in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) )","title":"distribution()"},{"location":"dyce/#dyce.h.H.distribution_xy","text":"Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method and ensures the values are float s: 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , Fraction ( 1 , 6 )), ( 2 , Fraction ( 1 , 6 )), ( 3 , Fraction ( 1 , 6 )), ( 4 , Fraction ( 1 , 6 )), ( 5 , Fraction ( 1 , 6 )), ( 6 , Fraction ( 1 , 6 ))] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py def distribution_xy ( self , fill_items : _MappingT = None , ) -> Tuple [ Tuple [ OutcomeP , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``float``s: ```python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" return cast ( Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]], tuple ( zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) ), )","title":"distribution_xy()"},{"location":"dyce/#dyce.h.H.eq","text":"Shorthand for self.map(operator.eq, other) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map method . Source code in dyce/h.py def eq ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.eq, other)``. ```python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_eq , other )","title":"eq()"},{"location":"dyce/#dyce.h.H.even","text":"Equivalent to self.umap(lambda outcome: outcome % 2 == 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py def even ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 == 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_even ( outcome : SupportsInt ) -> bool : return as_int ( outcome ) % 2 == 0 return self . umap ( is_even )","title":"even()"},{"location":"dyce/#dyce.h.H.exactly_k_times_in_n","text":"Experimental This method should be considered experimental and may disappear in future versions. Computes and returns the probability distribution where outcome appears exactly k times among n@self . 1 2 3 4 5 6 >>> H ( 6 ) . exactly_k_times_in_n ( outcome = 5 , n = 4 , k = 2 ) 150 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 2 , n = 3 , k = 3 ) 1 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 4 , n = 3 , k = 3 ) 8 Source code in dyce/h.py @experimental def exactly_k_times_in_n ( self , outcome : OutcomeP , n : SupportsInt , k : SupportsInt , ) -> int : \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``n@self``. ```python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) c_total = sum ( self . counts ()) return comb ( n , k ) * c_outcome ** k * ( c_total - c_outcome ) ** ( n - k )","title":"exactly_k_times_in_n()"},{"location":"dyce/#dyce.h.H.explode","text":"Shorthand for self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py def explode ( self , max_depth : SupportsInt = 1 ) -> \"H\" : r \"\"\" Shorthand for ``self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth)``. ```python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , op_add , max_depth , )","title":"explode()"},{"location":"dyce/#dyce.h.H.format","text":"Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( \" {:->65} \" . format ( \" 65 chars wide -->|\" )) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py def format ( self , fill_items : _MappingT = None , width : SupportsInt = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ```python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ```python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``True``, horizontal bars are scaled to *width*: ```python >>> h = (2@H(6)).ge(7) >>> print(\"{:->65}\".format(\" 65 chars wide -->|\")) ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : Union [ float , OutcomeP ] = float ( self . mean ()) except TypeError : mu = self . mean () if width <= 0 : def _parts (): yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 def lines (): yield f \"avg | { mu : 7.2f } \" try : std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except TypeError : pass outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( lines ())","title":"format()"},{"location":"dyce/#dyce.h.H.ge","text":"Shorthand for self.map(operator.ge, other) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map method . Source code in dyce/h.py def ge ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ge, other)``. ```python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ge , other )","title":"ge()"},{"location":"dyce/#dyce.h.H.gt","text":"Shorthand for self.map(operator.gt, other) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def gt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.gt, other)``. ```python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_gt , other )","title":"gt()"},{"location":"dyce/#dyce.h.H.items","text":"D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py def items ( self ) -> ItemsView [ OutcomeP , int ]: return cast ( ItemsView [ OutcomeP , int ], self . _h . items ())","title":"items()"},{"location":"dyce/#dyce.h.H.keys","text":"D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py def keys ( self ) -> KeysView [ OutcomeP ]: return cast ( KeysView [ OutcomeP ], self . _h . keys ())","title":"keys()"},{"location":"dyce/#dyce.h.H.le","text":"Shorthand for self.map(operator.le, other) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def le ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.le, other)``. ```python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_le , other )","title":"le()"},{"location":"dyce/#dyce.h.H.lowest_terms","text":"Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )); df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d6avg = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d6avg H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d6avg . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py def lowest_terms ( self ) -> \"H\" : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ```python >>> df = H((-1, -1, 0, 0, 1, 1)); df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ```python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return H ( self . _lowest_terms ())","title":"lowest_terms()"},{"location":"dyce/#dyce.h.H.lt","text":"Shorthand for self.map(operator.lt, other) : 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map method . Source code in dyce/h.py def lt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.lt, other)``: ```python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_lt , other )","title":"lt()"},{"location":"dyce/#dyce.h.H.map","text":"Applies oper to each outcome of the histogram paired with other . Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . add , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . add , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . mul , - 1 ) H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 . map ( operator . mul , - 1 ) == d6 * - 1 True 1 2 3 4 >>> d6 . map ( operator . gt , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . gt , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py def map ( self , oper : _BinaryOperatorT , other : _OperandT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram paired with *other*. Shorthands exist for many arithmetic operators and comparators. ```python >>> import operator >>> d6 = H(6) >>> d6.map(operator.add, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.add, d6) == d6 + d6 True ``` ```python >>> d6.map(operator.mul, -1) H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> d6.map(operator.mul, -1) == d6 * -1 True ``` ```python >>> d6.map(operator.gt, 3) H({False: 3, True: 3}) >>> d6.map(operator.gt, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( other , HAbleT ): other = other . h () if isinstance ( other , H ): return H (( oper ( s , o ), self [ s ] * other [ o ]) for s , o in product ( self , other )) else : return H (( oper ( outcome , other ), count ) for outcome , count in self . items ())","title":"map()"},{"location":"dyce/#dyce.h.H.mean","text":"Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py def mean ( self ) -> Union [ float , OutcomeP ]: \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 )","title":"mean()"},{"location":"dyce/#dyce.h.H.ne","text":"Shorthand for self.map(operator.ne, other) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map method . Source code in dyce/h.py def ne ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ne, other)``. ```python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ne , other )","title":"ne()"},{"location":"dyce/#dyce.h.H.odd","text":"Equivalent to self.umap(lambda outcome: outcome % 2 != 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py def odd ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 != 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_odd ( outcome : SupportsInt ) -> bool : return as_int ( outcome ) % 2 != 0 return self . umap ( is_odd )","title":"odd()"},{"location":"dyce/#dyce.h.H.order_stat_for_n_at_pos","text":"Experimental This method should be considered experimental and may disappear in future versions. Shorthand for self.order_stat_func_for_n(n)(pos) . Source code in dyce/h.py @experimental def order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> \"H\" : \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Shorthand for ``self.order_stat_func_for_n(n)(pos)``. \"\"\" return self . order_stat_func_for_n ( n )( pos )","title":"order_stat_for_n_at_pos()"},{"location":"dyce/#dyce.h.H.order_stat_func_for_n","text":"Experimental This method should be considered experimental and may disappear in future versions. Returns a function that takes a single argument ( pos ) and computes the probability distribution for each outcome appearing in that position among n@self . 1 2 3 4 >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> order_stat_for_5d6avg = d6avg . order_stat_func_for_n ( 5 ) >>> order_stat_for_5d6avg ( 3 ) # counts where outcome appears at index 3 H ({ 2 : 26 , 3 : 1432 , 4 : 4792 , 5 : 1526 }) The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where 2 appears at the fourth (index 3 ) position, 1432 ways where 3 appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria: 1 2 3 4 >>> from dyce import P >>> p_5d6avg = 5 @P ( d6avg ) >>> sum ( count for roll , count in p_5d6avg . rolls_with_counts () if roll [ 3 ] == 5 ) 1526 This method exists in addition to the H.order_stat_for_n_at_pos method because computing the betas for each outcome in n is unnecessary for each pos . Where different pos values are needed for the same n (e.g., in a loop) and where n is large, that overhead can be significant. The returned function caches those betas for n such that repeated querying or results at pos can be computed much faster: 1 2 3 4 5 6 7 In [ 2 ]: % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 100 , i ) for i in range ( 10 )] 1.61 s \u00b1 31.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 3 ]: %% timeit ... : order_stat_for_100d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 100 ) ... : [ order_stat_for_100d6_at_pos ( i ) for i in range ( 10 )] 170 ms \u00b1 3.41 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Source code in dyce/h.py @experimental def order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], \"H\" ]: \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``n@self``. ```python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``2`` appears at the fourth (index ``3``) position, 1432 ways where ``3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria: ```python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster: ```python In [2]: %timeit [H(6).order_stat_for_n_at_pos(100, i) for i in range(10)] 1.61 s \u00b1 31.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [3]: %%timeit ...: order_stat_for_100d6_at_pos = H(6).order_stat_func_for_n(100) ...: [order_stat_for_100d6_at_pos(i) for i in range(10)] 170 ms \u00b1 3.41 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) ``` \"\"\" betas_by_outcome : Dict [ OutcomeP , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ OutcomeP , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) def order_stat_for_n_at_pos ( pos : SupportsInt ) -> H : return H ( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos","title":"order_stat_func_for_n()"},{"location":"dyce/#dyce.h.H.outcomes","text":"More descriptive synonym for the keys method . Source code in dyce/h.py def outcomes ( self ) -> KeysView [ OutcomeP ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . keys ()","title":"outcomes()"},{"location":"dyce/#dyce.h.H.roll","text":"Returns a (weighted) random outcome, sorted. On ordering This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. Source code in dyce/h.py def roll ( self ) -> OutcomeP : r \"\"\" Returns a (weighted) random outcome, sorted. !!! tip \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" if not self : return 0 return choices ( * self . distribution_xy ())[ 0 ]","title":"roll()"},{"location":"dyce/#dyce.h.H.stdev","text":"Shorthand for math.sqrt(self.variance(mu)) . Source code in dyce/h.py def stdev ( self , mu : Union [ float , OutcomeP ] = None ) -> Union [ float , OutcomeP ]: \"\"\" Shorthand for ``math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu ))","title":"stdev()"},{"location":"dyce/#dyce.h.H.substitute","text":"Calls expand on each outcome, recursively up to max_depth times. If expand returns a number, it replaces the outcome. If it returns an H object , coalesce is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the lowest_terms method .) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: 1 2 3 4 5 6 7 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , outcome : - h if outcome == 4 else outcome ) ; sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( count for outcome , count in orig . items () if outcome == 4 ) / sum ( orig . counts ()) 0.4 >>> sum ( count for outcome , count in sub . items () if outcome < 0 ) / sum ( sub . counts ()) 0.4 An important exception If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: 1 2 >>> H ( 6 ) . substitute ( lambda h , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda h , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . add , max_depth = 6 ) >>> h_even = h . even () >>> print ( \" {:.3%} \" . format ( h_even [ 1 ] / sum ( h_even . counts ()))) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | Source code in dyce/h.py def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , ) -> \"H\" : r \"\"\" Calls *expand* on each outcome, recursively up to *max_depth* times. If *expand* returns a number, it replaces the outcome. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the [``lowest_terms`` method][dyce.h.H.lowest_terms].) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ```python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: ```python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, outcome: -h if outcome == 4 else outcome) ; sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(count for outcome, count in orig.items() if outcome == 4) / sum(orig.counts()) 0.4 >>> sum(count for outcome, count in sub.items() if outcome < 0) / sum(sub.counts()) 0.4 ``` !!! tip \"An important exception\" If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: ```python >>> H(6).substitute(lambda h, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda h, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ```python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.add, max_depth=6) >>> h_even = h.even() >>> print(\"{:.3%}\".format(h_even[1] / sum(h_even.counts()))) 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: ```python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=65, scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` \"\"\" max_depth = as_int ( max_depth ) def _substitute ( h : H , depth : int = 0 ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ OutcomeP , int , int ]] = [] for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , outcome ) # Account for the impact of expansion on peers expanded_scalar = sum ( expanded . counts ()) if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) else : items_for_reassembly . append (( expanded , count , 1 )) return H ( ( # Apply the total_scalar, but factor out this item's contribution ( outcome , count * total_scalar // s ) for outcome , count , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self )","title":"substitute()"},{"location":"dyce/#dyce.h.H.umap","text":"Applies oper to each outcome of the histogram: 1 2 >>> H ( 6 ) . umap ( lambda outcome : outcome * - 1 ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py def umap ( self , oper : _UnaryOperatorT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram: ```python >>> H(6).umap(lambda outcome: outcome * -1) H(-6) ``` ```python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = H (( oper ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : h_simple = H ( oper ( self . _simple_init )) if h_simple == h : return h_simple return h","title":"umap()"},{"location":"dyce/#dyce.h.H.values","text":"D.values() -> an object providing a view on D's values Source code in dyce/h.py def values ( self ) -> ValuesView [ int ]: return self . _h . values ()","title":"values()"},{"location":"dyce/#dyce.h.H.variance","text":"Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py def variance ( self , mu : Union [ float , OutcomeP ] = None ) -> Union [ float , OutcomeP ]: \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 )","title":"variance()"},{"location":"dyce/#dyce.h.H.vs","text":"Compares this histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self.within(0, 0, other) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py def vs ( self , other : _OperandT ) -> \"H\" : r \"\"\" Compares this histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``self.within(0, 0, other)``. ```python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other )","title":"vs()"},{"location":"dyce/#dyce.h.H.within","text":"Computes the difference between this histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py def within ( self , lo : OutcomeP , hi : OutcomeP , other : _OperandT = 0 ) -> \"H\" : r \"\"\" Computes the difference between this histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ```python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other )","title":"within()"},{"location":"dyce/#dyce.p.P","text":"An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). This class implements the HAbleT protocol and derives from the HAbleOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using binary arithmetic operations. Note that this class also provides its own @ and unary operator implementations that result in new P objects, not flattened histograms. 1 2 3 4 5 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) >>> - p_d6 P ( - 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True Arithmetic operators involving a number or another P object produce an H object : 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) Comparisons with H objects work as expected: 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram: 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering: 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HAbleT protocol , the P.h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ###","title":"P"},{"location":"dyce/#dyce.p.P.__init__","text":"Initializer. Source code in dyce/p.py def __init__ ( self , * args : Union [ SupportsInt , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs (): for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h else : yield H ( as_int ( a )) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs ) self . _homogeneous = len ( set ( self . _hs )) <= 1","title":"__init__()"},{"location":"dyce/#dyce.p.P.appearances_in_rolls","text":"Experimental This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being almost twice (about \\(\\frac{7}{4}\\) ) as efficient as the boolean accumulation technique for larger sets: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 In [ 3 ]: % timeit 3 @d4_eq3 + 2 @d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 4 ]: % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 402 \u00b5s \u00b1 5.59 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 5 ]: % timeit 9 @d4_eq3 + 6 @d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 6 ]: % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 597 \u00b5s \u00b1 9.46 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 7 ]: % timeit 90 @d4_eq3 + 60 @d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 8 ]: % timeit P ( 90 @P ( 4 ), 60 @P ( 6 )) . appearances_in_rolls ( 3 ) 7.5 ms \u00b1 84.6 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) In [ 9 ]: % timeit 900 @d4_eq3 + 600 @d6_eq3 3.34 s \u00b1 19.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 10 ]: % timeit P ( 900 @P ( 4 ), 600 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.93 s \u00b1 14.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py @experimental def appearances_in_rolls ( self , outcome : OutcomeP ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ```python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ```python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being almost twice (about $\\frac{7}{4}$) as efficient as the boolean accumulation technique for larger sets: ```python In [3]: %timeit 3@d4_eq3 + 2@d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [4]: %timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3) 402 \u00b5s \u00b1 5.59 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [5]: %timeit 9@d4_eq3 + 6@d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [6]: %timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3) 597 \u00b5s \u00b1 9.46 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [7]: %timeit 90@d4_eq3 + 60@d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [8]: %timeit P(90@P(4), 60@P(6)).appearances_in_rolls(3) 7.5 ms \u00b1 84.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) In [9]: %timeit 900@d4_eq3 + 600@d6_eq3 3.34 s \u00b1 19.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [10]: %timeit P(900@P(4), 600@P(6)).appearances_in_rolls(3) 1.93 s \u00b1 14.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" group_counters : List [ Counter [ OutcomeP ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ OutcomeP ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum (( H ( group_counter ) for group_counter in group_counters ), start = H ({}))","title":"appearances_in_rolls()"},{"location":"dyce/#dyce.p.P.h","text":"Roughly equivalent to H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) ) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HAbleT protocol : 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( width = 65 , scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d6avg + d6avg True Source code in dyce/p.py def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) )`` with some short-circuit optimizations. When provided no arguments, ``h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HAbleT`` protocol][dyce.h.HAbleT]: ```python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ```python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ```python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(width=65, scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ```python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum ( self , start = H ({}))","title":"h()"},{"location":"dyce/#dyce.p.P.roll","text":"Returns (weighted) random outcomes from contained histograms. Source code in dyce/p.py def roll ( self ) -> _RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self ))","title":"roll()"},{"location":"dyce/#dyce.p.P.rolls_with_counts","text":"Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, (1, 2) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d6avg + d6avg True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable: 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted: 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) : \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n@P(H(m)) . Enumerating combinations with replacements would yield all unique rolls: ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m)) To determine the count for a particular roll (a, b, \u2026, n) , we compute the multinomial coefficient for that roll and multiply by the scalar H(m)[a] * H(m)[b] * \u2026 * H(m)[n] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 In [ 1 ]: from dyce import H , P In [ 2 ]: for n in ( 6 , 8 ): ... : p = n @P ( 6 ) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 1.35 ms \u00b1 23.4 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 3.15 ms \u00b1 516 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.37 ms \u00b1 182 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 10.5 ms \u00b1 1.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.58 ms \u00b1 25.3 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 9.81 ms \u00b1 171 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 14.7 ms \u00b1 430 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 20.4 ms \u00b1 328 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 3 ]: for n in ( 3 , 4 ): ... : p = P ( n @P ( 6 ), * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 2 )): 16.1 ms \u00b1 1.09 ms per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 3 )): 39 ms \u00b1 602 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 4 )): 40.3 ms \u00b1 3.49 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 5 )): 46.2 ms \u00b1 7.43 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 538 ms \u00b1 9.46 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 534 ms \u00b1 30.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 536 ms \u00b1 13.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 604 ms \u00b1 52.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 4 ]: for n in ( 6 , 8 ): ... : p = P ( * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 2 )): 145 ms \u00b1 4.59 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 3 )): 147 ms \u00b1 3.6 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 158 ms \u00b1 1.38 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 147 ms \u00b1 691 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 6.09 s \u00b1 14.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 6.11 s \u00b1 36.9 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 6 )): 6.25 s \u00b1 47.5 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 7 )): 6.31 s \u00b1 42.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed for more flexible selections: ```python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: ```python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ```python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``(1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ```python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity: ```python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: ```python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable: ```python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted: ```python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ```python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$: $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls: ``((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``(a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ```ipython In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( _getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count","title":"rolls_with_counts()"},{"location":"dyce/#dyce.p.P.umap","text":"Shorthand for P(*(h.umap(oper) for h in self)) . See the H.umap method . Source code in dyce/p.py def umap ( self , oper : _UnaryOperatorT ) -> \"P\" : r \"\"\" Shorthand for ``P(*(h.umap(oper) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. \"\"\" return P ( * ( h . umap ( oper ) for h in self ))","title":"umap()"},{"location":"dyce/#dyce.h.HAbleT","text":"A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users.","title":"HAbleT"},{"location":"dyce/#dyce.h.HAbleT.h","text":"Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ...","title":"h()"},{"location":"dyce/#dyce.h.HAbleOpsMixin","text":"A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HAbleT protocol . The P class derives from this class.","title":"HAbleOpsMixin"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__add__","text":"Shorthand for operator.add(self.h(), other) . See the h method . Source code in dyce/h.py def __add__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.add(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_add ( self . h (), other )","title":"__add__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__and__","text":"Shorthand for operator.and_(self.h(), other) . See the h method . Source code in dyce/h.py def __and__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H : r \"\"\" Shorthand for ``operator.and_(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_and ( self . h (), other )","title":"__and__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__floordiv__","text":"Shorthand for operator.floordiv(self.h(), other) . See the h method . Source code in dyce/h.py def __floordiv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.floordiv(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_floordiv ( self . h (), other )","title":"__floordiv__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__mod__","text":"Shorthand for operator.mod(self.h(), other) . See the h method . Source code in dyce/h.py def __mod__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mod(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mod ( self . h (), other )","title":"__mod__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__mul__","text":"Shorthand for operator.mul(self.h(), other) . See the h method . Source code in dyce/h.py def __mul__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mul(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mul ( self . h (), other )","title":"__mul__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__or__","text":"Shorthand for operator.or_(self.h(), other) . See the h method . Source code in dyce/h.py def __or__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H : r \"\"\" Shorthand for ``operator.or_(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_or ( self . h (), other )","title":"__or__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__pow__","text":"Shorthand for operator.pow(self.h(), other) . See the h method . Source code in dyce/h.py def __pow__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.pow(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_pow ( self . h (), other )","title":"__pow__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__radd__","text":"Shorthand for operator.add(other, self.h()) . See the h method . Source code in dyce/h.py def __radd__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.add(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_add ( other , self . h ())","title":"__radd__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rand__","text":"Shorthand for operator.and_(other, self.h()) . See the h method . Source code in dyce/h.py def __rand__ ( self : HAbleT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``operator.and_(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_and ( other , self . h ())","title":"__rand__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rfloordiv__","text":"Shorthand for operator.floordiv(other, self.h()) . See the h method . Source code in dyce/h.py def __rfloordiv__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.floordiv(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_floordiv ( other , self . h ())","title":"__rfloordiv__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rmod__","text":"Shorthand for operator.mod(other, self.h()) . See the h method . Source code in dyce/h.py def __rmod__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.mod(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mod ( other , self . h ())","title":"__rmod__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rmul__","text":"Shorthand for operator.mul(other, self.h()) . See the h method . Source code in dyce/h.py def __rmul__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.mul(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_mul ( other , self . h ())","title":"__rmul__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__ror__","text":"Shorthand for operator.or_(other, self.h()) . See the h method . Source code in dyce/h.py def __ror__ ( self : HAbleT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``operator.or_(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_or ( other , self . h ())","title":"__ror__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rpow__","text":"Shorthand for operator.pow(other, self.h()) . See the h method . Source code in dyce/h.py def __rpow__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.pow(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_pow ( other , self . h ())","title":"__rpow__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rsub__","text":"Shorthand for operator.sub(other, self.h()) . See the h method . Source code in dyce/h.py def __rsub__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.sub(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_sub ( other , self . h ())","title":"__rsub__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rtruediv__","text":"Shorthand for operator.truediv(other, self.h()) . See the h method . Source code in dyce/h.py def __rtruediv__ ( self : HAbleT , other : OutcomeP ) -> H : r \"\"\" Shorthand for ``operator.truediv(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_truediv ( other , self . h ())","title":"__rtruediv__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__rxor__","text":"Shorthand for operator.xor(other, self.h()) . See the h method . Source code in dyce/h.py def __rxor__ ( self : HAbleT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``operator.xor(other, self.h())``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_xor ( other , self . h ())","title":"__rxor__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__sub__","text":"Shorthand for operator.sub(self.h(), other) . See the h method . Source code in dyce/h.py def __sub__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.sub(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_sub ( self . h (), other )","title":"__sub__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__truediv__","text":"Shorthand for operator.truediv(self.h(), other) . See the h method . Source code in dyce/h.py def __truediv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.truediv(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_truediv ( self . h (), other )","title":"__truediv__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.__xor__","text":"Shorthand for operator.xor(self.h(), other) . See the h method . Source code in dyce/h.py def __xor__ ( self : HAbleT , other : Union [ SupportsInt , H , HAbleT ]) -> H : r \"\"\" Shorthand for ``operator.xor(self.h(), other)``. See the [``h`` method][dyce.h.HAbleT.h]. \"\"\" return op_xor ( self . h (), other )","title":"__xor__()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.eq","text":"Shorthand for self.h().eq(other) . See the h method and H.eq . Source code in dyce/h.py def eq ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().eq(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other )","title":"eq()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.even","text":"Shorthand for self.h().even() . See the h method and H.even . Source code in dyce/h.py def even ( self : HAbleT ) -> H : r \"\"\" Shorthand for ``self.h().even()``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.even``][dyce.h.H.even]. \"\"\" return self . h () . even ()","title":"even()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.explode","text":"Shorthand for self.h().explode(max_depth) . See the h method and H.explode . Source code in dyce/h.py def explode ( self : HAbleT , max_depth : SupportsInt = 1 ) -> H : r \"\"\" Shorthand for ``self.h().explode(max_depth)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth )","title":"explode()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.ge","text":"Shorthand for self.h().ge(other) . See the h method and H.ge . Source code in dyce/h.py def ge ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ge(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other )","title":"ge()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.gt","text":"Shorthand for self.h().gt(other) . See the h method and H.gt . Source code in dyce/h.py def gt ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().gt(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other )","title":"gt()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.le","text":"Shorthand for self.h().le(other) . See the h method and H.le . Source code in dyce/h.py def le ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().le(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other )","title":"le()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.lt","text":"Shorthand for self.h().lt(other) . See the h method and H.lt . Source code in dyce/h.py def lt ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().lt(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other )","title":"lt()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.ne","text":"Shorthand for self.h().ne(other) . See the h method and H.ne . Source code in dyce/h.py def ne ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ne(other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other )","title":"ne()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.odd","text":"Shorthand for self.h().odd() . See the h method and H.odd . Source code in dyce/h.py def odd ( self : HAbleT ) -> H : r \"\"\" Shorthand for ``self.h().odd()``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.odd``][dyce.h.H.odd]. \"\"\" return self . h () . odd ()","title":"odd()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.substitute","text":"Shorthand for self.h().substitute(expand, coalesce, max_depth) . See the h method and H.substitute . Source code in dyce/h.py def substitute ( self : HAbleT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth )","title":"substitute()"},{"location":"dyce/#dyce.h.HAbleOpsMixin.within","text":"Shorthand for self.h().within(lo, hi, other) . See the h method and H.within . Source code in dyce/h.py def within ( self : HAbleT , lo : OutcomeP , hi : OutcomeP , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HAbleT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"within()"},{"location":"dyce.plt/","text":"dyce.plt package reference Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Suggestions and contributions are welcome. plt display_burst ( ax : AxesT , h_inner : H , outer : Union [ H , Iterable [ LabelT ]] = None , desc : str = None , inner_color : str = 'RdYlGn_r' , outer_color : str = None , text_color : str = 'black' , alpha : float = 0.5 ) -> None Experimental This method should be considered experimental and may disappear in future versions. Creates a dual, overlapping, cocentric pie chart in ax , which can be useful for visualizing relative probability distributions. See the visualization tutorial for examples. Source code in dyce/plt.py @experimental def display_burst ( ax : AxesT , h_inner : H , outer : Union [ H , Iterable [ LabelT ]] = None , desc : str = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : str = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Creates a dual, overlapping, cocentric pie chart in *ax*, which can be useful for visualizing relative probability distributions. See the [visualization tutorial](tutorial.md#visualization) for examples. \"\"\" assert matplotlib inner_colors = graph_colors ( inner_color , h_inner , alpha ) if outer is None : outer = ( ( \" {:.2%} \" . format ( float ( v )) if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . distribution () ) elif isinstance ( outer , H ): outer = (( str ( o ), c ) for o , c in outer . distribution ()) outer_labels , outer_values = list ( zip ( * outer )) outer_colors = graph_colors ( inner_color if outer_color is None else outer_color , outer_values , alpha , ) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.0 , labeldistance = 1.1 , startangle = 90 , colors = outer_colors , wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 0.9 , labeldistance = 0.8 , startangle = 90 , colors = inner_colors , textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.6 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" ) labels_cumulative ( h : H ) -> Iterator [ LabelT ] Experimental This method should be considered experimental and may disappear in future versions. Enumerates label, probability pairs for each outcome in h where each label contains several percentages. This can be useful for passing as the outer value to either display_burst or plot_burst . Source code in dyce/plt.py @experimental def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Enumerates label, probability pairs for each outcome in *h* where each label contains several percentages. This can be useful for passing as the *outer* value to either [``display_burst``][dyce.plt.display_burst] or [``plot_burst``][dyce.plt.plot_burst]. \"\"\" le_total , ge_total = 0.0 , 1.0 for outcome , probability in h . distribution (): le_total += probability label = \" {} {:.2%} ; \u2265 {:.2%} ; \u2264 {:.2%} \" . format ( outcome , float ( probability ), le_total , ge_total ) ge_total -= probability yield ( label , probability ) plot_burst ( h_inner : H , outer : Union [ H , Iterable [ LabelT ]] = None , desc : str = None , inner_color : str = 'RdYlGn_r' , outer_color : str = None , text_color : str = 'black' , alpha : float = 0.5 ) -> Tuple [ FigureT , AxesT ] Experimental This method should be considered experimental and may disappear in future versions. Wrapper around display_burst that creates a figure, axis pair and calls matplotlib.pyplot.tight_layout on the result. Source code in dyce/plt.py @experimental def plot_burst ( h_inner : H , outer : Union [ H , Iterable [ LabelT ]] = None , desc : str = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : str = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ FigureT , AxesT ]: \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Wrapper around [``display_burst``][dyce.plt.display_burst] that creates a figure, axis pair and calls [``matplotlib.pyplot.tight_layout``](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tight_layout.html) on the result. \"\"\" assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , inner_color , outer_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"<tt>dyce.plt</tt>"},{"location":"dyce.plt/#dyceplt-package-reference","text":"Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Suggestions and contributions are welcome.","title":"dyce.plt package reference"},{"location":"dyce.plt/#dyce.plt","text":"","title":"plt"},{"location":"dyce.plt/#dyce.plt.display_burst","text":"Experimental This method should be considered experimental and may disappear in future versions. Creates a dual, overlapping, cocentric pie chart in ax , which can be useful for visualizing relative probability distributions. See the visualization tutorial for examples. Source code in dyce/plt.py @experimental def display_burst ( ax : AxesT , h_inner : H , outer : Union [ H , Iterable [ LabelT ]] = None , desc : str = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : str = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Creates a dual, overlapping, cocentric pie chart in *ax*, which can be useful for visualizing relative probability distributions. See the [visualization tutorial](tutorial.md#visualization) for examples. \"\"\" assert matplotlib inner_colors = graph_colors ( inner_color , h_inner , alpha ) if outer is None : outer = ( ( \" {:.2%} \" . format ( float ( v )) if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . distribution () ) elif isinstance ( outer , H ): outer = (( str ( o ), c ) for o , c in outer . distribution ()) outer_labels , outer_values = list ( zip ( * outer )) outer_colors = graph_colors ( inner_color if outer_color is None else outer_color , outer_values , alpha , ) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.0 , labeldistance = 1.1 , startangle = 90 , colors = outer_colors , wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 0.9 , labeldistance = 0.8 , startangle = 90 , colors = inner_colors , textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.6 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" )","title":"display_burst()"},{"location":"dyce.plt/#dyce.plt.labels_cumulative","text":"Experimental This method should be considered experimental and may disappear in future versions. Enumerates label, probability pairs for each outcome in h where each label contains several percentages. This can be useful for passing as the outer value to either display_burst or plot_burst . Source code in dyce/plt.py @experimental def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Enumerates label, probability pairs for each outcome in *h* where each label contains several percentages. This can be useful for passing as the *outer* value to either [``display_burst``][dyce.plt.display_burst] or [``plot_burst``][dyce.plt.plot_burst]. \"\"\" le_total , ge_total = 0.0 , 1.0 for outcome , probability in h . distribution (): le_total += probability label = \" {} {:.2%} ; \u2265 {:.2%} ; \u2264 {:.2%} \" . format ( outcome , float ( probability ), le_total , ge_total ) ge_total -= probability yield ( label , probability )","title":"labels_cumulative()"},{"location":"dyce.plt/#dyce.plt.plot_burst","text":"Experimental This method should be considered experimental and may disappear in future versions. Wrapper around display_burst that creates a figure, axis pair and calls matplotlib.pyplot.tight_layout on the result. Source code in dyce/plt.py @experimental def plot_burst ( h_inner : H , outer : Union [ H , Iterable [ LabelT ]] = None , desc : str = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : str = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ FigureT , AxesT ]: \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. Wrapper around [``display_burst``][dyce.plt.display_burst] that creates a figure, axis pair and calls [``matplotlib.pyplot.tight_layout``](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tight_layout.html) on the result. \"\"\" assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , inner_color , outer_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"plot_burst()"},{"location":"license/","text":"License & credits The MIT License (MIT) Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contributors The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub - @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"License"},{"location":"license/#license-credits","text":"","title":"License &amp; credits"},{"location":"license/#the-mit-license-mit","text":"Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"license/#contributors","text":"The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub - @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"Contributors"},{"location":"translations/","text":"The following examples and translations are intended to showcase dyce \u2019s flexibility. If you have exposure to another tool , they may also help with transition. Modeling \u201c The Probability of 4d6, Drop the Lowest, Reroll 1s \u201d 1 2 3 4 5 6 7 8 >>> from dyce import H , P >>> p_4d6 = 4 @P ( 6 ) >>> res1 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : H ( 6 ) if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res2 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H ( range ( 2 , 7 ))) >>> res3 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res1 . distribution_xy (), ... marker = \".\" , ... label = \"Discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res2 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll first 1; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res3 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll all 1s; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Comparing various take-three-of-4d6 methods\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translating one example from markbrockettrobson/python_dice Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: 1 2 3 4 5 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = damage_half_on_save . distribution_xy () >>> matplotlib . pyplot . plot ( outcomes , probabilities , marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Expected outcomes for attack with saving throw for half damage\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP An alternative using the H.substitute method : 1 2 3 4 5 6 >>> save_roll . substitute ( ... lambda h , outcome : ... burning_arch_damage // 2 if outcome >= 10 ... else burning_arch_damage ... ) == damage_half_on_save True More translations from markbrockettrobson/python_dice 1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_ = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_ . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> _ = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( _ . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> _ = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( _ . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % } Translations from LordSembor/DnDice Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { ... , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { ... , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> import matplotlib # doctest: +SKIP >>> from dyce.plt import display_burst >>> plot_ax = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 0 )) # doctest: +SKIP >>> burst_ax = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 1 )) # doctest: +SKIP >>> sa_label = \"Normal attack\" >>> plot_ax . plot ( ... * single_attack . distribution_xy (), ... color = \"tab:green\" , ... label = sa_label , ... marker = \".\" , ... ) # doctest: +SKIP >>> gwf_label = \"\u201cGreat Weapon Fighting\u201d\" >>> plot_ax . plot ( ... * great_weapon_fighting . distribution_xy (), ... color = \"tab:blue\" , ... label = gwf_label , ... marker = \".\" , ... ) # doctest: +SKIP >>> plot_ax . legend () # doctest: +SKIP >>> plot_ax . set_title ( r \"Comparing a normal attack to an enhanced one\" ) # doctest: +SKIP >>> display_burst ( ... burst_ax , ... h_inner = great_weapon_fighting , ... outer = single_attack , ... desc = f \" { sa_label } vs. { gwf_label } \" , ... inner_color = \"RdYlBu_r\" , ... outer_color = \"RdYlGn_r\" , ... alpha = 0.9 , ... ) # doctest: +SKIP >>> matplotlib . pyplot . tight_layout () # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( _ : H , outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = advantage . substitute ( crit ) Example 2 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * normal_hit . distribution_xy (), ... marker = \".\" , ... label = \"Normal hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * critical_hit . distribution_xy (), ... marker = \".\" , ... label = \"Critical hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * advantage_weighted . distribution_xy (), ... marker = \".\" , ... label = \"Advantage-weighted\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling an advantage-weighted attack with critical hits\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c Roll and Keep in Anydice? \u201d Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: 1 2 3 4 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( * res . distribution_xy (), marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling taking the three highest of ten exploding d10s\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c How do I count the number of duplicates in anydice? \u201d Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 >>> def dupes ( p : P ): ... for roll , count in p . rolls_with_counts (): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... # Outcomes are ordered, so we only have to look at one neighbor ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... yield dupes , count >>> res = H ( dupes ( 8 @P ( 10 ))) Visualization: 1 2 3 4 5 6 7 >>> from dyce.plt import plot_burst >>> plot_burst ( ... res , ... desc = r \"Chances of rolling $n$ duplicates in 8d10\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . tight_layout () # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c Modelling [sic] opposed dice pools with a swap \u201d: Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 >>> from itertools import product >>> def brawl ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... yield a_successes - b_successes , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 >>> res = H ( brawl ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> def brawl_w_optional_swap ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... yield result , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> res = H ( brawl_w_optional_swap ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = H ( brawl_w_optional_swap ( 4 @P ( 6 ), 4 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Applications & translations"},{"location":"translations/#modeling-the-probability-of-4d6-drop-the-lowest-reroll-1s","text":"1 2 3 4 5 6 7 8 >>> from dyce import H , P >>> p_4d6 = 4 @P ( 6 ) >>> res1 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : H ( 6 ) if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res2 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H ( range ( 2 , 7 ))) >>> res3 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res1 . distribution_xy (), ... marker = \".\" , ... label = \"Discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res2 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll first 1; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res3 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll all 1s; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Comparing various take-three-of-4d6 methods\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Modeling \u201cThe Probability of 4d6, Drop the Lowest, Reroll 1s\u201d"},{"location":"translations/#translating-one-example-from-markbrockettrobsonpython_dice","text":"Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: 1 2 3 4 5 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = damage_half_on_save . distribution_xy () >>> matplotlib . pyplot . plot ( outcomes , probabilities , marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Expected outcomes for attack with saving throw for half damage\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP An alternative using the H.substitute method : 1 2 3 4 5 6 >>> save_roll . substitute ( ... lambda h , outcome : ... burning_arch_damage // 2 if outcome >= 10 ... else burning_arch_damage ... ) == damage_half_on_save True","title":"Translating one example from markbrockettrobson/python_dice"},{"location":"translations/#more-translations-from-markbrockettrobsonpython_dice","text":"1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_ = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_ . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> _ = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( _ . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> _ = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( _ . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % }","title":"More translations from markbrockettrobson/python_dice"},{"location":"translations/#translations-from-lordsembordndice","text":"Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { ... , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { ... , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> import matplotlib # doctest: +SKIP >>> from dyce.plt import display_burst >>> plot_ax = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 0 )) # doctest: +SKIP >>> burst_ax = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 1 )) # doctest: +SKIP >>> sa_label = \"Normal attack\" >>> plot_ax . plot ( ... * single_attack . distribution_xy (), ... color = \"tab:green\" , ... label = sa_label , ... marker = \".\" , ... ) # doctest: +SKIP >>> gwf_label = \"\u201cGreat Weapon Fighting\u201d\" >>> plot_ax . plot ( ... * great_weapon_fighting . distribution_xy (), ... color = \"tab:blue\" , ... label = gwf_label , ... marker = \".\" , ... ) # doctest: +SKIP >>> plot_ax . legend () # doctest: +SKIP >>> plot_ax . set_title ( r \"Comparing a normal attack to an enhanced one\" ) # doctest: +SKIP >>> display_burst ( ... burst_ax , ... h_inner = great_weapon_fighting , ... outer = single_attack , ... desc = f \" { sa_label } vs. { gwf_label } \" , ... inner_color = \"RdYlBu_r\" , ... outer_color = \"RdYlGn_r\" , ... alpha = 0.9 , ... ) # doctest: +SKIP >>> matplotlib . pyplot . tight_layout () # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( _ : H , outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = advantage . substitute ( crit ) Example 2 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * normal_hit . distribution_xy (), ... marker = \".\" , ... label = \"Normal hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * critical_hit . distribution_xy (), ... marker = \".\" , ... label = \"Critical hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * advantage_weighted . distribution_xy (), ... marker = \".\" , ... label = \"Advantage-weighted\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling an advantage-weighted attack with critical hits\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translations from LordSembor/DnDice"},{"location":"translations/#translation-of-the-accepted-answer-to-roll-and-keep-in-anydice","text":"Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: 1 2 3 4 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( * res . distribution_xy (), marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling taking the three highest of ten exploding d10s\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translation of the accepted answer to \u201cRoll and Keep in Anydice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-how-do-i-count-the-number-of-duplicates-in-anydice","text":"Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 >>> def dupes ( p : P ): ... for roll , count in p . rolls_with_counts (): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... # Outcomes are ordered, so we only have to look at one neighbor ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... yield dupes , count >>> res = H ( dupes ( 8 @P ( 10 ))) Visualization: 1 2 3 4 5 6 7 >>> from dyce.plt import plot_burst >>> plot_burst ( ... res , ... desc = r \"Chances of rolling $n$ duplicates in 8d10\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . tight_layout () # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translation of the accepted answer to \u201cHow do I count the number of duplicates in anydice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-modelling-sic-opposed-dice-pools-with-a-swap","text":"Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 >>> from itertools import product >>> def brawl ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... yield a_successes - b_successes , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 >>> res = H ( brawl ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> def brawl_w_optional_swap ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... yield result , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> res = H ( brawl_w_optional_swap ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = H ( brawl_w_optional_swap ( 4 @P ( 6 ), 4 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Translation of the accepted answer to \u201cModelling [sic] opposed dice pools with a swap\u201d:"},{"location":"tutorial/","text":"Basic examples dyce provides two key primitives: 1 >>> from dyce import H , P H objects represent histograms for modeling discrete outcomes. They encode discrete probability distributions as integer counts without any denominator. P objects represent pools (ordered sequences) of histograms. If all you need is aggregate outcomes (sums) from rolling a bunch of dice (or calculations on aggregate outcomes), H objects are probably sufficient. If you need to select certain histograms from a group prior to computing aggregate outcomes (e.g., taking the highest and lowest of each possible roll of n dice), that\u2019s where P objects come in. As a wise person whose name has been lost to history once said: \u201cLanguage is imperfect. If at all possible, shut up and point.\u201d So with that illuminating (or perhaps impenetrable) introduction out of the way, let\u2019s dive into some examples! A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H(n) is shorthand for explicitly enumerating outcomes \\([{{1} .. {n}}]\\) , each with a frequency of 1: 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P(n, ...) is shorthand for P(H(n), ...) . The above can be expressed more succinctly: 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case, Sicherman dice ) can be compared to histograms: 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. Histograms provide rudimentary formatting for convenience: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # The Miwin-Distribution is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 >>> miwin_iii = H (( 1 , 2 , 5 , 6 , 7 , 9 )) >>> miwin_iv = H (( 1 , 3 , 4 , 5 , 8 , 9 )) >>> miwin_v = H (( 2 , 3 , 4 , 6 , 7 , 8 )) >>> miwin_iii + miwin_iv + miwin_v H ({ 4 : 1 , 5 : 2 , 6 : 3 , 7 : 4 , 8 : 7 , ... , 22 : 7 , 23 : 4 , 24 : 3 , 25 : 2 , 26 : 1 }) >>> print (( miwin_iii + miwin_iv + miwin_v ) . format ( scaled = True , width = 65 )) avg | 15.00 std | 4.47 var | 20.00 4 | 0.46 % | ## 5 | 0.93 % | ##### 6 | 1.39 % | ####### 7 | 1.85 % | ########## 8 | 3.24 % | ################## 9 | 4.17 % | ####################### 10 | 4.63 % | ########################## 11 | 5.09 % | ############################ 12 | 7.87 % | ############################################ 13 | 8.80 % | ################################################# 14 | 8.33 % | ############################################### 15 | 6.48 % | #################################### 16 | 8.33 % | ############################################### 17 | 8.80 % | ################################################# 18 | 7.87 % | ############################################ 19 | 5.09 % | ############################ 20 | 4.63 % | ########################## 21 | 4.17 % | ####################### 22 | 3.24 % | ################## 23 | 1.85 % | ########## 24 | 1.39 % | ####### 25 | 0.93 % | ##### 26 | 0.46 % | ## One way to model the outcomes of subtracting the lesser of two six-sided dice from the greater is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms: 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest with negative values counting from the right, as one would expect (i.e., [0] , [1] , \u2026, [-2] , [-1] ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [\u2026] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable: 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool: 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 2 ] P ( 4 , 6 , 8 ) A brute-force way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( \" {: >2} d6: {: >6.2%} \" . format ( n , all_even [ 1 ] / sum ( all_even . counts ()))) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher on any single die when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( \" {: >2} d6-exploding: {: >6.2%} \" . format ( n , at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()))) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 % Visualization H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 >>> outcomes , probabilities = ( 2 @H ( 6 )) . distribution_xy () >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Distribution for 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.plt provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ): 1 2 3 >>> from dyce.plt import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position: 1 2 3 4 5 6 7 8 >>> d20 = H ( 20 ) >>> plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), inner_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring can also be used to compare two histograms directly. Ever been curious how your four shiny new fudge dice stack up against your trusty ol\u2019 double six-siders? Well wonder no more! The dyce abides: 1 2 3 4 >>> df_4 = 4 @H (( - 1 , 0 , 1 )) >>> d6_2 = 2 @H ( 6 ) >>> plot_burst ( df_4 , d6_2 , alpha = 0.9 ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Advanced exercise \u2013 modeling Risis Risus and its many community-developed alternative rules not only make for entertaining reading, but are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from typing import List , Tuple >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names : List [ str ] = [] ... rows : List [ Tuple [ float , ... ]] = [] ... for us in range ( them , them + num_rows ): ... row_names . append ( \" {} d6 \u2026\" . format ( us )) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . distribution_xy ()[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( \"\u2026 vs {} d6\" . format ( them )) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... \" {:.0%} \" . format ( rows [ y ][ x ]), ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib.pyplot.show presents: With a little elbow finger grease, we can roll up our\u2026erm\u2026fingerless gloves and even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> from typing import Callable , Dict , Tuple >>> def risus_combat_driver ( ... us : int , ... them : int , ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( \"cannot have negative numbers (us: {} , them: {} )\" . format ( us , them )) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... already_solved : Dict [ Tuple [ int , int ], H ] = {} ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in already_solved : return already_solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( _ : H , outcome ) -> H : ... if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die ... else : return H ({}) # ignore (immediately reroll) all ties ... ... already_solved [( us , them )] = this_round . substitute ( _next_round ) ... return already_solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } Using our risus_combat_driver from above, we can model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath rule for resolving ties ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional computation. This is for two reasons. First, dyce only provides mechanisms to approximate outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough. Second, with one narrow exception , dyce only provides a mechanism to substitute outcomes, not counts. Both of these limitations can be circumvented where distributions can be computed and encoded as histograms. For this mechanic, we can observe that a single six-sided die ( 1d6 ) has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes you can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue: 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem: \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{6}{10} = \\frac{3}{5} \\] Well, butter my butt and call me a biscuit! Math really is fun! \ud83e\uddc8 \ud83e\udd20 \ud83e\uddee Info The Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader\u2026at least one with nothing more pressing to do. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 1 : 3 , 0 : 2 }) # 3 dubyas, 2 doughnuts >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } Time to get meta-evil on those outcomes! dyce offers best-effort support for arbitrary number-like outcomes, including primitives from symbolic expression packages such as SymPy . 1 2 3 4 5 >>> import sympy.abc >>> d6x = H ( 6 ) + sympy . abc . x >>> d8y = H ( 8 ) + sympy . abc . y >>> P ( d6x , d8y , d6x ) . h () H ({ 2 * x + y + 3 : 1 , 2 * x + y + 4 : 3 , 2 * x + y + 5 : 6 , ... , 2 * x + y + 18 : 6 , 2 * x + y + 19 : 3 , 2 * x + y + 20 : 1 }) Be aware that performance can be quite slow, however. dyce remains opinionated about ordering. For non-critical contexts, dyce will attempt a \u201cnatural\u201d ordering based on the string representation of each outcome if relative values are indeterminate. This is to accommodate symbolic expressions whose relative values are often unknowable: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> expr = sympy . abc . x < sympy . abc . x * 3 >>> expr x < 3 * x >>> bool ( expr ) # nope Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> s = sympy . abc . x - 1 >>> d3x = H ( 3 ) * sympy . abc . x >>> d3x2 = H ( i * sympy . abc . x for i in range ( 3 , 0 , - 1 )) >>> d3x == d3x2 # stll results in consistent ordering True >>> P ( d3x , d3x2 ) P ( H ({ 2 * x : 1 , 3 * x : 1 , x : 1 }), H ({ 2 * x : 1 , 3 * x : 1 , x : 1 })) >>> sympy . abc . x * 3 in d3x True >>> sympy . abc . x - 1 in d3x False SymPy, for example, does not attempt simple relative comparisons between symbolic expressions, even where they are unambiguously resolvable. Instead, it relies on the caller to invoke its proprietary solver APIs: 1 2 3 4 5 6 7 >>> bool ( sympy . abc . x < sympy . abc . x + 1 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> import sympy.solvers.inequalities >>> sympy . solvers . inequalities . reduce_inequalities ( sympy . abc . x < sympy . abc . x + 1 , [ sympy . abc . x ]) True dyce , of course, is happily ignorant of all that keenness. (As it should be.) In practice, that means that certain operations won\u2019t work with symbolic expressions where correctness depends on ordering outcomes according to relative value (e.g., dice selection from pools). Flattening pools works: 1 2 3 >>> p = P ( d3x / 3 , ( d3x + 1 ) / 3 , ( d3x + 2 ) / 3 ) >>> p . h () H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Selecting the \u201clowest\u201d die doesn\u2019t: 1 2 3 4 >>> p . h ( 0 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational Selecting all dice works, since it\u2019s equivalent to flattening (no sorting is required): 1 2 >>> p . h ( slice ( None )) H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Enumerating rolls doesn\u2019t, even where there is no selection, because each roll\u2019s outcomes must be sorted least-to-greatest: 1 2 3 4 >>> list ( p . rolls_with_counts ()) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational P.roll \u201cworks\u201d (i.e., falls back to natural ordering of outcomes), but that is a deliberate compromise of convenience: 1 2 >>> p . roll () # doctest: +SKIP ( 2 * x / 3 , 2 * x / 3 + 1 / 3 , x / 3 + 2 / 3 ) P.umap can help pave the way back to concrete outcomes: 1 2 3 4 5 >>> f = lambda o : o . subs ({ sympy . abc . x : sympy . Rational ( 1 , 3 )}) >>> p . umap ( f ) P ( H ({ 1 / 9 : 1 , 2 / 9 : 1 , 1 / 3 : 1 }), H ({ 4 / 9 : 1 , 5 / 9 : 1 , 2 / 3 : 1 }), H ({ 7 / 9 : 1 , 8 / 9 : 1 , 1 : 1 })) >>> p . umap ( f ) . h ( - 1 ) H ({ 7 / 9 : 9 , 8 / 9 : 9 , 1 : 9 }) Further exploration Consider exploring the applications and translations for more examples, or jump right into the API .","title":"Tutorial"},{"location":"tutorial/#basic-examples","text":"dyce provides two key primitives: 1 >>> from dyce import H , P H objects represent histograms for modeling discrete outcomes. They encode discrete probability distributions as integer counts without any denominator. P objects represent pools (ordered sequences) of histograms. If all you need is aggregate outcomes (sums) from rolling a bunch of dice (or calculations on aggregate outcomes), H objects are probably sufficient. If you need to select certain histograms from a group prior to computing aggregate outcomes (e.g., taking the highest and lowest of each possible roll of n dice), that\u2019s where P objects come in. As a wise person whose name has been lost to history once said: \u201cLanguage is imperfect. If at all possible, shut up and point.\u201d So with that illuminating (or perhaps impenetrable) introduction out of the way, let\u2019s dive into some examples! A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H(n) is shorthand for explicitly enumerating outcomes \\([{{1} .. {n}}]\\) , each with a frequency of 1: 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P(n, ...) is shorthand for P(H(n), ...) . The above can be expressed more succinctly: 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case, Sicherman dice ) can be compared to histograms: 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. Histograms provide rudimentary formatting for convenience: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # The Miwin-Distribution is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 >>> miwin_iii = H (( 1 , 2 , 5 , 6 , 7 , 9 )) >>> miwin_iv = H (( 1 , 3 , 4 , 5 , 8 , 9 )) >>> miwin_v = H (( 2 , 3 , 4 , 6 , 7 , 8 )) >>> miwin_iii + miwin_iv + miwin_v H ({ 4 : 1 , 5 : 2 , 6 : 3 , 7 : 4 , 8 : 7 , ... , 22 : 7 , 23 : 4 , 24 : 3 , 25 : 2 , 26 : 1 }) >>> print (( miwin_iii + miwin_iv + miwin_v ) . format ( scaled = True , width = 65 )) avg | 15.00 std | 4.47 var | 20.00 4 | 0.46 % | ## 5 | 0.93 % | ##### 6 | 1.39 % | ####### 7 | 1.85 % | ########## 8 | 3.24 % | ################## 9 | 4.17 % | ####################### 10 | 4.63 % | ########################## 11 | 5.09 % | ############################ 12 | 7.87 % | ############################################ 13 | 8.80 % | ################################################# 14 | 8.33 % | ############################################### 15 | 6.48 % | #################################### 16 | 8.33 % | ############################################### 17 | 8.80 % | ################################################# 18 | 7.87 % | ############################################ 19 | 5.09 % | ############################ 20 | 4.63 % | ########################## 21 | 4.17 % | ####################### 22 | 3.24 % | ################## 23 | 1.85 % | ########## 24 | 1.39 % | ####### 25 | 0.93 % | ##### 26 | 0.46 % | ## One way to model the outcomes of subtracting the lesser of two six-sided dice from the greater is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms: 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest with negative values counting from the right, as one would expect (i.e., [0] , [1] , \u2026, [-2] , [-1] ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [\u2026] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable: 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool: 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 2 ] P ( 4 , 6 , 8 ) A brute-force way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( \" {: >2} d6: {: >6.2%} \" . format ( n , all_even [ 1 ] / sum ( all_even . counts ()))) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher on any single die when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( \" {: >2} d6-exploding: {: >6.2%} \" . format ( n , at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()))) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 %","title":"Basic examples"},{"location":"tutorial/#visualization","text":"H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 >>> outcomes , probabilities = ( 2 @H ( 6 )) . distribution_xy () >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Distribution for 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.plt provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ): 1 2 3 >>> from dyce.plt import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position: 1 2 3 4 5 6 7 8 >>> d20 = H ( 20 ) >>> plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), inner_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring can also be used to compare two histograms directly. Ever been curious how your four shiny new fudge dice stack up against your trusty ol\u2019 double six-siders? Well wonder no more! The dyce abides: 1 2 3 4 >>> df_4 = 4 @H (( - 1 , 0 , 1 )) >>> d6_2 = 2 @H ( 6 ) >>> plot_burst ( df_4 , d6_2 , alpha = 0.9 ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Visualization"},{"location":"tutorial/#advanced-exercise-modeling-risis","text":"Risus and its many community-developed alternative rules not only make for entertaining reading, but are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from typing import List , Tuple >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names : List [ str ] = [] ... rows : List [ Tuple [ float , ... ]] = [] ... for us in range ( them , them + num_rows ): ... row_names . append ( \" {} d6 \u2026\" . format ( us )) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . distribution_xy ()[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( \"\u2026 vs {} d6\" . format ( them )) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... \" {:.0%} \" . format ( rows [ y ][ x ]), ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib.pyplot.show presents: With a little elbow finger grease, we can roll up our\u2026erm\u2026fingerless gloves and even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> from typing import Callable , Dict , Tuple >>> def risus_combat_driver ( ... us : int , ... them : int , ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( \"cannot have negative numbers (us: {} , them: {} )\" . format ( us , them )) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... already_solved : Dict [ Tuple [ int , int ], H ] = {} ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in already_solved : return already_solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( _ : H , outcome ) -> H : ... if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die ... else : return H ({}) # ignore (immediately reroll) all ties ... ... already_solved [( us , them )] = this_round . substitute ( _next_round ) ... return already_solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } Using our risus_combat_driver from above, we can model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath rule for resolving ties ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional computation. This is for two reasons. First, dyce only provides mechanisms to approximate outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough. Second, with one narrow exception , dyce only provides a mechanism to substitute outcomes, not counts. Both of these limitations can be circumvented where distributions can be computed and encoded as histograms. For this mechanic, we can observe that a single six-sided die ( 1d6 ) has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes you can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue: 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem: \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{6}{10} = \\frac{3}{5} \\] Well, butter my butt and call me a biscuit! Math really is fun! \ud83e\uddc8 \ud83e\udd20 \ud83e\uddee Info The Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader\u2026at least one with nothing more pressing to do. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 1 : 3 , 0 : 2 }) # 3 dubyas, 2 doughnuts >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % }","title":"Advanced exercise \u2013 modeling Risis"},{"location":"tutorial/#time-to-get-meta-evil-on-those-outcomes","text":"dyce offers best-effort support for arbitrary number-like outcomes, including primitives from symbolic expression packages such as SymPy . 1 2 3 4 5 >>> import sympy.abc >>> d6x = H ( 6 ) + sympy . abc . x >>> d8y = H ( 8 ) + sympy . abc . y >>> P ( d6x , d8y , d6x ) . h () H ({ 2 * x + y + 3 : 1 , 2 * x + y + 4 : 3 , 2 * x + y + 5 : 6 , ... , 2 * x + y + 18 : 6 , 2 * x + y + 19 : 3 , 2 * x + y + 20 : 1 }) Be aware that performance can be quite slow, however. dyce remains opinionated about ordering. For non-critical contexts, dyce will attempt a \u201cnatural\u201d ordering based on the string representation of each outcome if relative values are indeterminate. This is to accommodate symbolic expressions whose relative values are often unknowable: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> expr = sympy . abc . x < sympy . abc . x * 3 >>> expr x < 3 * x >>> bool ( expr ) # nope Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> s = sympy . abc . x - 1 >>> d3x = H ( 3 ) * sympy . abc . x >>> d3x2 = H ( i * sympy . abc . x for i in range ( 3 , 0 , - 1 )) >>> d3x == d3x2 # stll results in consistent ordering True >>> P ( d3x , d3x2 ) P ( H ({ 2 * x : 1 , 3 * x : 1 , x : 1 }), H ({ 2 * x : 1 , 3 * x : 1 , x : 1 })) >>> sympy . abc . x * 3 in d3x True >>> sympy . abc . x - 1 in d3x False SymPy, for example, does not attempt simple relative comparisons between symbolic expressions, even where they are unambiguously resolvable. Instead, it relies on the caller to invoke its proprietary solver APIs: 1 2 3 4 5 6 7 >>> bool ( sympy . abc . x < sympy . abc . x + 1 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> import sympy.solvers.inequalities >>> sympy . solvers . inequalities . reduce_inequalities ( sympy . abc . x < sympy . abc . x + 1 , [ sympy . abc . x ]) True dyce , of course, is happily ignorant of all that keenness. (As it should be.) In practice, that means that certain operations won\u2019t work with symbolic expressions where correctness depends on ordering outcomes according to relative value (e.g., dice selection from pools). Flattening pools works: 1 2 3 >>> p = P ( d3x / 3 , ( d3x + 1 ) / 3 , ( d3x + 2 ) / 3 ) >>> p . h () H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Selecting the \u201clowest\u201d die doesn\u2019t: 1 2 3 4 >>> p . h ( 0 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational Selecting all dice works, since it\u2019s equivalent to flattening (no sorting is required): 1 2 >>> p . h ( slice ( None )) H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Enumerating rolls doesn\u2019t, even where there is no selection, because each roll\u2019s outcomes must be sorted least-to-greatest: 1 2 3 4 >>> list ( p . rolls_with_counts ()) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational P.roll \u201cworks\u201d (i.e., falls back to natural ordering of outcomes), but that is a deliberate compromise of convenience: 1 2 >>> p . roll () # doctest: +SKIP ( 2 * x / 3 , 2 * x / 3 + 1 / 3 , x / 3 + 2 / 3 ) P.umap can help pave the way back to concrete outcomes: 1 2 3 4 5 >>> f = lambda o : o . subs ({ sympy . abc . x : sympy . Rational ( 1 , 3 )}) >>> p . umap ( f ) P ( H ({ 1 / 9 : 1 , 2 / 9 : 1 , 1 / 3 : 1 }), H ({ 4 / 9 : 1 , 5 / 9 : 1 , 2 / 3 : 1 }), H ({ 7 / 9 : 1 , 8 / 9 : 1 , 1 : 1 })) >>> p . umap ( f ) . h ( - 1 ) H ({ 7 / 9 : 9 , 8 / 9 : 9 , 1 : 9 })","title":"Time to get meta-evil on those outcomes!"},{"location":"tutorial/#further-exploration","text":"Consider exploring the applications and translations for more examples, or jump right into the API .","title":"Further exploration"}]}