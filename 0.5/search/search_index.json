{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Copyright and other protections apply. Please see the accompanying LICENSE file for rights and restrictions governing use of this software. All rights not expressly waived or licensed are reserved. If that file is missing or appears to be modified from its original, then please contact the author before viewing or using this software in any capacity. Now you\u2019re playing with \u2026 dyce \u2013 simple Python tools for exploring dice outcomes and other finite discrete probabilities \ud83d\udca5 Now 100% Bear-ified\u2122 ! \ud83d\udc4c\ud83c\udffe\ud83d\udc3b ( Details below.) dyce is a pure-Python library for modeling arbitrarily complex dice mechanics. It strives for compact expression and efficient computation , especially for the most common cases. Its primary applications are: Computing finite discrete probability distributions for: Game designers who want to understand or experiment with various dice mechanics and interactions; and Design tool developers . Generating transparent, weighted random rolls for: Game environment developers who want flexible dice mechanic resolution in, e.g., virtual tabletops (VTTs), chat servers, etc. Beyond those audiences, dyce may be useful to anyone interested in exploring finite discrete probabilities but not in developing all the low-level math bits from scratch. dyce is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. If you\u2019re looking at something on which to build your own grammar or interface, dyce can serve you well. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Non-experimental features should be considered stable (but an unquenchable thirst to increase performance remains). See the release notes for a summary of version-to-version changes. Source code is available on GitHub . If you find it lacking in any way, please don\u2019t hesitate to bring it to my attention . Donors When one worries that the flickering light of humanity may be snuffed out at any moment, when one\u2019s heart breaks at the perverse celebration of judgment, vengeance, and death and the demonizing of empathy, compassion, and love, sometimes all that is needed is the kindness of a single stranger to reinvigorate one\u2019s faith that\u2014while all may not be right in the world\u2014there is hope for us human beings. David Eyk not only inspires others to explore creative writing , but has graciously ceded his PyPI project dedicated to his own prior work under a similar name . As such, dyce is now available as dycelib dyce ! Thanks to his generosity, millions dozens of future dyce users will be spared from typing superfluous characters. On behalf of myself, those souls, and our keyboards, we salute you, Mr. Eyk. \ud83d\ude47\u200d\u2642\ufe0f A taste dyce provides several core primitives. H objects represent histograms for modeling finite discrete outcomes, like individual dice. P objects represent pools (ordered sequences) of histograms. R objects (covered elsewhere ) represent nodes in arbitrary roller trees useful for translating from proprietary grammars and generating weighted random rolls that \u201cshow their work\u201d without the overhead of enumeration. All support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ()) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages anydyce , for example, makes use of these to integrate with matplotlib . Source: plot_2d6_lo_hi.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_bar from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot p_2d6 = 2 @ P ( H ( 6 )) p_2d6_lowest = p_2d6 . h ( 0 ) p_2d6_highest = p_2d6 . h ( - 1 ) ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_bar ( ax , [( \"Lowest\" , p_2d6_lowest ), ( \"Highest\" , p_2d6_highest )]) ax . legend () ax . set_title ( \"Taking the lowest or highest die of 2d6\" , color = text_color ) H objects and P objects can generate random rolls. 1 2 3 >>> d6 = H ( 6 ) >>> d6 . roll () # doctest: +SKIP 4 1 2 3 4 >>> d10 = H ( 10 ) - 1 >>> p_6d10 = 6 @P ( d10 ) >>> p_6d10 . roll () # doctest: +SKIP ( 0 , 1 , 2 , 3 , 5 , 7 ) See the tutorials on counting and rolling , as well as the API guide for much more thorough treatments, including detailed examples. Design philosophy dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. That\u2019s a highfalutin way of saying it doesn\u2019t guess. It knows , even if knowing is harder or more limiting. Which, if we possess a modicum of humility, it often is. Quote \u201cIt\u2019s frightening to think that you might not know something, but more frightening to think that, by and large, the world is run by people who have faith that they know exactly what is going on.\u201d \u2014Amos Tversky Because dyce exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. 1 It can be installed and run anywhere 2 , and modified as desired. On its own, dyce is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter or embedded in a special-purpose application. In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods). Comparison to alternatives The following is a best-effort 3 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen python-dice Robson et al. AnyDice Flick d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clements et al. dice-notation Garrido Latest release 2022 N/A 2021 Unknown 2021 2016 2021 2021 Actively maintained and documented \u2705 \u26a0\ufe0f 4 \u2705 \u2705 \u2705 \u274c \u2705 \u274c Combinatorics optimizations \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c \u274c Suitable as a dependency in other projects \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u2705 \u26a0\ufe0f 5 \u2705 \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Arbitrary expressions \u2705 \u26a0\ufe0f 6 \u2705 \u2705 \u2705 \u26a0\ufe0f 7 \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u26a0\ufe0f 8 \u274c \u26a0\ufe0f 8 \u2705 \u26a0\ufe0f 8 \u26a0\ufe0f 8 Open source (can inspect) \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 Permissive licensing (can use and extend) \u2705 \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705 License dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub . Installation Installation can be performed via PyPI . 1 2 % pip install dyce ... Alternately, you can download the source and install manually. 1 2 3 4 5 % git clone https://github.com/posita/dyce.git ... % cd dyce % python -m pip install . # -or- python -c 'from setuptools import setup ; setup()' install . ... Requirements dyce requires a relatively modern version of Python: CPython (3.7+) PyPy (CPython 3.7+ compatible) It has the following runtime dependencies: numerary for proper best-effort hacking around deficiencies in static and runtime numeric type-checking dyce will opportunistically use the following, if available at runtime: beartype for yummy runtime type-checking goodness (0.8+) matplotlib for visualizing histograms and pools numpy to supply dyce with an alternate random number generator implementation dyce leverages numerary for its opportunistic use of beartype . If you use beartype for type checking your code, but don\u2019t want dyce or numerary to use it internally, disable it with numerary \u2019s NUMERARY_BEARTYPE environment variable . See the hacking quick-start for additional development and testing dependencies. Customers This could be you ! \ud83d\udc4b Do you have a project that uses dyce ? Let me know , and I\u2019ll promote it here! And don\u2019t forget to do your part in perpetuating gratuitous badge-ification! 1 2 3 4 <!-- Markdown --> As of version 1.1, HighRollin is [ ![dyce-powered ]( https://raw.githubusercontent.com/posita/dyce/latest/docs/dyce-powered.svg )][dyce-powered]! [ dyce-powered ]: https://posita.github.io/dyce/ \"dyce-powered!\" 1 2 3 4 5 6 7 8 9 .. reStructuredText - see https://docutils.sourceforge.io/docs/ref/rst/directives.html#image As of version 1.1, HighRollin is |dyce-powered|! .. |dyce-powered| image :: https://raw.githubusercontent.com/posita/dyce/latest/docs/dyce-powered.svg :align: top :target: https://posita.github.io/dyce/ :alt: dyce-powered 1 2 3 4 5 <!-- HTML --> As of version 1.1, HighRollin is < a href = \"https://posita.github.io/dyce/\" >< img src = \"https://raw.githubusercontent.com/posita/dyce/latest/docs/dyce-powered.svg\" alt = \"dyce-powered\" style = \"vertical-align: middle;\" ></ a > ! You won\u2019t find any lexers, parsers, or tokenizers in dyce \u2019s core, other than straight-up Python. That being said, you can always \u201croll\u201d your own (see what we did there?) and lean on dyce underneath. It doesn\u2019t mind. It actually kind of likes it . \u21a9 Okay, maybe not literally anywhere, but you\u2019d be surprised . Void where prohibited. Certain restrictions apply. Do not taunt Happy Fun Ball . \u21a9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if you observe discrepancies. \u21a9 Sparsely documented. The author has expressed a desire to release a more polished version. \u21a9 Source can be downloaded and incorporated directly, but there is no packaging, versioning, or dependency tracking. \u21a9 \u21a9 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u21a9 Limited arithmetic operations are available. The library also provides game-specific functions. \u21a9 Results only. Input is limited to specialized grammar. \u21a9 \u21a9 \u21a9 \u21a9","title":"Introduction"},{"location":"#dyce-simple-python-tools-for-exploring-dice-outcomes-and-other-finite-discrete-probabilities","text":"\ud83d\udca5 Now 100% Bear-ified\u2122 ! \ud83d\udc4c\ud83c\udffe\ud83d\udc3b ( Details below.) dyce is a pure-Python library for modeling arbitrarily complex dice mechanics. It strives for compact expression and efficient computation , especially for the most common cases. Its primary applications are: Computing finite discrete probability distributions for: Game designers who want to understand or experiment with various dice mechanics and interactions; and Design tool developers . Generating transparent, weighted random rolls for: Game environment developers who want flexible dice mechanic resolution in, e.g., virtual tabletops (VTTs), chat servers, etc. Beyond those audiences, dyce may be useful to anyone interested in exploring finite discrete probabilities but not in developing all the low-level math bits from scratch. dyce is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. If you\u2019re looking at something on which to build your own grammar or interface, dyce can serve you well. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Non-experimental features should be considered stable (but an unquenchable thirst to increase performance remains). See the release notes for a summary of version-to-version changes. Source code is available on GitHub . If you find it lacking in any way, please don\u2019t hesitate to bring it to my attention .","title":"dyce \u2013 simple Python tools for exploring dice outcomes and other finite discrete probabilities"},{"location":"#donors","text":"When one worries that the flickering light of humanity may be snuffed out at any moment, when one\u2019s heart breaks at the perverse celebration of judgment, vengeance, and death and the demonizing of empathy, compassion, and love, sometimes all that is needed is the kindness of a single stranger to reinvigorate one\u2019s faith that\u2014while all may not be right in the world\u2014there is hope for us human beings. David Eyk not only inspires others to explore creative writing , but has graciously ceded his PyPI project dedicated to his own prior work under a similar name . As such, dyce is now available as dycelib dyce ! Thanks to his generosity, millions dozens of future dyce users will be spared from typing superfluous characters. On behalf of myself, those souls, and our keyboards, we salute you, Mr. Eyk. \ud83d\ude47\u200d\u2642\ufe0f","title":"Donors"},{"location":"#a-taste","text":"dyce provides several core primitives. H objects represent histograms for modeling finite discrete outcomes, like individual dice. P objects represent pools (ordered sequences) of histograms. R objects (covered elsewhere ) represent nodes in arbitrary roller trees useful for translating from proprietary grammars and generating weighted random rolls that \u201cshow their work\u201d without the overhead of enumeration. All support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ()) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages anydyce , for example, makes use of these to integrate with matplotlib . Source: plot_2d6_lo_hi.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_bar from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot p_2d6 = 2 @ P ( H ( 6 )) p_2d6_lowest = p_2d6 . h ( 0 ) p_2d6_highest = p_2d6 . h ( - 1 ) ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_bar ( ax , [( \"Lowest\" , p_2d6_lowest ), ( \"Highest\" , p_2d6_highest )]) ax . legend () ax . set_title ( \"Taking the lowest or highest die of 2d6\" , color = text_color ) H objects and P objects can generate random rolls. 1 2 3 >>> d6 = H ( 6 ) >>> d6 . roll () # doctest: +SKIP 4 1 2 3 4 >>> d10 = H ( 10 ) - 1 >>> p_6d10 = 6 @P ( d10 ) >>> p_6d10 . roll () # doctest: +SKIP ( 0 , 1 , 2 , 3 , 5 , 7 ) See the tutorials on counting and rolling , as well as the API guide for much more thorough treatments, including detailed examples.","title":"A taste"},{"location":"#design-philosophy","text":"dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. That\u2019s a highfalutin way of saying it doesn\u2019t guess. It knows , even if knowing is harder or more limiting. Which, if we possess a modicum of humility, it often is. Quote \u201cIt\u2019s frightening to think that you might not know something, but more frightening to think that, by and large, the world is run by people who have faith that they know exactly what is going on.\u201d \u2014Amos Tversky Because dyce exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. 1 It can be installed and run anywhere 2 , and modified as desired. On its own, dyce is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter or embedded in a special-purpose application. In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods).","title":"Design philosophy"},{"location":"#comparison-to-alternatives","text":"The following is a best-effort 3 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen python-dice Robson et al. AnyDice Flick d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clements et al. dice-notation Garrido Latest release 2022 N/A 2021 Unknown 2021 2016 2021 2021 Actively maintained and documented \u2705 \u26a0\ufe0f 4 \u2705 \u2705 \u2705 \u274c \u2705 \u274c Combinatorics optimizations \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c \u274c Suitable as a dependency in other projects \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u2705 \u26a0\ufe0f 5 \u2705 \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Arbitrary expressions \u2705 \u26a0\ufe0f 6 \u2705 \u2705 \u2705 \u26a0\ufe0f 7 \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u26a0\ufe0f 8 \u274c \u26a0\ufe0f 8 \u2705 \u26a0\ufe0f 8 \u26a0\ufe0f 8 Open source (can inspect) \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 Permissive licensing (can use and extend) \u2705 \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705","title":"Comparison to alternatives"},{"location":"#license","text":"dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub .","title":"License"},{"location":"#installation","text":"Installation can be performed via PyPI . 1 2 % pip install dyce ... Alternately, you can download the source and install manually. 1 2 3 4 5 % git clone https://github.com/posita/dyce.git ... % cd dyce % python -m pip install . # -or- python -c 'from setuptools import setup ; setup()' install . ...","title":"Installation"},{"location":"#requirements","text":"dyce requires a relatively modern version of Python: CPython (3.7+) PyPy (CPython 3.7+ compatible) It has the following runtime dependencies: numerary for proper best-effort hacking around deficiencies in static and runtime numeric type-checking dyce will opportunistically use the following, if available at runtime: beartype for yummy runtime type-checking goodness (0.8+) matplotlib for visualizing histograms and pools numpy to supply dyce with an alternate random number generator implementation dyce leverages numerary for its opportunistic use of beartype . If you use beartype for type checking your code, but don\u2019t want dyce or numerary to use it internally, disable it with numerary \u2019s NUMERARY_BEARTYPE environment variable . See the hacking quick-start for additional development and testing dependencies.","title":"Requirements"},{"location":"#customers","text":"This could be you ! \ud83d\udc4b Do you have a project that uses dyce ? Let me know , and I\u2019ll promote it here! And don\u2019t forget to do your part in perpetuating gratuitous badge-ification! 1 2 3 4 <!-- Markdown --> As of version 1.1, HighRollin is [ ![dyce-powered ]( https://raw.githubusercontent.com/posita/dyce/latest/docs/dyce-powered.svg )][dyce-powered]! [ dyce-powered ]: https://posita.github.io/dyce/ \"dyce-powered!\" 1 2 3 4 5 6 7 8 9 .. reStructuredText - see https://docutils.sourceforge.io/docs/ref/rst/directives.html#image As of version 1.1, HighRollin is |dyce-powered|! .. |dyce-powered| image :: https://raw.githubusercontent.com/posita/dyce/latest/docs/dyce-powered.svg :align: top :target: https://posita.github.io/dyce/ :alt: dyce-powered 1 2 3 4 5 <!-- HTML --> As of version 1.1, HighRollin is < a href = \"https://posita.github.io/dyce/\" >< img src = \"https://raw.githubusercontent.com/posita/dyce/latest/docs/dyce-powered.svg\" alt = \"dyce-powered\" style = \"vertical-align: middle;\" ></ a > ! You won\u2019t find any lexers, parsers, or tokenizers in dyce \u2019s core, other than straight-up Python. That being said, you can always \u201croll\u201d your own (see what we did there?) and lean on dyce underneath. It doesn\u2019t mind. It actually kind of likes it . \u21a9 Okay, maybe not literally anywhere, but you\u2019d be surprised . Void where prohibited. Certain restrictions apply. Do not taunt Happy Fun Ball . \u21a9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if you observe discrepancies. \u21a9 Sparsely documented. The author has expressed a desire to release a more polished version. \u21a9 Source can be downloaded and incorporated directly, but there is no packaging, versioning, or dependency tracking. \u21a9 \u21a9 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u21a9 Limited arithmetic operations are available. The library also provides game-specific functions. \u21a9 Results only. Input is limited to specialized grammar. \u21a9 \u21a9 \u21a9 \u21a9","title":"Customers"},{"location":"contrib/","text":"Contributing to dyce There are many ways you can contribute. You have only but to try. Starting discussions and filing issues You can file new issues as you find them. Please try to avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful. For more free-flow discussions (beefs, rants, ideas, recipes, etc.), consider starting or joining a discussion . Hacking quick-start An easy way to bootstrap an isolated development environment is: 1 2 3 4 5 6 7 8 9 10 % git clone --recurse-submodules https://github.com/posita/dyce.git \u2026 % cd dyce % /path/to/python -m venv .venv \u2026 % . .venv/bin/activate % pip install --upgrade --editable '.[dev]' \u2026 % python -m pre_commit install \u2026 Substitute your preferred virtual environment process for venv . The [dev] variant includes additional dependencies necessary for development and testing. See the [options.extras_require] section in setup.cfg . Unit tests are run with pytest via Tox . 1 2 3 4 % cd \u2026/path/to/dyce % . .venv/bin/activate % tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] \u2026 Special considerations for regenerating class diagrams We use Pyreverse to generate class diagrams. Pyreverse is not very flexible with respect to what it includes. We use PyGraphviz to get rid of unwanted entries from the .dot file generated by Pyreverse. This is because the pure-Python alternative we use elsewhere does not support editing . PyGraphviz has some special needs when it comes to installation. This dumpster fire is complicated and fragile. 1 Depending on your configuration, PyGraphviz may not be able to find the native Graphviz library it needs. This can often be remedied by setting the appropriate gcc environment variables . 1 CPATH = /opt/local/include LIBRARY_PATH = /optlocal/lib tox -e check-classdiagrams Submission guidelines If you are willing and able, consider submitting a pull request with a fix. See the docs if you\u2019re not already familiar with pull requests. dyce releases from master (although not always immediately), so a lot of these workflows are helpful. There are only a few additional guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file. 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub \u2013 [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Do your best to follow the source conventions as you observe them. If it\u2019s important to you, Existing comments are wrapped at 88 characters per line to match Black\u2019s default. (Don\u2019t spend too much effort on strict conformance, though. I can clean things up later if they really bother me.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in tests . If you want feedback on a work-in-progress, consider \u201cmentioning\u201d me ( @posita ), and describe specifically how I can help. Consider prefixing your pull request\u2019s title with something like, \u201c NEED FEEDBACK \u2013 \u201d. If your pull request is still in progress, but you are not blocked on anything, consider using the draft feature . Once you are ready for a merge, resolve any conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) If your pull request started out as a draft, promote it by requesting a review. Consider prefixing the pull request\u2019s title to something like, \u201c READY FOR MERGE \u2013 \u201d. I will try to get to it as soon as I can. It is uncanny how often those two properties are found together. \u21a9","title":"Contributing"},{"location":"contrib/#contributing-to-dyce","text":"There are many ways you can contribute. You have only but to try.","title":"Contributing to dyce"},{"location":"contrib/#starting-discussions-and-filing-issues","text":"You can file new issues as you find them. Please try to avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful. For more free-flow discussions (beefs, rants, ideas, recipes, etc.), consider starting or joining a discussion .","title":"Starting discussions and filing issues"},{"location":"contrib/#hacking-quick-start","text":"An easy way to bootstrap an isolated development environment is: 1 2 3 4 5 6 7 8 9 10 % git clone --recurse-submodules https://github.com/posita/dyce.git \u2026 % cd dyce % /path/to/python -m venv .venv \u2026 % . .venv/bin/activate % pip install --upgrade --editable '.[dev]' \u2026 % python -m pre_commit install \u2026 Substitute your preferred virtual environment process for venv . The [dev] variant includes additional dependencies necessary for development and testing. See the [options.extras_require] section in setup.cfg . Unit tests are run with pytest via Tox . 1 2 3 4 % cd \u2026/path/to/dyce % . .venv/bin/activate % tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] \u2026 Special considerations for regenerating class diagrams We use Pyreverse to generate class diagrams. Pyreverse is not very flexible with respect to what it includes. We use PyGraphviz to get rid of unwanted entries from the .dot file generated by Pyreverse. This is because the pure-Python alternative we use elsewhere does not support editing . PyGraphviz has some special needs when it comes to installation. This dumpster fire is complicated and fragile. 1 Depending on your configuration, PyGraphviz may not be able to find the native Graphviz library it needs. This can often be remedied by setting the appropriate gcc environment variables . 1 CPATH = /opt/local/include LIBRARY_PATH = /optlocal/lib tox -e check-classdiagrams","title":"Hacking quick-start"},{"location":"contrib/#submission-guidelines","text":"If you are willing and able, consider submitting a pull request with a fix. See the docs if you\u2019re not already familiar with pull requests. dyce releases from master (although not always immediately), so a lot of these workflows are helpful. There are only a few additional guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file. 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub \u2013 [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Do your best to follow the source conventions as you observe them. If it\u2019s important to you, Existing comments are wrapped at 88 characters per line to match Black\u2019s default. (Don\u2019t spend too much effort on strict conformance, though. I can clean things up later if they really bother me.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in tests . If you want feedback on a work-in-progress, consider \u201cmentioning\u201d me ( @posita ), and describe specifically how I can help. Consider prefixing your pull request\u2019s title with something like, \u201c NEED FEEDBACK \u2013 \u201d. If your pull request is still in progress, but you are not blocked on anything, consider using the draft feature . Once you are ready for a merge, resolve any conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) If your pull request started out as a draft, promote it by requesting a review. Consider prefixing the pull request\u2019s title to something like, \u201c READY FOR MERGE \u2013 \u201d. I will try to get to it as soon as I can. It is uncanny how often those two properties are found together. \u21a9","title":"Submission guidelines"},{"location":"countin/","text":"dyce provides two core primitives for enumeration 1 . 1 >>> from dyce import H , P H objects represent histograms for modeling discrete outcomes. They encode finite discrete probability distributions as integer counts without any denominator. P objects represent pools (ordered sequences) of histograms. If all you need is to aggregate outcomes (sums) from rolling a bunch of dice (or perform calculations on aggregate outcomes), H objects are probably sufficient. If you need to select certain histograms from a group prior to computing aggregate outcomes (e.g., taking the highest and lowest of each possible roll of n dice), that\u2019s where P objects come in. As a wise person whose name has been lost to history once said: \u201cLanguage is imperfect. If at all possible, shut up and point.\u201d So with that illuminating (or perhaps impenetrable) introduction out of the way, let\u2019s dive into some examples! Basic examples A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H ( n ) is shorthand for explicitly enumerating outcomes \\([{ {1} .. {n} }]\\) , each with a frequency of 1. 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> P ( H ( 6 ), H ( 6 )) P ( 6 , 6 ) Where n is an integer, P ( n , ... ) is shorthand for P ( H ( n ), ... ) . Python\u2019s matrix multiplication operator ( @ ) can also be used with pools. The above can be expressed more succinctly. 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case, Sicherman dice ) can be compared to histograms. 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. Histograms provide rudimentary formatting for convenience. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ()) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # The Miwin-Distribution is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 >>> miwin_iii = H (( 1 , 2 , 5 , 6 , 7 , 9 )) >>> miwin_iv = H (( 1 , 3 , 4 , 5 , 8 , 9 )) >>> miwin_v = H (( 2 , 3 , 4 , 6 , 7 , 8 )) >>> miwin_dist = miwin_iii + miwin_iv + miwin_v ; miwin_dist H ({ 4 : 1 , 5 : 2 , 6 : 3 , 7 : 4 , 8 : 7 , ... , 22 : 7 , 23 : 4 , 24 : 3 , 25 : 2 , 26 : 1 }) >>> print (( miwin_dist ) . format ( scaled = True )) avg | 15.00 std | 4.47 var | 20.00 4 | 0.46 % | ## 5 | 0.93 % | ##### 6 | 1.39 % | ####### 7 | 1.85 % | ########## 8 | 3.24 % | ################## 9 | 4.17 % | ####################### 10 | 4.63 % | ########################## 11 | 5.09 % | ############################ 12 | 7.87 % | ############################################ 13 | 8.80 % | ################################################# 14 | 8.33 % | ############################################### 15 | 6.48 % | #################################### 16 | 8.33 % | ############################################### 17 | 8.80 % | ################################################# 18 | 7.87 % | ############################################ 19 | 5.09 % | ############################ 20 | 4.63 % | ########################## 21 | 4.17 % | ####################### 22 | 3.24 % | ################## 23 | 1.85 % | ########## 24 | 1.39 % | ####### 25 | 0.93 % | ##### 26 | 0.46 % | ## One way to model the outcomes of subtracting the lesser of two six-sided dice from the greater is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms. 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest with negative values counting from the right, as one would expect (i.e., [ 0 ] , [ 1 ] , \u2026, [ - 2 ] , [ - 1 ] ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ()) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ()) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ()) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable. 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool. 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 3 ] P ( 4 , 6 ) An inefficient way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . is_even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( f \" { n : >2 } d6: { all_even [ 1 ] / sum ( all_even . counts ()) : >6.2% } \" ) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher on any single die when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> # By the time we're rolling a third die, we're guaranteed a nine or higher, so we only need to look that far >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( f \" { n : >2 } d6-exploding: { at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()) : >6.2% } \" ) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 % Dependent probabilities Where we can identify independent terms and reduce the dependent term to a calculation solely involving independent terms, dependent probabilities can often be compactly expressed via H.substitute , H.foreach , or P.foreach . First, we express independent terms as histograms or pools. Second, we express the dependent term as a callback function. Finally, we can pass the dependent callback function to H.substitute , H.foreach , or P.foreach , along with the independent terms (as arguments in the cases of the latter two). H.substitute is well suited to situations with a single independent term that can be expressed as a histogram. Say we want to roll a d6 and compare whether the result is strictly greater than its distance from some constant. 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6 = H ( 6 ) # independent term >>> constant = 4 >>> def outcome_vs_distance_to_constant ( __ : H , d6_outcome ): ... return d6_outcome > abs ( d6_outcome - constant ) # dependent term >>> print ( d6 . substitute ( outcome_vs_distance_to_constant ) . format ()) avg | 0.67 std | 0.47 var | 0.22 0 | 33.33 % | ################ 1 | 66.67 % | ################################# Instead of a constant, let\u2019s use another die as a second independent term. We\u2019ll roll a d4 and a d6 and compare whether the d6 is strictly greater than the absolute difference between dice. For multiple independent terms that can be expressed as histograms, the H.foreach class method is often easiest. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 = H ( 4 ) # first independent term >>> d6 = H ( 6 ) # second independent term >>> def outcome_vs_difference_dependent_term ( d4_outcome , d6_outcome ): ... return d6_outcome > abs ( d4_outcome - d6_outcome ) # dependent term >>> h = H . foreach ( outcome_vs_difference_dependent_term , d4_outcome = d4 , d6_outcome = d6 ) >>> print ( h . format ()) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### In the alternative, one could nest substitution functions, where the innermost holds the dependent term, and the outer functions each establish the scope of their respective independent outcomes. However, this isn\u2019t very readable, and is often less efficient than using H.foreach class method . 1 2 3 4 5 6 7 >>> def sub_d4 ( __ : H , d4_outcome ): ... def sub_d6 ( __ : H , d6_outcome ): ... return d6_outcome > abs ( d4_outcome - d6_outcome ) ... return d6 . substitute ( sub_d6 ) >>> d4 . substitute ( sub_d4 ) == h True Where the dependent term requires inspection of rolls from one or more pools as independent terms, P.foreach class method is useful. Let\u2019s say we have two pools. A roll from the first pool wins if it shows no duplicates but a roll from the second does. A roll from the second pool wins if it shows no duplicates but a roll from the first does. Otherwise, it\u2019s a tie (i.e., if neither or both rolls show duplicates). Let\u2019s compare how three six-sided dice fair against two four-sided dice. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> from enum import IntEnum >>> class DupeVs ( IntEnum ): ... SECOND_WINS = - 1 # where second_roll shows no duplicates, but first_roll does ... TIE = 0 # where both rolls show no duplicates or rolls pools have duplicates ... FIRST_WINS = 1 # where first_roll shows no duplicates, but second_roll does >>> def compare_fours ( first_roll , second_roll ): ... return DupeVs (( len ( set ( first_roll )) == len ( first_roll )) - ( len ( set ( second_roll )) == len ( second_roll ))) >>> h = P . foreach ( compare_fours , first_roll = P ( 6 , 6 , 6 ), second_roll = P ( 4 , 4 )) ; h H ({ < DupeVs . SECOND_WINS : - 1 > : 12 , < DupeVs . TIE : 0 > : 19 , < DupeVs . FIRST_WINS : 1 > : 5 }) >>> print ( h . format ()) avg | - 0.19 std | 0.66 var | 0.43 - 1 | 33.33 % | ################ 0 | 52.78 % | ########################## 1 | 13.89 % | ###### Visualization H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib . In addition, anydyce provides additional visualization and interactivity conveniences. (Many of the figures in these docs leverage anydyce in their construction.) Source: plot_histogram.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_bar from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_bar ( ax , [( \"\" , 3 @ H ( 6 ))]) ax . set_title ( \"Distribution for 3d6\" , color = text_color ) Time to get meta-evil on those outcomes! Thanks to numerary , dyce offers best-effort support for arbitrary number-like outcomes, including primitives from symbolic expression packages such as SymPy . 1 2 3 4 5 >>> import sympy.abc >>> d6x = H ( 6 ) + sympy . abc . x >>> d8y = H ( 8 ) + sympy . abc . y >>> P ( d6x , d8y , d6x ) . h () H ({ 2 * x + y + 3 : 1 , 2 * x + y + 4 : 3 , 2 * x + y + 5 : 6 , ... , 2 * x + y + 18 : 6 , 2 * x + y + 19 : 3 , 2 * x + y + 20 : 1 }) Note Be aware that, depending on implementation, performance can suffer quite a bit when using symbolic primitives. For histograms and pools, dyce remains opinionated about ordering. For non-critical contexts where relative values are indeterminate, dyce will attempt a \u201cnatural\u201d ordering based on the string representation of each outcome. This is to accommodate symbolic expressions whose relative values are often unknowable. 1 2 3 4 5 6 >>> expr = sympy . abc . x < sympy . abc . x * 3 ; expr x < 3 * x >>> bool ( expr ) # nope Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational SymPy does not even attempt simple relative comparisons between symbolic expressions, even where they are unambiguously resolvable. Instead, it relies on the caller to invoke its proprietary solver APIs. 1 2 3 4 5 6 7 >>> bool ( sympy . abc . x < sympy . abc . x + 1 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> import sympy.solvers.inequalities >>> sympy . solvers . inequalities . reduce_inequalities ( sympy . abc . x < sympy . abc . x + 1 , [ sympy . abc . x ]) True dyce , of course, is happily ignorant of all that keenness. (As it should be.) In practice, that means that certain operations won\u2019t work with symbolic expressions where correctness depends on ordering outcomes according to relative value (e.g., dice selection from pools). Flattening pools works. 1 2 3 4 5 >>> d3x = H ( 3 ) * sympy . abc . x ; d3x H ({ 2 * x : 1 , 3 * x : 1 , x : 1 }) >>> p = P ( d3x / 3 , ( d3x + 1 ) / 3 , ( d3x + 2 ) / 3 ) >>> p . h () H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Selecting the \u201clowest\u201d die doesn\u2019t. 1 2 3 4 >>> p . h ( 0 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational Selecting all dice works, since it\u2019s equivalent to flattening (no sorting is required). 1 2 >>> p . h ( slice ( None )) H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Enumerating rolls doesn\u2019t, even where there is no selection, because each roll\u2019s outcomes are sorted least-to-greatest. 1 2 3 4 >>> list ( p . rolls_with_counts ()) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational P.roll \u201cworks\u201d (i.e., falls back to natural ordering of outcomes), but that is a deliberate compromise of convenience. 1 2 >>> p . roll () # doctest: +SKIP ( 2 * x / 3 , 2 * x / 3 + 1 / 3 , x / 3 + 2 / 3 ) P.umap can help pave the way back to concrete outcomes. 1 2 3 4 5 >>> f = lambda outcome : outcome . subs ({ sympy . abc . x : sympy . Rational ( 1 , 3 )}) >>> p . umap ( f ) P ( H ({ 1 / 9 : 1 , 2 / 9 : 1 , 1 / 3 : 1 }), H ({ 4 / 9 : 1 , 5 / 9 : 1 , 2 / 3 : 1 }), H ({ 7 / 9 : 1 , 8 / 9 : 1 , 1 : 1 })) >>> p . umap ( f ) . h ( - 1 ) H ({ 7 / 9 : 9 , 8 / 9 : 9 , 1 : 9 }) Further exploration Consider delving into some applications and translations for more sophisticated examples, or jump right into the API . Anywhere you see a Binder logo , you can click on it to immediately start tinkering with a temporal instance of that example using anydyce . Just be aware that Binder will eventually delete any changes, so make sure to download any notebooks you want to preserve. dyce also provides additional primitives ( R objects and their kin) which are useful for producing weighted randomized rolls without the overhead of enumeration. These are covered seperately . \u21a9","title":"Countin\u2019 with histograms and pools"},{"location":"countin/#basic-examples","text":"A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H ( n ) is shorthand for explicitly enumerating outcomes \\([{ {1} .. {n} }]\\) , each with a frequency of 1. 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> P ( H ( 6 ), H ( 6 )) P ( 6 , 6 ) Where n is an integer, P ( n , ... ) is shorthand for P ( H ( n ), ... ) . Python\u2019s matrix multiplication operator ( @ ) can also be used with pools. The above can be expressed more succinctly. 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case, Sicherman dice ) can be compared to histograms. 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. Histograms provide rudimentary formatting for convenience. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ()) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # The Miwin-Distribution is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 >>> miwin_iii = H (( 1 , 2 , 5 , 6 , 7 , 9 )) >>> miwin_iv = H (( 1 , 3 , 4 , 5 , 8 , 9 )) >>> miwin_v = H (( 2 , 3 , 4 , 6 , 7 , 8 )) >>> miwin_dist = miwin_iii + miwin_iv + miwin_v ; miwin_dist H ({ 4 : 1 , 5 : 2 , 6 : 3 , 7 : 4 , 8 : 7 , ... , 22 : 7 , 23 : 4 , 24 : 3 , 25 : 2 , 26 : 1 }) >>> print (( miwin_dist ) . format ( scaled = True )) avg | 15.00 std | 4.47 var | 20.00 4 | 0.46 % | ## 5 | 0.93 % | ##### 6 | 1.39 % | ####### 7 | 1.85 % | ########## 8 | 3.24 % | ################## 9 | 4.17 % | ####################### 10 | 4.63 % | ########################## 11 | 5.09 % | ############################ 12 | 7.87 % | ############################################ 13 | 8.80 % | ################################################# 14 | 8.33 % | ############################################### 15 | 6.48 % | #################################### 16 | 8.33 % | ############################################### 17 | 8.80 % | ################################################# 18 | 7.87 % | ############################################ 19 | 5.09 % | ############################ 20 | 4.63 % | ########################## 21 | 4.17 % | ####################### 22 | 3.24 % | ################## 23 | 1.85 % | ########## 24 | 1.39 % | ####### 25 | 0.93 % | ##### 26 | 0.46 % | ## One way to model the outcomes of subtracting the lesser of two six-sided dice from the greater is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms. 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest with negative values counting from the right, as one would expect (i.e., [ 0 ] , [ 1 ] , \u2026, [ - 2 ] , [ - 1 ] ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ()) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ()) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ()) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable. 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool. 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 3 ] P ( 4 , 6 ) An inefficient way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . is_even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( f \" { n : >2 } d6: { all_even [ 1 ] / sum ( all_even . counts ()) : >6.2% } \" ) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher on any single die when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> # By the time we're rolling a third die, we're guaranteed a nine or higher, so we only need to look that far >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( f \" { n : >2 } d6-exploding: { at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()) : >6.2% } \" ) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 %","title":"Basic examples"},{"location":"countin/#dependent-probabilities","text":"Where we can identify independent terms and reduce the dependent term to a calculation solely involving independent terms, dependent probabilities can often be compactly expressed via H.substitute , H.foreach , or P.foreach . First, we express independent terms as histograms or pools. Second, we express the dependent term as a callback function. Finally, we can pass the dependent callback function to H.substitute , H.foreach , or P.foreach , along with the independent terms (as arguments in the cases of the latter two). H.substitute is well suited to situations with a single independent term that can be expressed as a histogram. Say we want to roll a d6 and compare whether the result is strictly greater than its distance from some constant. 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6 = H ( 6 ) # independent term >>> constant = 4 >>> def outcome_vs_distance_to_constant ( __ : H , d6_outcome ): ... return d6_outcome > abs ( d6_outcome - constant ) # dependent term >>> print ( d6 . substitute ( outcome_vs_distance_to_constant ) . format ()) avg | 0.67 std | 0.47 var | 0.22 0 | 33.33 % | ################ 1 | 66.67 % | ################################# Instead of a constant, let\u2019s use another die as a second independent term. We\u2019ll roll a d4 and a d6 and compare whether the d6 is strictly greater than the absolute difference between dice. For multiple independent terms that can be expressed as histograms, the H.foreach class method is often easiest. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 = H ( 4 ) # first independent term >>> d6 = H ( 6 ) # second independent term >>> def outcome_vs_difference_dependent_term ( d4_outcome , d6_outcome ): ... return d6_outcome > abs ( d4_outcome - d6_outcome ) # dependent term >>> h = H . foreach ( outcome_vs_difference_dependent_term , d4_outcome = d4 , d6_outcome = d6 ) >>> print ( h . format ()) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### In the alternative, one could nest substitution functions, where the innermost holds the dependent term, and the outer functions each establish the scope of their respective independent outcomes. However, this isn\u2019t very readable, and is often less efficient than using H.foreach class method . 1 2 3 4 5 6 7 >>> def sub_d4 ( __ : H , d4_outcome ): ... def sub_d6 ( __ : H , d6_outcome ): ... return d6_outcome > abs ( d4_outcome - d6_outcome ) ... return d6 . substitute ( sub_d6 ) >>> d4 . substitute ( sub_d4 ) == h True Where the dependent term requires inspection of rolls from one or more pools as independent terms, P.foreach class method is useful. Let\u2019s say we have two pools. A roll from the first pool wins if it shows no duplicates but a roll from the second does. A roll from the second pool wins if it shows no duplicates but a roll from the first does. Otherwise, it\u2019s a tie (i.e., if neither or both rolls show duplicates). Let\u2019s compare how three six-sided dice fair against two four-sided dice. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> from enum import IntEnum >>> class DupeVs ( IntEnum ): ... SECOND_WINS = - 1 # where second_roll shows no duplicates, but first_roll does ... TIE = 0 # where both rolls show no duplicates or rolls pools have duplicates ... FIRST_WINS = 1 # where first_roll shows no duplicates, but second_roll does >>> def compare_fours ( first_roll , second_roll ): ... return DupeVs (( len ( set ( first_roll )) == len ( first_roll )) - ( len ( set ( second_roll )) == len ( second_roll ))) >>> h = P . foreach ( compare_fours , first_roll = P ( 6 , 6 , 6 ), second_roll = P ( 4 , 4 )) ; h H ({ < DupeVs . SECOND_WINS : - 1 > : 12 , < DupeVs . TIE : 0 > : 19 , < DupeVs . FIRST_WINS : 1 > : 5 }) >>> print ( h . format ()) avg | - 0.19 std | 0.66 var | 0.43 - 1 | 33.33 % | ################ 0 | 52.78 % | ########################## 1 | 13.89 % | ######","title":"Dependent probabilities"},{"location":"countin/#visualization","text":"H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib . In addition, anydyce provides additional visualization and interactivity conveniences. (Many of the figures in these docs leverage anydyce in their construction.) Source: plot_histogram.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_bar from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_bar ( ax , [( \"\" , 3 @ H ( 6 ))]) ax . set_title ( \"Distribution for 3d6\" , color = text_color )","title":"Visualization"},{"location":"countin/#time-to-get-meta-evil-on-those-outcomes","text":"Thanks to numerary , dyce offers best-effort support for arbitrary number-like outcomes, including primitives from symbolic expression packages such as SymPy . 1 2 3 4 5 >>> import sympy.abc >>> d6x = H ( 6 ) + sympy . abc . x >>> d8y = H ( 8 ) + sympy . abc . y >>> P ( d6x , d8y , d6x ) . h () H ({ 2 * x + y + 3 : 1 , 2 * x + y + 4 : 3 , 2 * x + y + 5 : 6 , ... , 2 * x + y + 18 : 6 , 2 * x + y + 19 : 3 , 2 * x + y + 20 : 1 }) Note Be aware that, depending on implementation, performance can suffer quite a bit when using symbolic primitives. For histograms and pools, dyce remains opinionated about ordering. For non-critical contexts where relative values are indeterminate, dyce will attempt a \u201cnatural\u201d ordering based on the string representation of each outcome. This is to accommodate symbolic expressions whose relative values are often unknowable. 1 2 3 4 5 6 >>> expr = sympy . abc . x < sympy . abc . x * 3 ; expr x < 3 * x >>> bool ( expr ) # nope Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational SymPy does not even attempt simple relative comparisons between symbolic expressions, even where they are unambiguously resolvable. Instead, it relies on the caller to invoke its proprietary solver APIs. 1 2 3 4 5 6 7 >>> bool ( sympy . abc . x < sympy . abc . x + 1 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> import sympy.solvers.inequalities >>> sympy . solvers . inequalities . reduce_inequalities ( sympy . abc . x < sympy . abc . x + 1 , [ sympy . abc . x ]) True dyce , of course, is happily ignorant of all that keenness. (As it should be.) In practice, that means that certain operations won\u2019t work with symbolic expressions where correctness depends on ordering outcomes according to relative value (e.g., dice selection from pools). Flattening pools works. 1 2 3 4 5 >>> d3x = H ( 3 ) * sympy . abc . x ; d3x H ({ 2 * x : 1 , 3 * x : 1 , x : 1 }) >>> p = P ( d3x / 3 , ( d3x + 1 ) / 3 , ( d3x + 2 ) / 3 ) >>> p . h () H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Selecting the \u201clowest\u201d die doesn\u2019t. 1 2 3 4 >>> p . h ( 0 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational Selecting all dice works, since it\u2019s equivalent to flattening (no sorting is required). 1 2 >>> p . h ( slice ( None )) H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Enumerating rolls doesn\u2019t, even where there is no selection, because each roll\u2019s outcomes are sorted least-to-greatest. 1 2 3 4 >>> list ( p . rolls_with_counts ()) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational P.roll \u201cworks\u201d (i.e., falls back to natural ordering of outcomes), but that is a deliberate compromise of convenience. 1 2 >>> p . roll () # doctest: +SKIP ( 2 * x / 3 , 2 * x / 3 + 1 / 3 , x / 3 + 2 / 3 ) P.umap can help pave the way back to concrete outcomes. 1 2 3 4 5 >>> f = lambda outcome : outcome . subs ({ sympy . abc . x : sympy . Rational ( 1 , 3 )}) >>> p . umap ( f ) P ( H ({ 1 / 9 : 1 , 2 / 9 : 1 , 1 / 3 : 1 }), H ({ 4 / 9 : 1 , 5 / 9 : 1 , 2 / 3 : 1 }), H ({ 7 / 9 : 1 , 8 / 9 : 1 , 1 : 1 })) >>> p . umap ( f ) . h ( - 1 ) H ({ 7 / 9 : 9 , 8 / 9 : 9 , 1 : 9 })","title":"Time to get meta-evil on those outcomes!"},{"location":"countin/#further-exploration","text":"Consider delving into some applications and translations for more sophisticated examples, or jump right into the API . Anywhere you see a Binder logo , you can click on it to immediately start tinkering with a temporal instance of that example using anydyce . Just be aware that Binder will eventually delete any changes, so make sure to download any notebooks you want to preserve. dyce also provides additional primitives ( R objects and their kin) which are useful for producing weighted randomized rolls without the overhead of enumeration. These are covered seperately . \u21a9","title":"Further exploration"},{"location":"dyce.h/","text":"dyce . h package reference HableOpsMixin A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HableT protocol . The P class derives from this class. Info See HableT for notes on pronunciation. Source code in dyce/h.py class HableOpsMixin : r \"\"\" A \u201cmix-in\u201d class providing arithmetic operations for implementers of the [``HableT`` protocol][dyce.h.HableT]. The [``P`` class][dyce.p.P] derives from this class. !!! info See [``HableT``][dyce.h.HableT] for notes on pronunciation. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () @beartype def __add__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( self . h (), other ) @beartype def __radd__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( other , self . h ()) @beartype def __sub__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( self . h (), other ) @beartype def __rsub__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( other , self . h ()) @beartype def __mul__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( self . h (), other ) @beartype def __rmul__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( other , self . h ()) @beartype def __truediv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( self . h (), other ) @beartype def __rtruediv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( other , self . h ()) @beartype def __floordiv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( self . h (), other ) @beartype def __rfloordiv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( other , self . h ()) @beartype def __mod__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( self . h (), other ) @beartype def __rmod__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( other , self . h ()) @beartype def __pow__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( self . h (), other ) @beartype def __rpow__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( other , self . h ()) @beartype def __and__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( self . h (), other ) @beartype def __rand__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( other , self . h ()) @beartype def __xor__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( self . h (), other ) @beartype def __rxor__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( other , self . h ()) @beartype def __or__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( self . h (), other ) @beartype def __ror__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( other , self . h ()) @beartype def __neg__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__neg__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __neg__ ( self . h ()) @beartype def __pos__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pos__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pos__ ( self . h ()) @beartype def __abs__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__abs__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __abs__ ( self . h ()) @beartype def __invert__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__invert__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __invert__ ( self . h ()) @beartype def lt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().lt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other ) @beartype def le ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().le(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other ) @beartype def eq ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().eq(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other ) @beartype def ne ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ne(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other ) @beartype def gt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().gt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other ) @beartype def ge ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ge(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other ) @beartype def is_even ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_even()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_even``][dyce.h.H.is_even]. \"\"\" return self . h () . is_even () @beartype def is_odd ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_odd()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_odd``][dyce.h.H.is_odd]. \"\"\" return self . h () . is_odd () @beartype def explode ( self : HableT , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().explode(max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth , precision_limit ) @beartype def substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().substitute(expand, coalesce, max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth , precision_limit ) @beartype def within ( self : HableT , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``#!python self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other ) __slots__ : Union [ str , Iterable [ str ]] special __abs__ ( self : HableT ) -> H special Shorthand for operator . __abs__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __abs__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__abs__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __abs__ ( self . h ()) __add__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __add__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __add__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( self . h (), other ) __and__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H special Shorthand for operator . __and__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __and__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( self . h (), other ) __floordiv__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __floordiv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __floordiv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( self . h (), other ) __invert__ ( self : HableT ) -> H special Shorthand for operator . __invert__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __invert__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__invert__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __invert__ ( self . h ()) __mod__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __mod__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mod__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( self . h (), other ) __mul__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __mul__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mul__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( self . h (), other ) __neg__ ( self : HableT ) -> H special Shorthand for operator . __neg__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __neg__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__neg__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __neg__ ( self . h ()) __or__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H special Shorthand for operator . __or__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __or__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( self . h (), other ) __pos__ ( self : HableT ) -> H special Shorthand for operator . __pos__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __pos__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pos__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pos__ ( self . h ()) __pow__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __pow__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __pow__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( self . h (), other ) __radd__ ( self : HableT , other : RealLike ) -> H special Shorthand for operator . __add__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __radd__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( other , self . h ()) __rand__ ( self : HableT , other : SupportsInt ) -> H special Shorthand for operator . __and__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rand__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( other , self . h ()) __rfloordiv__ ( self : HableT , other : RealLike ) -> H special Shorthand for operator . __floordiv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rfloordiv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( other , self . h ()) __rmod__ ( self : HableT , other : RealLike ) -> H special Shorthand for operator . __mod__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmod__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( other , self . h ()) __rmul__ ( self : HableT , other : RealLike ) -> H special Shorthand for operator . __mul__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmul__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( other , self . h ()) __ror__ ( self : HableT , other : SupportsInt ) -> H special Shorthand for operator . __or__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __ror__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( other , self . h ()) __rpow__ ( self : HableT , other : RealLike ) -> H special Shorthand for operator . __pow__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rpow__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( other , self . h ()) __rsub__ ( self : HableT , other : RealLike ) -> H special Shorthand for operator . __sub__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rsub__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( other , self . h ()) __rtruediv__ ( self : HableT , other : RealLike ) -> H special Shorthand for operator . __truediv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rtruediv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( other , self . h ()) __rxor__ ( self : HableT , other : SupportsInt ) -> H special Shorthand for operator . __xor__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rxor__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( other , self . h ()) __sub__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __sub__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __sub__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( self . h (), other ) __truediv__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __truediv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __truediv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( self . h (), other ) __xor__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H special Shorthand for operator . __xor__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __xor__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( self . h (), other ) eq ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . eq ( other ) . See the h method and H.eq . Source code in dyce/h.py @beartype def eq ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().eq(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other ) explode ( self : HableT , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 , 1 )) -> H Shorthand for self . h () . explode ( max_depth , precision_limit ) . See the h method and H.explode . Source code in dyce/h.py @beartype def explode ( self : HableT , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().explode(max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth , precision_limit ) ge ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . ge ( other ) . See the h method and H.ge . Source code in dyce/h.py @beartype def ge ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ge(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other ) gt ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . gt ( other ) . See the h method and H.gt . Source code in dyce/h.py @beartype def gt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().gt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other ) is_even ( self : HableT ) -> H Shorthand for self . h () . is_even () . See the h method and H.is_even . Source code in dyce/h.py @beartype def is_even ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_even()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_even``][dyce.h.H.is_even]. \"\"\" return self . h () . is_even () is_odd ( self : HableT ) -> H Shorthand for self . h () . is_odd () . See the h method and H.is_odd . Source code in dyce/h.py @beartype def is_odd ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_odd()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_odd``][dyce.h.H.is_odd]. \"\"\" return self . h () . is_odd () le ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . le ( other ) . See the h method and H.le . Source code in dyce/h.py @beartype def le ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().le(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other ) lt ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . lt ( other ) . See the h method and H.lt . Source code in dyce/h.py @beartype def lt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().lt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other ) ne ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . ne ( other ) . See the h method and H.ne . Source code in dyce/h.py @beartype def ne ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ne(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other ) substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = < function coalesce_replace at 0x10609d040 > , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 , 1 )) -> H Shorthand for self . h () . substitute ( expand , coalesce , max_depth , precision_limit ) . See the h method and H.substitute . Source code in dyce/h.py @beartype def substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().substitute(expand, coalesce, max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth , precision_limit ) within ( self : HableT , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H Shorthand for self . h () . within ( lo , hi , other ) . See the h method and H.within . Source code in dyce/h.py @beartype def within ( self : HableT , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``#!python self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other ) HableT ( Protocol ) A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users. Info The intended pronunciation of Hable is AYCH-uh-bul 1 (i.e., H -able). Yes, that is a clumsy attempt at verbing . (You could totally H that, dude!) However, if you prefer something else (e.g. HAY-bul or AYCH-AY-bul ), no one is going to judge you. (Well, they might , but they shouldn\u2019t .) We all know what you mean. World Book Online (WBO) style pronunciation respelling . \u21a9 Source code in dyce/h.py @runtime_checkable class HableT ( Protocol , metaclass = CachingProtocolMeta , ): r \"\"\" A protocol whose implementer can be expressed as (or reduced to) an [``H`` object][dyce.h.H] by calling its [``h`` method][dyce.h.HableT.h]. Currently, only the [``P`` class][dyce.p.P] implements this protocol, but this affords an integration point for ``#!python dyce`` users. !!! info The intended pronunciation of ``Hable`` is *AYCH-uh-bul*[^1] (i.e., [``H``][dyce.h.H]-able). Yes, that is a clumsy attempt at [verbing](https://www.gocomics.com/calvinandhobbes/1993/01/25). (You could *totally* [``H``][dyce.h.H] that, dude!) However, if you prefer something else (e.g. *HAY-bul* or *AYCH-AY-bul*), no one is going to judge you. (Well, they *might*, but they *shouldn\u2019t*.) We all know what you mean. [^1]: World Book Online (WBO) style [pronunciation respelling](https://en.wikipedia.org/wiki/Pronunciation_respelling_for_English#Traditional_respelling_systems). \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ... __slots__ : Union [ str , Iterable [ str ]] special __init__ ( self , * args , ** kwargs ) special Source code in dyce/h.py def _no_init ( self , * args , ** kwargs ): raise TypeError ( 'Protocols cannot be instantiated' ) __subclasshook__ ( other ) special Source code in dyce/h.py def _proto_hook ( other ): if not cls . __dict__ . get ( '_is_protocol' , False ): return NotImplemented # First, perform various sanity checks. if not getattr ( cls , '_is_runtime_protocol' , False ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Instance and class checks can only be used with\" \" @runtime_checkable protocols\" ) if not _is_callable_members_only ( cls ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Protocols with non-method members\" \" don't support issubclass()\" ) if not isinstance ( other , type ): # Same error message as for issubclass(1, int). raise TypeError ( 'issubclass() arg 1 must be a class' ) # Second, perform the actual structural compatibility check. for attr in _get_protocol_attrs ( cls ): for base in other . __mro__ : # Check if the members appears in the class dictionary... if attr in base . __dict__ : if base . __dict__ [ attr ] is None : return NotImplemented break # ...or in annotations, if it is a sub-protocol. annotations = getattr ( base , '__annotations__' , {}) if ( isinstance ( annotations , collections . abc . Mapping ) and attr in annotations and issubclass ( other , Generic ) and other . _is_protocol ): break else : return NotImplemented return True h ( self ) -> H Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ... aggregate_with_counts ( source_counts : Iterable [ Tuple [ Union [ H , RealLike ], int ]], h_type : Type [ H ] = < class ' dyce . h . H '>) -> H Aggregates source_counts into an H object . Each source_count is a two-tuple of either an outcome-count pair or a histogram-count pair. This function is used in the implementation of the H.substitute and P.foreach methods. Unlike those, the histogram returned from this function is not reduced to its lowest terms. In nearly all cases, when a source contains a histogram, it takes on the corresponding count\u2019s \u201cscale\u201d. In other words, the sum of the counts of the histogram retains the same proportion as the count in relation to other outcomes. This becomes clearer when there is no overlap between the histogram and the other outcomes. 1 2 3 4 >>> from dyce.h import aggregate_with_counts >>> source_counts = (( H ( 3 ), 3 ), ( H ( - 3 ), 2 )) >>> h = aggregate_with_counts ( source_counts ) . lowest_terms () ; h H ({ - 3 : 2 , - 2 : 2 , - 1 : 2 , 1 : 3 , 2 : 3 , 3 : 3 }) An important exception If a source is the empty histogram ( H({}) ), it and its count is omitted from the result without scaling. 1 2 3 >>> source_counts = (( H ( 2 ), 1 ), ( H ({}), 20 )) >>> aggregate_with_counts ( source_counts ) H ({ 1 : 1 , 2 : 1 }) Source code in dyce/h.py @beartype def aggregate_with_counts ( source_counts : Iterable [ Tuple [ Union [ H , RealLike ], int ]], h_type : Type [ H ] = H , ) -> H : r \"\"\" Aggregates *source_counts* into an [``H`` object][dyce.h.H]. Each source_count is a two-tuple of either an outcome-count pair or a histogram-count pair. This function is used in the implementation of the [``H.substitute``][dyce.h.H.substitute] and [``P.foreach``][dyce.p.P.foreach] methods. Unlike those, the histogram returned from this function is *not* reduced to its lowest terms. In nearly all cases, when a source contains a histogram, it takes on the corresponding count\u2019s \u201cscale\u201d. In other words, the sum of the counts of the histogram retains the same proportion as the count in relation to other outcomes. This becomes clearer when there is no overlap between the histogram and the other outcomes. ``` python >>> from dyce.h import aggregate_with_counts >>> source_counts = ((H(3), 3), (H(-3), 2)) >>> h = aggregate_with_counts(source_counts).lowest_terms() ; h H({-3: 2, -2: 2, -1: 2, 1: 3, 2: 3, 3: 3}) ``` !!! note \"An important exception\" If a source is the empty histogram (``H({})``), it and its count is omitted from the result without scaling. ``` python >>> source_counts = ((H(2), 1), (H({}), 20)) >>> aggregate_with_counts(source_counts) H({1: 1, 2: 1}) ``` \"\"\" aggregate_scalar = 1 outcome_counts : List [ Tuple [ RealLike , int ]] = [] for outcome_or_h , count in source_counts : if isinstance ( outcome_or_h , H ): if outcome_or_h : h_scalar = outcome_or_h . total for i , ( prior_outcome , prior_count ) in enumerate ( outcome_counts ): outcome_counts [ i ] = ( prior_outcome , prior_count * h_scalar ) for new_outcome , new_count in outcome_or_h . items (): outcome_counts . append ( ( new_outcome , count * aggregate_scalar * new_count ) ) aggregate_scalar *= h_scalar else : outcome_counts . append (( outcome_or_h , count * aggregate_scalar )) return h_type ( outcome_counts ) coalesce_replace ( h : H , outcome : RealLike ) -> H Default behavior for H.substitute . Returns h unmodified ( outcome is ignored). Source code in dyce/h.py def coalesce_replace ( h : H , outcome : RealLike ) -> H : r \"\"\" Default behavior for [``H.substitute``][dyce.h.H.substitute]. Returns *h* unmodified (*outcome* is ignored). \"\"\" return h resolve_dependent_probability ( dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : _SourceT ) -> H Deprecated This function has been moved to the H.foreach class method. This alias will be removed in a future release. Shorthand for H . foreach ( dependent_term , ** independent_sources ) . Source code in dyce/h.py @deprecated def resolve_dependent_probability ( dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : _SourceT , ) -> H : r \"\"\" !!! warning \"Deprecated\" This function has been moved to the [``H.foreach``][dyce.h.H.foreach] class method. This alias will be removed in a future release. Shorthand for ``#!python H.foreach(dependent_term, **independent_sources)``. \"\"\" return H . foreach ( dependent_term , ** independent_sources ) sum_h ( hs : Iterable [ H ]) Shorthand for H ({}) if h_sum == 0 else sum ( hs ) . This is to ensure that summing zero or more histograms always returns a histograms. Source code in dyce/h.py @beartype def sum_h ( hs : Iterable [ H ]): \"\"\" Shorthand for ``#!python H({}) if h_sum == 0 else sum(hs)``. This is to ensure that summing zero or more histograms always returns a histograms. \"\"\" h_sum = sum ( hs ) return H ({}) if h_sum == 0 else h_sum","title":"<tt>dyce.h</tt>"},{"location":"dyce.h/#dyceh-package-reference","text":"","title":"dyce.h package reference"},{"location":"dyce.h/#dyce.h.HableOpsMixin","text":"A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HableT protocol . The P class derives from this class. Info See HableT for notes on pronunciation. Source code in dyce/h.py class HableOpsMixin : r \"\"\" A \u201cmix-in\u201d class providing arithmetic operations for implementers of the [``HableT`` protocol][dyce.h.HableT]. The [``P`` class][dyce.p.P] derives from this class. !!! info See [``HableT``][dyce.h.HableT] for notes on pronunciation. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () @beartype def __add__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( self . h (), other ) @beartype def __radd__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( other , self . h ()) @beartype def __sub__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( self . h (), other ) @beartype def __rsub__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( other , self . h ()) @beartype def __mul__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( self . h (), other ) @beartype def __rmul__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( other , self . h ()) @beartype def __truediv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( self . h (), other ) @beartype def __rtruediv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( other , self . h ()) @beartype def __floordiv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( self . h (), other ) @beartype def __rfloordiv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( other , self . h ()) @beartype def __mod__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( self . h (), other ) @beartype def __rmod__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( other , self . h ()) @beartype def __pow__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( self . h (), other ) @beartype def __rpow__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( other , self . h ()) @beartype def __and__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( self . h (), other ) @beartype def __rand__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( other , self . h ()) @beartype def __xor__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( self . h (), other ) @beartype def __rxor__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( other , self . h ()) @beartype def __or__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( self . h (), other ) @beartype def __ror__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( other , self . h ()) @beartype def __neg__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__neg__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __neg__ ( self . h ()) @beartype def __pos__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pos__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pos__ ( self . h ()) @beartype def __abs__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__abs__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __abs__ ( self . h ()) @beartype def __invert__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__invert__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __invert__ ( self . h ()) @beartype def lt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().lt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other ) @beartype def le ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().le(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other ) @beartype def eq ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().eq(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other ) @beartype def ne ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ne(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other ) @beartype def gt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().gt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other ) @beartype def ge ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ge(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other ) @beartype def is_even ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_even()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_even``][dyce.h.H.is_even]. \"\"\" return self . h () . is_even () @beartype def is_odd ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_odd()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_odd``][dyce.h.H.is_odd]. \"\"\" return self . h () . is_odd () @beartype def explode ( self : HableT , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().explode(max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth , precision_limit ) @beartype def substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().substitute(expand, coalesce, max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth , precision_limit ) @beartype def within ( self : HableT , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``#!python self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"HableOpsMixin"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__slots__","text":"","title":"__slots__"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__abs__","text":"Shorthand for operator . __abs__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __abs__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__abs__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __abs__ ( self . h ())","title":"__abs__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__add__","text":"Shorthand for operator . __add__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __add__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( self . h (), other )","title":"__add__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__and__","text":"Shorthand for operator . __and__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __and__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( self . h (), other )","title":"__and__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__floordiv__","text":"Shorthand for operator . __floordiv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __floordiv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( self . h (), other )","title":"__floordiv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__invert__","text":"Shorthand for operator . __invert__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __invert__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__invert__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __invert__ ( self . h ())","title":"__invert__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__mod__","text":"Shorthand for operator . __mod__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mod__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( self . h (), other )","title":"__mod__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__mul__","text":"Shorthand for operator . __mul__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mul__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( self . h (), other )","title":"__mul__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__neg__","text":"Shorthand for operator . __neg__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __neg__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__neg__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __neg__ ( self . h ())","title":"__neg__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__or__","text":"Shorthand for operator . __or__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __or__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( self . h (), other )","title":"__or__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__pos__","text":"Shorthand for operator . __pos__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __pos__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pos__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pos__ ( self . h ())","title":"__pos__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__pow__","text":"Shorthand for operator . __pow__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __pow__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( self . h (), other )","title":"__pow__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__radd__","text":"Shorthand for operator . __add__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __radd__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( other , self . h ())","title":"__radd__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rand__","text":"Shorthand for operator . __and__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rand__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( other , self . h ())","title":"__rand__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rfloordiv__","text":"Shorthand for operator . __floordiv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rfloordiv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( other , self . h ())","title":"__rfloordiv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rmod__","text":"Shorthand for operator . __mod__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmod__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( other , self . h ())","title":"__rmod__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rmul__","text":"Shorthand for operator . __mul__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmul__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( other , self . h ())","title":"__rmul__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__ror__","text":"Shorthand for operator . __or__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __ror__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( other , self . h ())","title":"__ror__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rpow__","text":"Shorthand for operator . __pow__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rpow__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( other , self . h ())","title":"__rpow__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rsub__","text":"Shorthand for operator . __sub__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rsub__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( other , self . h ())","title":"__rsub__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rtruediv__","text":"Shorthand for operator . __truediv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rtruediv__ ( self : HableT , other : RealLike ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( other , self . h ())","title":"__rtruediv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rxor__","text":"Shorthand for operator . __xor__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rxor__ ( self : HableT , other : SupportsInt ) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( other , self . h ())","title":"__rxor__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__sub__","text":"Shorthand for operator . __sub__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __sub__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( self . h (), other )","title":"__sub__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__truediv__","text":"Shorthand for operator . __truediv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __truediv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( self . h (), other )","title":"__truediv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__xor__","text":"Shorthand for operator . __xor__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __xor__ ( self : HableT , other : Union [ SupportsInt , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( self . h (), other )","title":"__xor__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.eq","text":"Shorthand for self . h () . eq ( other ) . See the h method and H.eq . Source code in dyce/h.py @beartype def eq ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().eq(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other )","title":"eq()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.explode","text":"Shorthand for self . h () . explode ( max_depth , precision_limit ) . See the h method and H.explode . Source code in dyce/h.py @beartype def explode ( self : HableT , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().explode(max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth , precision_limit )","title":"explode()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.ge","text":"Shorthand for self . h () . ge ( other ) . See the h method and H.ge . Source code in dyce/h.py @beartype def ge ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ge(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other )","title":"ge()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.gt","text":"Shorthand for self . h () . gt ( other ) . See the h method and H.gt . Source code in dyce/h.py @beartype def gt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().gt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other )","title":"gt()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.is_even","text":"Shorthand for self . h () . is_even () . See the h method and H.is_even . Source code in dyce/h.py @beartype def is_even ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_even()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_even``][dyce.h.H.is_even]. \"\"\" return self . h () . is_even ()","title":"is_even()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.is_odd","text":"Shorthand for self . h () . is_odd () . See the h method and H.is_odd . Source code in dyce/h.py @beartype def is_odd ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_odd()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_odd``][dyce.h.H.is_odd]. \"\"\" return self . h () . is_odd ()","title":"is_odd()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.le","text":"Shorthand for self . h () . le ( other ) . See the h method and H.le . Source code in dyce/h.py @beartype def le ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().le(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other )","title":"le()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.lt","text":"Shorthand for self . h () . lt ( other ) . See the h method and H.lt . Source code in dyce/h.py @beartype def lt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().lt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other )","title":"lt()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.ne","text":"Shorthand for self . h () . ne ( other ) . See the h method and H.ne . Source code in dyce/h.py @beartype def ne ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ne(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other )","title":"ne()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.substitute","text":"Shorthand for self . h () . substitute ( expand , coalesce , max_depth , precision_limit ) . See the h method and H.substitute . Source code in dyce/h.py @beartype def substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.h().substitute(expand, coalesce, max_depth, precision_limit)``. See the [``h`` method][dyce.h.HableT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth , precision_limit )","title":"substitute()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.within","text":"Shorthand for self . h () . within ( lo , hi , other ) . See the h method and H.within . Source code in dyce/h.py @beartype def within ( self : HableT , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``#!python self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"within()"},{"location":"dyce.h/#dyce.h.HableT","text":"A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users. Info The intended pronunciation of Hable is AYCH-uh-bul 1 (i.e., H -able). Yes, that is a clumsy attempt at verbing . (You could totally H that, dude!) However, if you prefer something else (e.g. HAY-bul or AYCH-AY-bul ), no one is going to judge you. (Well, they might , but they shouldn\u2019t .) We all know what you mean. World Book Online (WBO) style pronunciation respelling . \u21a9 Source code in dyce/h.py @runtime_checkable class HableT ( Protocol , metaclass = CachingProtocolMeta , ): r \"\"\" A protocol whose implementer can be expressed as (or reduced to) an [``H`` object][dyce.h.H] by calling its [``h`` method][dyce.h.HableT.h]. Currently, only the [``P`` class][dyce.p.P] implements this protocol, but this affords an integration point for ``#!python dyce`` users. !!! info The intended pronunciation of ``Hable`` is *AYCH-uh-bul*[^1] (i.e., [``H``][dyce.h.H]-able). Yes, that is a clumsy attempt at [verbing](https://www.gocomics.com/calvinandhobbes/1993/01/25). (You could *totally* [``H``][dyce.h.H] that, dude!) However, if you prefer something else (e.g. *HAY-bul* or *AYCH-AY-bul*), no one is going to judge you. (Well, they *might*, but they *shouldn\u2019t*.) We all know what you mean. [^1]: World Book Online (WBO) style [pronunciation respelling](https://en.wikipedia.org/wiki/Pronunciation_respelling_for_English#Traditional_respelling_systems). \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ...","title":"HableT"},{"location":"dyce.h/#dyce.h.HableT.__slots__","text":"","title":"__slots__"},{"location":"dyce.h/#dyce.h.HableT.__init__","text":"Source code in dyce/h.py def _no_init ( self , * args , ** kwargs ): raise TypeError ( 'Protocols cannot be instantiated' )","title":"__init__()"},{"location":"dyce.h/#dyce.h.HableT.__subclasshook__","text":"Source code in dyce/h.py def _proto_hook ( other ): if not cls . __dict__ . get ( '_is_protocol' , False ): return NotImplemented # First, perform various sanity checks. if not getattr ( cls , '_is_runtime_protocol' , False ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Instance and class checks can only be used with\" \" @runtime_checkable protocols\" ) if not _is_callable_members_only ( cls ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Protocols with non-method members\" \" don't support issubclass()\" ) if not isinstance ( other , type ): # Same error message as for issubclass(1, int). raise TypeError ( 'issubclass() arg 1 must be a class' ) # Second, perform the actual structural compatibility check. for attr in _get_protocol_attrs ( cls ): for base in other . __mro__ : # Check if the members appears in the class dictionary... if attr in base . __dict__ : if base . __dict__ [ attr ] is None : return NotImplemented break # ...or in annotations, if it is a sub-protocol. annotations = getattr ( base , '__annotations__' , {}) if ( isinstance ( annotations , collections . abc . Mapping ) and attr in annotations and issubclass ( other , Generic ) and other . _is_protocol ): break else : return NotImplemented return True","title":"__subclasshook__()"},{"location":"dyce.h/#dyce.h.HableT.h","text":"Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ...","title":"h()"},{"location":"dyce.h/#dyce.h.aggregate_with_counts","text":"Aggregates source_counts into an H object . Each source_count is a two-tuple of either an outcome-count pair or a histogram-count pair. This function is used in the implementation of the H.substitute and P.foreach methods. Unlike those, the histogram returned from this function is not reduced to its lowest terms. In nearly all cases, when a source contains a histogram, it takes on the corresponding count\u2019s \u201cscale\u201d. In other words, the sum of the counts of the histogram retains the same proportion as the count in relation to other outcomes. This becomes clearer when there is no overlap between the histogram and the other outcomes. 1 2 3 4 >>> from dyce.h import aggregate_with_counts >>> source_counts = (( H ( 3 ), 3 ), ( H ( - 3 ), 2 )) >>> h = aggregate_with_counts ( source_counts ) . lowest_terms () ; h H ({ - 3 : 2 , - 2 : 2 , - 1 : 2 , 1 : 3 , 2 : 3 , 3 : 3 }) An important exception If a source is the empty histogram ( H({}) ), it and its count is omitted from the result without scaling. 1 2 3 >>> source_counts = (( H ( 2 ), 1 ), ( H ({}), 20 )) >>> aggregate_with_counts ( source_counts ) H ({ 1 : 1 , 2 : 1 }) Source code in dyce/h.py @beartype def aggregate_with_counts ( source_counts : Iterable [ Tuple [ Union [ H , RealLike ], int ]], h_type : Type [ H ] = H , ) -> H : r \"\"\" Aggregates *source_counts* into an [``H`` object][dyce.h.H]. Each source_count is a two-tuple of either an outcome-count pair or a histogram-count pair. This function is used in the implementation of the [``H.substitute``][dyce.h.H.substitute] and [``P.foreach``][dyce.p.P.foreach] methods. Unlike those, the histogram returned from this function is *not* reduced to its lowest terms. In nearly all cases, when a source contains a histogram, it takes on the corresponding count\u2019s \u201cscale\u201d. In other words, the sum of the counts of the histogram retains the same proportion as the count in relation to other outcomes. This becomes clearer when there is no overlap between the histogram and the other outcomes. ``` python >>> from dyce.h import aggregate_with_counts >>> source_counts = ((H(3), 3), (H(-3), 2)) >>> h = aggregate_with_counts(source_counts).lowest_terms() ; h H({-3: 2, -2: 2, -1: 2, 1: 3, 2: 3, 3: 3}) ``` !!! note \"An important exception\" If a source is the empty histogram (``H({})``), it and its count is omitted from the result without scaling. ``` python >>> source_counts = ((H(2), 1), (H({}), 20)) >>> aggregate_with_counts(source_counts) H({1: 1, 2: 1}) ``` \"\"\" aggregate_scalar = 1 outcome_counts : List [ Tuple [ RealLike , int ]] = [] for outcome_or_h , count in source_counts : if isinstance ( outcome_or_h , H ): if outcome_or_h : h_scalar = outcome_or_h . total for i , ( prior_outcome , prior_count ) in enumerate ( outcome_counts ): outcome_counts [ i ] = ( prior_outcome , prior_count * h_scalar ) for new_outcome , new_count in outcome_or_h . items (): outcome_counts . append ( ( new_outcome , count * aggregate_scalar * new_count ) ) aggregate_scalar *= h_scalar else : outcome_counts . append (( outcome_or_h , count * aggregate_scalar )) return h_type ( outcome_counts )","title":"aggregate_with_counts()"},{"location":"dyce.h/#dyce.h.coalesce_replace","text":"Default behavior for H.substitute . Returns h unmodified ( outcome is ignored). Source code in dyce/h.py def coalesce_replace ( h : H , outcome : RealLike ) -> H : r \"\"\" Default behavior for [``H.substitute``][dyce.h.H.substitute]. Returns *h* unmodified (*outcome* is ignored). \"\"\" return h","title":"coalesce_replace()"},{"location":"dyce.h/#dyce.h.resolve_dependent_probability","text":"Deprecated This function has been moved to the H.foreach class method. This alias will be removed in a future release. Shorthand for H . foreach ( dependent_term , ** independent_sources ) . Source code in dyce/h.py @deprecated def resolve_dependent_probability ( dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : _SourceT , ) -> H : r \"\"\" !!! warning \"Deprecated\" This function has been moved to the [``H.foreach``][dyce.h.H.foreach] class method. This alias will be removed in a future release. Shorthand for ``#!python H.foreach(dependent_term, **independent_sources)``. \"\"\" return H . foreach ( dependent_term , ** independent_sources )","title":"resolve_dependent_probability()"},{"location":"dyce.h/#dyce.h.sum_h","text":"Shorthand for H ({}) if h_sum == 0 else sum ( hs ) . This is to ensure that summing zero or more histograms always returns a histograms. Source code in dyce/h.py @beartype def sum_h ( hs : Iterable [ H ]): \"\"\" Shorthand for ``#!python H({}) if h_sum == 0 else sum(hs)``. This is to ensure that summing zero or more histograms always returns a histograms. \"\"\" h_sum = sum ( hs ) return H ({}) if h_sum == 0 else h_sum","title":"sum_h()"},{"location":"dyce/","text":"dyce package reference dyce provides several core primitives: H \u2013 histograms (outcomes or individual dice) P \u2013 collections of histograms (pools) R \u2013 scalars, histograms, pools, operators, etc. for assembling roller trees (see dyce.r for details) H ( Mapping , Generic ) An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode finite discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, a denominator is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derived, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ). 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed. 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative). 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps. 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes. 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ()) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand. 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes. 1 2 >>> len ( 2 @d6 ) 11 The total property can be used to compute the total number of combinations and each outcome\u2019s probability. 1 2 3 4 5 >>> from fractions import Fraction >>> ( 2 @d6 ) . total 36 >>> [( outcome , Fraction ( count , ( 2 @d6 ) . total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ()) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ()) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ) ; d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ()) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore [operator] Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method . 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands. 1 2 >>> d6 . ge ( 4 ) == d6 . ge ( 4 ) . lowest_terms () True Source code in dyce/h.py class H ( _MappingT ): r \"\"\" An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. ``#!python H`` objects encode finite discrete probability distributions as integer counts without any denominator. !!! info The lack of an explicit denominator is intentional and has two benefits. First, a denominator is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derived, as shown below. The [initializer][dyce.h.H.__init__] takes a single parameter, *items*. In its most explicit form, *items* maps outcome values to counts. Modeling a single six-sided die (``1d6``) can be expressed as: ``` python >>> from dyce import H >>> d6 = H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1}) ``` An iterable of pairs can also be used (similar to ``#!python dict``). ``` python >>> d6 == H(((1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1))) True ``` Two shorthands are provided. If *items* is an iterable of numbers, counts of 1 are assumed. ``` python >>> d6 == H((1, 2, 3, 4, 5, 6)) True ``` Repeated items are accumulated, as one would expect. ``` python >>> H((2, 3, 3, 4, 4, 5)) H({2: 1, 3: 2, 4: 2, 5: 1}) ``` If *items* is an integer, it is shorthand for creating a sequential range $[{1} .. {items}]$ (or $[{items} .. {-1}]$ if *items* is negative). ``` python >>> d6 == H(6) True ``` Histograms are maps, so we can test equivalence against other maps. ``` python >>> H(6) == {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1} True ``` Simple indexes can be used to look up an outcome\u2019s count. ``` python >>> H((2, 3, 3, 4, 4, 5))[3] 2 ``` Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes. ``` python >>> d6 + 4 H({5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1}) ``` ``` python >>> d6 * -1 H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> d6 * -1 == -d6 True >>> d6 * -1 == H(-6) True ``` If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice (``2d6``) can be expressed as: ``` python >>> d6 + d6 H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> print((d6 + d6).format()) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78% |# 3 | 5.56% |## 4 | 8.33% |#### 5 | 11.11% |##### 6 | 13.89% |###### 7 | 16.67% |######## 8 | 13.89% |###### 9 | 11.11% |##### 10 | 8.33% |#### 11 | 5.56% |## 12 | 2.78% |# ``` To sum ${n}$ identical histograms, the matrix multiplication operator (``@``) provides a shorthand. ``` python >>> 3@d6 == d6 + d6 + d6 True ``` The ``#!python len`` built-in function can be used to show the number of distinct outcomes. ``` python >>> len(2@d6) 11 ``` The [``total`` property][dyce.h.H.total] can be used to compute the total number of combinations and each outcome\u2019s probability. ``` python >>> from fractions import Fraction >>> (2@d6).total 36 >>> [(outcome, Fraction(count, (2@d6).total)) for outcome, count in (2@d6).items()] [(2, Fraction(1, 36)), (3, Fraction(1, 18)), (4, Fraction(1, 12)), (5, Fraction(1, 9)), (6, Fraction(5, 36)), (7, Fraction(1, 6)), ..., (12, Fraction(1, 36))] ``` Histograms provide common comparators (e.g., [``eq``][dyce.h.H.eq] [``ne``][dyce.h.H.ne], etc.). One way to count how often a first six-sided die shows a different face than a second is: ``` python >>> d6.ne(d6) H({False: 6, True: 30}) >>> print(d6.ne(d6).format()) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67% |######## 1 | 83.33% |######################################### ``` Or, how often a first six-sided die shows a face less than a second is: ``` python >>> d6.lt(d6) H({False: 21, True: 15}) >>> print(d6.lt(d6).format()) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33% |############################# 1 | 41.67% |#################### ``` Or how often at least one ``#!python 2`` will show when rolling four six-sided dice: ``` python >>> d6_eq2 = d6.eq(2) ; d6_eq2 # how often a 2 shows on a single six-sided die H({False: 5, True: 1}) >>> 4@d6_eq2 # count of 2s showing on 4d6 H({0: 625, 1: 500, 2: 150, 3: 20, 4: 1}) >>> (4@d6_eq2).ge(1) # how often that count is at least one H({False: 625, True: 671}) >>> print((4@d6_eq2).ge(1).format()) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23% |######################## 1 | 51.77% |######################### ``` !!! bug \"Mind your parentheses\" Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the ``#!python @`` operator, because it behaves differently than the ``d`` operator in most dedicated grammars. More specifically, in Python, ``#!python @`` has a [lower precedence](https://docs.python.org/3/reference/expressions.html#operator-precedence) than ``#!python .`` and ``#!python [\u2026]``. ``` python >>> 2@d6[7] # type: ignore [operator] Traceback (most recent call last): ... KeyError: 7 >>> 2@d6.le(7) # probably not what was intended H({2: 36}) >>> 2@d6.le(7) == 2@(d6.le(7)) True ``` ``` python >>> (2@d6)[7] 6 >>> (2@d6).le(7) H({False: 15, True: 21}) >>> 2@d6.le(7) == (2@d6).le(7) False ``` Counts are generally accumulated without reduction. To reduce, call the [``lowest_terms`` method][dyce.h.H.lowest_terms]. ``` python >>> d6.ge(4) H({False: 3, True: 3}) >>> d6.ge(4).lowest_terms() H({False: 1, True: 1}) ``` Testing equivalence implicitly performs reductions of operands. ``` python >>> d6.ge(4) == d6.ge(4).lowest_terms() True ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_h\" , \"_simple_init\" ) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ RealLike ] = counter () if isinstance ( items , MappingC ): items = items . items () if isinstance ( items , SupportsInt ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , RealLike ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HableT ): tmp . update ( items . h ()) elif isinstance ( items , IterableC ): # items is either an Iterable[RealLike] or an Iterable[Tuple[RealLike, # SupportsInt]] (although this technically supports Iterable[Union[RealLike, # Tuple[RealLike, SupportsInt]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 } # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : if self . _simple_init is not None : arg = str ( self . _simple_init ) elif sys . version_info >= ( 3 , 8 ): arg = pformat ( self . _h , sort_dicts = False ) else : arg = dict . __repr__ ( self . _h ) return f \" { type ( self ) . __name__ } ( { arg } )\" @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __eq__ ( self , other . h ()) elif isinstance ( other , H ): return __eq__ ( self . lowest_terms () . _h , other . lowest_terms () . _h ) else : return super () . __eq__ ( other ) @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __ne__ ( self , other . h ()) elif isinstance ( other , H ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) @beartype def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ())) @beartype def __len__ ( self ) -> int : return len ( self . _h ) @beartype def __getitem__ ( self , key : RealLike ) -> int : return __getitem__ ( self . _h , key ) @beartype def __iter__ ( self ) -> Iterator [ RealLike ]: return iter ( self . _h ) @beartype def __add__ ( self , other : _OperandT ) -> H : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented @beartype def __radd__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented @beartype def __sub__ ( self , other : _OperandT ) -> H : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented @beartype def __rsub__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented @beartype def __mul__ ( self , other : _OperandT ) -> H : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmul__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented @beartype def __matmul__ ( self , other : SupportsInt ) -> H : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return sum_h ( repeat ( self , other )) @beartype def __rmatmul__ ( self , other : SupportsInt ) -> H : return self . __matmul__ ( other ) @beartype def __truediv__ ( self , other : _OperandT ) -> H : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rtruediv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented @beartype def __floordiv__ ( self , other : _OperandT ) -> H : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rfloordiv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented @beartype def __mod__ ( self , other : _OperandT ) -> H : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmod__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented @beartype def __pow__ ( self , other : _OperandT ) -> H : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented @beartype def __rpow__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented @beartype def __and__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __rand__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __xor__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except NotImplementedError : return NotImplemented @beartype def __rxor__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __or__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __ror__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __neg__ ( self ) -> H : return self . umap ( __neg__ ) @beartype def __pos__ ( self ) -> H : return self . umap ( __pos__ ) @beartype def __abs__ ( self ) -> H : return self . umap ( __abs__ ) @beartype def __invert__ ( self ) -> H : return self . umap ( __invert__ ) @beartype def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . _h . values () @beartype def items ( self ) -> ItemsView [ RealLike , int ]: return self . _h . items () @beartype def keys ( self ) -> KeysView [ RealLike ]: return self . outcomes () @beartype def outcomes ( self ) -> KeysView [ RealLike ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . _h . keys () @beartype def values ( self ) -> ValuesView [ int ]: return self . counts () # ---- Properties ------------------------------------------------------------------ @property def total ( self ) -> int : r \"\"\" !!! warning \"Experimental\" This propertyshould be considered experimental and may change or disappear in future versions. Equivalent to ``#!python sum(self.counts())``. \"\"\" @experimental def _total () -> int : return sum ( self . counts ()) return _total () # ---- Methods --------------------------------------------------------------------- @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ \"H\" , RealLike ]], ** independent_sources : _SourceT , ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each set of outcomes from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Returned histograms are always reduced to their lowest terms. For example rolling a d20, re-rolling a ``#!python 1`` if it comes up, and keeping the result might be expressed as[^1]: [^1]: This is primarily for illustration. [``H.substitute``][dyce.h.H.substitute] is often better suited to cases involving re-rolling a single independent term such as this one. ``` python >>> d20 = H(20) >>> def reroll_one_dependent_term(d20_outcome): ... if d20_outcome == 1: ... return d20 ... else: ... return d20_outcome >>> H.foreach(reroll_one_dependent_term, d20_outcome=d20) H({1: 1, 2: 21, 3: 21, ..., 19: 21, 20: 21}) ``` The ``#!python foreach`` class method merely wraps *dependent_term* and calls [``P.foreach``][dyce.p.P.foreach]. In doing so, it imposes a very modest overhead that is negligible in most cases. ``` python --8<-- \"docs/assets/perf_foreach.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_foreach.ipy\"><code>perf_foreach.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_foreach.ipy\" ``` </details> \"\"\" from dyce import P def _dependent_term ( ** roll_kw ): outcome_kw : Dict [ str , RealLike ] = {} for key , roll in roll_kw . items (): assert isinstance ( roll , tuple ) assert len ( roll ) == 1 outcome_kw [ key ] = roll [ 0 ] return dependent_term ( ** outcome_kw ) return P . foreach ( _dependent_term , ** independent_sources ) @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT ) -> H : r \"\"\" Applies *bin_op* to each outcome of the histogram as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> d6 = H(6) >>> d6.map(operator.__add__, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.__add__, d6) == d6 + d6 True ``` ``` python >>> d6.map(operator.__pow__, 2) H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1}) >>> d6.map(operator.__pow__, 2) == d6 ** 2 True ``` ``` python >>> d6.map(operator.__gt__, 3) H({False: 3, True: 3}) >>> d6.map(operator.__gt__, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( right_operand , HableT ): right_operand = right_operand . h () if isinstance ( right_operand , H ): return type ( self )( ( bin_op ( s , o ), self [ s ] * right_operand [ o ]) for s , o in product ( self , right_operand ) ) else : return type ( self )( ( bin_op ( outcome , right_operand ), count ) for outcome , count in self . items () ) @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> H : r \"\"\" Analogous to the [``map`` method][dyce.h.H.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> d6 = H(6) >>> d6.rmap(2, operator.__pow__) H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1}) >>> d6.rmap(2, operator.__pow__) == 2 ** d6 True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.h.H.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" return type ( self )( ( bin_op ( left_operand , outcome ), count ) for outcome , count in self . items () ) @beartype def umap ( self , un_op : _UnaryOperatorT ) -> H : r \"\"\" Applies *un_op* to each outcome of the histogram. ``` python >>> import operator >>> H(6).umap(operator.__neg__) H(-6) ``` ``` python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = type ( self )(( un_op ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : simple_init = un_op ( self . _simple_init ) if isinstance ( simple_init , SupportsInt ): h_simple = type ( self )( simple_init ) if h_simple == h : return h_simple return h @beartype def lt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__lt__, other).umap(bool)``. ``` python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __lt__ , other ) . umap ( bool ) @beartype def le ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__le__, other).umap(bool)``. ``` python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __le__ , other ) . umap ( bool ) @beartype def eq ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__eq__, other).umap(bool)``. ``` python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __eq__ , other ) . umap ( bool ) @beartype def ne ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ne__, other).umap(bool)``. ``` python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ne__ , other ) . umap ( bool ) @beartype def gt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__gt__, other).umap(bool)``. ``` python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __gt__ , other ) . umap ( bool ) @beartype def ge ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ge__, other).umap(bool)``. ``` python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ge__ , other ) . umap ( bool ) @beartype def is_even ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_even)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_even ) @beartype def is_odd ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_odd)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_odd ) @beartype def accumulate ( self , other : _SourceT ) -> H : r \"\"\" Accumulates counts. ``` python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , MappingC ): other = other . items () elif not isinstance ( other , IterableC ): other = cast ( Iterable [ RealLike ], ( other ,)) return type ( self )( chain ( self . items (), cast ( Iterable , other ))) @experimental @beartype def exactly_k_times_in_n ( self , outcome : RealLike , n : SupportsInt , k : SupportsInt , ) -> int : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``#!python n@self``. ``` python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) return comb ( n , k ) * c_outcome ** k * ( self . total - c_outcome ) ** ( n - k ) @beartype def explode ( self , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.substitute(lambda h, outcome: outcome if len(h) == 1 else h if outcome == max(h) else outcome, operator.__add__, max_depth, precision_limit)``. ``` python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : outcome if len ( h ) == 1 else h if outcome == max ( h ) else outcome , __add__ , max_depth , precision_limit , ) @beartype def lowest_terms ( self ) -> H : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ``` python >>> df = H((-1, -1, 0, 0, 1, 1)) ; df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ``` python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return type ( self )( self . _lowest_terms ()) @experimental @beartype def order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Shorthand for ``#!python self.order_stat_func_for_n(n)(pos)``. \"\"\" # TODO(posita): Explore different memoization strategies (e.g., with # functools.cache) for this method and H.order_stat_func_for_n return self . order_stat_func_for_n ( n )( pos ) @experimental @beartype def order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], \"H\" ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``#!python n@self``. ``` python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``#!python 2`` appears at the fourth (index ``#!python 3``) position, 1432 ways where ``#!python 3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. ``` python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster. ``` python --8<-- \"docs/assets/perf_order_stat_for_n.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_order_stat_for_n.ipy\"><code>perf_order_stat_for_n.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_order_stat_for_n.ipy\" ``` </details> \"\"\" betas_by_outcome : Dict [ RealLike , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ RealLike , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) @beartype def order_stat_for_n_at_pos ( pos : SupportsInt ) -> H : return type ( self )( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos @beartype def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" !!! warning \"Experimental\" The *precision_limit* parameter should be considered experimental and may change or disappear in future versions. Calls *expand* on each outcome. If *expand* returns a single outcome, it replaces the existing outcome. If it returns an [``H`` object][dyce.h.H], expansion is performed again (recursively) on that object until *max_depth* or *precision_limit* is exhausted. *coalesce* is called on the original outcome and the expanded histogram or outcome and the returned histogram is \u201cfolded\u201d into result. (More on these terms and concepts below.) The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. !!! note \"*coalesce* is not called unless *expand* returns a histogram\" If *expand* returns a single outcome, it *always* replaces the existing outcome. This is intentional. To return a single outcome, but trigger *coalesce*, characterize that outcome as a single-sided die (e.g., ``#!python H({outcome: 1})``. See the [``coalesce_replace``][dyce.h.coalesce_replace] and [``lowest_terms``][dyce.h.H.lowest_terms] methods. This method can be used to model complex mechanics. The following models re-rolling a face of 1 on the first roll: ``` python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). This method uses the [``aggregate_with_counts``][dyce.h.aggregate_with_counts] function in its implementation. As such, If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. ``` python >>> H(6).substitute(lambda __, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda __, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``#!python substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions with dependent variables. Consider the following mechanic: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ``` python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.__add__, max_depth=6) >>> h_even = h.is_even() >>> print(f\"{h_even[1] / h_even.total:.3%}\") 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. ``` python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` When *expand* returns an [``H`` object][dyce.h.H], outcomes produced from the corresponding *coalesce* are accumulated, but the counts retain their \u201cscale\u201d within the context of the expansion. This becomes clearer when there is no overlap between the substituted histogram and the other outcomes. ``` python >>> d6 = H(6) >>> d00 = (H(10) - 1) * 10 ; d00 H({0: 1, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) >>> set(d6) & set(d00) == set() # no outcomes in common True >>> d6_d00 = d6.substitute( ... # If a one comes up when rolling the d6, ... # roll a d00 and take that result instead ... lambda h, outcome: d00 if outcome == 1 else outcome ... ) ; d6_d00 H({0: 1, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) ``` Note that the sum of the outcomes\u2019 counts from the d00 make up the same proportion as the one\u2019s outcome and count they replaced from the d6. ``` python >>> from fractions import Fraction >>> Fraction( ... sum(count for outcome, count in d6_d00.items() if outcome in d00), ... d6_d00.total, ... ) Fraction(1, 6) >>> Fraction(d6[1], d6.total) Fraction(1, 6) ``` !!! tip \"Precision limits\" This method will halt recursive substitution on any branch *either* when its depth exceeds *max_depth* *or* its \u201ccontextual precision\u201d is *precision_limit* or less. In either case, substitution is attempted for all of the outcomes of a(n expanded) histogram or none of them. The contextual precision of a histogram is its proportion to the whole. The contextual precision of the original (or top-level) histogram is ``#!python Fraction(1, 1)``. By setting *precision_limit* to that value, we basically ensure no substitution. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... precision_limit=Fraction(1, 1), # no substitution ... ) == d6 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... max_depth=0, # no substitution ... ) == d6 True ``` Let\u2019s make a contrived, but illustrative modification to our d6/d00 example from above. If a one comes up when rolling a d6, roll a d00, but re-roll any 80s. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, # <-- we'll never hit this ... # will halt substitution after the original one from the d6 ... precision_limit=Fraction(1, 6), ... ) == d6_d00 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the first 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10), ... ) H({0: 11, 2: 100, ..., 6: 100, 10: 11, ..., 70: 11, 80: 1, 90: 11}) >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the second 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10) - Fraction(1, 1000000000), # <-- juuust under the wire ... ) H({0: 111, 2: 1000, ..., 6: 1000, 10: 111, ..., 70: 111, 80: 1, 90: 111}) ``` The default value for *precision_limit* is zero, which basically means it is ignored and recursion is limited solely by *max_depth*. If you want to ensure that this method stops delving based *solely* on precision, set *max_depth* to ``#!python -1``, which is equivalent to ``#!python sys.getrecursionlimit() + 1``[^1]. Be aware that this skews results in favor of non-limited branches. ``` python >>> h = H({1: 1, 2: 2, 3: 3}) >>> print(h.explode(max_depth=5).format(scaled=True)) avg | 4.59 std | 3.96 var | 15.65 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 18 | 1.56% |## >>> print(h.explode(max_depth=-1, precision_limit=Fraction(1, 6 ** 2)).format(scaled=True)) avg | 4.63 std | 4.09 var | 16.72 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 19 | 0.26% | 20 | 0.52% | 21 | 0.78% |# ``` Also be aware that without *max_depth* as a safety net, some substitutions are guaranteed to result in ``#!python RecursionError``s, even with very high *precision_limit*s. ``` python >>> H(1).substitute( ... lambda h, outcome: H({outcome + 1: 1}), # expands to a single-sided die ... max_depth=-1, ... precision_limit=Fraction(999999, 1000000), ... ) Traceback (most recent call last): ... RecursionError: maximum recursion depth exceeded in comparison ``` [``H.explode``][dyce.h.H.explode]\u2019s *expand* implementation guards against this by returning ``#!python outcome`` if the passed histogram has only one face. Consider a similar approach for your own *expand* implementations if outcomes\u2019 contextual probabilities do not asymptotically approach zero. [^1]: This method will \u201cbottom out\u201d far earlier. As of this writing, the practical limit of its implementation (without optimization) is something close to $\\frac {1} {3} \\times \\left( limit - depth \\right)$, where $limit$ is ``#!python sys.getrecursionlimit()`` and $depth$ is ``#!python len(inspect.stack(0))``. This also assumes the provided implementations for *expand* and *coalesce* don\u2019t contribute significantly to the call stack. Setting *max_depth* to ``#!python -1`` or one beyond the absolute limit signals that the caller wants it out of the way. \"\"\" max_depth = as_int ( max_depth ) if max_depth == - 1 : max_depth = sys . getrecursionlimit () + 1 if max_depth < 0 : raise ValueError ( \"max_depth cannot be an arbitrary negative number (use -1 explicitly to indicate no limit)\" ) if precision_limit < 0 or precision_limit > 1 : raise ValueError ( f \"precision_limit ( { precision_limit } ) must be between zero and one, inclusive\" ) def _substitute ( h : H , depth : int = 0 , contextual_precision : Fraction = Fraction ( 1 ), ) -> H : assert coalesce is not None if depth == max_depth or contextual_precision <= precision_limit : return h def _expand_and_coalesce () -> Iterator [ Tuple [ Union [ H , RealLike ], int ]]: total = h . total for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded_precision = Fraction ( contextual_precision . numerator * count , contextual_precision . denominator * total , ) expanded = _substitute ( expanded , depth + 1 , expanded_precision ) # Coalesce the result expanded = coalesce ( expanded , outcome ) yield expanded , count return aggregate_with_counts ( _expand_and_coalesce (), type ( self )) return _substitute ( self ) . lowest_terms () @beartype def vs ( self , other : _OperandT ) -> H : r \"\"\" Compares the histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``#!python self.within(0, 0, other)``. ``` python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other ) @beartype def within ( self , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Computes the difference between the histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ``` python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format()) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format()) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other ) @overload def distribution ( self , fill_items : Optional [ _MappingT ] = None , ) -> Iterator [ Tuple [ RealLike , Fraction ]]: ... @overload def distribution ( self , fill_items : _MappingT , rational_t : _RationalInitializerT [ _T ], ) -> Iterator [ Tuple [ RealLike , _T ]]: ... @overload def distribution ( self , * , rational_t : _RationalInitializerT [ _T ], ) -> Iterator [ Tuple [ RealLike , _T ]]: ... @experimental @beartype def distribution ( self , fill_items : Optional [ _MappingT ] = None , # TODO(posita): See <https://github.com/python/mypy/issues/10854> for context on # all the @overload work-around nonsense above and remove those once that issue # is addressed. rational_t : _RationalInitializerT [ _T ] = cast ( _RationalInitializerT , Fraction ), ) -> Iterator [ Tuple [ RealLike , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. ``` python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes. ``` python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` !!! warning \"Experimental\" The *rational_t* argument to this method should be considered experimental and may change or disappear in future versions. If provided, *rational_t* must be a callable that takes two ``#!python int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. ``` python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] ``` ``` python >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` !!! note The arguments passed to *rational_t* are not reduced to the lowest terms. The *rational_t* argument is a convenience. Iteration or comprehension can be used to accomplish something similar. ``` python >>> [(outcome, f\"{probability.numerator}/{probability.denominator}\") for outcome, probability in (h).distribution()] [(1, '1/8'), (2, '1/8'), (3, '1/4'), (4, '1/4'), (5, '1/8'), (6, '1/8')] ``` Many number implementations can convert directly from ``#!python fractions.Fraction``s. ``` python >>> import sympy.abc >>> [(outcome, sympy.Rational(probability)) for outcome, probability in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> [(outcome, sage.rings.rational.Rational(probability)) for outcome, probability in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) ) @beartype def distribution_xy ( self , fill_items : Optional [ _MappingT ] = None , ) -> Tuple [ Tuple [ RealLike , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``#!python float``s. ``` python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" # TODO(posita): See <https://github.com/python/typing/issues/193> return tuple ( # type: ignore [return-value] zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) ) @beartype def format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsInt = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ``` python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ``` python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``#!python True``, horizontal bars are scaled to *width*. ``` python >>> h = (2@H(6)).ge(7) >>> print(f\"{' 65 chars wide -->|':->65}\") ---------------------------------------------- 65 chars wide -->| >>> print(h.format(scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : RealLike = float ( self . mean ()) except ( OverflowError , TypeError ): mu = self . mean () if width <= 0 : def _parts () -> Iterator [ str ]: yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 def _lines () -> Iterator [ str ]: try : yield f \"avg | { mu : 7.2f } \" std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except ( OverflowError , TypeError ) as exc : warnings . warn ( f \" { str ( exc ) } ; mu: { mu } \" ) if self : outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( _lines ()) @beartype def mean ( self ) -> RealLike : r \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 ) @beartype def stdev ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Shorthand for ``#!python math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu )) @beartype def variance ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 ) @beartype def roll ( self ) -> RealLike : r \"\"\" Returns a (weighted) random outcome, sorted. \"\"\" return ( rng . RNG . choices ( population = tuple ( self . outcomes ()), weights = tuple ( self . counts ()), k = 1 , )[ 0 ] if self else 0 ) def _lowest_terms ( self ) -> Iterable [ Tuple [ RealLike , int ]]: counts_gcd = gcd ( * self . counts ()) return (( k , v // counts_gcd ) for k , v in self . items ()) __slots__ : Union [ str , Iterable [ str ]] special total : int property readonly Experimental This propertyshould be considered experimental and may change or disappear in future versions. Equivalent to sum ( self . counts ()) . __abs__ ( self ) -> H special Source code in dyce/h.py @beartype def __abs__ ( self ) -> H : return self . umap ( __abs__ ) __add__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __add__ ( self , other : _OperandT ) -> H : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented __and__ ( self , other : Union [ SupportsInt , 'H' , 'HableT' ]) -> H special Source code in dyce/h.py @beartype def __and__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __eq__ ( self , other ) -> bool special Source code in dyce/h.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __eq__ ( self , other . h ()) elif isinstance ( other , H ): return __eq__ ( self . lowest_terms () . _h , other . lowest_terms () . _h ) else : return super () . __eq__ ( other ) __floordiv__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __floordiv__ ( self , other : _OperandT ) -> H : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented __getitem__ ( self , key : RealLike ) -> int special Source code in dyce/h.py @beartype def __getitem__ ( self , key : RealLike ) -> int : return __getitem__ ( self . _h , key ) __hash__ ( self ) -> int special Return hash(self). Source code in dyce/h.py @beartype def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ())) __init__ ( self , items : _SourceT ) -> None special Initializer. Source code in dyce/h.py @beartype def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ RealLike ] = counter () if isinstance ( items , MappingC ): items = items . items () if isinstance ( items , SupportsInt ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , RealLike ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HableT ): tmp . update ( items . h ()) elif isinstance ( items , IterableC ): # items is either an Iterable[RealLike] or an Iterable[Tuple[RealLike, # SupportsInt]] (although this technically supports Iterable[Union[RealLike, # Tuple[RealLike, SupportsInt]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 } __invert__ ( self ) -> H special Source code in dyce/h.py @beartype def __invert__ ( self ) -> H : return self . umap ( __invert__ ) __iter__ ( self ) -> Iterator [ RealLike ] special Source code in dyce/h.py @beartype def __iter__ ( self ) -> Iterator [ RealLike ]: return iter ( self . _h ) __len__ ( self ) -> int special Source code in dyce/h.py @beartype def __len__ ( self ) -> int : return len ( self . _h ) __matmul__ ( self , other : SupportsInt ) -> H special Source code in dyce/h.py @beartype def __matmul__ ( self , other : SupportsInt ) -> H : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return sum_h ( repeat ( self , other )) __mod__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __mod__ ( self , other : _OperandT ) -> H : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented __mul__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __mul__ ( self , other : _OperandT ) -> H : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented __ne__ ( self , other ) -> bool special Source code in dyce/h.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __ne__ ( self , other . h ()) elif isinstance ( other , H ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) __neg__ ( self ) -> H special Source code in dyce/h.py @beartype def __neg__ ( self ) -> H : return self . umap ( __neg__ ) __or__ ( self , other : Union [ SupportsInt , 'H' , 'HableT' ]) -> H special Source code in dyce/h.py @beartype def __or__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __pos__ ( self ) -> H special Source code in dyce/h.py @beartype def __pos__ ( self ) -> H : return self . umap ( __pos__ ) __pow__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __pow__ ( self , other : _OperandT ) -> H : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented __radd__ ( self , other : RealLike ) -> H special Source code in dyce/h.py @beartype def __radd__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented __rand__ ( self , other : SupportsInt ) -> H special Source code in dyce/h.py @beartype def __rand__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented __repr__ ( self ) -> str special Source code in dyce/h.py @beartype def __repr__ ( self ) -> str : if self . _simple_init is not None : arg = str ( self . _simple_init ) elif sys . version_info >= ( 3 , 8 ): arg = pformat ( self . _h , sort_dicts = False ) else : arg = dict . __repr__ ( self . _h ) return f \" { type ( self ) . __name__ } ( { arg } )\" __rfloordiv__ ( self , other : RealLike ) -> H special Source code in dyce/h.py @beartype def __rfloordiv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented __rmatmul__ ( self , other : SupportsInt ) -> H special Source code in dyce/h.py @beartype def __rmatmul__ ( self , other : SupportsInt ) -> H : return self . __matmul__ ( other ) __rmod__ ( self , other : RealLike ) -> H special Source code in dyce/h.py @beartype def __rmod__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented __rmul__ ( self , other : RealLike ) -> H special Source code in dyce/h.py @beartype def __rmul__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented __ror__ ( self , other : SupportsInt ) -> H special Source code in dyce/h.py @beartype def __ror__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented __rpow__ ( self , other : RealLike ) -> H special Source code in dyce/h.py @beartype def __rpow__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented __rsub__ ( self , other : RealLike ) -> H special Source code in dyce/h.py @beartype def __rsub__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented __rtruediv__ ( self , other : RealLike ) -> H special Source code in dyce/h.py @beartype def __rtruediv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented __rxor__ ( self , other : SupportsInt ) -> H special Source code in dyce/h.py @beartype def __rxor__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented __sub__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __sub__ ( self , other : _OperandT ) -> H : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented __truediv__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __truediv__ ( self , other : _OperandT ) -> H : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented __xor__ ( self , other : Union [ SupportsInt , 'H' , 'HableT' ]) -> H special Source code in dyce/h.py @beartype def __xor__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except NotImplementedError : return NotImplemented accumulate ( self , other : _SourceT ) -> H Accumulates counts. 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py @beartype def accumulate ( self , other : _SourceT ) -> H : r \"\"\" Accumulates counts. ``` python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , MappingC ): other = other . items () elif not isinstance ( other , IterableC ): other = cast ( Iterable [ RealLike ], ( other ,)) return type ( self )( chain ( self . items (), cast ( Iterable , other ))) counts ( self ) -> ValuesView [ int ] More descriptive synonym for the values method . Source code in dyce/h.py @beartype def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . _h . values () distribution ( self , fill_items : Optional [ _MappingT ] = None , rational_t : _RationalInitializerT [ _T ] = < class ' fractions . Fraction '>) -> Iterator[Tuple[RealLike, _T]] Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. 1 2 3 4 5 >>> h = H (( 1 , 2 , 3 , 3 , 4 , 4 , 5 , 6 )) >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . ge ( 3 ) . distribution ()) [( False , Fraction ( 1 , 4 )), ( True , Fraction ( 3 , 4 ))] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes. 1 2 3 4 >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . distribution ( fill_items = { 0 : 0 , 7 : 0 })) [( 0 , Fraction ( 0 , 1 )), ( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 )), ( 7 , Fraction ( 0 , 1 ))] Experimental The rational_t argument to this method should be considered experimental and may change or disappear in future versions. If provided, rational_t must be a callable that takes two int s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. 1 2 >>> list ( h . distribution ( rational_t = lambda n , d : f \" { n } / { d } \" )) [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '2/8' ), ( 4 , '2/8' ), ( 5 , '1/8' ), ( 6 , '1/8' )] 1 2 3 >>> import sympy >>> list ( h . distribution ( rational_t = sympy . Rational )) [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> list ( h . distribution ( rational_t = lambda n , d : sage . rings . rational . Rational (( n , d )))) # doctest: +SKIP [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] Note The arguments passed to rational_t are not reduced to the lowest terms. The rational_t argument is a convenience. Iteration or comprehension can be used to accomplish something similar. 1 2 >>> [( outcome , f \" { probability . numerator } / { probability . denominator } \" ) for outcome , probability in ( h ) . distribution ()] [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '1/4' ), ( 4 , '1/4' ), ( 5 , '1/8' ), ( 6 , '1/8' )] Many number implementations can convert directly from fractions . Fraction s. 1 2 3 >>> import sympy.abc >>> [( outcome , sympy . Rational ( probability )) for outcome , probability in ( h + sympy . abc . x ) . distribution ()] [( x + 1 , 1 / 8 ), ( x + 2 , 1 / 8 ), ( x + 3 , 1 / 4 ), ( x + 4 , 1 / 4 ), ( x + 5 , 1 / 8 ), ( x + 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> [( outcome , sage . rings . rational . Rational ( probability )) for outcome , probability in h . distribution ()] # doctest: +SKIP [( 1 , 1 / 6 ), ( 2 , 1 / 6 ), ( 3 , 1 / 3 ), ( 4 , 1 / 3 ), ( 5 , 1 / 6 ), ( 6 , 1 / 6 )] Source code in dyce/h.py @experimental @beartype def distribution ( self , fill_items : Optional [ _MappingT ] = None , # TODO(posita): See <https://github.com/python/mypy/issues/10854> for context on # all the @overload work-around nonsense above and remove those once that issue # is addressed. rational_t : _RationalInitializerT [ _T ] = cast ( _RationalInitializerT , Fraction ), ) -> Iterator [ Tuple [ RealLike , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. ``` python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes. ``` python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` !!! warning \"Experimental\" The *rational_t* argument to this method should be considered experimental and may change or disappear in future versions. If provided, *rational_t* must be a callable that takes two ``#!python int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. ``` python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] ``` ``` python >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` !!! note The arguments passed to *rational_t* are not reduced to the lowest terms. The *rational_t* argument is a convenience. Iteration or comprehension can be used to accomplish something similar. ``` python >>> [(outcome, f\"{probability.numerator}/{probability.denominator}\") for outcome, probability in (h).distribution()] [(1, '1/8'), (2, '1/8'), (3, '1/4'), (4, '1/4'), (5, '1/8'), (6, '1/8')] ``` Many number implementations can convert directly from ``#!python fractions.Fraction``s. ``` python >>> import sympy.abc >>> [(outcome, sympy.Rational(probability)) for outcome, probability in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> [(outcome, sage.rings.rational.Rational(probability)) for outcome, probability in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) ) distribution_xy ( self , fill_items : Optional [ _MappingT ] = None ) -> Tuple [ Tuple [ RealLike , ... ], Tuple [ float , ... ]] Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method and ensures the values are float s. 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , Fraction ( 1 , 6 )), ( 2 , Fraction ( 1 , 6 )), ( 3 , Fraction ( 1 , 6 )), ( 4 , Fraction ( 1 , 6 )), ( 5 , Fraction ( 1 , 6 )), ( 6 , Fraction ( 1 , 6 ))] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py @beartype def distribution_xy ( self , fill_items : Optional [ _MappingT ] = None , ) -> Tuple [ Tuple [ RealLike , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``#!python float``s. ``` python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" # TODO(posita): See <https://github.com/python/typing/issues/193> return tuple ( # type: ignore [return-value] zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) ) eq ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __eq__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map and umap methods. Source code in dyce/h.py @beartype def eq ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__eq__, other).umap(bool)``. ``` python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __eq__ , other ) . umap ( bool ) exactly_k_times_in_n ( self , outcome : RealLike , n : SupportsInt , k : SupportsInt ) -> int Experimental This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where outcome appears exactly k times among n @self . 1 2 3 4 5 6 >>> H ( 6 ) . exactly_k_times_in_n ( outcome = 5 , n = 4 , k = 2 ) 150 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 2 , n = 3 , k = 3 ) 1 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 4 , n = 3 , k = 3 ) 8 Source code in dyce/h.py @experimental @beartype def exactly_k_times_in_n ( self , outcome : RealLike , n : SupportsInt , k : SupportsInt , ) -> int : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``#!python n@self``. ``` python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) return comb ( n , k ) * c_outcome ** k * ( self . total - c_outcome ) ** ( n - k ) explode ( self , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 , 1 )) -> H Shorthand for self . substitute ( lambda h , outcome : outcome if len ( h ) == 1 else h if outcome == max ( h ) else outcome , operator . __add__ , max_depth , precision_limit ) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py @beartype def explode ( self , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.substitute(lambda h, outcome: outcome if len(h) == 1 else h if outcome == max(h) else outcome, operator.__add__, max_depth, precision_limit)``. ``` python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : outcome if len ( h ) == 1 else h if outcome == max ( h ) else outcome , __add__ , max_depth , precision_limit , ) foreach ( dependent_term : Callable [ ... , Union [ 'H' , RealLike ]], ** independent_sources : _SourceT ) -> H classmethod Experimental This method should be considered experimental and may change or disappear in future versions. Calls dependent_term for each set of outcomes from the product of independent_sources and accumulates the results. This is useful for resolving dependent probabilities. Returned histograms are always reduced to their lowest terms. For example rolling a d20, re-rolling a 1 if it comes up, and keeping the result might be expressed as 1 : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> d20 = H ( 20 ) >>> def reroll_one_dependent_term ( d20_outcome ): ... if d20_outcome == 1 : ... return d20 ... else : ... return d20_outcome >>> H . foreach ( reroll_one_dependent_term , d20_outcome = d20 ) H ({ 1 : 1 , 2 : 21 , 3 : 21 , ... , 19 : 21 , 20 : 21 }) The foreach class method merely wraps dependent_term and calls P.foreach . In doing so, it imposes a very modest overhead that is negligible in most cases. 1 2 3 4 5 % timeit P . foreach ( dependent_term_p , roll_1 = H ( 6 ), roll_2 = H ( 8 ), roll_3 = H ( 10 ), roll_n = H ( 20 )) 219 ms \u00b1 5.58 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) % timeit H . foreach ( dependent_term_h , outcome_1 = H ( 6 ), outcome_2 = H ( 8 ), outcome_3 = H ( 10 ), outcome_n = H ( 20 )) 230 ms \u00b1 6.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source: perf_foreach.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 from dyce import H , P def dependent_term ( val_1 , val_2 , val_3 , val_n , ): import math ; math . gcd ( 456 ** 123 , 123 ** 456 ) # emulate an expensive calculation return ( ( val_1 == val_2 ) + ( val_2 == val_3 ) + ( val_1 == val_3 ) + ( val_n > val_1 and val_n > val_2 and val_n > val_3 ) ) def dependent_term_h ( outcome_1 , outcome_2 , outcome_3 , outcome_n , ): return dependent_term ( outcome_1 , outcome_2 , outcome_3 , outcome_n ) def dependent_term_p ( roll_1 , roll_2 , roll_3 , roll_n , ): return dependent_term ( roll_1 , roll_2 , roll_3 , roll_n ) source_1 = H ( 6 ) source_2 = H ( 8 ) source_3 = H ( 10 ) source_n = H ( 20 ) print ( f \"%timeit P.foreach( { dependent_term_p . __name__ } , roll_1= { source_1 } , roll_2= { source_2 } , roll_3= { source_3 } , roll_n= { source_n } )\" ) % timeit P . foreach ( dependent_term_p , roll_1 = source_1 , roll_2 = source_2 , roll_3 = source_3 , roll_n = source_n ) print () print ( f \"%timeit H.foreach( { dependent_term_h . __name__ } , outcome_1= { source_1 } , outcome_2= { source_2 } , outcome_3= { source_3 } , outcome_n= { source_n } )\" ) % timeit H . foreach ( dependent_term_h , outcome_1 = source_1 , outcome_2 = source_2 , outcome_3 = source_3 , outcome_n = source_n ) print () This is primarily for illustration. H.substitute is often better suited to cases involving re-rolling a single independent term such as this one. \u21a9 Source code in dyce/h.py @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ \"H\" , RealLike ]], ** independent_sources : _SourceT , ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each set of outcomes from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Returned histograms are always reduced to their lowest terms. For example rolling a d20, re-rolling a ``#!python 1`` if it comes up, and keeping the result might be expressed as[^1]: [^1]: This is primarily for illustration. [``H.substitute``][dyce.h.H.substitute] is often better suited to cases involving re-rolling a single independent term such as this one. ``` python >>> d20 = H(20) >>> def reroll_one_dependent_term(d20_outcome): ... if d20_outcome == 1: ... return d20 ... else: ... return d20_outcome >>> H.foreach(reroll_one_dependent_term, d20_outcome=d20) H({1: 1, 2: 21, 3: 21, ..., 19: 21, 20: 21}) ``` The ``#!python foreach`` class method merely wraps *dependent_term* and calls [``P.foreach``][dyce.p.P.foreach]. In doing so, it imposes a very modest overhead that is negligible in most cases. ``` python --8<-- \"docs/assets/perf_foreach.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_foreach.ipy\"><code>perf_foreach.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_foreach.ipy\" ``` </details> \"\"\" from dyce import P def _dependent_term ( ** roll_kw ): outcome_kw : Dict [ str , RealLike ] = {} for key , roll in roll_kw . items (): assert isinstance ( roll , tuple ) assert len ( roll ) == 1 outcome_kw [ key ] = roll [ 0 ] return dependent_term ( ** outcome_kw ) return P . foreach ( _dependent_term , ** independent_sources ) format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsInt = 65 , scaled : bool = False , tick : str = '#' , sep : str = ' \\n ' ) -> str Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( f \" { ' 65 chars wide -->|' : ->65 } \" ) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py @beartype def format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsInt = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ``` python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ``` python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``#!python True``, horizontal bars are scaled to *width*. ``` python >>> h = (2@H(6)).ge(7) >>> print(f\"{' 65 chars wide -->|':->65}\") ---------------------------------------------- 65 chars wide -->| >>> print(h.format(scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : RealLike = float ( self . mean ()) except ( OverflowError , TypeError ): mu = self . mean () if width <= 0 : def _parts () -> Iterator [ str ]: yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 def _lines () -> Iterator [ str ]: try : yield f \"avg | { mu : 7.2f } \" std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except ( OverflowError , TypeError ) as exc : warnings . warn ( f \" { str ( exc ) } ; mu: { mu } \" ) if self : outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( _lines ()) ge ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __ge__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map and umap methods. Source code in dyce/h.py @beartype def ge ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ge__, other).umap(bool)``. ``` python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ge__ , other ) . umap ( bool ) gt ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __gt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def gt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__gt__, other).umap(bool)``. ``` python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __gt__ , other ) . umap ( bool ) is_even ( self ) -> H Equivalent to self . umap ( dyce . types . is_even ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py @beartype def is_even ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_even)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_even ) is_odd ( self ) -> H Equivalent to self . umap ( dyce . types . is_odd ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py @beartype def is_odd ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_odd)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_odd ) items ( self ) -> ItemsView [ RealLike , int ] D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py @beartype def items ( self ) -> ItemsView [ RealLike , int ]: return self . _h . items () keys ( self ) -> KeysView [ RealLike ] D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py @beartype def keys ( self ) -> KeysView [ RealLike ]: return self . outcomes () le ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __le__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def le ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__le__, other).umap(bool)``. ``` python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __le__ , other ) . umap ( bool ) lowest_terms ( self ) -> H Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )) ; df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d6avg = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d6avg H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d6avg . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py @beartype def lowest_terms ( self ) -> H : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ``` python >>> df = H((-1, -1, 0, 0, 1, 1)) ; df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ``` python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return type ( self )( self . _lowest_terms ()) lt ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __lt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map and umap methods. Source code in dyce/h.py @beartype def lt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__lt__, other).umap(bool)``. ``` python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __lt__ , other ) . umap ( bool ) map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT ) -> H Applies bin_op to each outcome of the histogram as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . __add__ , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . __add__ , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . __pow__ , 2 ) H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 }) >>> d6 . map ( operator . __pow__ , 2 ) == d6 ** 2 True 1 2 3 4 >>> d6 . map ( operator . __gt__ , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . __gt__ , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT ) -> H : r \"\"\" Applies *bin_op* to each outcome of the histogram as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> d6 = H(6) >>> d6.map(operator.__add__, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.__add__, d6) == d6 + d6 True ``` ``` python >>> d6.map(operator.__pow__, 2) H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1}) >>> d6.map(operator.__pow__, 2) == d6 ** 2 True ``` ``` python >>> d6.map(operator.__gt__, 3) H({False: 3, True: 3}) >>> d6.map(operator.__gt__, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( right_operand , HableT ): right_operand = right_operand . h () if isinstance ( right_operand , H ): return type ( self )( ( bin_op ( s , o ), self [ s ] * right_operand [ o ]) for s , o in product ( self , right_operand ) ) else : return type ( self )( ( bin_op ( outcome , right_operand ), count ) for outcome , count in self . items () ) mean ( self ) -> RealLike Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py @beartype def mean ( self ) -> RealLike : r \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 ) ne ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __ne__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map and umap methods. Source code in dyce/h.py @beartype def ne ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ne__, other).umap(bool)``. ``` python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ne__ , other ) . umap ( bool ) order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> H Experimental This method should be considered experimental and may change or disappear in future versions. Shorthand for self . order_stat_func_for_n ( n )( pos ) . Source code in dyce/h.py @experimental @beartype def order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Shorthand for ``#!python self.order_stat_func_for_n(n)(pos)``. \"\"\" # TODO(posita): Explore different memoization strategies (e.g., with # functools.cache) for this method and H.order_stat_func_for_n return self . order_stat_func_for_n ( n )( pos ) order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], 'H' ] Experimental This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument ( pos ) and computes the probability distribution for each outcome appearing in that position among n @self . 1 2 3 4 >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> order_stat_for_5d6avg = d6avg . order_stat_func_for_n ( 5 ) >>> order_stat_for_5d6avg ( 3 ) # counts where outcome appears at index 3 H ({ 2 : 26 , 3 : 1432 , 4 : 4792 , 5 : 1526 }) The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where 2 appears at the fourth (index 3 ) position, 1432 ways where 3 appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. 1 2 3 4 >>> from dyce import P >>> p_5d6avg = 5 @P ( d6avg ) >>> sum ( count for roll , count in p_5d6avg . rolls_with_counts () if roll [ 3 ] == 5 ) 1526 This method exists in addition to the H.order_stat_for_n_at_pos method because computing the betas for each outcome in n is unnecessary for each pos . Where different pos values are needed for the same n (e.g., in a loop) and where n is large, that overhead can be significant. The returned function caches those betas for n such that repeated querying or results at pos can be computed much faster. 1 2 3 4 5 % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 30 , i ) for i in range ( 10 )] 462 ms \u00b1 16.9 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) % timeit order_stat_for_30d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 30 ) ; [ order_stat_for_30d6_at_pos ( i ) for i in range ( 10 )] 54.4 ms \u00b1 1.47 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Source: perf_order_stat_for_n.ipy 1 2 3 4 5 6 7 8 9 from dyce import H print ( f \"%timeit [H(6).order_stat_for_n_at_pos(30, i) for i in range(10)]\" ) % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 30 , i ) for i in range ( 10 )] print () print ( f \"%timeit order_stat_for_30d6_at_pos = H(6).order_stat_func_for_n(30) ; [order_stat_for_30d6_at_pos(i) for i in range(10)]\" ) % timeit order_stat_for_30d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 30 ) ; [ order_stat_for_30d6_at_pos ( i ) for i in range ( 10 )] print () Source code in dyce/h.py @experimental @beartype def order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], \"H\" ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``#!python n@self``. ``` python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``#!python 2`` appears at the fourth (index ``#!python 3``) position, 1432 ways where ``#!python 3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. ``` python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster. ``` python --8<-- \"docs/assets/perf_order_stat_for_n.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_order_stat_for_n.ipy\"><code>perf_order_stat_for_n.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_order_stat_for_n.ipy\" ``` </details> \"\"\" betas_by_outcome : Dict [ RealLike , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ RealLike , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) @beartype def order_stat_for_n_at_pos ( pos : SupportsInt ) -> H : return type ( self )( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos outcomes ( self ) -> KeysView [ RealLike ] More descriptive synonym for the keys method . Source code in dyce/h.py @beartype def outcomes ( self ) -> KeysView [ RealLike ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . _h . keys () rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> H Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . rmap ( 2 , operator . __pow__ ) H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 }) >>> d6 . rmap ( 2 , operator . __pow__ ) == 2 ** d6 True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/h.py @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> H : r \"\"\" Analogous to the [``map`` method][dyce.h.H.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> d6 = H(6) >>> d6.rmap(2, operator.__pow__) H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1}) >>> d6.rmap(2, operator.__pow__) == 2 ** d6 True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.h.H.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" return type ( self )( ( bin_op ( left_operand , outcome ), count ) for outcome , count in self . items () ) roll ( self ) -> RealLike Returns a (weighted) random outcome, sorted. Source code in dyce/h.py @beartype def roll ( self ) -> RealLike : r \"\"\" Returns a (weighted) random outcome, sorted. \"\"\" return ( rng . RNG . choices ( population = tuple ( self . outcomes ()), weights = tuple ( self . counts ()), k = 1 , )[ 0 ] if self else 0 ) stdev ( self , mu : Optional [ RealLike ] = None ) -> RealLike Shorthand for math . sqrt ( self . variance ( mu )) . Source code in dyce/h.py @beartype def stdev ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Shorthand for ``#!python math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu )) substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = < function coalesce_replace at 0x10609d040 > , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 , 1 )) -> H Experimental The precision_limit parameter should be considered experimental and may change or disappear in future versions. Calls expand on each outcome. If expand returns a single outcome, it replaces the existing outcome. If it returns an H object , expansion is performed again (recursively) on that object until max_depth or precision_limit is exhausted. coalesce is called on the original outcome and the expanded histogram or outcome and the returned histogram is \u201cfolded\u201d into result. (More on these terms and concepts below.) The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. coalesce is not called unless expand returns a histogram If expand returns a single outcome, it always replaces the existing outcome. This is intentional. To return a single outcome, but trigger coalesce , characterize that outcome as a single-sided die (e.g., H ({ outcome : 1 }) . See the coalesce_replace and lowest_terms methods. This method can be used to model complex mechanics. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). This method uses the aggregate_with_counts function in its implementation. As such, If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. 1 2 >>> H ( 6 ) . substitute ( lambda __ , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda __ , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions with dependent variables. Consider the following mechanic: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . __add__ , max_depth = 6 ) >>> h_even = h . is_even () >>> print ( f \" { h_even [ 1 ] / h_even . total : .3% } \" ) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | When expand returns an H object , outcomes produced from the corresponding coalesce are accumulated, but the counts retain their \u201cscale\u201d within the context of the expansion. This becomes clearer when there is no overlap between the substituted histogram and the other outcomes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 >>> d6 = H ( 6 ) >>> d00 = ( H ( 10 ) - 1 ) * 10 ; d00 H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }) >>> set ( d6 ) & set ( d00 ) == set () # no outcomes in common True >>> d6_d00 = d6 . substitute ( ... # If a one comes up when rolling the d6, ... # roll a d00 and take that result instead ... lambda h , outcome : d00 if outcome == 1 else outcome ... ) ; d6_d00 H ({ 0 : 1 , 2 : 10 , 3 : 10 , 4 : 10 , 5 : 10 , 6 : 10 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }) Note that the sum of the outcomes\u2019 counts from the d00 make up the same proportion as the one\u2019s outcome and count they replaced from the d6. 1 2 3 4 5 6 7 8 >>> from fractions import Fraction >>> Fraction ( ... sum ( count for outcome , count in d6_d00 . items () if outcome in d00 ), ... d6_d00 . total , ... ) Fraction ( 1 , 6 ) >>> Fraction ( d6 [ 1 ], d6 . total ) Fraction ( 1 , 6 ) Precision limits This method will halt recursive substitution on any branch either when its depth exceeds max_depth or its \u201ccontextual precision\u201d is precision_limit or less. In either case, substitution is attempted for all of the outcomes of a(n expanded) histogram or none of them. The contextual precision of a histogram is its proportion to the whole. The contextual precision of the original (or top-level) histogram is Fraction ( 1 , 1 ) . By setting precision_limit to that value, we basically ensure no substitution. 1 2 3 4 5 6 7 8 9 10 >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome == 1 else outcome , ... precision_limit = Fraction ( 1 , 1 ), # no substitution ... ) == d6 True >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome == 1 else outcome , ... max_depth = 0 , # no substitution ... ) == d6 True Let\u2019s make a contrived, but illustrative modification to our d6/d00 example from above. If a one comes up when rolling a d6, roll a d00, but re-roll any 80s. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome in ( 1 , 80 ) else outcome , ... max_depth = 100 , # <-- we'll never hit this ... # will halt substitution after the original one from the d6 ... precision_limit = Fraction ( 1 , 6 ), ... ) == d6_d00 True >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome in ( 1 , 80 ) else outcome , ... max_depth = 100 , ... # will halt substitution after the first 80 substitution ... # after the original one from the d6 ... precision_limit = Fraction ( 1 , 6 ) * Fraction ( 1 , 10 ), ... ) H ({ 0 : 11 , 2 : 100 , ... , 6 : 100 , 10 : 11 , ... , 70 : 11 , 80 : 1 , 90 : 11 }) >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome in ( 1 , 80 ) else outcome , ... max_depth = 100 , ... # will halt substitution after the second 80 substitution ... # after the original one from the d6 ... precision_limit = Fraction ( 1 , 6 ) * Fraction ( 1 , 10 ) - Fraction ( 1 , 1000000000 ), # <-- juuust under the wire ... ) H ({ 0 : 111 , 2 : 1000 , ... , 6 : 1000 , 10 : 111 , ... , 70 : 111 , 80 : 1 , 90 : 111 }) The default value for precision_limit is zero, which basically means it is ignored and recursion is limited solely by max_depth . If you want to ensure that this method stops delving based solely on precision, set max_depth to - 1 , which is equivalent to sys . getrecursionlimit () + 1 1 . Be aware that this skews results in favor of non-limited branches. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> h = H ({ 1 : 1 , 2 : 2 , 3 : 3 }) >>> print ( h . explode ( max_depth = 5 ) . format ( scaled = True )) avg | 4.59 std | 3.96 var | 15.65 1 | 16.67 % | ######################## 2 | 33.33 % | ################################################# 4 | 8.33 % | ############ 5 | 16.67 % | ######################## 7 | 4.17 % | ###### 8 | 8.33 % | ############ 10 | 2.08 % | ### 11 | 4.17 % | ###### 13 | 1.04 % | # 14 | 2.08 % | ### 16 | 0.52 % | 17 | 1.04 % | # 18 | 1.56 % | ## >>> print ( h . explode ( max_depth =- 1 , precision_limit = Fraction ( 1 , 6 ** 2 )) . format ( scaled = True )) avg | 4.63 std | 4.09 var | 16.72 1 | 16.67 % | ######################## 2 | 33.33 % | ################################################# 4 | 8.33 % | ############ 5 | 16.67 % | ######################## 7 | 4.17 % | ###### 8 | 8.33 % | ############ 10 | 2.08 % | ### 11 | 4.17 % | ###### 13 | 1.04 % | # 14 | 2.08 % | ### 16 | 0.52 % | 17 | 1.04 % | # 19 | 0.26 % | 20 | 0.52 % | 21 | 0.78 % | # Also be aware that without max_depth as a safety net, some substitutions are guaranteed to result in RecursionError s, even with very high precision_limit s. 1 2 3 4 5 6 7 8 >>> H ( 1 ) . substitute ( ... lambda h , outcome : H ({ outcome + 1 : 1 }), # expands to a single-sided die ... max_depth =- 1 , ... precision_limit = Fraction ( 999999 , 1000000 ), ... ) Traceback ( most recent call last ): ... RecursionError : maximum recursion depth exceeded in comparison H.explode \u2019s expand implementation guards against this by returning outcome if the passed histogram has only one face. Consider a similar approach for your own expand implementations if outcomes\u2019 contextual probabilities do not asymptotically approach zero. This method will \u201cbottom out\u201d far earlier. As of this writing, the practical limit of its implementation (without optimization) is something close to \\(\\frac {1} {3} \\times \\left( limit - depth \\right)\\) , where \\(limit\\) is sys . getrecursionlimit () and \\(depth\\) is len ( inspect . stack ( 0 )) . This also assumes the provided implementations for expand and coalesce don\u2019t contribute significantly to the call stack. Setting max_depth to - 1 or one beyond the absolute limit signals that the caller wants it out of the way. \u21a9 Source code in dyce/h.py @beartype def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" !!! warning \"Experimental\" The *precision_limit* parameter should be considered experimental and may change or disappear in future versions. Calls *expand* on each outcome. If *expand* returns a single outcome, it replaces the existing outcome. If it returns an [``H`` object][dyce.h.H], expansion is performed again (recursively) on that object until *max_depth* or *precision_limit* is exhausted. *coalesce* is called on the original outcome and the expanded histogram or outcome and the returned histogram is \u201cfolded\u201d into result. (More on these terms and concepts below.) The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. !!! note \"*coalesce* is not called unless *expand* returns a histogram\" If *expand* returns a single outcome, it *always* replaces the existing outcome. This is intentional. To return a single outcome, but trigger *coalesce*, characterize that outcome as a single-sided die (e.g., ``#!python H({outcome: 1})``. See the [``coalesce_replace``][dyce.h.coalesce_replace] and [``lowest_terms``][dyce.h.H.lowest_terms] methods. This method can be used to model complex mechanics. The following models re-rolling a face of 1 on the first roll: ``` python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). This method uses the [``aggregate_with_counts``][dyce.h.aggregate_with_counts] function in its implementation. As such, If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. ``` python >>> H(6).substitute(lambda __, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda __, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``#!python substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions with dependent variables. Consider the following mechanic: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ``` python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.__add__, max_depth=6) >>> h_even = h.is_even() >>> print(f\"{h_even[1] / h_even.total:.3%}\") 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. ``` python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` When *expand* returns an [``H`` object][dyce.h.H], outcomes produced from the corresponding *coalesce* are accumulated, but the counts retain their \u201cscale\u201d within the context of the expansion. This becomes clearer when there is no overlap between the substituted histogram and the other outcomes. ``` python >>> d6 = H(6) >>> d00 = (H(10) - 1) * 10 ; d00 H({0: 1, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) >>> set(d6) & set(d00) == set() # no outcomes in common True >>> d6_d00 = d6.substitute( ... # If a one comes up when rolling the d6, ... # roll a d00 and take that result instead ... lambda h, outcome: d00 if outcome == 1 else outcome ... ) ; d6_d00 H({0: 1, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) ``` Note that the sum of the outcomes\u2019 counts from the d00 make up the same proportion as the one\u2019s outcome and count they replaced from the d6. ``` python >>> from fractions import Fraction >>> Fraction( ... sum(count for outcome, count in d6_d00.items() if outcome in d00), ... d6_d00.total, ... ) Fraction(1, 6) >>> Fraction(d6[1], d6.total) Fraction(1, 6) ``` !!! tip \"Precision limits\" This method will halt recursive substitution on any branch *either* when its depth exceeds *max_depth* *or* its \u201ccontextual precision\u201d is *precision_limit* or less. In either case, substitution is attempted for all of the outcomes of a(n expanded) histogram or none of them. The contextual precision of a histogram is its proportion to the whole. The contextual precision of the original (or top-level) histogram is ``#!python Fraction(1, 1)``. By setting *precision_limit* to that value, we basically ensure no substitution. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... precision_limit=Fraction(1, 1), # no substitution ... ) == d6 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... max_depth=0, # no substitution ... ) == d6 True ``` Let\u2019s make a contrived, but illustrative modification to our d6/d00 example from above. If a one comes up when rolling a d6, roll a d00, but re-roll any 80s. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, # <-- we'll never hit this ... # will halt substitution after the original one from the d6 ... precision_limit=Fraction(1, 6), ... ) == d6_d00 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the first 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10), ... ) H({0: 11, 2: 100, ..., 6: 100, 10: 11, ..., 70: 11, 80: 1, 90: 11}) >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the second 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10) - Fraction(1, 1000000000), # <-- juuust under the wire ... ) H({0: 111, 2: 1000, ..., 6: 1000, 10: 111, ..., 70: 111, 80: 1, 90: 111}) ``` The default value for *precision_limit* is zero, which basically means it is ignored and recursion is limited solely by *max_depth*. If you want to ensure that this method stops delving based *solely* on precision, set *max_depth* to ``#!python -1``, which is equivalent to ``#!python sys.getrecursionlimit() + 1``[^1]. Be aware that this skews results in favor of non-limited branches. ``` python >>> h = H({1: 1, 2: 2, 3: 3}) >>> print(h.explode(max_depth=5).format(scaled=True)) avg | 4.59 std | 3.96 var | 15.65 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 18 | 1.56% |## >>> print(h.explode(max_depth=-1, precision_limit=Fraction(1, 6 ** 2)).format(scaled=True)) avg | 4.63 std | 4.09 var | 16.72 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 19 | 0.26% | 20 | 0.52% | 21 | 0.78% |# ``` Also be aware that without *max_depth* as a safety net, some substitutions are guaranteed to result in ``#!python RecursionError``s, even with very high *precision_limit*s. ``` python >>> H(1).substitute( ... lambda h, outcome: H({outcome + 1: 1}), # expands to a single-sided die ... max_depth=-1, ... precision_limit=Fraction(999999, 1000000), ... ) Traceback (most recent call last): ... RecursionError: maximum recursion depth exceeded in comparison ``` [``H.explode``][dyce.h.H.explode]\u2019s *expand* implementation guards against this by returning ``#!python outcome`` if the passed histogram has only one face. Consider a similar approach for your own *expand* implementations if outcomes\u2019 contextual probabilities do not asymptotically approach zero. [^1]: This method will \u201cbottom out\u201d far earlier. As of this writing, the practical limit of its implementation (without optimization) is something close to $\\frac {1} {3} \\times \\left( limit - depth \\right)$, where $limit$ is ``#!python sys.getrecursionlimit()`` and $depth$ is ``#!python len(inspect.stack(0))``. This also assumes the provided implementations for *expand* and *coalesce* don\u2019t contribute significantly to the call stack. Setting *max_depth* to ``#!python -1`` or one beyond the absolute limit signals that the caller wants it out of the way. \"\"\" max_depth = as_int ( max_depth ) if max_depth == - 1 : max_depth = sys . getrecursionlimit () + 1 if max_depth < 0 : raise ValueError ( \"max_depth cannot be an arbitrary negative number (use -1 explicitly to indicate no limit)\" ) if precision_limit < 0 or precision_limit > 1 : raise ValueError ( f \"precision_limit ( { precision_limit } ) must be between zero and one, inclusive\" ) def _substitute ( h : H , depth : int = 0 , contextual_precision : Fraction = Fraction ( 1 ), ) -> H : assert coalesce is not None if depth == max_depth or contextual_precision <= precision_limit : return h def _expand_and_coalesce () -> Iterator [ Tuple [ Union [ H , RealLike ], int ]]: total = h . total for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded_precision = Fraction ( contextual_precision . numerator * count , contextual_precision . denominator * total , ) expanded = _substitute ( expanded , depth + 1 , expanded_precision ) # Coalesce the result expanded = coalesce ( expanded , outcome ) yield expanded , count return aggregate_with_counts ( _expand_and_coalesce (), type ( self )) return _substitute ( self ) . lowest_terms () umap ( self , un_op : _UnaryOperatorT ) -> H Applies un_op to each outcome of the histogram. 1 2 3 >>> import operator >>> H ( 6 ) . umap ( operator . __neg__ ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py @beartype def umap ( self , un_op : _UnaryOperatorT ) -> H : r \"\"\" Applies *un_op* to each outcome of the histogram. ``` python >>> import operator >>> H(6).umap(operator.__neg__) H(-6) ``` ``` python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = type ( self )(( un_op ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : simple_init = un_op ( self . _simple_init ) if isinstance ( simple_init , SupportsInt ): h_simple = type ( self )( simple_init ) if h_simple == h : return h_simple return h values ( self ) -> ValuesView [ int ] D.values() -> an object providing a view on D's values Source code in dyce/h.py @beartype def values ( self ) -> ValuesView [ int ]: return self . counts () variance ( self , mu : Optional [ RealLike ] = None ) -> RealLike Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py @beartype def variance ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 ) vs ( self , other : _OperandT ) -> H Compares the histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self . within ( 0 , 0 , other ) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py @beartype def vs ( self , other : _OperandT ) -> H : r \"\"\" Compares the histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``#!python self.within(0, 0, other)``. ``` python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other ) within ( self , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H Computes the difference between the histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ()) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ()) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py @beartype def within ( self , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Computes the difference between the histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ``` python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format()) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format()) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other ) P ( Sequence , Generic , HableOpsMixin ) An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). 1 2 3 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True This class implements the HableT protocol and derives from the HableOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using arithmetic operations. 1 2 >>> - p_d6 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) To perform arithmetic on individual H objects in a pool without flattening, use the map , rmap , and umap methods. 1 2 3 >>> import operator >>> P ( 4 , 6 , 8 ) . umap ( operator . __neg__ ) P ( - 8 , - 6 , - 4 ) 1 2 >>> P ( 4 , 6 ) . map ( operator . __pow__ , 2 ) P ( H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 }), H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 })) 1 2 >>> P ( 4 , 6 ) . rmap ( 2 , operator . __pow__ ) P ( H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 }), H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 })) Comparisons with H objects work as expected. 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram. 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering. 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HableT protocol , the h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ()) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ### Source code in dyce/p.py class P ( Sequence [ H ], HableOpsMixin ): r \"\"\" An immutable pool (ordered sequence) supporting group operations for zero or more [``H`` objects][dyce.h.H] (provided or created from the [initializer][dyce.p.P.__init__]\u2019s *args* parameter). ``` python >>> from dyce import P >>> p_d6 = P(6) ; p_d6 # shorthand for P(H(6)) P(6) ``` ``` python >>> P(p_d6, p_d6) # 2d6 P(6, 6) >>> 2@p_d6 # also 2d6 P(6, 6) >>> 2@(2@p_d6) == 4@p_d6 True ``` ``` python >>> p = P(4, P(6, P(8, P(10, P(12, P(20)))))) ; p P(4, 6, 8, 10, 12, 20) >>> sum(p.roll()) in p.h() True ``` This class implements the [``HableT`` protocol][dyce.h.HableT] and derives from the [``HableOpsMixin`` class][dyce.h.HableOpsMixin], which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the [``h`` method][dyce.p.P.h], or implicitly by using arithmetic operations. ``` python >>> -p_d6 H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) ``` ``` python >>> p_d6 + p_d6 H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` ``` python >>> 2 * P(8) - 1 H({1: 1, 3: 1, 5: 1, 7: 1, 9: 1, 11: 1, 13: 1, 15: 1}) ``` To perform arithmetic on individual [``H`` objects][dyce.h.H] in a pool without flattening, use the [``map``][dyce.p.P.map], [``rmap``][dyce.p.P.rmap], and [``umap``][dyce.p.P.umap] methods. ``` python >>> import operator >>> P(4, 6, 8).umap(operator.__neg__) P(-8, -6, -4) ``` ``` python >>> P(4, 6).map(operator.__pow__, 2) P(H({1: 1, 4: 1, 9: 1, 16: 1}), H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1})) ``` ``` python >>> P(4, 6).rmap(2, operator.__pow__) P(H({2: 1, 4: 1, 8: 1, 16: 1}), H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1})) ``` Comparisons with [``H`` objects][dyce.h.H] work as expected. ``` python >>> from dyce import H >>> 3@p_d6 == H(6) + H(6) + H(6) True ``` Indexing selects a contained histogram. ``` python >>> P(4, 6, 8)[0] H(4) ``` Note that pools are opinionated about ordering. ``` python >>> P(8, 6, 4) P(4, 6, 8) >>> P(8, 6, 4)[0] == P(8, 4, 6)[0] == H(4) True ``` In an extension to (departure from) the [``HableT`` protocol][dyce.h.HableT], the [``h`` method][dyce.p.P.h]\u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice (``3d6``) can be expressed as: ``` python >>> p_3d6 = 3@p_d6 >>> p_3d6.h(-2, -1) H({2: 1, 3: 3, 4: 7, 5: 12, 6: 19, 7: 27, 8: 34, 9: 36, 10: 34, 11: 27, 12: 16}) >>> print(p_3d6.h(-2, -1).format()) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46% | 3 | 1.39% | 4 | 3.24% |# 5 | 5.56% |## 6 | 8.80% |#### 7 | 12.50% |###### 8 | 15.74% |####### 9 | 16.67% |######## 10 | 15.74% |####### 11 | 12.50% |###### 12 | 7.41% |### ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_hs\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , * args : Union [ SupportsInt , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs () -> Iterator [ H ]: for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h elif isinstance ( a , SupportsInt ): yield H ( a ) else : raise ValueError ( f \"unrecognized initializer { args } \" ) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : def _parts () -> Iterator [ str ]: for h in self : yield ( str ( h . _simple_init ) if h . _simple_init is not None else repr ( h )) args = \", \" . join ( _parts ()) return f \" { type ( self ) . __name__ } ( { args } )\" @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , P ): return __eq__ ( self . _hs , other . _hs ) else : return NotImplemented @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , P ): return __ne__ ( self . _hs , other . _hs ) else : return NotImplemented @beartype def __len__ ( self ) -> int : return len ( self . _hs ) @overload def __getitem__ ( self , key : SupportsIndex ) -> H : ... @overload def __getitem__ ( self , key : slice ) -> P : ... @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( self , key : _GetItemT ) -> Union [ H , \"P\" ]: # type: ignore [override] if isinstance ( key , slice ): return P ( * self . _hs [ key ]) else : return self . _hs [ __index__ ( key )] @beartype def __iter__ ( self ) -> Iterator [ H ]: return iter ( self . _hs ) @beartype def __matmul__ ( self , other : SupportsInt ) -> P : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return P ( * chain . from_iterable ( repeat ( self , other ))) @beartype def __rmatmul__ ( self , other : SupportsInt ) -> P : return self . __matmul__ ( other ) @beartype def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``#!python H((sum(roll), count) for roll, count in self.rolls_with_counts(*which))`` with some short-circuit optimizations. When provided no arguments, ``#!python h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HableT`` protocol][dyce.h.HableT]. ``` python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ``` python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ``` python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_h ( self ) # ---- Properties ------------------------------------------------------------------ @property def is_homogeneous ( self ) -> bool : r \"\"\" !!! warning \"Experimental\" This property should be considered experimental and may change or disappear in future versions. A flag indicating whether the pool\u2019s population of histograms is homogeneous. ``` python >>> P(6, 6).is_homogeneous True >>> P(4, 6, 8).is_homogeneous False ``` \"\"\" return len ( set ( self . _hs )) <= 1 # ---- Methods --------------------------------------------------------------------- @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : Union [ \"P\" , H , HableT , _SourceT ], ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each unique set of rolls from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Rolls are sorted least to greatest. Returned histograms are always reduced to their lowest terms. ``` python >>> from dyce.p import RollT >>> def three_way_vs(first: RollT, second: RollT, third: RollT): ... first_reversed = first[::-1] ... second_reversed = second[::-1] ... third_reversed = third[::-1] ... if first_reversed > second_reversed and first_reversed > third_reversed: ... return 1 # first is the clear winner ... elif second_reversed > first_reversed and second_reversed > third_reversed: ... return 2 # second is the clear winner ... elif third_reversed > first_reversed and third_reversed > second_reversed: ... return 3 # third is the clear winner ... else: ... return 0 # there was a tie somewhere >>> P.foreach( ... three_way_vs, ... first=P(6, 6), # first has pool of two d6s ... second=P(6, 6), # second has pool of two d6s ... third=P(4, 8), # third has pool of one d4 and one d8 ... ) H({0: 1103, 1: 5783, 2: 5783, 3: 8067}) ``` When all of ``#!python foreach``\u2019s arguments are [``P`` objects][dyce.p.P] of size 1 or anything other than a ``P`` object, this function behaves similarly to [``H.foreach``][dyce.h.H] (although the signature of the *dependent_term* callback function differs slightly between the two interfaces). ``` python >>> from itertools import chain >>> P.foreach( ... lambda **kw: sum(chain(*kw.values())), # receives single-element rolls ... src1=P(6), # pool of size 1 ... src2=H(6), # histogram ... src3=range(6, 0, -1), # histogram source ... ) == H.foreach( ... lambda **kw: sum(kw.values()), # receives outcomes ... src1=P(6).h(), # histogram ... src2=H(6), # histogram ... src3={1, 2, 3, 4, 5, 6}, # histogram source ... ) True ``` The ``#!python foreach`` class method is equivalent to nesting loops iterating over [``P.rolls_with_counts``][dyce.p.P.rolls_with_counts] for each independent term and then aggregating the results. ``` python >>> def dependent_term( ... *, ... roll_1, ... roll_2, ... # ... ... roll_n, ... ): ... return ( ... (roll_2[-1] > roll_1[-1]) ... + (roll_n[-1] > roll_2[-1]) ... # ... ... ) >>> source_1 = P(8) >>> source_2 = P(6, 6) >>> # ... >>> source_n = P(4, 4, 4) >>> h = P.foreach( ... dependent_term, ... roll_1=source_1, ... roll_2=source_2, ... # ... ... roll_n=source_n, ... ) ; h H({0: 3821, 1: 5126, 2: 269}) >>> def resolve(): ... for roll_1, count_1 in source_1.rolls_with_counts(): ... for roll_2, count_2 in source_2.rolls_with_counts(): ... # ... ... for roll_n, count_n in source_n.rolls_with_counts(): ... # ... ... yield dependent_term( ... roll_1=roll_1, ... roll_2=roll_2, ... # ... ... roll_n=roll_n, ... ), ( ... count_1 ... * count_2 ... # * ... ... * count_n ... ) >>> from dyce.h import aggregate_with_counts >>> aggregate_with_counts(resolve()) == h True ``` \"\"\" pools_by_kw : Dict [ str , P ] = {} for source_name , source in independent_sources . items (): if isinstance ( source , H ): pools_by_kw [ source_name ] = P ( source ) elif isinstance ( source , P ): pools_by_kw [ source_name ] = source elif isinstance ( source , HableT ): pools_by_kw [ source_name ] = P ( source . h ()) else : pools_by_kw [ source_name ] = P ( H ( source )) def _kw_roll_count_tuples ( pool_name : str , ) -> Iterator [ Tuple [ str , RollT , int ]]: for roll , count in pools_by_kw [ pool_name ] . rolls_with_counts (): yield pool_name , roll , count def _resolve_dependent_term_for_rolls () -> Iterator [ Tuple [ Union [ H , RealLike ], int ] ]: for kw_roll_count_tuples in product ( * ( _kw_roll_count_tuples ( pool_name ) for pool_name in pools_by_kw ) ): combined_count = reduce ( __mul__ , ( count for _ , _ , count in kw_roll_count_tuples ), 1 ) rolls_by_name = { name : roll for name , roll , _ in kw_roll_count_tuples } yield dependent_term ( ** rolls_by_name ), combined_count return aggregate_with_counts ( _resolve_dependent_term_for_rolls ()) . lowest_terms () @experimental @beartype def appearances_in_rolls ( self , outcome : RealLike ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``#!python H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ``` python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ``` python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being about twice as fast as the boolean accumulation technique for larger sets. ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_appearances_in_rolls.ipy\"><code>perf_appearances_in_rolls.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.ipy\" ``` </details> \"\"\" group_counters : List [ Counter [ RealLike ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ RealLike ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_h ( H ( group_counter ) for group_counter in group_counters ) @beartype def roll ( self ) -> RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. !!! note \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self )) @beartype def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding two-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the two-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed for more flexible selections. ``` python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. ``` python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ``` python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``#!python (1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ``` python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. ``` python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable. ``` python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted. ``` python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ``` python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$. $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``#!python n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls. ``#!python ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``#!python (a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``#!python H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ``` python --8<-- \"docs/assets/perf_rolls_with_counts.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_rolls_with_counts.ipy\"><code>perf_rolls_with_counts.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_rolls_with_counts.ipy\" ``` </details> \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count @beartype def map ( self , op : _BinaryOperatorT , right_operand : _OperandT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.map(op, right_operand) for h in self))``. See the [``H.map`` method][dyce.h.H.map]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.map(operator.__mul__, -1) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) ``` \"\"\" return P ( * ( h . map ( op , right_operand ) for h in self )) @beartype def rmap ( self , left_operand : RealLike , op : _BinaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.rmap(left_operand, op) for h in self))``. See the [``H.rmap`` method][dyce.h.H.rmap]. ``` python >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(Fraction).rmap(1, operator.__truediv__) P(H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1}), H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1})) ``` \"\"\" return P ( * ( h . rmap ( left_operand , op ) for h in self )) @beartype def umap ( self , op : _UnaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.umap(op) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(operator.__neg__) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) >>> p_3d6.umap(operator.__abs__) P(H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1})) ``` \"\"\" return P ( * ( h . umap ( op ) for h in self )) __slots__ : Union [ str , Iterable [ str ]] special is_homogeneous : bool property readonly Experimental This property should be considered experimental and may change or disappear in future versions. A flag indicating whether the pool\u2019s population of histograms is homogeneous. 1 2 3 4 >>> P ( 6 , 6 ) . is_homogeneous True >>> P ( 4 , 6 , 8 ) . is_homogeneous False __eq__ ( self , other ) -> bool special Source code in dyce/p.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , P ): return __eq__ ( self . _hs , other . _hs ) else : return NotImplemented __getitem__ ( self , key : _GetItemT ) -> Union [ H , 'P' ] special Source code in dyce/p.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( self , key : _GetItemT ) -> Union [ H , \"P\" ]: # type: ignore [override] if isinstance ( key , slice ): return P ( * self . _hs [ key ]) else : return self . _hs [ __index__ ( key )] __init__ ( self , * args : Union [ SupportsInt , 'P' , H ]) -> None special Initializer. Source code in dyce/p.py @beartype def __init__ ( self , * args : Union [ SupportsInt , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs () -> Iterator [ H ]: for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h elif isinstance ( a , SupportsInt ): yield H ( a ) else : raise ValueError ( f \"unrecognized initializer { args } \" ) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs ) __iter__ ( self ) -> Iterator [ H ] special Source code in dyce/p.py @beartype def __iter__ ( self ) -> Iterator [ H ]: return iter ( self . _hs ) __len__ ( self ) -> int special Source code in dyce/p.py @beartype def __len__ ( self ) -> int : return len ( self . _hs ) __matmul__ ( self , other : SupportsInt ) -> P special Source code in dyce/p.py @beartype def __matmul__ ( self , other : SupportsInt ) -> P : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return P ( * chain . from_iterable ( repeat ( self , other ))) __ne__ ( self , other ) -> bool special Source code in dyce/p.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , P ): return __ne__ ( self . _hs , other . _hs ) else : return NotImplemented __repr__ ( self ) -> str special Source code in dyce/p.py @beartype def __repr__ ( self ) -> str : def _parts () -> Iterator [ str ]: for h in self : yield ( str ( h . _simple_init ) if h . _simple_init is not None else repr ( h )) args = \", \" . join ( _parts ()) return f \" { type ( self ) . __name__ } ( { args } )\" __rmatmul__ ( self , other : SupportsInt ) -> P special Source code in dyce/p.py @beartype def __rmatmul__ ( self , other : SupportsInt ) -> P : return self . __matmul__ ( other ) appearances_in_rolls ( self , outcome : RealLike ) -> H Experimental This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H (( sum ( 1 for v in roll if v == outcome ), count ) for roll , count in self . rolls_with_counts ()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being about twice as fast as the boolean accumulation technique for larger sets. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 % timeit 3 @d4_eq3 + 2 @d6_eq3 397 \u00b5s \u00b1 17.5 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 653 \u00b5s \u00b1 23.9 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit 9 @d4_eq3 + 6 @d6_eq3 1.39 ms \u00b1 53.9 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.12 ms \u00b1 35.3 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit 27 @d4_eq3 + 18 @d6_eq3 7.14 ms \u00b1 223 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) % timeit P ( 27 @P ( 4 ), 18 @P ( 6 )) . appearances_in_rolls ( 3 ) 3.32 ms \u00b1 109 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) % timeit 81 @d4_eq3 + 54 @d6_eq3 46.7 ms \u00b1 1.01 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) % timeit P ( 81 @P ( 4 ), 54 @P ( 6 )) . appearances_in_rolls ( 3 ) 17.1 ms \u00b1 416 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Source: perf_appearances_in_rolls.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 from dyce import H , P p_2d6 = P ( 6 , 6 ) d4 , d6 = H ( 4 ), H ( 6 ) p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) print ( f \"%timeit 3@d4_eq3 + 2@d6_eq3\" ) % timeit 3 @d4_eq3 + 2 @d6_eq3 print () print ( f \"%timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) print () print ( f \"%timeit 9@d4_eq3 + 6@d6_eq3\" ) % timeit 9 @d4_eq3 + 6 @d6_eq3 print () print ( f \"%timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) print () print ( f \"%timeit 27@d4_eq3 + 18@d6_eq3\" ) % timeit 27 @d4_eq3 + 18 @d6_eq3 print () print ( f \"%timeit P(27@P(4), 18@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 27 @P ( 4 ), 18 @P ( 6 )) . appearances_in_rolls ( 3 ) print () print ( f \"%timeit 81@d4_eq3 + 54@d6_eq3\" ) % timeit 81 @d4_eq3 + 54 @d6_eq3 print () print ( f \"%timeit P(81@P(4), 54@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 81 @P ( 4 ), 54 @P ( 6 )) . appearances_in_rolls ( 3 ) print () Source code in dyce/p.py @experimental @beartype def appearances_in_rolls ( self , outcome : RealLike ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``#!python H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ``` python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ``` python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being about twice as fast as the boolean accumulation technique for larger sets. ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_appearances_in_rolls.ipy\"><code>perf_appearances_in_rolls.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.ipy\" ``` </details> \"\"\" group_counters : List [ Counter [ RealLike ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ RealLike ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_h ( H ( group_counter ) for group_counter in group_counters ) foreach ( dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : Union [ 'P' , H , HableT , _SourceT ]) -> H classmethod Experimental This method should be considered experimental and may change or disappear in future versions. Calls dependent_term for each unique set of rolls from the product of independent_sources and accumulates the results. This is useful for resolving dependent probabilities. Rolls are sorted least to greatest. Returned histograms are always reduced to their lowest terms. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from dyce.p import RollT >>> def three_way_vs ( first : RollT , second : RollT , third : RollT ): ... first_reversed = first [:: - 1 ] ... second_reversed = second [:: - 1 ] ... third_reversed = third [:: - 1 ] ... if first_reversed > second_reversed and first_reversed > third_reversed : ... return 1 # first is the clear winner ... elif second_reversed > first_reversed and second_reversed > third_reversed : ... return 2 # second is the clear winner ... elif third_reversed > first_reversed and third_reversed > second_reversed : ... return 3 # third is the clear winner ... else : ... return 0 # there was a tie somewhere >>> P . foreach ( ... three_way_vs , ... first = P ( 6 , 6 ), # first has pool of two d6s ... second = P ( 6 , 6 ), # second has pool of two d6s ... third = P ( 4 , 8 ), # third has pool of one d4 and one d8 ... ) H ({ 0 : 1103 , 1 : 5783 , 2 : 5783 , 3 : 8067 }) When all of foreach \u2019s arguments are P objects of size 1 or anything other than a P object, this function behaves similarly to H.foreach (although the signature of the dependent_term callback function differs slightly between the two interfaces). 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from itertools import chain >>> P . foreach ( ... lambda ** kw : sum ( chain ( * kw . values ())), # receives single-element rolls ... src1 = P ( 6 ), # pool of size 1 ... src2 = H ( 6 ), # histogram ... src3 = range ( 6 , 0 , - 1 ), # histogram source ... ) == H . foreach ( ... lambda ** kw : sum ( kw . values ()), # receives outcomes ... src1 = P ( 6 ) . h (), # histogram ... src2 = H ( 6 ), # histogram ... src3 = { 1 , 2 , 3 , 4 , 5 , 6 }, # histogram source ... ) True The foreach class method is equivalent to nesting loops iterating over P.rolls_with_counts for each independent term and then aggregating the results. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> def dependent_term ( ... * , ... roll_1 , ... roll_2 , ... # ... ... roll_n , ... ): ... return ( ... ( roll_2 [ - 1 ] > roll_1 [ - 1 ]) ... + ( roll_n [ - 1 ] > roll_2 [ - 1 ]) ... # ... ... ) >>> source_1 = P ( 8 ) >>> source_2 = P ( 6 , 6 ) >>> # ... >>> source_n = P ( 4 , 4 , 4 ) >>> h = P . foreach ( ... dependent_term , ... roll_1 = source_1 , ... roll_2 = source_2 , ... # ... ... roll_n = source_n , ... ) ; h H ({ 0 : 3821 , 1 : 5126 , 2 : 269 }) >>> def resolve (): ... for roll_1 , count_1 in source_1 . rolls_with_counts (): ... for roll_2 , count_2 in source_2 . rolls_with_counts (): ... # ... ... for roll_n , count_n in source_n . rolls_with_counts (): ... # ... ... yield dependent_term ( ... roll_1 = roll_1 , ... roll_2 = roll_2 , ... # ... ... roll_n = roll_n , ... ), ( ... count_1 ... * count_2 ... # * ... ... * count_n ... ) >>> from dyce.h import aggregate_with_counts >>> aggregate_with_counts ( resolve ()) == h True Source code in dyce/p.py @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : Union [ \"P\" , H , HableT , _SourceT ], ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each unique set of rolls from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Rolls are sorted least to greatest. Returned histograms are always reduced to their lowest terms. ``` python >>> from dyce.p import RollT >>> def three_way_vs(first: RollT, second: RollT, third: RollT): ... first_reversed = first[::-1] ... second_reversed = second[::-1] ... third_reversed = third[::-1] ... if first_reversed > second_reversed and first_reversed > third_reversed: ... return 1 # first is the clear winner ... elif second_reversed > first_reversed and second_reversed > third_reversed: ... return 2 # second is the clear winner ... elif third_reversed > first_reversed and third_reversed > second_reversed: ... return 3 # third is the clear winner ... else: ... return 0 # there was a tie somewhere >>> P.foreach( ... three_way_vs, ... first=P(6, 6), # first has pool of two d6s ... second=P(6, 6), # second has pool of two d6s ... third=P(4, 8), # third has pool of one d4 and one d8 ... ) H({0: 1103, 1: 5783, 2: 5783, 3: 8067}) ``` When all of ``#!python foreach``\u2019s arguments are [``P`` objects][dyce.p.P] of size 1 or anything other than a ``P`` object, this function behaves similarly to [``H.foreach``][dyce.h.H] (although the signature of the *dependent_term* callback function differs slightly between the two interfaces). ``` python >>> from itertools import chain >>> P.foreach( ... lambda **kw: sum(chain(*kw.values())), # receives single-element rolls ... src1=P(6), # pool of size 1 ... src2=H(6), # histogram ... src3=range(6, 0, -1), # histogram source ... ) == H.foreach( ... lambda **kw: sum(kw.values()), # receives outcomes ... src1=P(6).h(), # histogram ... src2=H(6), # histogram ... src3={1, 2, 3, 4, 5, 6}, # histogram source ... ) True ``` The ``#!python foreach`` class method is equivalent to nesting loops iterating over [``P.rolls_with_counts``][dyce.p.P.rolls_with_counts] for each independent term and then aggregating the results. ``` python >>> def dependent_term( ... *, ... roll_1, ... roll_2, ... # ... ... roll_n, ... ): ... return ( ... (roll_2[-1] > roll_1[-1]) ... + (roll_n[-1] > roll_2[-1]) ... # ... ... ) >>> source_1 = P(8) >>> source_2 = P(6, 6) >>> # ... >>> source_n = P(4, 4, 4) >>> h = P.foreach( ... dependent_term, ... roll_1=source_1, ... roll_2=source_2, ... # ... ... roll_n=source_n, ... ) ; h H({0: 3821, 1: 5126, 2: 269}) >>> def resolve(): ... for roll_1, count_1 in source_1.rolls_with_counts(): ... for roll_2, count_2 in source_2.rolls_with_counts(): ... # ... ... for roll_n, count_n in source_n.rolls_with_counts(): ... # ... ... yield dependent_term( ... roll_1=roll_1, ... roll_2=roll_2, ... # ... ... roll_n=roll_n, ... ), ( ... count_1 ... * count_2 ... # * ... ... * count_n ... ) >>> from dyce.h import aggregate_with_counts >>> aggregate_with_counts(resolve()) == h True ``` \"\"\" pools_by_kw : Dict [ str , P ] = {} for source_name , source in independent_sources . items (): if isinstance ( source , H ): pools_by_kw [ source_name ] = P ( source ) elif isinstance ( source , P ): pools_by_kw [ source_name ] = source elif isinstance ( source , HableT ): pools_by_kw [ source_name ] = P ( source . h ()) else : pools_by_kw [ source_name ] = P ( H ( source )) def _kw_roll_count_tuples ( pool_name : str , ) -> Iterator [ Tuple [ str , RollT , int ]]: for roll , count in pools_by_kw [ pool_name ] . rolls_with_counts (): yield pool_name , roll , count def _resolve_dependent_term_for_rolls () -> Iterator [ Tuple [ Union [ H , RealLike ], int ] ]: for kw_roll_count_tuples in product ( * ( _kw_roll_count_tuples ( pool_name ) for pool_name in pools_by_kw ) ): combined_count = reduce ( __mul__ , ( count for _ , _ , count in kw_roll_count_tuples ), 1 ) rolls_by_name = { name : roll for name , roll , _ in kw_roll_count_tuples } yield dependent_term ( ** rolls_by_name ), combined_count return aggregate_with_counts ( _resolve_dependent_term_for_rolls ()) . lowest_terms () h ( self , * which : _GetItemT ) -> H Roughly equivalent to H (( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which )) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HableT protocol . 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d6avg + d6avg True Source code in dyce/p.py @beartype def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``#!python H((sum(roll), count) for roll, count in self.rolls_with_counts(*which))`` with some short-circuit optimizations. When provided no arguments, ``#!python h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HableT`` protocol][dyce.h.HableT]. ``` python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ``` python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ``` python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_h ( self ) map ( self , op : _BinaryOperatorT , right_operand : _OperandT ) -> P Shorthand for P ( * ( h . map ( op , right_operand ) for h in self )) . See the H.map method . 1 2 3 4 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . map ( operator . __mul__ , - 1 ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) Source code in dyce/p.py @beartype def map ( self , op : _BinaryOperatorT , right_operand : _OperandT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.map(op, right_operand) for h in self))``. See the [``H.map`` method][dyce.h.H.map]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.map(operator.__mul__, -1) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) ``` \"\"\" return P ( * ( h . map ( op , right_operand ) for h in self )) rmap ( self , left_operand : RealLike , op : _BinaryOperatorT ) -> P Shorthand for P ( * ( h . rmap ( left_operand , op ) for h in self )) . See the H.rmap method . 1 2 3 4 5 >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( Fraction ) . rmap ( 1 , operator . __truediv__ ) P ( H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 }), H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 })) Source code in dyce/p.py @beartype def rmap ( self , left_operand : RealLike , op : _BinaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.rmap(left_operand, op) for h in self))``. See the [``H.rmap`` method][dyce.h.H.rmap]. ``` python >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(Fraction).rmap(1, operator.__truediv__) P(H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1}), H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1})) ``` \"\"\" return P ( * ( h . rmap ( left_operand , op ) for h in self )) roll ( self ) -> RollT Returns (weighted) random outcomes from contained histograms. On ordering This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. Source code in dyce/p.py @beartype def roll ( self ) -> RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. !!! note \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self )) rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ] Returns an iterator yielding two-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the two-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, ( 1 , 2 ) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d6avg + d6avg True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable. 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted. 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) . \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n @P ( H ( m )) . Enumerating combinations with replacements would yield all unique rolls. (( 1 , 1 , \u2026 , 1 ), ( 1 , 1 , \u2026 , 2 ), \u2026 , ( 1 , 1 , \u2026 , m ), \u2026 , ( m - 1 , m , \u2026 , m ), ( m , m , \u2026 , m )) To determine the count for a particular roll ( a , b , \u2026 , n ) , we compute the multinomial coefficient for that roll and multiply by the scalar H ( m )[ a ] * H ( m )[ b ] * \u2026 * H ( m )[ n ] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 0 )): 22.7 \u00b5s \u00b1 463 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 1 )): 740 \u00b5s \u00b1 16.4 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 2.25 ms \u00b1 97.7 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 4.44 ms \u00b1 219 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 2.12 ms \u00b1 26 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 4.46 ms \u00b1 75.5 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 7.89 ms \u00b1 186 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 12.7 ms \u00b1 287 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 0 )): 22.6 \u00b5s \u00b1 820 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 1 )): 2.51 ms \u00b1 102 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 2 )): 5.31 ms \u00b1 63 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 3 )): 5.37 ms \u00b1 98.5 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 2 )): 32.4 ms \u00b1 1.36 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 3 )): 78.6 ms \u00b1 918 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 4 )): 80.8 ms \u00b1 2.18 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 5 )): 79.9 ms \u00b1 2.81 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 0 )): 22.6 \u00b5s \u00b1 438 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 1 )): 8.98 ms \u00b1 169 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 2 )): 9.09 ms \u00b1 205 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 3 )): 9.09 ms \u00b1 350 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 2 )): 312 ms \u00b1 9.72 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 3 )): 314 ms \u00b1 2.45 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 4 )): 334 ms \u00b1 10.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 5 )): 324 ms \u00b1 5.48 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source: perf_rolls_with_counts.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from dyce import H , P for n in ( 4 , 6 ): p = n @P ( 6 ) for i in range ( len ( p ) - 4 , len ( p )): print ( f \"( { p } ).h(slice( { i } )):\" ) % timeit p . h ( slice ( i )) print () for n in ( 2 , 3 ): p = P ( n @P ( 6 ), * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) for i in range ( len ( p ) - 4 , len ( p )): print ( f \"( { p } ).h(slice( { i } )):\" ) % timeit p . h ( slice ( i )) print () for n in ( 4 , 6 ): p = P ( * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) for i in range ( len ( p ) - 4 , len ( p )): print ( f \"( { p } ).h(slice( { i } )):\" ) % timeit p . h ( slice ( i )) print () Source code in dyce/p.py @beartype def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding two-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the two-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed for more flexible selections. ``` python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. ``` python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ``` python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``#!python (1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ``` python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. ``` python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable. ``` python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted. ``` python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ``` python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$. $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``#!python n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls. ``#!python ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``#!python (a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``#!python H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ``` python --8<-- \"docs/assets/perf_rolls_with_counts.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_rolls_with_counts.ipy\"><code>perf_rolls_with_counts.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_rolls_with_counts.ipy\" ``` </details> \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count umap ( self , op : _UnaryOperatorT ) -> P Shorthand for P ( * ( h . umap ( op ) for h in self )) . See the H.umap method . 1 2 3 4 5 6 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( operator . __neg__ ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) >>> p_3d6 . umap ( operator . __abs__ ) P ( H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 })) Source code in dyce/p.py @beartype def umap ( self , op : _UnaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.umap(op) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(operator.__neg__) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) >>> p_3d6.umap(operator.__abs__) P(H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1})) ``` \"\"\" return P ( * ( h . umap ( op ) for h in self ))","title":"<tt>dyce</tt>"},{"location":"dyce/#dyce-package-reference","text":"dyce provides several core primitives: H \u2013 histograms (outcomes or individual dice) P \u2013 collections of histograms (pools) R \u2013 scalars, histograms, pools, operators, etc. for assembling roller trees (see dyce.r for details)","title":"dyce package reference"},{"location":"dyce/#dyce.h.H","text":"An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode finite discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, a denominator is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derived, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ). 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed. 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative). 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps. 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes. 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ()) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand. 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes. 1 2 >>> len ( 2 @d6 ) 11 The total property can be used to compute the total number of combinations and each outcome\u2019s probability. 1 2 3 4 5 >>> from fractions import Fraction >>> ( 2 @d6 ) . total 36 >>> [( outcome , Fraction ( count , ( 2 @d6 ) . total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ()) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ()) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ) ; d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ()) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore [operator] Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method . 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands. 1 2 >>> d6 . ge ( 4 ) == d6 . ge ( 4 ) . lowest_terms () True Source code in dyce/h.py class H ( _MappingT ): r \"\"\" An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. ``#!python H`` objects encode finite discrete probability distributions as integer counts without any denominator. !!! info The lack of an explicit denominator is intentional and has two benefits. First, a denominator is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derived, as shown below. The [initializer][dyce.h.H.__init__] takes a single parameter, *items*. In its most explicit form, *items* maps outcome values to counts. Modeling a single six-sided die (``1d6``) can be expressed as: ``` python >>> from dyce import H >>> d6 = H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1}) ``` An iterable of pairs can also be used (similar to ``#!python dict``). ``` python >>> d6 == H(((1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1))) True ``` Two shorthands are provided. If *items* is an iterable of numbers, counts of 1 are assumed. ``` python >>> d6 == H((1, 2, 3, 4, 5, 6)) True ``` Repeated items are accumulated, as one would expect. ``` python >>> H((2, 3, 3, 4, 4, 5)) H({2: 1, 3: 2, 4: 2, 5: 1}) ``` If *items* is an integer, it is shorthand for creating a sequential range $[{1} .. {items}]$ (or $[{items} .. {-1}]$ if *items* is negative). ``` python >>> d6 == H(6) True ``` Histograms are maps, so we can test equivalence against other maps. ``` python >>> H(6) == {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1} True ``` Simple indexes can be used to look up an outcome\u2019s count. ``` python >>> H((2, 3, 3, 4, 4, 5))[3] 2 ``` Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes. ``` python >>> d6 + 4 H({5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1}) ``` ``` python >>> d6 * -1 H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> d6 * -1 == -d6 True >>> d6 * -1 == H(-6) True ``` If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice (``2d6``) can be expressed as: ``` python >>> d6 + d6 H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> print((d6 + d6).format()) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78% |# 3 | 5.56% |## 4 | 8.33% |#### 5 | 11.11% |##### 6 | 13.89% |###### 7 | 16.67% |######## 8 | 13.89% |###### 9 | 11.11% |##### 10 | 8.33% |#### 11 | 5.56% |## 12 | 2.78% |# ``` To sum ${n}$ identical histograms, the matrix multiplication operator (``@``) provides a shorthand. ``` python >>> 3@d6 == d6 + d6 + d6 True ``` The ``#!python len`` built-in function can be used to show the number of distinct outcomes. ``` python >>> len(2@d6) 11 ``` The [``total`` property][dyce.h.H.total] can be used to compute the total number of combinations and each outcome\u2019s probability. ``` python >>> from fractions import Fraction >>> (2@d6).total 36 >>> [(outcome, Fraction(count, (2@d6).total)) for outcome, count in (2@d6).items()] [(2, Fraction(1, 36)), (3, Fraction(1, 18)), (4, Fraction(1, 12)), (5, Fraction(1, 9)), (6, Fraction(5, 36)), (7, Fraction(1, 6)), ..., (12, Fraction(1, 36))] ``` Histograms provide common comparators (e.g., [``eq``][dyce.h.H.eq] [``ne``][dyce.h.H.ne], etc.). One way to count how often a first six-sided die shows a different face than a second is: ``` python >>> d6.ne(d6) H({False: 6, True: 30}) >>> print(d6.ne(d6).format()) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67% |######## 1 | 83.33% |######################################### ``` Or, how often a first six-sided die shows a face less than a second is: ``` python >>> d6.lt(d6) H({False: 21, True: 15}) >>> print(d6.lt(d6).format()) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33% |############################# 1 | 41.67% |#################### ``` Or how often at least one ``#!python 2`` will show when rolling four six-sided dice: ``` python >>> d6_eq2 = d6.eq(2) ; d6_eq2 # how often a 2 shows on a single six-sided die H({False: 5, True: 1}) >>> 4@d6_eq2 # count of 2s showing on 4d6 H({0: 625, 1: 500, 2: 150, 3: 20, 4: 1}) >>> (4@d6_eq2).ge(1) # how often that count is at least one H({False: 625, True: 671}) >>> print((4@d6_eq2).ge(1).format()) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23% |######################## 1 | 51.77% |######################### ``` !!! bug \"Mind your parentheses\" Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the ``#!python @`` operator, because it behaves differently than the ``d`` operator in most dedicated grammars. More specifically, in Python, ``#!python @`` has a [lower precedence](https://docs.python.org/3/reference/expressions.html#operator-precedence) than ``#!python .`` and ``#!python [\u2026]``. ``` python >>> 2@d6[7] # type: ignore [operator] Traceback (most recent call last): ... KeyError: 7 >>> 2@d6.le(7) # probably not what was intended H({2: 36}) >>> 2@d6.le(7) == 2@(d6.le(7)) True ``` ``` python >>> (2@d6)[7] 6 >>> (2@d6).le(7) H({False: 15, True: 21}) >>> 2@d6.le(7) == (2@d6).le(7) False ``` Counts are generally accumulated without reduction. To reduce, call the [``lowest_terms`` method][dyce.h.H.lowest_terms]. ``` python >>> d6.ge(4) H({False: 3, True: 3}) >>> d6.ge(4).lowest_terms() H({False: 1, True: 1}) ``` Testing equivalence implicitly performs reductions of operands. ``` python >>> d6.ge(4) == d6.ge(4).lowest_terms() True ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_h\" , \"_simple_init\" ) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ RealLike ] = counter () if isinstance ( items , MappingC ): items = items . items () if isinstance ( items , SupportsInt ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , RealLike ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HableT ): tmp . update ( items . h ()) elif isinstance ( items , IterableC ): # items is either an Iterable[RealLike] or an Iterable[Tuple[RealLike, # SupportsInt]] (although this technically supports Iterable[Union[RealLike, # Tuple[RealLike, SupportsInt]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 } # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : if self . _simple_init is not None : arg = str ( self . _simple_init ) elif sys . version_info >= ( 3 , 8 ): arg = pformat ( self . _h , sort_dicts = False ) else : arg = dict . __repr__ ( self . _h ) return f \" { type ( self ) . __name__ } ( { arg } )\" @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __eq__ ( self , other . h ()) elif isinstance ( other , H ): return __eq__ ( self . lowest_terms () . _h , other . lowest_terms () . _h ) else : return super () . __eq__ ( other ) @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __ne__ ( self , other . h ()) elif isinstance ( other , H ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) @beartype def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ())) @beartype def __len__ ( self ) -> int : return len ( self . _h ) @beartype def __getitem__ ( self , key : RealLike ) -> int : return __getitem__ ( self . _h , key ) @beartype def __iter__ ( self ) -> Iterator [ RealLike ]: return iter ( self . _h ) @beartype def __add__ ( self , other : _OperandT ) -> H : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented @beartype def __radd__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented @beartype def __sub__ ( self , other : _OperandT ) -> H : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented @beartype def __rsub__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented @beartype def __mul__ ( self , other : _OperandT ) -> H : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmul__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented @beartype def __matmul__ ( self , other : SupportsInt ) -> H : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return sum_h ( repeat ( self , other )) @beartype def __rmatmul__ ( self , other : SupportsInt ) -> H : return self . __matmul__ ( other ) @beartype def __truediv__ ( self , other : _OperandT ) -> H : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rtruediv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented @beartype def __floordiv__ ( self , other : _OperandT ) -> H : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rfloordiv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented @beartype def __mod__ ( self , other : _OperandT ) -> H : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmod__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented @beartype def __pow__ ( self , other : _OperandT ) -> H : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented @beartype def __rpow__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented @beartype def __and__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __rand__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __xor__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except NotImplementedError : return NotImplemented @beartype def __rxor__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __or__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __ror__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __neg__ ( self ) -> H : return self . umap ( __neg__ ) @beartype def __pos__ ( self ) -> H : return self . umap ( __pos__ ) @beartype def __abs__ ( self ) -> H : return self . umap ( __abs__ ) @beartype def __invert__ ( self ) -> H : return self . umap ( __invert__ ) @beartype def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . _h . values () @beartype def items ( self ) -> ItemsView [ RealLike , int ]: return self . _h . items () @beartype def keys ( self ) -> KeysView [ RealLike ]: return self . outcomes () @beartype def outcomes ( self ) -> KeysView [ RealLike ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . _h . keys () @beartype def values ( self ) -> ValuesView [ int ]: return self . counts () # ---- Properties ------------------------------------------------------------------ @property def total ( self ) -> int : r \"\"\" !!! warning \"Experimental\" This propertyshould be considered experimental and may change or disappear in future versions. Equivalent to ``#!python sum(self.counts())``. \"\"\" @experimental def _total () -> int : return sum ( self . counts ()) return _total () # ---- Methods --------------------------------------------------------------------- @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ \"H\" , RealLike ]], ** independent_sources : _SourceT , ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each set of outcomes from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Returned histograms are always reduced to their lowest terms. For example rolling a d20, re-rolling a ``#!python 1`` if it comes up, and keeping the result might be expressed as[^1]: [^1]: This is primarily for illustration. [``H.substitute``][dyce.h.H.substitute] is often better suited to cases involving re-rolling a single independent term such as this one. ``` python >>> d20 = H(20) >>> def reroll_one_dependent_term(d20_outcome): ... if d20_outcome == 1: ... return d20 ... else: ... return d20_outcome >>> H.foreach(reroll_one_dependent_term, d20_outcome=d20) H({1: 1, 2: 21, 3: 21, ..., 19: 21, 20: 21}) ``` The ``#!python foreach`` class method merely wraps *dependent_term* and calls [``P.foreach``][dyce.p.P.foreach]. In doing so, it imposes a very modest overhead that is negligible in most cases. ``` python --8<-- \"docs/assets/perf_foreach.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_foreach.ipy\"><code>perf_foreach.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_foreach.ipy\" ``` </details> \"\"\" from dyce import P def _dependent_term ( ** roll_kw ): outcome_kw : Dict [ str , RealLike ] = {} for key , roll in roll_kw . items (): assert isinstance ( roll , tuple ) assert len ( roll ) == 1 outcome_kw [ key ] = roll [ 0 ] return dependent_term ( ** outcome_kw ) return P . foreach ( _dependent_term , ** independent_sources ) @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT ) -> H : r \"\"\" Applies *bin_op* to each outcome of the histogram as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> d6 = H(6) >>> d6.map(operator.__add__, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.__add__, d6) == d6 + d6 True ``` ``` python >>> d6.map(operator.__pow__, 2) H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1}) >>> d6.map(operator.__pow__, 2) == d6 ** 2 True ``` ``` python >>> d6.map(operator.__gt__, 3) H({False: 3, True: 3}) >>> d6.map(operator.__gt__, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( right_operand , HableT ): right_operand = right_operand . h () if isinstance ( right_operand , H ): return type ( self )( ( bin_op ( s , o ), self [ s ] * right_operand [ o ]) for s , o in product ( self , right_operand ) ) else : return type ( self )( ( bin_op ( outcome , right_operand ), count ) for outcome , count in self . items () ) @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> H : r \"\"\" Analogous to the [``map`` method][dyce.h.H.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> d6 = H(6) >>> d6.rmap(2, operator.__pow__) H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1}) >>> d6.rmap(2, operator.__pow__) == 2 ** d6 True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.h.H.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" return type ( self )( ( bin_op ( left_operand , outcome ), count ) for outcome , count in self . items () ) @beartype def umap ( self , un_op : _UnaryOperatorT ) -> H : r \"\"\" Applies *un_op* to each outcome of the histogram. ``` python >>> import operator >>> H(6).umap(operator.__neg__) H(-6) ``` ``` python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = type ( self )(( un_op ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : simple_init = un_op ( self . _simple_init ) if isinstance ( simple_init , SupportsInt ): h_simple = type ( self )( simple_init ) if h_simple == h : return h_simple return h @beartype def lt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__lt__, other).umap(bool)``. ``` python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __lt__ , other ) . umap ( bool ) @beartype def le ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__le__, other).umap(bool)``. ``` python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __le__ , other ) . umap ( bool ) @beartype def eq ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__eq__, other).umap(bool)``. ``` python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __eq__ , other ) . umap ( bool ) @beartype def ne ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ne__, other).umap(bool)``. ``` python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ne__ , other ) . umap ( bool ) @beartype def gt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__gt__, other).umap(bool)``. ``` python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __gt__ , other ) . umap ( bool ) @beartype def ge ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ge__, other).umap(bool)``. ``` python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ge__ , other ) . umap ( bool ) @beartype def is_even ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_even)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_even ) @beartype def is_odd ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_odd)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_odd ) @beartype def accumulate ( self , other : _SourceT ) -> H : r \"\"\" Accumulates counts. ``` python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , MappingC ): other = other . items () elif not isinstance ( other , IterableC ): other = cast ( Iterable [ RealLike ], ( other ,)) return type ( self )( chain ( self . items (), cast ( Iterable , other ))) @experimental @beartype def exactly_k_times_in_n ( self , outcome : RealLike , n : SupportsInt , k : SupportsInt , ) -> int : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``#!python n@self``. ``` python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) return comb ( n , k ) * c_outcome ** k * ( self . total - c_outcome ) ** ( n - k ) @beartype def explode ( self , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.substitute(lambda h, outcome: outcome if len(h) == 1 else h if outcome == max(h) else outcome, operator.__add__, max_depth, precision_limit)``. ``` python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : outcome if len ( h ) == 1 else h if outcome == max ( h ) else outcome , __add__ , max_depth , precision_limit , ) @beartype def lowest_terms ( self ) -> H : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ``` python >>> df = H((-1, -1, 0, 0, 1, 1)) ; df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ``` python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return type ( self )( self . _lowest_terms ()) @experimental @beartype def order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Shorthand for ``#!python self.order_stat_func_for_n(n)(pos)``. \"\"\" # TODO(posita): Explore different memoization strategies (e.g., with # functools.cache) for this method and H.order_stat_func_for_n return self . order_stat_func_for_n ( n )( pos ) @experimental @beartype def order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], \"H\" ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``#!python n@self``. ``` python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``#!python 2`` appears at the fourth (index ``#!python 3``) position, 1432 ways where ``#!python 3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. ``` python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster. ``` python --8<-- \"docs/assets/perf_order_stat_for_n.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_order_stat_for_n.ipy\"><code>perf_order_stat_for_n.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_order_stat_for_n.ipy\" ``` </details> \"\"\" betas_by_outcome : Dict [ RealLike , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ RealLike , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) @beartype def order_stat_for_n_at_pos ( pos : SupportsInt ) -> H : return type ( self )( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos @beartype def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" !!! warning \"Experimental\" The *precision_limit* parameter should be considered experimental and may change or disappear in future versions. Calls *expand* on each outcome. If *expand* returns a single outcome, it replaces the existing outcome. If it returns an [``H`` object][dyce.h.H], expansion is performed again (recursively) on that object until *max_depth* or *precision_limit* is exhausted. *coalesce* is called on the original outcome and the expanded histogram or outcome and the returned histogram is \u201cfolded\u201d into result. (More on these terms and concepts below.) The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. !!! note \"*coalesce* is not called unless *expand* returns a histogram\" If *expand* returns a single outcome, it *always* replaces the existing outcome. This is intentional. To return a single outcome, but trigger *coalesce*, characterize that outcome as a single-sided die (e.g., ``#!python H({outcome: 1})``. See the [``coalesce_replace``][dyce.h.coalesce_replace] and [``lowest_terms``][dyce.h.H.lowest_terms] methods. This method can be used to model complex mechanics. The following models re-rolling a face of 1 on the first roll: ``` python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). This method uses the [``aggregate_with_counts``][dyce.h.aggregate_with_counts] function in its implementation. As such, If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. ``` python >>> H(6).substitute(lambda __, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda __, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``#!python substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions with dependent variables. Consider the following mechanic: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ``` python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.__add__, max_depth=6) >>> h_even = h.is_even() >>> print(f\"{h_even[1] / h_even.total:.3%}\") 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. ``` python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` When *expand* returns an [``H`` object][dyce.h.H], outcomes produced from the corresponding *coalesce* are accumulated, but the counts retain their \u201cscale\u201d within the context of the expansion. This becomes clearer when there is no overlap between the substituted histogram and the other outcomes. ``` python >>> d6 = H(6) >>> d00 = (H(10) - 1) * 10 ; d00 H({0: 1, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) >>> set(d6) & set(d00) == set() # no outcomes in common True >>> d6_d00 = d6.substitute( ... # If a one comes up when rolling the d6, ... # roll a d00 and take that result instead ... lambda h, outcome: d00 if outcome == 1 else outcome ... ) ; d6_d00 H({0: 1, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) ``` Note that the sum of the outcomes\u2019 counts from the d00 make up the same proportion as the one\u2019s outcome and count they replaced from the d6. ``` python >>> from fractions import Fraction >>> Fraction( ... sum(count for outcome, count in d6_d00.items() if outcome in d00), ... d6_d00.total, ... ) Fraction(1, 6) >>> Fraction(d6[1], d6.total) Fraction(1, 6) ``` !!! tip \"Precision limits\" This method will halt recursive substitution on any branch *either* when its depth exceeds *max_depth* *or* its \u201ccontextual precision\u201d is *precision_limit* or less. In either case, substitution is attempted for all of the outcomes of a(n expanded) histogram or none of them. The contextual precision of a histogram is its proportion to the whole. The contextual precision of the original (or top-level) histogram is ``#!python Fraction(1, 1)``. By setting *precision_limit* to that value, we basically ensure no substitution. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... precision_limit=Fraction(1, 1), # no substitution ... ) == d6 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... max_depth=0, # no substitution ... ) == d6 True ``` Let\u2019s make a contrived, but illustrative modification to our d6/d00 example from above. If a one comes up when rolling a d6, roll a d00, but re-roll any 80s. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, # <-- we'll never hit this ... # will halt substitution after the original one from the d6 ... precision_limit=Fraction(1, 6), ... ) == d6_d00 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the first 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10), ... ) H({0: 11, 2: 100, ..., 6: 100, 10: 11, ..., 70: 11, 80: 1, 90: 11}) >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the second 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10) - Fraction(1, 1000000000), # <-- juuust under the wire ... ) H({0: 111, 2: 1000, ..., 6: 1000, 10: 111, ..., 70: 111, 80: 1, 90: 111}) ``` The default value for *precision_limit* is zero, which basically means it is ignored and recursion is limited solely by *max_depth*. If you want to ensure that this method stops delving based *solely* on precision, set *max_depth* to ``#!python -1``, which is equivalent to ``#!python sys.getrecursionlimit() + 1``[^1]. Be aware that this skews results in favor of non-limited branches. ``` python >>> h = H({1: 1, 2: 2, 3: 3}) >>> print(h.explode(max_depth=5).format(scaled=True)) avg | 4.59 std | 3.96 var | 15.65 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 18 | 1.56% |## >>> print(h.explode(max_depth=-1, precision_limit=Fraction(1, 6 ** 2)).format(scaled=True)) avg | 4.63 std | 4.09 var | 16.72 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 19 | 0.26% | 20 | 0.52% | 21 | 0.78% |# ``` Also be aware that without *max_depth* as a safety net, some substitutions are guaranteed to result in ``#!python RecursionError``s, even with very high *precision_limit*s. ``` python >>> H(1).substitute( ... lambda h, outcome: H({outcome + 1: 1}), # expands to a single-sided die ... max_depth=-1, ... precision_limit=Fraction(999999, 1000000), ... ) Traceback (most recent call last): ... RecursionError: maximum recursion depth exceeded in comparison ``` [``H.explode``][dyce.h.H.explode]\u2019s *expand* implementation guards against this by returning ``#!python outcome`` if the passed histogram has only one face. Consider a similar approach for your own *expand* implementations if outcomes\u2019 contextual probabilities do not asymptotically approach zero. [^1]: This method will \u201cbottom out\u201d far earlier. As of this writing, the practical limit of its implementation (without optimization) is something close to $\\frac {1} {3} \\times \\left( limit - depth \\right)$, where $limit$ is ``#!python sys.getrecursionlimit()`` and $depth$ is ``#!python len(inspect.stack(0))``. This also assumes the provided implementations for *expand* and *coalesce* don\u2019t contribute significantly to the call stack. Setting *max_depth* to ``#!python -1`` or one beyond the absolute limit signals that the caller wants it out of the way. \"\"\" max_depth = as_int ( max_depth ) if max_depth == - 1 : max_depth = sys . getrecursionlimit () + 1 if max_depth < 0 : raise ValueError ( \"max_depth cannot be an arbitrary negative number (use -1 explicitly to indicate no limit)\" ) if precision_limit < 0 or precision_limit > 1 : raise ValueError ( f \"precision_limit ( { precision_limit } ) must be between zero and one, inclusive\" ) def _substitute ( h : H , depth : int = 0 , contextual_precision : Fraction = Fraction ( 1 ), ) -> H : assert coalesce is not None if depth == max_depth or contextual_precision <= precision_limit : return h def _expand_and_coalesce () -> Iterator [ Tuple [ Union [ H , RealLike ], int ]]: total = h . total for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded_precision = Fraction ( contextual_precision . numerator * count , contextual_precision . denominator * total , ) expanded = _substitute ( expanded , depth + 1 , expanded_precision ) # Coalesce the result expanded = coalesce ( expanded , outcome ) yield expanded , count return aggregate_with_counts ( _expand_and_coalesce (), type ( self )) return _substitute ( self ) . lowest_terms () @beartype def vs ( self , other : _OperandT ) -> H : r \"\"\" Compares the histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``#!python self.within(0, 0, other)``. ``` python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other ) @beartype def within ( self , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Computes the difference between the histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ``` python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format()) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format()) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other ) @overload def distribution ( self , fill_items : Optional [ _MappingT ] = None , ) -> Iterator [ Tuple [ RealLike , Fraction ]]: ... @overload def distribution ( self , fill_items : _MappingT , rational_t : _RationalInitializerT [ _T ], ) -> Iterator [ Tuple [ RealLike , _T ]]: ... @overload def distribution ( self , * , rational_t : _RationalInitializerT [ _T ], ) -> Iterator [ Tuple [ RealLike , _T ]]: ... @experimental @beartype def distribution ( self , fill_items : Optional [ _MappingT ] = None , # TODO(posita): See <https://github.com/python/mypy/issues/10854> for context on # all the @overload work-around nonsense above and remove those once that issue # is addressed. rational_t : _RationalInitializerT [ _T ] = cast ( _RationalInitializerT , Fraction ), ) -> Iterator [ Tuple [ RealLike , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. ``` python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes. ``` python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` !!! warning \"Experimental\" The *rational_t* argument to this method should be considered experimental and may change or disappear in future versions. If provided, *rational_t* must be a callable that takes two ``#!python int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. ``` python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] ``` ``` python >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` !!! note The arguments passed to *rational_t* are not reduced to the lowest terms. The *rational_t* argument is a convenience. Iteration or comprehension can be used to accomplish something similar. ``` python >>> [(outcome, f\"{probability.numerator}/{probability.denominator}\") for outcome, probability in (h).distribution()] [(1, '1/8'), (2, '1/8'), (3, '1/4'), (4, '1/4'), (5, '1/8'), (6, '1/8')] ``` Many number implementations can convert directly from ``#!python fractions.Fraction``s. ``` python >>> import sympy.abc >>> [(outcome, sympy.Rational(probability)) for outcome, probability in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> [(outcome, sage.rings.rational.Rational(probability)) for outcome, probability in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) ) @beartype def distribution_xy ( self , fill_items : Optional [ _MappingT ] = None , ) -> Tuple [ Tuple [ RealLike , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``#!python float``s. ``` python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" # TODO(posita): See <https://github.com/python/typing/issues/193> return tuple ( # type: ignore [return-value] zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) ) @beartype def format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsInt = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ``` python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ``` python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``#!python True``, horizontal bars are scaled to *width*. ``` python >>> h = (2@H(6)).ge(7) >>> print(f\"{' 65 chars wide -->|':->65}\") ---------------------------------------------- 65 chars wide -->| >>> print(h.format(scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : RealLike = float ( self . mean ()) except ( OverflowError , TypeError ): mu = self . mean () if width <= 0 : def _parts () -> Iterator [ str ]: yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 def _lines () -> Iterator [ str ]: try : yield f \"avg | { mu : 7.2f } \" std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except ( OverflowError , TypeError ) as exc : warnings . warn ( f \" { str ( exc ) } ; mu: { mu } \" ) if self : outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( _lines ()) @beartype def mean ( self ) -> RealLike : r \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 ) @beartype def stdev ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Shorthand for ``#!python math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu )) @beartype def variance ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 ) @beartype def roll ( self ) -> RealLike : r \"\"\" Returns a (weighted) random outcome, sorted. \"\"\" return ( rng . RNG . choices ( population = tuple ( self . outcomes ()), weights = tuple ( self . counts ()), k = 1 , )[ 0 ] if self else 0 ) def _lowest_terms ( self ) -> Iterable [ Tuple [ RealLike , int ]]: counts_gcd = gcd ( * self . counts ()) return (( k , v // counts_gcd ) for k , v in self . items ())","title":"H"},{"location":"dyce/#dyce.h.H.__slots__","text":"","title":"__slots__"},{"location":"dyce/#dyce.h.H.total","text":"Experimental This propertyshould be considered experimental and may change or disappear in future versions. Equivalent to sum ( self . counts ()) .","title":"total"},{"location":"dyce/#dyce.h.H.__abs__","text":"Source code in dyce/h.py @beartype def __abs__ ( self ) -> H : return self . umap ( __abs__ )","title":"__abs__()"},{"location":"dyce/#dyce.h.H.__add__","text":"Source code in dyce/h.py @beartype def __add__ ( self , other : _OperandT ) -> H : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented","title":"__add__()"},{"location":"dyce/#dyce.h.H.__and__","text":"Source code in dyce/h.py @beartype def __and__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__and__()"},{"location":"dyce/#dyce.h.H.__eq__","text":"Source code in dyce/h.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __eq__ ( self , other . h ()) elif isinstance ( other , H ): return __eq__ ( self . lowest_terms () . _h , other . lowest_terms () . _h ) else : return super () . __eq__ ( other )","title":"__eq__()"},{"location":"dyce/#dyce.h.H.__floordiv__","text":"Source code in dyce/h.py @beartype def __floordiv__ ( self , other : _OperandT ) -> H : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented","title":"__floordiv__()"},{"location":"dyce/#dyce.h.H.__getitem__","text":"Source code in dyce/h.py @beartype def __getitem__ ( self , key : RealLike ) -> int : return __getitem__ ( self . _h , key )","title":"__getitem__()"},{"location":"dyce/#dyce.h.H.__hash__","text":"Return hash(self). Source code in dyce/h.py @beartype def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ()))","title":"__hash__()"},{"location":"dyce/#dyce.h.H.__init__","text":"Initializer. Source code in dyce/h.py @beartype def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ RealLike ] = counter () if isinstance ( items , MappingC ): items = items . items () if isinstance ( items , SupportsInt ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , RealLike ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HableT ): tmp . update ( items . h ()) elif isinstance ( items , IterableC ): # items is either an Iterable[RealLike] or an Iterable[Tuple[RealLike, # SupportsInt]] (although this technically supports Iterable[Union[RealLike, # Tuple[RealLike, SupportsInt]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 }","title":"__init__()"},{"location":"dyce/#dyce.h.H.__invert__","text":"Source code in dyce/h.py @beartype def __invert__ ( self ) -> H : return self . umap ( __invert__ )","title":"__invert__()"},{"location":"dyce/#dyce.h.H.__iter__","text":"Source code in dyce/h.py @beartype def __iter__ ( self ) -> Iterator [ RealLike ]: return iter ( self . _h )","title":"__iter__()"},{"location":"dyce/#dyce.h.H.__len__","text":"Source code in dyce/h.py @beartype def __len__ ( self ) -> int : return len ( self . _h )","title":"__len__()"},{"location":"dyce/#dyce.h.H.__matmul__","text":"Source code in dyce/h.py @beartype def __matmul__ ( self , other : SupportsInt ) -> H : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return sum_h ( repeat ( self , other ))","title":"__matmul__()"},{"location":"dyce/#dyce.h.H.__mod__","text":"Source code in dyce/h.py @beartype def __mod__ ( self , other : _OperandT ) -> H : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented","title":"__mod__()"},{"location":"dyce/#dyce.h.H.__mul__","text":"Source code in dyce/h.py @beartype def __mul__ ( self , other : _OperandT ) -> H : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented","title":"__mul__()"},{"location":"dyce/#dyce.h.H.__ne__","text":"Source code in dyce/h.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __ne__ ( self , other . h ()) elif isinstance ( other , H ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other )","title":"__ne__()"},{"location":"dyce/#dyce.h.H.__neg__","text":"Source code in dyce/h.py @beartype def __neg__ ( self ) -> H : return self . umap ( __neg__ )","title":"__neg__()"},{"location":"dyce/#dyce.h.H.__or__","text":"Source code in dyce/h.py @beartype def __or__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__or__()"},{"location":"dyce/#dyce.h.H.__pos__","text":"Source code in dyce/h.py @beartype def __pos__ ( self ) -> H : return self . umap ( __pos__ )","title":"__pos__()"},{"location":"dyce/#dyce.h.H.__pow__","text":"Source code in dyce/h.py @beartype def __pow__ ( self , other : _OperandT ) -> H : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented","title":"__pow__()"},{"location":"dyce/#dyce.h.H.__radd__","text":"Source code in dyce/h.py @beartype def __radd__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented","title":"__radd__()"},{"location":"dyce/#dyce.h.H.__rand__","text":"Source code in dyce/h.py @beartype def __rand__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rand__()"},{"location":"dyce/#dyce.h.H.__repr__","text":"Source code in dyce/h.py @beartype def __repr__ ( self ) -> str : if self . _simple_init is not None : arg = str ( self . _simple_init ) elif sys . version_info >= ( 3 , 8 ): arg = pformat ( self . _h , sort_dicts = False ) else : arg = dict . __repr__ ( self . _h ) return f \" { type ( self ) . __name__ } ( { arg } )\"","title":"__repr__()"},{"location":"dyce/#dyce.h.H.__rfloordiv__","text":"Source code in dyce/h.py @beartype def __rfloordiv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented","title":"__rfloordiv__()"},{"location":"dyce/#dyce.h.H.__rmatmul__","text":"Source code in dyce/h.py @beartype def __rmatmul__ ( self , other : SupportsInt ) -> H : return self . __matmul__ ( other )","title":"__rmatmul__()"},{"location":"dyce/#dyce.h.H.__rmod__","text":"Source code in dyce/h.py @beartype def __rmod__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented","title":"__rmod__()"},{"location":"dyce/#dyce.h.H.__rmul__","text":"Source code in dyce/h.py @beartype def __rmul__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented","title":"__rmul__()"},{"location":"dyce/#dyce.h.H.__ror__","text":"Source code in dyce/h.py @beartype def __ror__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__ror__()"},{"location":"dyce/#dyce.h.H.__rpow__","text":"Source code in dyce/h.py @beartype def __rpow__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented","title":"__rpow__()"},{"location":"dyce/#dyce.h.H.__rsub__","text":"Source code in dyce/h.py @beartype def __rsub__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented","title":"__rsub__()"},{"location":"dyce/#dyce.h.H.__rtruediv__","text":"Source code in dyce/h.py @beartype def __rtruediv__ ( self , other : RealLike ) -> H : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented","title":"__rtruediv__()"},{"location":"dyce/#dyce.h.H.__rxor__","text":"Source code in dyce/h.py @beartype def __rxor__ ( self , other : SupportsInt ) -> H : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rxor__()"},{"location":"dyce/#dyce.h.H.__sub__","text":"Source code in dyce/h.py @beartype def __sub__ ( self , other : _OperandT ) -> H : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented","title":"__sub__()"},{"location":"dyce/#dyce.h.H.__truediv__","text":"Source code in dyce/h.py @beartype def __truediv__ ( self , other : _OperandT ) -> H : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented","title":"__truediv__()"},{"location":"dyce/#dyce.h.H.__xor__","text":"Source code in dyce/h.py @beartype def __xor__ ( self , other : Union [ SupportsInt , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except NotImplementedError : return NotImplemented","title":"__xor__()"},{"location":"dyce/#dyce.h.H.accumulate","text":"Accumulates counts. 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py @beartype def accumulate ( self , other : _SourceT ) -> H : r \"\"\" Accumulates counts. ``` python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , MappingC ): other = other . items () elif not isinstance ( other , IterableC ): other = cast ( Iterable [ RealLike ], ( other ,)) return type ( self )( chain ( self . items (), cast ( Iterable , other )))","title":"accumulate()"},{"location":"dyce/#dyce.h.H.counts","text":"More descriptive synonym for the values method . Source code in dyce/h.py @beartype def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . _h . values ()","title":"counts()"},{"location":"dyce/#dyce.h.H.distribution","text":"Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. 1 2 3 4 5 >>> h = H (( 1 , 2 , 3 , 3 , 4 , 4 , 5 , 6 )) >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . ge ( 3 ) . distribution ()) [( False , Fraction ( 1 , 4 )), ( True , Fraction ( 3 , 4 ))] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes. 1 2 3 4 >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . distribution ( fill_items = { 0 : 0 , 7 : 0 })) [( 0 , Fraction ( 0 , 1 )), ( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 )), ( 7 , Fraction ( 0 , 1 ))] Experimental The rational_t argument to this method should be considered experimental and may change or disappear in future versions. If provided, rational_t must be a callable that takes two int s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. 1 2 >>> list ( h . distribution ( rational_t = lambda n , d : f \" { n } / { d } \" )) [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '2/8' ), ( 4 , '2/8' ), ( 5 , '1/8' ), ( 6 , '1/8' )] 1 2 3 >>> import sympy >>> list ( h . distribution ( rational_t = sympy . Rational )) [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> list ( h . distribution ( rational_t = lambda n , d : sage . rings . rational . Rational (( n , d )))) # doctest: +SKIP [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] Note The arguments passed to rational_t are not reduced to the lowest terms. The rational_t argument is a convenience. Iteration or comprehension can be used to accomplish something similar. 1 2 >>> [( outcome , f \" { probability . numerator } / { probability . denominator } \" ) for outcome , probability in ( h ) . distribution ()] [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '1/4' ), ( 4 , '1/4' ), ( 5 , '1/8' ), ( 6 , '1/8' )] Many number implementations can convert directly from fractions . Fraction s. 1 2 3 >>> import sympy.abc >>> [( outcome , sympy . Rational ( probability )) for outcome , probability in ( h + sympy . abc . x ) . distribution ()] [( x + 1 , 1 / 8 ), ( x + 2 , 1 / 8 ), ( x + 3 , 1 / 4 ), ( x + 4 , 1 / 4 ), ( x + 5 , 1 / 8 ), ( x + 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> [( outcome , sage . rings . rational . Rational ( probability )) for outcome , probability in h . distribution ()] # doctest: +SKIP [( 1 , 1 / 6 ), ( 2 , 1 / 6 ), ( 3 , 1 / 3 ), ( 4 , 1 / 3 ), ( 5 , 1 / 6 ), ( 6 , 1 / 6 )] Source code in dyce/h.py @experimental @beartype def distribution ( self , fill_items : Optional [ _MappingT ] = None , # TODO(posita): See <https://github.com/python/mypy/issues/10854> for context on # all the @overload work-around nonsense above and remove those once that issue # is addressed. rational_t : _RationalInitializerT [ _T ] = cast ( _RationalInitializerT , Fraction ), ) -> Iterator [ Tuple [ RealLike , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. ``` python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes. ``` python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` !!! warning \"Experimental\" The *rational_t* argument to this method should be considered experimental and may change or disappear in future versions. If provided, *rational_t* must be a callable that takes two ``#!python int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. ``` python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] ``` ``` python >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` !!! note The arguments passed to *rational_t* are not reduced to the lowest terms. The *rational_t* argument is a convenience. Iteration or comprehension can be used to accomplish something similar. ``` python >>> [(outcome, f\"{probability.numerator}/{probability.denominator}\") for outcome, probability in (h).distribution()] [(1, '1/8'), (2, '1/8'), (3, '1/4'), (4, '1/4'), (5, '1/8'), (6, '1/8')] ``` Many number implementations can convert directly from ``#!python fractions.Fraction``s. ``` python >>> import sympy.abc >>> [(outcome, sympy.Rational(probability)) for outcome, probability in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> [(outcome, sage.rings.rational.Rational(probability)) for outcome, probability in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) )","title":"distribution()"},{"location":"dyce/#dyce.h.H.distribution_xy","text":"Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method and ensures the values are float s. 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , Fraction ( 1 , 6 )), ( 2 , Fraction ( 1 , 6 )), ( 3 , Fraction ( 1 , 6 )), ( 4 , Fraction ( 1 , 6 )), ( 5 , Fraction ( 1 , 6 )), ( 6 , Fraction ( 1 , 6 ))] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py @beartype def distribution_xy ( self , fill_items : Optional [ _MappingT ] = None , ) -> Tuple [ Tuple [ RealLike , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``#!python float``s. ``` python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" # TODO(posita): See <https://github.com/python/typing/issues/193> return tuple ( # type: ignore [return-value] zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) )","title":"distribution_xy()"},{"location":"dyce/#dyce.h.H.eq","text":"Shorthand for self . map ( operator . __eq__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map and umap methods. Source code in dyce/h.py @beartype def eq ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__eq__, other).umap(bool)``. ``` python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __eq__ , other ) . umap ( bool )","title":"eq()"},{"location":"dyce/#dyce.h.H.exactly_k_times_in_n","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where outcome appears exactly k times among n @self . 1 2 3 4 5 6 >>> H ( 6 ) . exactly_k_times_in_n ( outcome = 5 , n = 4 , k = 2 ) 150 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 2 , n = 3 , k = 3 ) 1 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 4 , n = 3 , k = 3 ) 8 Source code in dyce/h.py @experimental @beartype def exactly_k_times_in_n ( self , outcome : RealLike , n : SupportsInt , k : SupportsInt , ) -> int : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``#!python n@self``. ``` python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) return comb ( n , k ) * c_outcome ** k * ( self . total - c_outcome ) ** ( n - k )","title":"exactly_k_times_in_n()"},{"location":"dyce/#dyce.h.H.explode","text":"Shorthand for self . substitute ( lambda h , outcome : outcome if len ( h ) == 1 else h if outcome == max ( h ) else outcome , operator . __add__ , max_depth , precision_limit ) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py @beartype def explode ( self , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" Shorthand for ``#!python self.substitute(lambda h, outcome: outcome if len(h) == 1 else h if outcome == max(h) else outcome, operator.__add__, max_depth, precision_limit)``. ``` python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : outcome if len ( h ) == 1 else h if outcome == max ( h ) else outcome , __add__ , max_depth , precision_limit , )","title":"explode()"},{"location":"dyce/#dyce.h.H.foreach","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Calls dependent_term for each set of outcomes from the product of independent_sources and accumulates the results. This is useful for resolving dependent probabilities. Returned histograms are always reduced to their lowest terms. For example rolling a d20, re-rolling a 1 if it comes up, and keeping the result might be expressed as 1 : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> d20 = H ( 20 ) >>> def reroll_one_dependent_term ( d20_outcome ): ... if d20_outcome == 1 : ... return d20 ... else : ... return d20_outcome >>> H . foreach ( reroll_one_dependent_term , d20_outcome = d20 ) H ({ 1 : 1 , 2 : 21 , 3 : 21 , ... , 19 : 21 , 20 : 21 }) The foreach class method merely wraps dependent_term and calls P.foreach . In doing so, it imposes a very modest overhead that is negligible in most cases. 1 2 3 4 5 % timeit P . foreach ( dependent_term_p , roll_1 = H ( 6 ), roll_2 = H ( 8 ), roll_3 = H ( 10 ), roll_n = H ( 20 )) 219 ms \u00b1 5.58 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) % timeit H . foreach ( dependent_term_h , outcome_1 = H ( 6 ), outcome_2 = H ( 8 ), outcome_3 = H ( 10 ), outcome_n = H ( 20 )) 230 ms \u00b1 6.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source: perf_foreach.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 from dyce import H , P def dependent_term ( val_1 , val_2 , val_3 , val_n , ): import math ; math . gcd ( 456 ** 123 , 123 ** 456 ) # emulate an expensive calculation return ( ( val_1 == val_2 ) + ( val_2 == val_3 ) + ( val_1 == val_3 ) + ( val_n > val_1 and val_n > val_2 and val_n > val_3 ) ) def dependent_term_h ( outcome_1 , outcome_2 , outcome_3 , outcome_n , ): return dependent_term ( outcome_1 , outcome_2 , outcome_3 , outcome_n ) def dependent_term_p ( roll_1 , roll_2 , roll_3 , roll_n , ): return dependent_term ( roll_1 , roll_2 , roll_3 , roll_n ) source_1 = H ( 6 ) source_2 = H ( 8 ) source_3 = H ( 10 ) source_n = H ( 20 ) print ( f \"%timeit P.foreach( { dependent_term_p . __name__ } , roll_1= { source_1 } , roll_2= { source_2 } , roll_3= { source_3 } , roll_n= { source_n } )\" ) % timeit P . foreach ( dependent_term_p , roll_1 = source_1 , roll_2 = source_2 , roll_3 = source_3 , roll_n = source_n ) print () print ( f \"%timeit H.foreach( { dependent_term_h . __name__ } , outcome_1= { source_1 } , outcome_2= { source_2 } , outcome_3= { source_3 } , outcome_n= { source_n } )\" ) % timeit H . foreach ( dependent_term_h , outcome_1 = source_1 , outcome_2 = source_2 , outcome_3 = source_3 , outcome_n = source_n ) print () This is primarily for illustration. H.substitute is often better suited to cases involving re-rolling a single independent term such as this one. \u21a9 Source code in dyce/h.py @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ \"H\" , RealLike ]], ** independent_sources : _SourceT , ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each set of outcomes from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Returned histograms are always reduced to their lowest terms. For example rolling a d20, re-rolling a ``#!python 1`` if it comes up, and keeping the result might be expressed as[^1]: [^1]: This is primarily for illustration. [``H.substitute``][dyce.h.H.substitute] is often better suited to cases involving re-rolling a single independent term such as this one. ``` python >>> d20 = H(20) >>> def reroll_one_dependent_term(d20_outcome): ... if d20_outcome == 1: ... return d20 ... else: ... return d20_outcome >>> H.foreach(reroll_one_dependent_term, d20_outcome=d20) H({1: 1, 2: 21, 3: 21, ..., 19: 21, 20: 21}) ``` The ``#!python foreach`` class method merely wraps *dependent_term* and calls [``P.foreach``][dyce.p.P.foreach]. In doing so, it imposes a very modest overhead that is negligible in most cases. ``` python --8<-- \"docs/assets/perf_foreach.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_foreach.ipy\"><code>perf_foreach.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_foreach.ipy\" ``` </details> \"\"\" from dyce import P def _dependent_term ( ** roll_kw ): outcome_kw : Dict [ str , RealLike ] = {} for key , roll in roll_kw . items (): assert isinstance ( roll , tuple ) assert len ( roll ) == 1 outcome_kw [ key ] = roll [ 0 ] return dependent_term ( ** outcome_kw ) return P . foreach ( _dependent_term , ** independent_sources )","title":"foreach()"},{"location":"dyce/#dyce.h.H.format","text":"Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( f \" { ' 65 chars wide -->|' : ->65 } \" ) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py @beartype def format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsInt = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ``` python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ``` python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``#!python True``, horizontal bars are scaled to *width*. ``` python >>> h = (2@H(6)).ge(7) >>> print(f\"{' 65 chars wide -->|':->65}\") ---------------------------------------------- 65 chars wide -->| >>> print(h.format(scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : RealLike = float ( self . mean ()) except ( OverflowError , TypeError ): mu = self . mean () if width <= 0 : def _parts () -> Iterator [ str ]: yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 def _lines () -> Iterator [ str ]: try : yield f \"avg | { mu : 7.2f } \" std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except ( OverflowError , TypeError ) as exc : warnings . warn ( f \" { str ( exc ) } ; mu: { mu } \" ) if self : outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( _lines ())","title":"format()"},{"location":"dyce/#dyce.h.H.ge","text":"Shorthand for self . map ( operator . __ge__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map and umap methods. Source code in dyce/h.py @beartype def ge ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ge__, other).umap(bool)``. ``` python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ge__ , other ) . umap ( bool )","title":"ge()"},{"location":"dyce/#dyce.h.H.gt","text":"Shorthand for self . map ( operator . __gt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def gt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__gt__, other).umap(bool)``. ``` python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __gt__ , other ) . umap ( bool )","title":"gt()"},{"location":"dyce/#dyce.h.H.is_even","text":"Equivalent to self . umap ( dyce . types . is_even ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py @beartype def is_even ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_even)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_even )","title":"is_even()"},{"location":"dyce/#dyce.h.H.is_odd","text":"Equivalent to self . umap ( dyce . types . is_odd ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py @beartype def is_odd ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_odd)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_odd )","title":"is_odd()"},{"location":"dyce/#dyce.h.H.items","text":"D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py @beartype def items ( self ) -> ItemsView [ RealLike , int ]: return self . _h . items ()","title":"items()"},{"location":"dyce/#dyce.h.H.keys","text":"D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py @beartype def keys ( self ) -> KeysView [ RealLike ]: return self . outcomes ()","title":"keys()"},{"location":"dyce/#dyce.h.H.le","text":"Shorthand for self . map ( operator . __le__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def le ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__le__, other).umap(bool)``. ``` python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __le__ , other ) . umap ( bool )","title":"le()"},{"location":"dyce/#dyce.h.H.lowest_terms","text":"Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )) ; df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d6avg = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d6avg H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d6avg . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py @beartype def lowest_terms ( self ) -> H : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ``` python >>> df = H((-1, -1, 0, 0, 1, 1)) ; df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ``` python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return type ( self )( self . _lowest_terms ())","title":"lowest_terms()"},{"location":"dyce/#dyce.h.H.lt","text":"Shorthand for self . map ( operator . __lt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map and umap methods. Source code in dyce/h.py @beartype def lt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__lt__, other).umap(bool)``. ``` python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __lt__ , other ) . umap ( bool )","title":"lt()"},{"location":"dyce/#dyce.h.H.map","text":"Applies bin_op to each outcome of the histogram as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . __add__ , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . __add__ , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . __pow__ , 2 ) H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 }) >>> d6 . map ( operator . __pow__ , 2 ) == d6 ** 2 True 1 2 3 4 >>> d6 . map ( operator . __gt__ , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . __gt__ , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT ) -> H : r \"\"\" Applies *bin_op* to each outcome of the histogram as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> d6 = H(6) >>> d6.map(operator.__add__, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.__add__, d6) == d6 + d6 True ``` ``` python >>> d6.map(operator.__pow__, 2) H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1}) >>> d6.map(operator.__pow__, 2) == d6 ** 2 True ``` ``` python >>> d6.map(operator.__gt__, 3) H({False: 3, True: 3}) >>> d6.map(operator.__gt__, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( right_operand , HableT ): right_operand = right_operand . h () if isinstance ( right_operand , H ): return type ( self )( ( bin_op ( s , o ), self [ s ] * right_operand [ o ]) for s , o in product ( self , right_operand ) ) else : return type ( self )( ( bin_op ( outcome , right_operand ), count ) for outcome , count in self . items () )","title":"map()"},{"location":"dyce/#dyce.h.H.mean","text":"Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py @beartype def mean ( self ) -> RealLike : r \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 )","title":"mean()"},{"location":"dyce/#dyce.h.H.ne","text":"Shorthand for self . map ( operator . __ne__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map and umap methods. Source code in dyce/h.py @beartype def ne ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ne__, other).umap(bool)``. ``` python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ne__ , other ) . umap ( bool )","title":"ne()"},{"location":"dyce/#dyce.h.H.order_stat_for_n_at_pos","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Shorthand for self . order_stat_func_for_n ( n )( pos ) . Source code in dyce/h.py @experimental @beartype def order_stat_for_n_at_pos ( self , n : SupportsInt , pos : SupportsInt ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Shorthand for ``#!python self.order_stat_func_for_n(n)(pos)``. \"\"\" # TODO(posita): Explore different memoization strategies (e.g., with # functools.cache) for this method and H.order_stat_func_for_n return self . order_stat_func_for_n ( n )( pos )","title":"order_stat_for_n_at_pos()"},{"location":"dyce/#dyce.h.H.order_stat_func_for_n","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument ( pos ) and computes the probability distribution for each outcome appearing in that position among n @self . 1 2 3 4 >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> order_stat_for_5d6avg = d6avg . order_stat_func_for_n ( 5 ) >>> order_stat_for_5d6avg ( 3 ) # counts where outcome appears at index 3 H ({ 2 : 26 , 3 : 1432 , 4 : 4792 , 5 : 1526 }) The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where 2 appears at the fourth (index 3 ) position, 1432 ways where 3 appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. 1 2 3 4 >>> from dyce import P >>> p_5d6avg = 5 @P ( d6avg ) >>> sum ( count for roll , count in p_5d6avg . rolls_with_counts () if roll [ 3 ] == 5 ) 1526 This method exists in addition to the H.order_stat_for_n_at_pos method because computing the betas for each outcome in n is unnecessary for each pos . Where different pos values are needed for the same n (e.g., in a loop) and where n is large, that overhead can be significant. The returned function caches those betas for n such that repeated querying or results at pos can be computed much faster. 1 2 3 4 5 % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 30 , i ) for i in range ( 10 )] 462 ms \u00b1 16.9 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) % timeit order_stat_for_30d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 30 ) ; [ order_stat_for_30d6_at_pos ( i ) for i in range ( 10 )] 54.4 ms \u00b1 1.47 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Source: perf_order_stat_for_n.ipy 1 2 3 4 5 6 7 8 9 from dyce import H print ( f \"%timeit [H(6).order_stat_for_n_at_pos(30, i) for i in range(10)]\" ) % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 30 , i ) for i in range ( 10 )] print () print ( f \"%timeit order_stat_for_30d6_at_pos = H(6).order_stat_func_for_n(30) ; [order_stat_for_30d6_at_pos(i) for i in range(10)]\" ) % timeit order_stat_for_30d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 30 ) ; [ order_stat_for_30d6_at_pos ( i ) for i in range ( 10 )] print () Source code in dyce/h.py @experimental @beartype def order_stat_func_for_n ( self , n : SupportsInt ) -> Callable [[ SupportsInt ], \"H\" ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``#!python n@self``. ``` python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``#!python 2`` appears at the fourth (index ``#!python 3``) position, 1432 ways where ``#!python 3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. ``` python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster. ``` python --8<-- \"docs/assets/perf_order_stat_for_n.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_order_stat_for_n.ipy\"><code>perf_order_stat_for_n.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_order_stat_for_n.ipy\" ``` </details> \"\"\" betas_by_outcome : Dict [ RealLike , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ RealLike , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) @beartype def order_stat_for_n_at_pos ( pos : SupportsInt ) -> H : return type ( self )( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos","title":"order_stat_func_for_n()"},{"location":"dyce/#dyce.h.H.outcomes","text":"More descriptive synonym for the keys method . Source code in dyce/h.py @beartype def outcomes ( self ) -> KeysView [ RealLike ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . _h . keys ()","title":"outcomes()"},{"location":"dyce/#dyce.h.H.rmap","text":"Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . rmap ( 2 , operator . __pow__ ) H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 }) >>> d6 . rmap ( 2 , operator . __pow__ ) == 2 ** d6 True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/h.py @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> H : r \"\"\" Analogous to the [``map`` method][dyce.h.H.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> d6 = H(6) >>> d6.rmap(2, operator.__pow__) H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1}) >>> d6.rmap(2, operator.__pow__) == 2 ** d6 True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.h.H.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" return type ( self )( ( bin_op ( left_operand , outcome ), count ) for outcome , count in self . items () )","title":"rmap()"},{"location":"dyce/#dyce.h.H.roll","text":"Returns a (weighted) random outcome, sorted. Source code in dyce/h.py @beartype def roll ( self ) -> RealLike : r \"\"\" Returns a (weighted) random outcome, sorted. \"\"\" return ( rng . RNG . choices ( population = tuple ( self . outcomes ()), weights = tuple ( self . counts ()), k = 1 , )[ 0 ] if self else 0 )","title":"roll()"},{"location":"dyce/#dyce.h.H.stdev","text":"Shorthand for math . sqrt ( self . variance ( mu )) . Source code in dyce/h.py @beartype def stdev ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Shorthand for ``#!python math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu ))","title":"stdev()"},{"location":"dyce/#dyce.h.H.substitute","text":"Experimental The precision_limit parameter should be considered experimental and may change or disappear in future versions. Calls expand on each outcome. If expand returns a single outcome, it replaces the existing outcome. If it returns an H object , expansion is performed again (recursively) on that object until max_depth or precision_limit is exhausted. coalesce is called on the original outcome and the expanded histogram or outcome and the returned histogram is \u201cfolded\u201d into result. (More on these terms and concepts below.) The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. coalesce is not called unless expand returns a histogram If expand returns a single outcome, it always replaces the existing outcome. This is intentional. To return a single outcome, but trigger coalesce , characterize that outcome as a single-sided die (e.g., H ({ outcome : 1 }) . See the coalesce_replace and lowest_terms methods. This method can be used to model complex mechanics. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). This method uses the aggregate_with_counts function in its implementation. As such, If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. 1 2 >>> H ( 6 ) . substitute ( lambda __ , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda __ , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions with dependent variables. Consider the following mechanic: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . __add__ , max_depth = 6 ) >>> h_even = h . is_even () >>> print ( f \" { h_even [ 1 ] / h_even . total : .3% } \" ) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | When expand returns an H object , outcomes produced from the corresponding coalesce are accumulated, but the counts retain their \u201cscale\u201d within the context of the expansion. This becomes clearer when there is no overlap between the substituted histogram and the other outcomes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 >>> d6 = H ( 6 ) >>> d00 = ( H ( 10 ) - 1 ) * 10 ; d00 H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }) >>> set ( d6 ) & set ( d00 ) == set () # no outcomes in common True >>> d6_d00 = d6 . substitute ( ... # If a one comes up when rolling the d6, ... # roll a d00 and take that result instead ... lambda h , outcome : d00 if outcome == 1 else outcome ... ) ; d6_d00 H ({ 0 : 1 , 2 : 10 , 3 : 10 , 4 : 10 , 5 : 10 , 6 : 10 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }) Note that the sum of the outcomes\u2019 counts from the d00 make up the same proportion as the one\u2019s outcome and count they replaced from the d6. 1 2 3 4 5 6 7 8 >>> from fractions import Fraction >>> Fraction ( ... sum ( count for outcome , count in d6_d00 . items () if outcome in d00 ), ... d6_d00 . total , ... ) Fraction ( 1 , 6 ) >>> Fraction ( d6 [ 1 ], d6 . total ) Fraction ( 1 , 6 ) Precision limits This method will halt recursive substitution on any branch either when its depth exceeds max_depth or its \u201ccontextual precision\u201d is precision_limit or less. In either case, substitution is attempted for all of the outcomes of a(n expanded) histogram or none of them. The contextual precision of a histogram is its proportion to the whole. The contextual precision of the original (or top-level) histogram is Fraction ( 1 , 1 ) . By setting precision_limit to that value, we basically ensure no substitution. 1 2 3 4 5 6 7 8 9 10 >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome == 1 else outcome , ... precision_limit = Fraction ( 1 , 1 ), # no substitution ... ) == d6 True >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome == 1 else outcome , ... max_depth = 0 , # no substitution ... ) == d6 True Let\u2019s make a contrived, but illustrative modification to our d6/d00 example from above. If a one comes up when rolling a d6, roll a d00, but re-roll any 80s. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome in ( 1 , 80 ) else outcome , ... max_depth = 100 , # <-- we'll never hit this ... # will halt substitution after the original one from the d6 ... precision_limit = Fraction ( 1 , 6 ), ... ) == d6_d00 True >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome in ( 1 , 80 ) else outcome , ... max_depth = 100 , ... # will halt substitution after the first 80 substitution ... # after the original one from the d6 ... precision_limit = Fraction ( 1 , 6 ) * Fraction ( 1 , 10 ), ... ) H ({ 0 : 11 , 2 : 100 , ... , 6 : 100 , 10 : 11 , ... , 70 : 11 , 80 : 1 , 90 : 11 }) >>> d6 . substitute ( ... lambda h , outcome : d00 if outcome in ( 1 , 80 ) else outcome , ... max_depth = 100 , ... # will halt substitution after the second 80 substitution ... # after the original one from the d6 ... precision_limit = Fraction ( 1 , 6 ) * Fraction ( 1 , 10 ) - Fraction ( 1 , 1000000000 ), # <-- juuust under the wire ... ) H ({ 0 : 111 , 2 : 1000 , ... , 6 : 1000 , 10 : 111 , ... , 70 : 111 , 80 : 1 , 90 : 111 }) The default value for precision_limit is zero, which basically means it is ignored and recursion is limited solely by max_depth . If you want to ensure that this method stops delving based solely on precision, set max_depth to - 1 , which is equivalent to sys . getrecursionlimit () + 1 1 . Be aware that this skews results in favor of non-limited branches. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> h = H ({ 1 : 1 , 2 : 2 , 3 : 3 }) >>> print ( h . explode ( max_depth = 5 ) . format ( scaled = True )) avg | 4.59 std | 3.96 var | 15.65 1 | 16.67 % | ######################## 2 | 33.33 % | ################################################# 4 | 8.33 % | ############ 5 | 16.67 % | ######################## 7 | 4.17 % | ###### 8 | 8.33 % | ############ 10 | 2.08 % | ### 11 | 4.17 % | ###### 13 | 1.04 % | # 14 | 2.08 % | ### 16 | 0.52 % | 17 | 1.04 % | # 18 | 1.56 % | ## >>> print ( h . explode ( max_depth =- 1 , precision_limit = Fraction ( 1 , 6 ** 2 )) . format ( scaled = True )) avg | 4.63 std | 4.09 var | 16.72 1 | 16.67 % | ######################## 2 | 33.33 % | ################################################# 4 | 8.33 % | ############ 5 | 16.67 % | ######################## 7 | 4.17 % | ###### 8 | 8.33 % | ############ 10 | 2.08 % | ### 11 | 4.17 % | ###### 13 | 1.04 % | # 14 | 2.08 % | ### 16 | 0.52 % | 17 | 1.04 % | # 19 | 0.26 % | 20 | 0.52 % | 21 | 0.78 % | # Also be aware that without max_depth as a safety net, some substitutions are guaranteed to result in RecursionError s, even with very high precision_limit s. 1 2 3 4 5 6 7 8 >>> H ( 1 ) . substitute ( ... lambda h , outcome : H ({ outcome + 1 : 1 }), # expands to a single-sided die ... max_depth =- 1 , ... precision_limit = Fraction ( 999999 , 1000000 ), ... ) Traceback ( most recent call last ): ... RecursionError : maximum recursion depth exceeded in comparison H.explode \u2019s expand implementation guards against this by returning outcome if the passed histogram has only one face. Consider a similar approach for your own expand implementations if outcomes\u2019 contextual probabilities do not asymptotically approach zero. This method will \u201cbottom out\u201d far earlier. As of this writing, the practical limit of its implementation (without optimization) is something close to \\(\\frac {1} {3} \\times \\left( limit - depth \\right)\\) , where \\(limit\\) is sys . getrecursionlimit () and \\(depth\\) is len ( inspect . stack ( 0 )) . This also assumes the provided implementations for expand and coalesce don\u2019t contribute significantly to the call stack. Setting max_depth to - 1 or one beyond the absolute limit signals that the caller wants it out of the way. \u21a9 Source code in dyce/h.py @beartype def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsInt = 1 , precision_limit : Fraction = Fraction ( 0 ), ) -> H : r \"\"\" !!! warning \"Experimental\" The *precision_limit* parameter should be considered experimental and may change or disappear in future versions. Calls *expand* on each outcome. If *expand* returns a single outcome, it replaces the existing outcome. If it returns an [``H`` object][dyce.h.H], expansion is performed again (recursively) on that object until *max_depth* or *precision_limit* is exhausted. *coalesce* is called on the original outcome and the expanded histogram or outcome and the returned histogram is \u201cfolded\u201d into result. (More on these terms and concepts below.) The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. !!! note \"*coalesce* is not called unless *expand* returns a histogram\" If *expand* returns a single outcome, it *always* replaces the existing outcome. This is intentional. To return a single outcome, but trigger *coalesce*, characterize that outcome as a single-sided die (e.g., ``#!python H({outcome: 1})``. See the [``coalesce_replace``][dyce.h.coalesce_replace] and [``lowest_terms``][dyce.h.H.lowest_terms] methods. This method can be used to model complex mechanics. The following models re-rolling a face of 1 on the first roll: ``` python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). This method uses the [``aggregate_with_counts``][dyce.h.aggregate_with_counts] function in its implementation. As such, If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. ``` python >>> H(6).substitute(lambda __, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda __, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``#!python substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions with dependent variables. Consider the following mechanic: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ``` python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.__add__, max_depth=6) >>> h_even = h.is_even() >>> print(f\"{h_even[1] / h_even.total:.3%}\") 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. ``` python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` When *expand* returns an [``H`` object][dyce.h.H], outcomes produced from the corresponding *coalesce* are accumulated, but the counts retain their \u201cscale\u201d within the context of the expansion. This becomes clearer when there is no overlap between the substituted histogram and the other outcomes. ``` python >>> d6 = H(6) >>> d00 = (H(10) - 1) * 10 ; d00 H({0: 1, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) >>> set(d6) & set(d00) == set() # no outcomes in common True >>> d6_d00 = d6.substitute( ... # If a one comes up when rolling the d6, ... # roll a d00 and take that result instead ... lambda h, outcome: d00 if outcome == 1 else outcome ... ) ; d6_d00 H({0: 1, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 10: 1, 20: 1, 30: 1, 40: 1, 50: 1, 60: 1, 70: 1, 80: 1, 90: 1}) ``` Note that the sum of the outcomes\u2019 counts from the d00 make up the same proportion as the one\u2019s outcome and count they replaced from the d6. ``` python >>> from fractions import Fraction >>> Fraction( ... sum(count for outcome, count in d6_d00.items() if outcome in d00), ... d6_d00.total, ... ) Fraction(1, 6) >>> Fraction(d6[1], d6.total) Fraction(1, 6) ``` !!! tip \"Precision limits\" This method will halt recursive substitution on any branch *either* when its depth exceeds *max_depth* *or* its \u201ccontextual precision\u201d is *precision_limit* or less. In either case, substitution is attempted for all of the outcomes of a(n expanded) histogram or none of them. The contextual precision of a histogram is its proportion to the whole. The contextual precision of the original (or top-level) histogram is ``#!python Fraction(1, 1)``. By setting *precision_limit* to that value, we basically ensure no substitution. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... precision_limit=Fraction(1, 1), # no substitution ... ) == d6 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome == 1 else outcome, ... max_depth=0, # no substitution ... ) == d6 True ``` Let\u2019s make a contrived, but illustrative modification to our d6/d00 example from above. If a one comes up when rolling a d6, roll a d00, but re-roll any 80s. ``` python >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, # <-- we'll never hit this ... # will halt substitution after the original one from the d6 ... precision_limit=Fraction(1, 6), ... ) == d6_d00 True >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the first 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10), ... ) H({0: 11, 2: 100, ..., 6: 100, 10: 11, ..., 70: 11, 80: 1, 90: 11}) >>> d6.substitute( ... lambda h, outcome: d00 if outcome in (1, 80) else outcome, ... max_depth=100, ... # will halt substitution after the second 80 substitution ... # after the original one from the d6 ... precision_limit=Fraction(1, 6) * Fraction(1, 10) - Fraction(1, 1000000000), # <-- juuust under the wire ... ) H({0: 111, 2: 1000, ..., 6: 1000, 10: 111, ..., 70: 111, 80: 1, 90: 111}) ``` The default value for *precision_limit* is zero, which basically means it is ignored and recursion is limited solely by *max_depth*. If you want to ensure that this method stops delving based *solely* on precision, set *max_depth* to ``#!python -1``, which is equivalent to ``#!python sys.getrecursionlimit() + 1``[^1]. Be aware that this skews results in favor of non-limited branches. ``` python >>> h = H({1: 1, 2: 2, 3: 3}) >>> print(h.explode(max_depth=5).format(scaled=True)) avg | 4.59 std | 3.96 var | 15.65 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 18 | 1.56% |## >>> print(h.explode(max_depth=-1, precision_limit=Fraction(1, 6 ** 2)).format(scaled=True)) avg | 4.63 std | 4.09 var | 16.72 1 | 16.67% |######################## 2 | 33.33% |################################################# 4 | 8.33% |############ 5 | 16.67% |######################## 7 | 4.17% |###### 8 | 8.33% |############ 10 | 2.08% |### 11 | 4.17% |###### 13 | 1.04% |# 14 | 2.08% |### 16 | 0.52% | 17 | 1.04% |# 19 | 0.26% | 20 | 0.52% | 21 | 0.78% |# ``` Also be aware that without *max_depth* as a safety net, some substitutions are guaranteed to result in ``#!python RecursionError``s, even with very high *precision_limit*s. ``` python >>> H(1).substitute( ... lambda h, outcome: H({outcome + 1: 1}), # expands to a single-sided die ... max_depth=-1, ... precision_limit=Fraction(999999, 1000000), ... ) Traceback (most recent call last): ... RecursionError: maximum recursion depth exceeded in comparison ``` [``H.explode``][dyce.h.H.explode]\u2019s *expand* implementation guards against this by returning ``#!python outcome`` if the passed histogram has only one face. Consider a similar approach for your own *expand* implementations if outcomes\u2019 contextual probabilities do not asymptotically approach zero. [^1]: This method will \u201cbottom out\u201d far earlier. As of this writing, the practical limit of its implementation (without optimization) is something close to $\\frac {1} {3} \\times \\left( limit - depth \\right)$, where $limit$ is ``#!python sys.getrecursionlimit()`` and $depth$ is ``#!python len(inspect.stack(0))``. This also assumes the provided implementations for *expand* and *coalesce* don\u2019t contribute significantly to the call stack. Setting *max_depth* to ``#!python -1`` or one beyond the absolute limit signals that the caller wants it out of the way. \"\"\" max_depth = as_int ( max_depth ) if max_depth == - 1 : max_depth = sys . getrecursionlimit () + 1 if max_depth < 0 : raise ValueError ( \"max_depth cannot be an arbitrary negative number (use -1 explicitly to indicate no limit)\" ) if precision_limit < 0 or precision_limit > 1 : raise ValueError ( f \"precision_limit ( { precision_limit } ) must be between zero and one, inclusive\" ) def _substitute ( h : H , depth : int = 0 , contextual_precision : Fraction = Fraction ( 1 ), ) -> H : assert coalesce is not None if depth == max_depth or contextual_precision <= precision_limit : return h def _expand_and_coalesce () -> Iterator [ Tuple [ Union [ H , RealLike ], int ]]: total = h . total for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded_precision = Fraction ( contextual_precision . numerator * count , contextual_precision . denominator * total , ) expanded = _substitute ( expanded , depth + 1 , expanded_precision ) # Coalesce the result expanded = coalesce ( expanded , outcome ) yield expanded , count return aggregate_with_counts ( _expand_and_coalesce (), type ( self )) return _substitute ( self ) . lowest_terms ()","title":"substitute()"},{"location":"dyce/#dyce.h.H.umap","text":"Applies un_op to each outcome of the histogram. 1 2 3 >>> import operator >>> H ( 6 ) . umap ( operator . __neg__ ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py @beartype def umap ( self , un_op : _UnaryOperatorT ) -> H : r \"\"\" Applies *un_op* to each outcome of the histogram. ``` python >>> import operator >>> H(6).umap(operator.__neg__) H(-6) ``` ``` python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = type ( self )(( un_op ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : simple_init = un_op ( self . _simple_init ) if isinstance ( simple_init , SupportsInt ): h_simple = type ( self )( simple_init ) if h_simple == h : return h_simple return h","title":"umap()"},{"location":"dyce/#dyce.h.H.values","text":"D.values() -> an object providing a view on D's values Source code in dyce/h.py @beartype def values ( self ) -> ValuesView [ int ]: return self . counts ()","title":"values()"},{"location":"dyce/#dyce.h.H.variance","text":"Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py @beartype def variance ( self , mu : Optional [ RealLike ] = None ) -> RealLike : r \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 )","title":"variance()"},{"location":"dyce/#dyce.h.H.vs","text":"Compares the histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self . within ( 0 , 0 , other ) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py @beartype def vs ( self , other : _OperandT ) -> H : r \"\"\" Compares the histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``#!python self.within(0, 0, other)``. ``` python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other )","title":"vs()"},{"location":"dyce/#dyce.h.H.within","text":"Computes the difference between the histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ()) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ()) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py @beartype def within ( self , lo : RealLike , hi : RealLike , other : _OperandT = 0 ) -> H : r \"\"\" Computes the difference between the histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ``` python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format()) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format()) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other )","title":"within()"},{"location":"dyce/#dyce.p.P","text":"An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). 1 2 3 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True This class implements the HableT protocol and derives from the HableOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using arithmetic operations. 1 2 >>> - p_d6 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) To perform arithmetic on individual H objects in a pool without flattening, use the map , rmap , and umap methods. 1 2 3 >>> import operator >>> P ( 4 , 6 , 8 ) . umap ( operator . __neg__ ) P ( - 8 , - 6 , - 4 ) 1 2 >>> P ( 4 , 6 ) . map ( operator . __pow__ , 2 ) P ( H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 }), H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 })) 1 2 >>> P ( 4 , 6 ) . rmap ( 2 , operator . __pow__ ) P ( H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 }), H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 })) Comparisons with H objects work as expected. 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram. 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering. 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HableT protocol , the h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ()) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ### Source code in dyce/p.py class P ( Sequence [ H ], HableOpsMixin ): r \"\"\" An immutable pool (ordered sequence) supporting group operations for zero or more [``H`` objects][dyce.h.H] (provided or created from the [initializer][dyce.p.P.__init__]\u2019s *args* parameter). ``` python >>> from dyce import P >>> p_d6 = P(6) ; p_d6 # shorthand for P(H(6)) P(6) ``` ``` python >>> P(p_d6, p_d6) # 2d6 P(6, 6) >>> 2@p_d6 # also 2d6 P(6, 6) >>> 2@(2@p_d6) == 4@p_d6 True ``` ``` python >>> p = P(4, P(6, P(8, P(10, P(12, P(20)))))) ; p P(4, 6, 8, 10, 12, 20) >>> sum(p.roll()) in p.h() True ``` This class implements the [``HableT`` protocol][dyce.h.HableT] and derives from the [``HableOpsMixin`` class][dyce.h.HableOpsMixin], which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the [``h`` method][dyce.p.P.h], or implicitly by using arithmetic operations. ``` python >>> -p_d6 H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) ``` ``` python >>> p_d6 + p_d6 H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` ``` python >>> 2 * P(8) - 1 H({1: 1, 3: 1, 5: 1, 7: 1, 9: 1, 11: 1, 13: 1, 15: 1}) ``` To perform arithmetic on individual [``H`` objects][dyce.h.H] in a pool without flattening, use the [``map``][dyce.p.P.map], [``rmap``][dyce.p.P.rmap], and [``umap``][dyce.p.P.umap] methods. ``` python >>> import operator >>> P(4, 6, 8).umap(operator.__neg__) P(-8, -6, -4) ``` ``` python >>> P(4, 6).map(operator.__pow__, 2) P(H({1: 1, 4: 1, 9: 1, 16: 1}), H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1})) ``` ``` python >>> P(4, 6).rmap(2, operator.__pow__) P(H({2: 1, 4: 1, 8: 1, 16: 1}), H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1})) ``` Comparisons with [``H`` objects][dyce.h.H] work as expected. ``` python >>> from dyce import H >>> 3@p_d6 == H(6) + H(6) + H(6) True ``` Indexing selects a contained histogram. ``` python >>> P(4, 6, 8)[0] H(4) ``` Note that pools are opinionated about ordering. ``` python >>> P(8, 6, 4) P(4, 6, 8) >>> P(8, 6, 4)[0] == P(8, 4, 6)[0] == H(4) True ``` In an extension to (departure from) the [``HableT`` protocol][dyce.h.HableT], the [``h`` method][dyce.p.P.h]\u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice (``3d6``) can be expressed as: ``` python >>> p_3d6 = 3@p_d6 >>> p_3d6.h(-2, -1) H({2: 1, 3: 3, 4: 7, 5: 12, 6: 19, 7: 27, 8: 34, 9: 36, 10: 34, 11: 27, 12: 16}) >>> print(p_3d6.h(-2, -1).format()) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46% | 3 | 1.39% | 4 | 3.24% |# 5 | 5.56% |## 6 | 8.80% |#### 7 | 12.50% |###### 8 | 15.74% |####### 9 | 16.67% |######## 10 | 15.74% |####### 11 | 12.50% |###### 12 | 7.41% |### ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_hs\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , * args : Union [ SupportsInt , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs () -> Iterator [ H ]: for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h elif isinstance ( a , SupportsInt ): yield H ( a ) else : raise ValueError ( f \"unrecognized initializer { args } \" ) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : def _parts () -> Iterator [ str ]: for h in self : yield ( str ( h . _simple_init ) if h . _simple_init is not None else repr ( h )) args = \", \" . join ( _parts ()) return f \" { type ( self ) . __name__ } ( { args } )\" @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , P ): return __eq__ ( self . _hs , other . _hs ) else : return NotImplemented @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , P ): return __ne__ ( self . _hs , other . _hs ) else : return NotImplemented @beartype def __len__ ( self ) -> int : return len ( self . _hs ) @overload def __getitem__ ( self , key : SupportsIndex ) -> H : ... @overload def __getitem__ ( self , key : slice ) -> P : ... @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( self , key : _GetItemT ) -> Union [ H , \"P\" ]: # type: ignore [override] if isinstance ( key , slice ): return P ( * self . _hs [ key ]) else : return self . _hs [ __index__ ( key )] @beartype def __iter__ ( self ) -> Iterator [ H ]: return iter ( self . _hs ) @beartype def __matmul__ ( self , other : SupportsInt ) -> P : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return P ( * chain . from_iterable ( repeat ( self , other ))) @beartype def __rmatmul__ ( self , other : SupportsInt ) -> P : return self . __matmul__ ( other ) @beartype def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``#!python H((sum(roll), count) for roll, count in self.rolls_with_counts(*which))`` with some short-circuit optimizations. When provided no arguments, ``#!python h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HableT`` protocol][dyce.h.HableT]. ``` python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ``` python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ``` python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_h ( self ) # ---- Properties ------------------------------------------------------------------ @property def is_homogeneous ( self ) -> bool : r \"\"\" !!! warning \"Experimental\" This property should be considered experimental and may change or disappear in future versions. A flag indicating whether the pool\u2019s population of histograms is homogeneous. ``` python >>> P(6, 6).is_homogeneous True >>> P(4, 6, 8).is_homogeneous False ``` \"\"\" return len ( set ( self . _hs )) <= 1 # ---- Methods --------------------------------------------------------------------- @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : Union [ \"P\" , H , HableT , _SourceT ], ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each unique set of rolls from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Rolls are sorted least to greatest. Returned histograms are always reduced to their lowest terms. ``` python >>> from dyce.p import RollT >>> def three_way_vs(first: RollT, second: RollT, third: RollT): ... first_reversed = first[::-1] ... second_reversed = second[::-1] ... third_reversed = third[::-1] ... if first_reversed > second_reversed and first_reversed > third_reversed: ... return 1 # first is the clear winner ... elif second_reversed > first_reversed and second_reversed > third_reversed: ... return 2 # second is the clear winner ... elif third_reversed > first_reversed and third_reversed > second_reversed: ... return 3 # third is the clear winner ... else: ... return 0 # there was a tie somewhere >>> P.foreach( ... three_way_vs, ... first=P(6, 6), # first has pool of two d6s ... second=P(6, 6), # second has pool of two d6s ... third=P(4, 8), # third has pool of one d4 and one d8 ... ) H({0: 1103, 1: 5783, 2: 5783, 3: 8067}) ``` When all of ``#!python foreach``\u2019s arguments are [``P`` objects][dyce.p.P] of size 1 or anything other than a ``P`` object, this function behaves similarly to [``H.foreach``][dyce.h.H] (although the signature of the *dependent_term* callback function differs slightly between the two interfaces). ``` python >>> from itertools import chain >>> P.foreach( ... lambda **kw: sum(chain(*kw.values())), # receives single-element rolls ... src1=P(6), # pool of size 1 ... src2=H(6), # histogram ... src3=range(6, 0, -1), # histogram source ... ) == H.foreach( ... lambda **kw: sum(kw.values()), # receives outcomes ... src1=P(6).h(), # histogram ... src2=H(6), # histogram ... src3={1, 2, 3, 4, 5, 6}, # histogram source ... ) True ``` The ``#!python foreach`` class method is equivalent to nesting loops iterating over [``P.rolls_with_counts``][dyce.p.P.rolls_with_counts] for each independent term and then aggregating the results. ``` python >>> def dependent_term( ... *, ... roll_1, ... roll_2, ... # ... ... roll_n, ... ): ... return ( ... (roll_2[-1] > roll_1[-1]) ... + (roll_n[-1] > roll_2[-1]) ... # ... ... ) >>> source_1 = P(8) >>> source_2 = P(6, 6) >>> # ... >>> source_n = P(4, 4, 4) >>> h = P.foreach( ... dependent_term, ... roll_1=source_1, ... roll_2=source_2, ... # ... ... roll_n=source_n, ... ) ; h H({0: 3821, 1: 5126, 2: 269}) >>> def resolve(): ... for roll_1, count_1 in source_1.rolls_with_counts(): ... for roll_2, count_2 in source_2.rolls_with_counts(): ... # ... ... for roll_n, count_n in source_n.rolls_with_counts(): ... # ... ... yield dependent_term( ... roll_1=roll_1, ... roll_2=roll_2, ... # ... ... roll_n=roll_n, ... ), ( ... count_1 ... * count_2 ... # * ... ... * count_n ... ) >>> from dyce.h import aggregate_with_counts >>> aggregate_with_counts(resolve()) == h True ``` \"\"\" pools_by_kw : Dict [ str , P ] = {} for source_name , source in independent_sources . items (): if isinstance ( source , H ): pools_by_kw [ source_name ] = P ( source ) elif isinstance ( source , P ): pools_by_kw [ source_name ] = source elif isinstance ( source , HableT ): pools_by_kw [ source_name ] = P ( source . h ()) else : pools_by_kw [ source_name ] = P ( H ( source )) def _kw_roll_count_tuples ( pool_name : str , ) -> Iterator [ Tuple [ str , RollT , int ]]: for roll , count in pools_by_kw [ pool_name ] . rolls_with_counts (): yield pool_name , roll , count def _resolve_dependent_term_for_rolls () -> Iterator [ Tuple [ Union [ H , RealLike ], int ] ]: for kw_roll_count_tuples in product ( * ( _kw_roll_count_tuples ( pool_name ) for pool_name in pools_by_kw ) ): combined_count = reduce ( __mul__ , ( count for _ , _ , count in kw_roll_count_tuples ), 1 ) rolls_by_name = { name : roll for name , roll , _ in kw_roll_count_tuples } yield dependent_term ( ** rolls_by_name ), combined_count return aggregate_with_counts ( _resolve_dependent_term_for_rolls ()) . lowest_terms () @experimental @beartype def appearances_in_rolls ( self , outcome : RealLike ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``#!python H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ``` python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ``` python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being about twice as fast as the boolean accumulation technique for larger sets. ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_appearances_in_rolls.ipy\"><code>perf_appearances_in_rolls.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.ipy\" ``` </details> \"\"\" group_counters : List [ Counter [ RealLike ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ RealLike ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_h ( H ( group_counter ) for group_counter in group_counters ) @beartype def roll ( self ) -> RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. !!! note \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self )) @beartype def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding two-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the two-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed for more flexible selections. ``` python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. ``` python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ``` python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``#!python (1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ``` python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. ``` python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable. ``` python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted. ``` python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ``` python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$. $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``#!python n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls. ``#!python ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``#!python (a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``#!python H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ``` python --8<-- \"docs/assets/perf_rolls_with_counts.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_rolls_with_counts.ipy\"><code>perf_rolls_with_counts.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_rolls_with_counts.ipy\" ``` </details> \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count @beartype def map ( self , op : _BinaryOperatorT , right_operand : _OperandT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.map(op, right_operand) for h in self))``. See the [``H.map`` method][dyce.h.H.map]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.map(operator.__mul__, -1) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) ``` \"\"\" return P ( * ( h . map ( op , right_operand ) for h in self )) @beartype def rmap ( self , left_operand : RealLike , op : _BinaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.rmap(left_operand, op) for h in self))``. See the [``H.rmap`` method][dyce.h.H.rmap]. ``` python >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(Fraction).rmap(1, operator.__truediv__) P(H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1}), H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1})) ``` \"\"\" return P ( * ( h . rmap ( left_operand , op ) for h in self )) @beartype def umap ( self , op : _UnaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.umap(op) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(operator.__neg__) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) >>> p_3d6.umap(operator.__abs__) P(H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1})) ``` \"\"\" return P ( * ( h . umap ( op ) for h in self ))","title":"P"},{"location":"dyce/#dyce.p.P.__slots__","text":"","title":"__slots__"},{"location":"dyce/#dyce.p.P.is_homogeneous","text":"Experimental This property should be considered experimental and may change or disappear in future versions. A flag indicating whether the pool\u2019s population of histograms is homogeneous. 1 2 3 4 >>> P ( 6 , 6 ) . is_homogeneous True >>> P ( 4 , 6 , 8 ) . is_homogeneous False","title":"is_homogeneous"},{"location":"dyce/#dyce.p.P.__eq__","text":"Source code in dyce/p.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , P ): return __eq__ ( self . _hs , other . _hs ) else : return NotImplemented","title":"__eq__()"},{"location":"dyce/#dyce.p.P.__getitem__","text":"Source code in dyce/p.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( self , key : _GetItemT ) -> Union [ H , \"P\" ]: # type: ignore [override] if isinstance ( key , slice ): return P ( * self . _hs [ key ]) else : return self . _hs [ __index__ ( key )]","title":"__getitem__()"},{"location":"dyce/#dyce.p.P.__init__","text":"Initializer. Source code in dyce/p.py @beartype def __init__ ( self , * args : Union [ SupportsInt , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs () -> Iterator [ H ]: for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h elif isinstance ( a , SupportsInt ): yield H ( a ) else : raise ValueError ( f \"unrecognized initializer { args } \" ) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs )","title":"__init__()"},{"location":"dyce/#dyce.p.P.__iter__","text":"Source code in dyce/p.py @beartype def __iter__ ( self ) -> Iterator [ H ]: return iter ( self . _hs )","title":"__iter__()"},{"location":"dyce/#dyce.p.P.__len__","text":"Source code in dyce/p.py @beartype def __len__ ( self ) -> int : return len ( self . _hs )","title":"__len__()"},{"location":"dyce/#dyce.p.P.__matmul__","text":"Source code in dyce/p.py @beartype def __matmul__ ( self , other : SupportsInt ) -> P : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return P ( * chain . from_iterable ( repeat ( self , other )))","title":"__matmul__()"},{"location":"dyce/#dyce.p.P.__ne__","text":"Source code in dyce/p.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , P ): return __ne__ ( self . _hs , other . _hs ) else : return NotImplemented","title":"__ne__()"},{"location":"dyce/#dyce.p.P.__repr__","text":"Source code in dyce/p.py @beartype def __repr__ ( self ) -> str : def _parts () -> Iterator [ str ]: for h in self : yield ( str ( h . _simple_init ) if h . _simple_init is not None else repr ( h )) args = \", \" . join ( _parts ()) return f \" { type ( self ) . __name__ } ( { args } )\"","title":"__repr__()"},{"location":"dyce/#dyce.p.P.__rmatmul__","text":"Source code in dyce/p.py @beartype def __rmatmul__ ( self , other : SupportsInt ) -> P : return self . __matmul__ ( other )","title":"__rmatmul__()"},{"location":"dyce/#dyce.p.P.appearances_in_rolls","text":"Experimental This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H (( sum ( 1 for v in roll if v == outcome ), count ) for roll , count in self . rolls_with_counts ()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being about twice as fast as the boolean accumulation technique for larger sets. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 % timeit 3 @d4_eq3 + 2 @d6_eq3 397 \u00b5s \u00b1 17.5 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 653 \u00b5s \u00b1 23.9 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit 9 @d4_eq3 + 6 @d6_eq3 1.39 ms \u00b1 53.9 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.12 ms \u00b1 35.3 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) % timeit 27 @d4_eq3 + 18 @d6_eq3 7.14 ms \u00b1 223 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) % timeit P ( 27 @P ( 4 ), 18 @P ( 6 )) . appearances_in_rolls ( 3 ) 3.32 ms \u00b1 109 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) % timeit 81 @d4_eq3 + 54 @d6_eq3 46.7 ms \u00b1 1.01 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) % timeit P ( 81 @P ( 4 ), 54 @P ( 6 )) . appearances_in_rolls ( 3 ) 17.1 ms \u00b1 416 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Source: perf_appearances_in_rolls.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 from dyce import H , P p_2d6 = P ( 6 , 6 ) d4 , d6 = H ( 4 ), H ( 6 ) p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) print ( f \"%timeit 3@d4_eq3 + 2@d6_eq3\" ) % timeit 3 @d4_eq3 + 2 @d6_eq3 print () print ( f \"%timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) print () print ( f \"%timeit 9@d4_eq3 + 6@d6_eq3\" ) % timeit 9 @d4_eq3 + 6 @d6_eq3 print () print ( f \"%timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) print () print ( f \"%timeit 27@d4_eq3 + 18@d6_eq3\" ) % timeit 27 @d4_eq3 + 18 @d6_eq3 print () print ( f \"%timeit P(27@P(4), 18@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 27 @P ( 4 ), 18 @P ( 6 )) . appearances_in_rolls ( 3 ) print () print ( f \"%timeit 81@d4_eq3 + 54@d6_eq3\" ) % timeit 81 @d4_eq3 + 54 @d6_eq3 print () print ( f \"%timeit P(81@P(4), 54@P(6)).appearances_in_rolls(3)\" ) % timeit P ( 81 @P ( 4 ), 54 @P ( 6 )) . appearances_in_rolls ( 3 ) print () Source code in dyce/p.py @experimental @beartype def appearances_in_rolls ( self , outcome : RealLike ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``#!python H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ``` python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ``` python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being about twice as fast as the boolean accumulation technique for larger sets. ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_appearances_in_rolls.ipy\"><code>perf_appearances_in_rolls.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_appearances_in_rolls.ipy\" ``` </details> \"\"\" group_counters : List [ Counter [ RealLike ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ RealLike ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_h ( H ( group_counter ) for group_counter in group_counters )","title":"appearances_in_rolls()"},{"location":"dyce/#dyce.p.P.foreach","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Calls dependent_term for each unique set of rolls from the product of independent_sources and accumulates the results. This is useful for resolving dependent probabilities. Rolls are sorted least to greatest. Returned histograms are always reduced to their lowest terms. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from dyce.p import RollT >>> def three_way_vs ( first : RollT , second : RollT , third : RollT ): ... first_reversed = first [:: - 1 ] ... second_reversed = second [:: - 1 ] ... third_reversed = third [:: - 1 ] ... if first_reversed > second_reversed and first_reversed > third_reversed : ... return 1 # first is the clear winner ... elif second_reversed > first_reversed and second_reversed > third_reversed : ... return 2 # second is the clear winner ... elif third_reversed > first_reversed and third_reversed > second_reversed : ... return 3 # third is the clear winner ... else : ... return 0 # there was a tie somewhere >>> P . foreach ( ... three_way_vs , ... first = P ( 6 , 6 ), # first has pool of two d6s ... second = P ( 6 , 6 ), # second has pool of two d6s ... third = P ( 4 , 8 ), # third has pool of one d4 and one d8 ... ) H ({ 0 : 1103 , 1 : 5783 , 2 : 5783 , 3 : 8067 }) When all of foreach \u2019s arguments are P objects of size 1 or anything other than a P object, this function behaves similarly to H.foreach (although the signature of the dependent_term callback function differs slightly between the two interfaces). 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from itertools import chain >>> P . foreach ( ... lambda ** kw : sum ( chain ( * kw . values ())), # receives single-element rolls ... src1 = P ( 6 ), # pool of size 1 ... src2 = H ( 6 ), # histogram ... src3 = range ( 6 , 0 , - 1 ), # histogram source ... ) == H . foreach ( ... lambda ** kw : sum ( kw . values ()), # receives outcomes ... src1 = P ( 6 ) . h (), # histogram ... src2 = H ( 6 ), # histogram ... src3 = { 1 , 2 , 3 , 4 , 5 , 6 }, # histogram source ... ) True The foreach class method is equivalent to nesting loops iterating over P.rolls_with_counts for each independent term and then aggregating the results. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> def dependent_term ( ... * , ... roll_1 , ... roll_2 , ... # ... ... roll_n , ... ): ... return ( ... ( roll_2 [ - 1 ] > roll_1 [ - 1 ]) ... + ( roll_n [ - 1 ] > roll_2 [ - 1 ]) ... # ... ... ) >>> source_1 = P ( 8 ) >>> source_2 = P ( 6 , 6 ) >>> # ... >>> source_n = P ( 4 , 4 , 4 ) >>> h = P . foreach ( ... dependent_term , ... roll_1 = source_1 , ... roll_2 = source_2 , ... # ... ... roll_n = source_n , ... ) ; h H ({ 0 : 3821 , 1 : 5126 , 2 : 269 }) >>> def resolve (): ... for roll_1 , count_1 in source_1 . rolls_with_counts (): ... for roll_2 , count_2 in source_2 . rolls_with_counts (): ... # ... ... for roll_n , count_n in source_n . rolls_with_counts (): ... # ... ... yield dependent_term ( ... roll_1 = roll_1 , ... roll_2 = roll_2 , ... # ... ... roll_n = roll_n , ... ), ( ... count_1 ... * count_2 ... # * ... ... * count_n ... ) >>> from dyce.h import aggregate_with_counts >>> aggregate_with_counts ( resolve ()) == h True Source code in dyce/p.py @classmethod @beartype def foreach ( cls , dependent_term : Callable [ ... , Union [ H , RealLike ]], ** independent_sources : Union [ \"P\" , H , HableT , _SourceT ], ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Calls ``#!python dependent_term`` for each unique set of rolls from the product of ``independent_sources`` and accumulates the results. This is useful for resolving dependent probabilities. Rolls are sorted least to greatest. Returned histograms are always reduced to their lowest terms. ``` python >>> from dyce.p import RollT >>> def three_way_vs(first: RollT, second: RollT, third: RollT): ... first_reversed = first[::-1] ... second_reversed = second[::-1] ... third_reversed = third[::-1] ... if first_reversed > second_reversed and first_reversed > third_reversed: ... return 1 # first is the clear winner ... elif second_reversed > first_reversed and second_reversed > third_reversed: ... return 2 # second is the clear winner ... elif third_reversed > first_reversed and third_reversed > second_reversed: ... return 3 # third is the clear winner ... else: ... return 0 # there was a tie somewhere >>> P.foreach( ... three_way_vs, ... first=P(6, 6), # first has pool of two d6s ... second=P(6, 6), # second has pool of two d6s ... third=P(4, 8), # third has pool of one d4 and one d8 ... ) H({0: 1103, 1: 5783, 2: 5783, 3: 8067}) ``` When all of ``#!python foreach``\u2019s arguments are [``P`` objects][dyce.p.P] of size 1 or anything other than a ``P`` object, this function behaves similarly to [``H.foreach``][dyce.h.H] (although the signature of the *dependent_term* callback function differs slightly between the two interfaces). ``` python >>> from itertools import chain >>> P.foreach( ... lambda **kw: sum(chain(*kw.values())), # receives single-element rolls ... src1=P(6), # pool of size 1 ... src2=H(6), # histogram ... src3=range(6, 0, -1), # histogram source ... ) == H.foreach( ... lambda **kw: sum(kw.values()), # receives outcomes ... src1=P(6).h(), # histogram ... src2=H(6), # histogram ... src3={1, 2, 3, 4, 5, 6}, # histogram source ... ) True ``` The ``#!python foreach`` class method is equivalent to nesting loops iterating over [``P.rolls_with_counts``][dyce.p.P.rolls_with_counts] for each independent term and then aggregating the results. ``` python >>> def dependent_term( ... *, ... roll_1, ... roll_2, ... # ... ... roll_n, ... ): ... return ( ... (roll_2[-1] > roll_1[-1]) ... + (roll_n[-1] > roll_2[-1]) ... # ... ... ) >>> source_1 = P(8) >>> source_2 = P(6, 6) >>> # ... >>> source_n = P(4, 4, 4) >>> h = P.foreach( ... dependent_term, ... roll_1=source_1, ... roll_2=source_2, ... # ... ... roll_n=source_n, ... ) ; h H({0: 3821, 1: 5126, 2: 269}) >>> def resolve(): ... for roll_1, count_1 in source_1.rolls_with_counts(): ... for roll_2, count_2 in source_2.rolls_with_counts(): ... # ... ... for roll_n, count_n in source_n.rolls_with_counts(): ... # ... ... yield dependent_term( ... roll_1=roll_1, ... roll_2=roll_2, ... # ... ... roll_n=roll_n, ... ), ( ... count_1 ... * count_2 ... # * ... ... * count_n ... ) >>> from dyce.h import aggregate_with_counts >>> aggregate_with_counts(resolve()) == h True ``` \"\"\" pools_by_kw : Dict [ str , P ] = {} for source_name , source in independent_sources . items (): if isinstance ( source , H ): pools_by_kw [ source_name ] = P ( source ) elif isinstance ( source , P ): pools_by_kw [ source_name ] = source elif isinstance ( source , HableT ): pools_by_kw [ source_name ] = P ( source . h ()) else : pools_by_kw [ source_name ] = P ( H ( source )) def _kw_roll_count_tuples ( pool_name : str , ) -> Iterator [ Tuple [ str , RollT , int ]]: for roll , count in pools_by_kw [ pool_name ] . rolls_with_counts (): yield pool_name , roll , count def _resolve_dependent_term_for_rolls () -> Iterator [ Tuple [ Union [ H , RealLike ], int ] ]: for kw_roll_count_tuples in product ( * ( _kw_roll_count_tuples ( pool_name ) for pool_name in pools_by_kw ) ): combined_count = reduce ( __mul__ , ( count for _ , _ , count in kw_roll_count_tuples ), 1 ) rolls_by_name = { name : roll for name , roll , _ in kw_roll_count_tuples } yield dependent_term ( ** rolls_by_name ), combined_count return aggregate_with_counts ( _resolve_dependent_term_for_rolls ()) . lowest_terms ()","title":"foreach()"},{"location":"dyce/#dyce.p.P.h","text":"Roughly equivalent to H (( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which )) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HableT protocol . 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d6avg + d6avg True Source code in dyce/p.py @beartype def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``#!python H((sum(roll), count) for roll, count in self.rolls_with_counts(*which))`` with some short-circuit optimizations. When provided no arguments, ``#!python h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HableT`` protocol][dyce.h.HableT]. ``` python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ``` python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format()) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ``` python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_h ( self )","title":"h()"},{"location":"dyce/#dyce.p.P.map","text":"Shorthand for P ( * ( h . map ( op , right_operand ) for h in self )) . See the H.map method . 1 2 3 4 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . map ( operator . __mul__ , - 1 ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) Source code in dyce/p.py @beartype def map ( self , op : _BinaryOperatorT , right_operand : _OperandT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.map(op, right_operand) for h in self))``. See the [``H.map`` method][dyce.h.H.map]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.map(operator.__mul__, -1) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) ``` \"\"\" return P ( * ( h . map ( op , right_operand ) for h in self ))","title":"map()"},{"location":"dyce/#dyce.p.P.rmap","text":"Shorthand for P ( * ( h . rmap ( left_operand , op ) for h in self )) . See the H.rmap method . 1 2 3 4 5 >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( Fraction ) . rmap ( 1 , operator . __truediv__ ) P ( H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 }), H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 })) Source code in dyce/p.py @beartype def rmap ( self , left_operand : RealLike , op : _BinaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.rmap(left_operand, op) for h in self))``. See the [``H.rmap`` method][dyce.h.H.rmap]. ``` python >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(Fraction).rmap(1, operator.__truediv__) P(H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1}), H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1})) ``` \"\"\" return P ( * ( h . rmap ( left_operand , op ) for h in self ))","title":"rmap()"},{"location":"dyce/#dyce.p.P.roll","text":"Returns (weighted) random outcomes from contained histograms. On ordering This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. Source code in dyce/p.py @beartype def roll ( self ) -> RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. !!! note \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self ))","title":"roll()"},{"location":"dyce/#dyce.p.P.rolls_with_counts","text":"Returns an iterator yielding two-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the two-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, ( 1 , 2 ) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d6avg + d6avg True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable. 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted. 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) . \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n @P ( H ( m )) . Enumerating combinations with replacements would yield all unique rolls. (( 1 , 1 , \u2026 , 1 ), ( 1 , 1 , \u2026 , 2 ), \u2026 , ( 1 , 1 , \u2026 , m ), \u2026 , ( m - 1 , m , \u2026 , m ), ( m , m , \u2026 , m )) To determine the count for a particular roll ( a , b , \u2026 , n ) , we compute the multinomial coefficient for that roll and multiply by the scalar H ( m )[ a ] * H ( m )[ b ] * \u2026 * H ( m )[ n ] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 0 )): 22.7 \u00b5s \u00b1 463 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 1 )): 740 \u00b5s \u00b1 16.4 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 2.25 ms \u00b1 97.7 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 4.44 ms \u00b1 219 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 2.12 ms \u00b1 26 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 4.46 ms \u00b1 75.5 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 7.89 ms \u00b1 186 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 12.7 ms \u00b1 287 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 0 )): 22.6 \u00b5s \u00b1 820 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 1 )): 2.51 ms \u00b1 102 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 2 )): 5.31 ms \u00b1 63 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 )) . h ( slice ( 3 )): 5.37 ms \u00b1 98.5 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 2 )): 32.4 ms \u00b1 1.36 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 3 )): 78.6 ms \u00b1 918 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 4 )): 80.8 ms \u00b1 2.18 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 5 )): 79.9 ms \u00b1 2.81 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 0 )): 22.6 \u00b5s \u00b1 438 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 1 )): 8.98 ms \u00b1 169 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 2 )): 9.09 ms \u00b1 205 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 3 )): 9.09 ms \u00b1 350 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 2 )): 312 ms \u00b1 9.72 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 3 )): 314 ms \u00b1 2.45 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 4 )): 334 ms \u00b1 10.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 }), H ({ - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 }), H ({ - 3 : 1 , - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 }), H ({ - 2 : 1 , - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 }), H ({ - 1 : 1 , 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }))) . h ( slice ( 5 )): 324 ms \u00b1 5.48 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source: perf_rolls_with_counts.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from dyce import H , P for n in ( 4 , 6 ): p = n @P ( 6 ) for i in range ( len ( p ) - 4 , len ( p )): print ( f \"( { p } ).h(slice( { i } )):\" ) % timeit p . h ( slice ( i )) print () for n in ( 2 , 3 ): p = P ( n @P ( 6 ), * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) for i in range ( len ( p ) - 4 , len ( p )): print ( f \"( { p } ).h(slice( { i } )):\" ) % timeit p . h ( slice ( i )) print () for n in ( 4 , 6 ): p = P ( * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) for i in range ( len ( p ) - 4 , len ( p )): print ( f \"( { p } ).h(slice( { i } )):\" ) % timeit p . h ( slice ( i )) print () Source code in dyce/p.py @beartype def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding two-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the two-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed for more flexible selections. ``` python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. ``` python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ``` python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``#!python (1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ``` python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. ``` python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable. ``` python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted. ``` python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ``` python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$. $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``#!python n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls. ``#!python ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``#!python (a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``#!python H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ``` python --8<-- \"docs/assets/perf_rolls_with_counts.txt\" ``` <details> <summary>Source: <a href=\"https://github.com/posita/dyce/blob/latest/docs/assets/perf_rolls_with_counts.ipy\"><code>perf_rolls_with_counts.ipy</code></a></summary> ``` python --8<-- \"docs/assets/perf_rolls_with_counts.ipy\" ``` </details> \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count","title":"rolls_with_counts()"},{"location":"dyce/#dyce.p.P.umap","text":"Shorthand for P ( * ( h . umap ( op ) for h in self )) . See the H.umap method . 1 2 3 4 5 6 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( operator . __neg__ ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) >>> p_3d6 . umap ( operator . __abs__ ) P ( H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 })) Source code in dyce/p.py @beartype def umap ( self , op : _UnaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.umap(op) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(operator.__neg__) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) >>> p_3d6.umap(operator.__abs__) P(H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1})) ``` \"\"\" return P ( * ( h . umap ( op ) for h in self ))","title":"umap()"},{"location":"dyce.r/","text":"dyce . r package reference Experimental This package is an attempt to provide primitives for producing weighted randomized rolls without the overhead of enumeration. Rolls can be inspected to understand how specific values are derived. It should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Feedback, suggestions, and contributions are welcome and appreciated. Roller class hierarchy BasicOpRoller ( R ) A roller for applying op to some variation of outcomes from sources . Any RollOutcome s returned by op are used directly in the creation of a new Roll . Source code in dyce/r.py class BasicOpRoller ( R ): r \"\"\" A [roller][dyce.r.R] for applying *op* to some variation of outcomes from *sources*. Any [``RollOutcome``][dyce.r.RollOutcome]s returned by *op* are used directly in the creation of a new [``Roll``][dyce.r.Roll]. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_op\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _op = op # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( op= { self . op !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . op , other . op )) @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) res = self . op ( self , ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), ) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def op ( self ) -> BasicOperatorT : r \"\"\" The operator this roller applies to its sources. \"\"\" return self . _op __slots__ : Union [ str , Iterable [ str ]] special op : BasicOperatorT property readonly The operator this roller applies to its sources. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . op , other . op )) __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _op = op __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( op= { self . op !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) res = self . op ( self , ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), ) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , ) BinarySumOpRoller ( NarySumOpRoller ) An NarySumOpRoller for applying a binary operator bin_op to the sum of all outcomes from its left_source and the sum of all outcomes from its right_source . Source code in dyce/r.py class BinarySumOpRoller ( NarySumOpRoller ): r \"\"\" An [``NarySumOpRoller``][dyce.r.NarySumOpRoller] for applying a binary operator *bin_op* to the sum of all outcomes from its *left_source* and the sum of all outcomes from its *right_source*. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_bin_op\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: left_operand , right_operand = roll_outcomes return bin_op ( left_operand , right_operand ) super () . __init__ ( op = _op , sources = ( left_source , right_source ), annotation = annotation , ** kw ) self . _bin_op = bin_op # ---- Properties ------------------------------------------------------------------ @property def bin_op ( self ) -> _RollOutcomeBinaryOperatorT : r \"\"\" The operator this roller applies to its sources. \"\"\" return self . _bin_op # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : def _source_repr ( source : _SourceT ) -> str : return indent ( repr ( source ), \" \" ) . strip () left_source , right_source = self . sources return f \"\"\" { type ( self ) . __name__ } ( bin_op= { self . bin_op !r} , left_source= { _source_repr ( left_source ) } , right_source= { _source_repr ( right_source ) } , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . bin_op , other . bin_op )) __slots__ : Union [ str , Iterable [ str ]] special bin_op : _RollOutcomeBinaryOperatorT property readonly The operator this roller applies to its sources. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . bin_op , other . bin_op )) __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: left_operand , right_operand = roll_outcomes return bin_op ( left_operand , right_operand ) super () . __init__ ( op = _op , sources = ( left_source , right_source ), annotation = annotation , ** kw ) self . _bin_op = bin_op __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : def _source_repr ( source : _SourceT ) -> str : return indent ( repr ( source ), \" \" ) . strip () left_source , right_source = self . sources return f \"\"\" { type ( self ) . __name__ } ( bin_op= { self . bin_op !r} , left_source= { _source_repr ( left_source ) } , right_source= { _source_repr ( right_source ) } , annotation= { self . annotation !r} , )\"\"\" FilterRoller ( R ) A roller for applying predicate to filter outcomes its sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 >>> r_d6 = R . from_value ( H ( 6 )) >>> filter_r = ( 2 @r_d6 ) . filter ( ... lambda outcome : outcome . value is not None and outcome . value > 3 , # type: ignore [operator] ... ) >>> ( filter_r ) . roll () Roll ( r = FilterRoller ( predicate =< function < lambda > at ...> , sources = ( RepeatRoller ( n = 2 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( Roll ( r = RepeatRoller ( n = 2 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 5 , sources = (), ), ), source_rolls = (), ), ), ), ), ) See the section on \u201c Filtering and substitution \u201d more examples. Source code in dyce/r.py class FilterRoller ( R ): r \"\"\" A [roller][dyce.r.R] for applying *predicate* to filter outcomes its *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1639580307) -- END MONKEY PATCH --> ``` python >>> r_d6 = R.from_value(H(6)) >>> filter_r = (2@r_d6).filter( ... lambda outcome: outcome.value is not None and outcome.value > 3, # type: ignore [operator] ... ) >>> (filter_r).roll() Roll( r=FilterRoller( predicate=<function <lambda> at ...>, sources=( RepeatRoller( n=2, source=ValueRoller(value=H(6), annotation=''), annotation='', ), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ), RollOutcome( value=5, sources=(), ), ), source_rolls=( Roll( r=RepeatRoller( n=2, source=ValueRoller(value=H(6), annotation=''), annotation='', ), roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=5, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=H(6), annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=H(6), annotation=''), roll_outcomes=( RollOutcome( value=5, sources=(), ), ), source_rolls=(), ), ), ), ), ) ``` See the section on \u201c[Filtering and substitution](rollin.md#filtering-and-substitution)\u201d more examples. \"\"\" __slots__ : Tuple [ str , ... ] = ( \"_predicate\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , predicate : _PredicateT , sources : Iterable [ R ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _predicate = predicate # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( predicate= { self . predicate !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and _callable_cmp ( self . predicate , other . predicate ) @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _filtered_roll_outcomes () -> Iterator [ RollOutcome ]: for roll_outcome in chain . from_iterable ( source_rolls ): if roll_outcome . value is not None : if self . predicate ( roll_outcome ): yield roll_outcome else : yield roll_outcome . euthanize () return Roll ( self , roll_outcomes = _filtered_roll_outcomes (), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def predicate ( self ) -> _PredicateT : r \"\"\" The predicate this roller applies to filter its sources. \"\"\" return self . _predicate __slots__ : Tuple [ str , ... ] special predicate : _PredicateT property readonly The predicate this roller applies to filter its sources. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and _callable_cmp ( self . predicate , other . predicate ) __init__ ( self , predicate : _PredicateT , sources : Iterable [ R ], annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , predicate : _PredicateT , sources : Iterable [ R ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _predicate = predicate __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( predicate= { self . predicate !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _filtered_roll_outcomes () -> Iterator [ RollOutcome ]: for roll_outcome in chain . from_iterable ( source_rolls ): if roll_outcome . value is not None : if self . predicate ( roll_outcome ): yield roll_outcome else : yield roll_outcome . euthanize () return Roll ( self , roll_outcomes = _filtered_roll_outcomes (), source_rolls = source_rolls , ) NarySumOpRoller ( BasicOpRoller ) A BasicOpRoller for applying op to the sum of outcomes grouped by each of sources . Source code in dyce/r.py class NarySumOpRoller ( BasicOpRoller ): r \"\"\" A [``BasicOpRoller``][dyce.r.BasicOpRoller] for applying *op* to the sum of outcomes grouped by each of *sources*. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _sum_roll_outcomes_by_rolls () -> Iterator [ RollOutcome ]: for source_roll in source_rolls : if len ( source_roll ) == 1 and source_roll [ 0 ] . value is not None : yield from source_roll else : yield RollOutcome ( sum ( source_roll . outcomes ()), sources = source_roll ) res = self . op ( self , _sum_roll_outcomes_by_rolls ()) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , ) __slots__ : Union [ str , Iterable [ str ]] special roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _sum_roll_outcomes_by_rolls () -> Iterator [ RollOutcome ]: for source_roll in source_rolls : if len ( source_roll ) == 1 and source_roll [ 0 ] . value is not None : yield from source_roll else : yield RollOutcome ( sum ( source_roll . outcomes ()), sources = source_roll ) res = self . op ( self , _sum_roll_outcomes_by_rolls ()) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , ) PoolRoller ( R ) A roller for rolling flattened \u201cpools\u201d from all sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 >>> PoolRoller (( ... PoolRoller (( ... ValueRoller ( 11 ), ... ValueRoller ( 12 ), ... )), ... PoolRoller (( ... PoolRoller (( ... ValueRoller ( 211 ), ... ValueRoller ( 212 ), ... )), ... PoolRoller (( ... ValueRoller ( 221 ), ... ValueRoller ( 222 ), ... )), ... )), ... ValueRoller ( 3 ), ... )) . roll () Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 11 , sources =... , ), RollOutcome ( value = 12 , sources =... , ), RollOutcome ( value = 211 , sources =... , ), RollOutcome ( value = 212 , sources =... , ), RollOutcome ( value = 221 , sources =... , ), RollOutcome ( value = 222 , sources =... , ), RollOutcome ( value = 3 , sources =... , ), ), source_rolls =... , ) Source code in dyce/r.py class PoolRoller ( R ): r \"\"\" A [roller][dyce.r.R] for rolling flattened \u201cpools\u201d from all *sources*. ``` python >>> PoolRoller(( ... PoolRoller(( ... ValueRoller(11), ... ValueRoller(12), ... )), ... PoolRoller(( ... PoolRoller(( ... ValueRoller(211), ... ValueRoller(212), ... )), ... PoolRoller(( ... ValueRoller(221), ... ValueRoller(222), ... )), ... )), ... ValueRoller(3), ... )).roll() Roll( r=..., roll_outcomes=( RollOutcome( value=11, sources=..., ), RollOutcome( value=12, sources=..., ), RollOutcome( value=211, sources=..., ), RollOutcome( value=212, sources=..., ), RollOutcome( value=221, sources=..., ), RollOutcome( value=222, sources=..., ), RollOutcome( value=3, sources=..., ), ), source_rolls=..., ) ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , ) __slots__ : Union [ str , Iterable [ str ]] special roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , ) R Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Where H objects and P objects are used primarily for enumerating weighted outcomes, R objects represent rollers. More specifically, they are immutable nodes assembled in tree-like structures to represent calculations. Unlike H or P objects, rollers generate rolls that conform to weighted outcomes without engaging in computationally expensive enumeration. Roller trees are typically composed from various R class methods and operators as well as arithmetic operations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> from dyce import H , P , R >>> d6 = H ( 6 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> (( 4 * r_d6 + 3 ) ** 2 % 5 ) . gt ( 2 ) BinarySumOpRoller ( bin_op =< function R . gt .< locals >. _gt at ...> , left_source = BinarySumOpRoller ( bin_op =< built - in function mod > , left_source = BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = BinarySumOpRoller ( bin_op =< built - in function add > , left_source = BinarySumOpRoller ( bin_op =< built - in function mul > , left_source = ValueRoller ( value = 4 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 3 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 5 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) Info No optimizations are made when initializing roller trees. They retain their exact structure, even where such structures could be trivially reduced. 1 2 3 4 5 6 7 >>> r_6 = R . from_value ( 6 ) >>> r_6_abs_3 = 3 @abs ( r_6 ) >>> r_6_abs_6_abs_6_abs = R . from_sources ( abs ( r_6 ), abs ( r_6 ), abs ( r_6 )) >>> tuple ( r_6_abs_3 . roll () . outcomes ()), tuple ( r_6_abs_6_abs_6_abs . roll () . outcomes ()) # they generate the same rolls (( 6 , 6 , 6 ), ( 6 , 6 , 6 )) >>> r_6_abs_3 == r_6_abs_6_abs_6_abs # and yet, they're different animals False This is because the structure itself contains information that might be required by certain contexts. If such information loss is permissible and reduction is desirable, consider using histograms instead. Roller trees can can be queried via the roll method , which produces Roll objects . 1 2 3 4 5 >>> roll = r_d6 . roll () >>> tuple ( roll . outcomes ()) ( 4 ,) >>> roll . total () 4 1 2 3 4 >>> d6 + 3 H ({ 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> ( r_d6 + 3 ) . roll () . total () in ( d6 + 3 ) True Roll objects are much richer than mere sequences of outcomes. They are also tree-like structures that mirror the roller trees used to produce them, capturing references to rollers and the outcomes generated at each node. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 >>> roll = ( r_d6 + 3 ) . roll () >>> roll . total () 8 >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 8 , sources = ( RollOutcome ( value = 5 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 5 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Rollers afford optional annotations as a convenience to callers. They are taken into account when comparing roller trees, but otherwise ignored, internally. One use is to capture references to nodes in an abstract syntax tree generated from parsing a proprietary grammar. Any provided annotation can be retrieved using the annotation property . The annotate method can be used to apply an annotation to existing roller. The R class itself acts as a base from which several computation-specific implementations derive (such as expressing operands like outcomes or histograms, unary operations, binary operations, pools, etc.). Source code in dyce/r.py class R : r \"\"\" !!! warning \"Experimental\" This class (and its descendants) should be considered experimental and may change or disappear in future versions. Where [``H`` objects][dyce.h.H] and [``P`` objects][dyce.p.P] are used primarily for enumerating weighted outcomes, ``#!python R`` objects represent rollers. More specifically, they are immutable nodes assembled in tree-like structures to represent calculations. Unlike [``H``][dyce.h.H] or [``P``][dyce.p.P] objects, rollers generate rolls that conform to weighted outcomes without engaging in computationally expensive enumeration. Roller trees are typically composed from various ``#!python R`` class methods and operators as well as arithmetic operations. ``` python >>> from dyce import H, P, R >>> d6 = H(6) >>> r_d6 = R.from_value(d6) ; r_d6 ValueRoller(value=H(6), annotation='') >>> ((4 * r_d6 + 3) ** 2 % 5).gt(2) BinarySumOpRoller( bin_op=<function R.gt.<locals>._gt at ...>, left_source=BinarySumOpRoller( bin_op=<built-in function mod>, left_source=BinarySumOpRoller( bin_op=<built-in function pow>, left_source=BinarySumOpRoller( bin_op=<built-in function add>, left_source=BinarySumOpRoller( bin_op=<built-in function mul>, left_source=ValueRoller(value=4, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ), right_source=ValueRoller(value=3, annotation=''), annotation='', ), right_source=ValueRoller(value=2, annotation=''), annotation='', ), right_source=ValueRoller(value=5, annotation=''), annotation='', ), right_source=ValueRoller(value=2, annotation=''), annotation='', ) ``` !!! info No optimizations are made when initializing roller trees. They retain their exact structure, even where such structures could be trivially reduced. ``` python >>> r_6 = R.from_value(6) >>> r_6_abs_3 = 3@abs(r_6) >>> r_6_abs_6_abs_6_abs = R.from_sources(abs(r_6), abs(r_6), abs(r_6)) >>> tuple(r_6_abs_3.roll().outcomes()), tuple(r_6_abs_6_abs_6_abs.roll().outcomes()) # they generate the same rolls ((6, 6, 6), (6, 6, 6)) >>> r_6_abs_3 == r_6_abs_6_abs_6_abs # and yet, they're different animals False ``` This is because the structure itself contains information that might be required by certain contexts. If such information loss is permissible and reduction is desirable, consider using [histograms][dyce.h.H] instead. Roller trees can can be queried via the [``roll`` method][dyce.r.R.roll], which produces [``Roll`` objects][dyce.r.Roll]. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056380) -- END MONKEY PATCH --> ``` python >>> roll = r_d6.roll() >>> tuple(roll.outcomes()) (4,) >>> roll.total() 4 ``` ``` python >>> d6 + 3 H({4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}) >>> (r_d6 + 3).roll().total() in (d6 + 3) True ``` [``Roll`` objects][dyce.r.Roll] are much richer than mere sequences of outcomes. They are also tree-like structures that mirror the roller trees used to produce them, capturing references to rollers and the outcomes generated at each node. ``` python >>> roll = (r_d6 + 3).roll() >>> roll.total() 8 >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=8, sources=( RollOutcome( value=5, sources=(), ), RollOutcome( value=3, sources=(), ), ), ), ), source_rolls=( Roll( r=ValueRoller(value=H(6), annotation=''), roll_outcomes=( RollOutcome( value=5, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` Rollers afford optional annotations as a convenience to callers. They are taken into account when comparing roller trees, but otherwise ignored, internally. One use is to capture references to nodes in an abstract syntax tree generated from parsing a proprietary grammar. Any provided *annotation* can be retrieved using the [``annotation`` property][dyce.r.R.annotation]. The [``annotate`` method][dyce.r.R.annotate] can be used to apply an annotation to existing roller. The ``#!python R`` class itself acts as a base from which several computation-specific implementations derive (such as expressing operands like outcomes or histograms, unary operations, binary operations, pools, etc.). <!-- BEGIN MONKEY PATCH -- For type-checking docstrings >>> from typing import Tuple, Union >>> from dyce.r import PoolRoller, Roll, RollOutcome, ValueRoller >>> which: Tuple[Union[int, slice], ...] -- END MONKEY PATCH --> \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_annotation\" , \"_sources\" ) # ---- Initializer ----------------------------------------------------------------- @experimental @beartype def __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ () self . _sources = tuple ( sources ) self . _annotation = annotation # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , R ): return ( ( isinstance ( self , type ( other )) or isinstance ( other , type ( self ))) and __eq__ ( self . sources , other . sources ) # order matters and __eq__ ( self . annotation , other . annotation ) ) else : return super () . __eq__ ( other ) @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , R ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) @beartype def __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented @beartype def __radd__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented @beartype def __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented @beartype def __rsub__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented @beartype def __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmul__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented @beartype def __matmul__ ( self , other : SupportsInt ) -> R : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return RepeatRoller ( other , self ) @beartype def __rmatmul__ ( self , other : SupportsInt ) -> R : return self . __matmul__ ( other ) @beartype def __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rtruediv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented @beartype def __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rfloordiv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented @beartype def __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmod__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented @beartype def __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented @beartype def __rpow__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented @beartype def __and__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __and__ , other ) else : return self . map ( __and__ , as_int ( other )) except NotImplementedError : return NotImplemented @beartype def __rand__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __and__ ) except NotImplementedError : return NotImplemented @beartype def __xor__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __xor__ , other ) else : return self . map ( __xor__ , as_int ( other )) except NotImplementedError : return NotImplemented @beartype def __rxor__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __xor__ ) except NotImplementedError : return NotImplemented @beartype def __or__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __or__ , other ) else : return self . map ( __or__ , as_int ( other )) except NotImplementedError : return NotImplemented @beartype def __ror__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __or__ ) except NotImplementedError : return NotImplemented @beartype def __neg__ ( self ) -> UnarySumOpRoller : return self . umap ( __neg__ ) @beartype def __pos__ ( self ) -> UnarySumOpRoller : return self . umap ( __pos__ ) @beartype def __abs__ ( self ) -> UnarySumOpRoller : return self . umap ( __abs__ ) @beartype def __invert__ ( self ) -> UnarySumOpRoller : return self . umap ( __invert__ ) @abstractmethod def roll ( self ) -> Roll : r \"\"\" Sub-classes should implement this method to return a new [``Roll`` object][dyce.r.Roll] taking into account any [sources][dyce.r.R.sources]. !!! note Implementors guarantee that all [``RollOutcome``][dyce.r.RollOutcome]s in the returned [``Roll``][dyce.r.Roll] *must* be associated with a roll, *including all roll outcomes\u2019 [``sources``][dyce.r.RollOutcome.sources]*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633403927) -- END MONKEY PATCH --> !!! tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of ``#!python None`` with the excluded roll outcome as its source. The [``RollOutcome.euthanize``][dyce.r.RollOutcome.euthanize] convenience method is provided for this purpose. See the section on \u201c[Dropping dice from prior rolls \u2026](rollin.md#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8)\u201d as well as the note in [``Roll.__init__``][dyce.r.Roll.__init__] for additional color. ``` python >>> from itertools import chain >>> class AntonChigurhRoller(R): ... h_coin_toss = H((0, 1)) ... def roll(self) -> Roll: ... source_rolls = list(self.source_rolls()) ... def _roll_outcomes_gen(): ... for roll_outcome in chain.from_iterable(source_rolls): ... if roll_outcome.value is None: ... # Omit those already deceased ... continue ... elif self.h_coin_toss.roll(): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else: ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome.euthanize() ... return Roll(self, roll_outcomes=_roll_outcomes_gen(), source_rolls=source_rolls) >>> ac_r = AntonChigurhRoller(sources=(R.from_value(1), R.from_value(2), R.from_value(3))) >>> ac_r.roll() Roll( r=AntonChigurhRoller( sources=( ValueRoller(value=1, annotation=''), ValueRoller(value=2, annotation=''), ValueRoller(value=3, annotation=''), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=1, annotation=''), roll_outcomes=( RollOutcome( value=1, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=2, annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` \"\"\" ... # ---- Properties ------------------------------------------------------------------ @property def annotation ( self ) -> Any : r \"\"\" Any provided annotation. \"\"\" return self . _annotation @property def sources ( self ) -> Tuple [ _SourceT , ... ]: r \"\"\" The roller\u2019s direct sources (if any). \"\"\" return self . _sources # ---- Methods --------------------------------------------------------------------- @classmethod @beartype def from_sources ( cls , * sources : _SourceT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable(rs, annotation=annotation)``. See the [``from_sources_iterable`` method][dyce.r.R.from_sources_iterable]. \"\"\" return cls . from_sources_iterable ( sources , annotation = annotation ) @classmethod @beartype def from_sources_iterable ( cls , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Creates and returns a roller for \u201cpooling\u201d zero or more *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056341) -- END MONKEY PATCH --> ``` python >>> r_pool = R.from_sources_iterable(R.from_value(h) for h in (H((1, 2)), H((3, 4)), H((5, 6)))) >>> roll = r_pool.roll() >>> tuple(roll.outcomes()) (2, 4, 6) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=4, sources=(), ), RollOutcome( value=6, sources=(), ), ), source_rolls=..., ) ``` \"\"\" return PoolRoller ( sources , annotation = annotation ) @classmethod @beartype def from_value ( cls , value : _ValueT , annotation : Any = \"\" , ) -> ValueRoller : r \"\"\" Creates and returns a [``ValueRoller``][dyce.r.ValueRoller] from *value*. ``` python >>> R.from_value(6) ValueRoller(value=6, annotation='') ``` ``` python >>> R.from_value(H(6)) ValueRoller(value=H(6), annotation='') ``` ``` python >>> R.from_value(P(6, 6)) ValueRoller(value=P(6, 6), annotation='') ``` \"\"\" return ValueRoller ( value , annotation = annotation ) @classmethod @beartype def from_values ( cls , * values : _ValueT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_values_iterable(values, annotation=annotation)``. See the [``from_values_iterable`` method][dyce.r.R.from_values_iterable]. \"\"\" return cls . from_values_iterable ( values , annotation = annotation ) @classmethod @beartype def from_values_iterable ( cls , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``from_sources_iterable``][dyce.r.R.from_sources_iterable] methods. \"\"\" return cls . from_sources_iterable ( ( cls . from_value ( value ) for value in values ), annotation = annotation , ) @classmethod @beartype def filter_from_sources ( cls , predicate : _PredicateT , * sources : _SourceT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable(predicate, sources, annotation=annotation)``. See the [``filter_from_sources_iterable`` method][dyce.r.R.filter_from_sources_iterable]. \"\"\" return cls . filter_from_sources_iterable ( predicate , sources , annotation = annotation ) @classmethod @beartype def filter_from_sources_iterable ( cls , predicate : _PredicateT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Creates and returns a [``FilterRoller``][dyce.r.FilterRoller] for applying filterion *predicate* to sorted outcomes from *sources*. ``` python >>> r_filter = R.filter_from_sources_iterable( ... lambda outcome: bool(outcome.is_even().value), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_filter FilterRoller( predicate=<function <lambda> at ...>, sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_filter.roll().outcomes()) (4, 6, 2, 8, 0) ``` \"\"\" return FilterRoller ( predicate , sources , annotation = annotation ) @classmethod @beartype def filter_from_values ( cls , predicate : _PredicateT , * values : _ValueT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_values_iterable(predicate, values, annotation=annotation)``. See the [``filter_from_values_iterable`` method][dyce.r.R.filter_from_values_iterable]. \"\"\" return cls . filter_from_values_iterable ( predicate , values , annotation = annotation ) @classmethod @beartype def filter_from_values_iterable ( cls , predicate : _PredicateT , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``filter_from_sources_iterable``][dyce.r.R.filter_from_sources_iterable] methods. \"\"\" return cls . filter_from_sources_iterable ( predicate , ( cls . from_value ( value ) for value in values ), annotation = annotation , ) @classmethod @beartype def select_from_sources ( cls , which : Iterable [ _GetItemT ], * sources : _SourceT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable(which, sources, annotation=annotation)``. See the [``select_from_sources_iterable`` method][dyce.r.R.select_from_sources_iterable]. \"\"\" return cls . select_from_sources_iterable ( which , sources , annotation = annotation ) @classmethod @beartype def select_from_sources_iterable ( cls , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Creates and returns a [``SelectionRoller``][dyce.r.SelectionRoller] for applying selection *which* to sorted outcomes from *sources*. ``` python >>> r_select = R.select_from_sources_iterable( ... (0, -1, slice(3, 6), slice(6, 3, -1), -1, 0), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_select SelectionRoller( which=(0, -1, slice(3, 6, None), slice(6, 3, -1), -1, 0), sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_select.roll().outcomes()) (0, 9, 3, 4, 5, 6, 5, 4, 9, 0) ``` \"\"\" return SelectionRoller ( which , sources , annotation = annotation ) @classmethod @beartype def select_from_values ( cls , which : Iterable [ _GetItemT ], * values : _ValueT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_values_iterable(which, values, annotation=annotation)``. See the [``select_from_values_iterable`` method][dyce.r.R.select_from_values_iterable]. \"\"\" return cls . select_from_values_iterable ( which , values , annotation = annotation ) @classmethod @beartype def select_from_values_iterable ( cls , which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``select_from_sources_iterable``][dyce.r.R.select_from_sources_iterable] methods. \"\"\" return cls . select_from_sources_iterable ( which , ( cls . from_value ( value ) for value in values ), annotation = annotation , ) @beartype def source_rolls ( self ) -> Iterator [ \"Roll\" ]: r \"\"\" Generates new rolls from all [``sources``][dyce.r.R.sources]. \"\"\" for source in self . sources : yield source . roll () @beartype def annotate ( self , annotation : Any = \"\" ) -> R : r \"\"\" Generates a copy of the roller with the desired annotation. ``` python >>> r_just_the_n_of_us = R.from_value(5, annotation=\"But I'm 42!\") ; r_just_the_n_of_us ValueRoller(value=5, annotation=\"But I'm 42!\") >>> r_just_the_n_of_us.annotate(\"I'm a 42-year-old investment banker!\") ValueRoller(value=5, annotation=\"I'm a 42-year-old investment banker!\") ``` \"\"\" r = copy ( self ) r . _annotation = annotation return r @beartype def map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Creates and returns a [``BinarySumOpRoller``][dyce.r.BinarySumOpRoller] for applying *bin_op* to this roller and *right_operand* as its sources. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).map(operator.__pow__, 2) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=H(6), annotation=''), right_source=ValueRoller(value=2, annotation=''), annotation='', ) >>> r_bin_op == R.from_value(H(6)) ** 2 True ``` \"\"\" if isinstance ( right_operand , RealLike ): right_operand = ValueRoller ( right_operand ) if isinstance ( right_operand , ( R , RollOutcome )): return BinarySumOpRoller ( bin_op , self , right_operand , annotation = annotation ) else : raise NotImplementedError @beartype def rmap ( self , left_operand : Union [ RealLike , \"RollOutcome\" ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Analogous to the [``map`` method][dyce.r.R.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).rmap(2, operator.__pow__) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=2, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_bin_op == 2 ** R.from_value(H(6)) True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.R.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return BinarySumOpRoller ( bin_op , ValueRoller ( left_operand ), self , annotation = annotation ) elif isinstance ( left_operand , RollOutcome ): return BinarySumOpRoller ( bin_op , left_operand , self , annotation = annotation ) else : raise NotImplementedError @beartype def umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = \"\" , ) -> UnarySumOpRoller : r \"\"\" Creates and returns a [``UnarySumOpRoller``][dyce.r.UnarySumOpRoller] roller for applying *un_op* to this roller as its source. ``` python >>> import operator >>> r_un_op = R.from_value(H(6)).umap(operator.__neg__) ; r_un_op UnarySumOpRoller( un_op=<built-in function neg>, source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_un_op == -R.from_value(H(6)) True ``` \"\"\" return UnarySumOpRoller ( un_op , self , annotation = annotation ) @beartype def lt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.lt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _lt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . lt ( right_operand ) return self . map ( _lt , other ) @beartype def le ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.le(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _le ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . le ( right_operand ) return self . map ( _le , other ) @beartype def eq ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.eq(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _eq ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . eq ( right_operand ) return self . map ( _eq , other ) @beartype def ne ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ne(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ne ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ne ( right_operand ) return self . map ( _ne , other ) @beartype def gt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.gt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _gt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . gt ( right_operand ) return self . map ( _gt , other ) @beartype def ge ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ge(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ge ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ge ( right_operand ) return self . map ( _ge , other ) @beartype def is_even ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_even())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_even ( operand : RollOutcome ) -> RollOutcome : return operand . is_even () return self . umap ( _is_even ) @beartype def is_odd ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_odd())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_odd ( operand : RollOutcome ) -> RollOutcome : return operand . is_odd () return self . umap ( _is_odd ) @beartype def filter ( self , predicate : _PredicateT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python type(self).filter_from_sources(predicate, self, annotation=annotation)``. See the [``filter_from_sources`` method][dyce.r.R.filter_from_sources]. \"\"\" return type ( self ) . filter_from_sources ( predicate , self , annotation = annotation ) @beartype def select ( self , * which : _GetItemT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python self.select_iterable(which, annotation=annotation)``. See the [``select_iterable`` method][dyce.r.R.select_iterable]. \"\"\" return self . select_iterable ( which , annotation = annotation ) @beartype def select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python type(self).select_from_sources(which, self, annotation=annotation)``. See the [``select_from_sources`` method][dyce.r.R.select_from_sources]. \"\"\" return type ( self ) . select_from_sources ( which , self , annotation = annotation ) __slots__ : Union [ str , Iterable [ str ]] special annotation : Any property readonly Any provided annotation. sources : Tuple [ _SourceT , ... ] property readonly The roller\u2019s direct sources (if any). __abs__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __abs__ ( self ) -> UnarySumOpRoller : return self . umap ( __abs__ ) __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented __and__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __and__ , other ) else : return self . map ( __and__ , as_int ( other )) except NotImplementedError : return NotImplemented __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , R ): return ( ( isinstance ( self , type ( other )) or isinstance ( other , type ( self ))) and __eq__ ( self . sources , other . sources ) # order matters and __eq__ ( self . annotation , other . annotation ) ) else : return super () . __eq__ ( other ) __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = '' , ** kw ) special Initializer. Source code in dyce/r.py @experimental @beartype def __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ () self . _sources = tuple ( sources ) self . _annotation = annotation __invert__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __invert__ ( self ) -> UnarySumOpRoller : return self . umap ( __invert__ ) __matmul__ ( self , other : SupportsInt ) -> R special Source code in dyce/r.py @beartype def __matmul__ ( self , other : SupportsInt ) -> R : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return RepeatRoller ( other , self ) __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented __ne__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , R ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) __neg__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __neg__ ( self ) -> UnarySumOpRoller : return self . umap ( __neg__ ) __or__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __or__ , other ) else : return self . map ( __or__ , as_int ( other )) except NotImplementedError : return NotImplemented __pos__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __pos__ ( self ) -> UnarySumOpRoller : return self . umap ( __pos__ ) __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented __radd__ ( self , other : RealLike ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented __rand__ ( self , other : SupportsInt ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __and__ ) except NotImplementedError : return NotImplemented __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" __rfloordiv__ ( self , other : RealLike ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented __rmatmul__ ( self , other : SupportsInt ) -> R special Source code in dyce/r.py @beartype def __rmatmul__ ( self , other : SupportsInt ) -> R : return self . __matmul__ ( other ) __rmod__ ( self , other : RealLike ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented __rmul__ ( self , other : RealLike ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented __ror__ ( self , other : SupportsInt ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __or__ ) except NotImplementedError : return NotImplemented __rpow__ ( self , other : RealLike ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented __rsub__ ( self , other : RealLike ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented __rtruediv__ ( self , other : RealLike ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented __rxor__ ( self , other : SupportsInt ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __xor__ ) except NotImplementedError : return NotImplemented __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented __xor__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __xor__ , other ) else : return self . map ( __xor__ , as_int ( other )) except NotImplementedError : return NotImplemented annotate ( self , annotation : Any = '' ) -> R Generates a copy of the roller with the desired annotation. 1 2 3 4 >>> r_just_the_n_of_us = R . from_value ( 5 , annotation = \"But I'm 42!\" ) ; r_just_the_n_of_us ValueRoller ( value = 5 , annotation = \"But I'm 42!\" ) >>> r_just_the_n_of_us . annotate ( \"I'm a 42-year-old investment banker!\" ) ValueRoller ( value = 5 , annotation = \"I'm a 42-year-old investment banker!\" ) Source code in dyce/r.py @beartype def annotate ( self , annotation : Any = \"\" ) -> R : r \"\"\" Generates a copy of the roller with the desired annotation. ``` python >>> r_just_the_n_of_us = R.from_value(5, annotation=\"But I'm 42!\") ; r_just_the_n_of_us ValueRoller(value=5, annotation=\"But I'm 42!\") >>> r_just_the_n_of_us.annotate(\"I'm a 42-year-old investment banker!\") ValueRoller(value=5, annotation=\"I'm a 42-year-old investment banker!\") ``` \"\"\" r = copy ( self ) r . _annotation = annotation return r eq ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . eq ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def eq ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.eq(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _eq ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . eq ( right_operand ) return self . map ( _eq , other ) filter ( self , predicate : _PredicateT , annotation : Any = '' ) -> FilterRoller Shorthand for type ( self ) . filter_from_sources ( predicate , self , annotation = annotation ) . See the filter_from_sources method . Source code in dyce/r.py @beartype def filter ( self , predicate : _PredicateT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python type(self).filter_from_sources(predicate, self, annotation=annotation)``. See the [``filter_from_sources`` method][dyce.r.R.filter_from_sources]. \"\"\" return type ( self ) . filter_from_sources ( predicate , self , annotation = annotation ) filter_from_sources ( predicate : _PredicateT , * sources : _SourceT , * , annotation : Any = '' ) -> FilterRoller classmethod Shorthand for cls . filter_from_sources_iterable ( predicate , sources , annotation = annotation ) . See the filter_from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def filter_from_sources ( cls , predicate : _PredicateT , * sources : _SourceT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable(predicate, sources, annotation=annotation)``. See the [``filter_from_sources_iterable`` method][dyce.r.R.filter_from_sources_iterable]. \"\"\" return cls . filter_from_sources_iterable ( predicate , sources , annotation = annotation ) filter_from_sources_iterable ( predicate : _PredicateT , sources : Iterable [ _SourceT ], annotation : Any = '' ) -> FilterRoller classmethod Creates and returns a FilterRoller for applying filterion predicate to sorted outcomes from sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_filter = R . filter_from_sources_iterable ( ... lambda outcome : bool ( outcome . is_even () . value ), ... ( R . from_value ( i ) for i in ( 5 , 4 , 6 , 3 , 7 , 2 , 8 , 1 , 9 , 0 )), ... ) ; r_filter FilterRoller ( predicate =< function < lambda > at ...> , sources = ( ValueRoller ( value = 5 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ... , ValueRoller ( value = 9 , annotation = '' ), ValueRoller ( value = 0 , annotation = '' ), ), annotation = '' , ) >>> tuple ( r_filter . roll () . outcomes ()) ( 4 , 6 , 2 , 8 , 0 ) Source code in dyce/r.py @classmethod @beartype def filter_from_sources_iterable ( cls , predicate : _PredicateT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Creates and returns a [``FilterRoller``][dyce.r.FilterRoller] for applying filterion *predicate* to sorted outcomes from *sources*. ``` python >>> r_filter = R.filter_from_sources_iterable( ... lambda outcome: bool(outcome.is_even().value), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_filter FilterRoller( predicate=<function <lambda> at ...>, sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_filter.roll().outcomes()) (4, 6, 2, 8, 0) ``` \"\"\" return FilterRoller ( predicate , sources , annotation = annotation ) filter_from_values ( predicate : _PredicateT , * values : _ValueT , * , annotation : Any = '' ) -> FilterRoller classmethod Shorthand for cls . filter_from_values_iterable ( predicate , values , annotation = annotation ) . See the filter_from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def filter_from_values ( cls , predicate : _PredicateT , * values : _ValueT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_values_iterable(predicate, values, annotation=annotation)``. See the [``filter_from_values_iterable`` method][dyce.r.R.filter_from_values_iterable]. \"\"\" return cls . filter_from_values_iterable ( predicate , values , annotation = annotation ) filter_from_values_iterable ( predicate : _PredicateT , values : Iterable [ _ValueT ], annotation : Any = '' ) -> FilterRoller classmethod Shorthand for cls . filter_from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and filter_from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def filter_from_values_iterable ( cls , predicate : _PredicateT , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``filter_from_sources_iterable``][dyce.r.R.filter_from_sources_iterable] methods. \"\"\" return cls . filter_from_sources_iterable ( predicate , ( cls . from_value ( value ) for value in values ), annotation = annotation , ) from_sources ( * sources : _SourceT , * , annotation : Any = '' ) -> PoolRoller classmethod Shorthand for cls . from_sources_iterable ( rs , annotation = annotation ) . See the from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def from_sources ( cls , * sources : _SourceT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable(rs, annotation=annotation)``. See the [``from_sources_iterable`` method][dyce.r.R.from_sources_iterable]. \"\"\" return cls . from_sources_iterable ( sources , annotation = annotation ) from_sources_iterable ( sources : Iterable [ _SourceT ], annotation : Any = '' ) -> PoolRoller classmethod Creates and returns a roller for \u201cpooling\u201d zero or more sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> r_pool = R . from_sources_iterable ( R . from_value ( h ) for h in ( H (( 1 , 2 )), H (( 3 , 4 )), H (( 5 , 6 )))) >>> roll = r_pool . roll () >>> tuple ( roll . outcomes ()) ( 2 , 4 , 6 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), RollOutcome ( value = 6 , sources = (), ), ), source_rolls =... , ) Source code in dyce/r.py @classmethod @beartype def from_sources_iterable ( cls , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Creates and returns a roller for \u201cpooling\u201d zero or more *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056341) -- END MONKEY PATCH --> ``` python >>> r_pool = R.from_sources_iterable(R.from_value(h) for h in (H((1, 2)), H((3, 4)), H((5, 6)))) >>> roll = r_pool.roll() >>> tuple(roll.outcomes()) (2, 4, 6) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=4, sources=(), ), RollOutcome( value=6, sources=(), ), ), source_rolls=..., ) ``` \"\"\" return PoolRoller ( sources , annotation = annotation ) from_value ( value : _ValueT , annotation : Any = '' ) -> ValueRoller classmethod Creates and returns a ValueRoller from value . 1 2 >>> R . from_value ( 6 ) ValueRoller ( value = 6 , annotation = '' ) 1 2 >>> R . from_value ( H ( 6 )) ValueRoller ( value = H ( 6 ), annotation = '' ) 1 2 >>> R . from_value ( P ( 6 , 6 )) ValueRoller ( value = P ( 6 , 6 ), annotation = '' ) Source code in dyce/r.py @classmethod @beartype def from_value ( cls , value : _ValueT , annotation : Any = \"\" , ) -> ValueRoller : r \"\"\" Creates and returns a [``ValueRoller``][dyce.r.ValueRoller] from *value*. ``` python >>> R.from_value(6) ValueRoller(value=6, annotation='') ``` ``` python >>> R.from_value(H(6)) ValueRoller(value=H(6), annotation='') ``` ``` python >>> R.from_value(P(6, 6)) ValueRoller(value=P(6, 6), annotation='') ``` \"\"\" return ValueRoller ( value , annotation = annotation ) from_values ( * values : _ValueT , * , annotation : Any = '' ) -> PoolRoller classmethod Shorthand for cls . from_values_iterable ( values , annotation = annotation ) . See the from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def from_values ( cls , * values : _ValueT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_values_iterable(values, annotation=annotation)``. See the [``from_values_iterable`` method][dyce.r.R.from_values_iterable]. \"\"\" return cls . from_values_iterable ( values , annotation = annotation ) from_values_iterable ( values : Iterable [ _ValueT ], annotation : Any = '' ) -> PoolRoller classmethod Shorthand for cls . from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def from_values_iterable ( cls , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``from_sources_iterable``][dyce.r.R.from_sources_iterable] methods. \"\"\" return cls . from_sources_iterable ( ( cls . from_value ( value ) for value in values ), annotation = annotation , ) ge ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . ge ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ge ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ge(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ge ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ge ( right_operand ) return self . map ( _ge , other ) gt ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . gt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def gt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.gt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _gt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . gt ( right_operand ) return self . map ( _gt , other ) is_even ( self ) -> UnarySumOpRoller Shorthand for: self . umap ( lambda operand : operand . is_even ()) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_even())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_even ( operand : RollOutcome ) -> RollOutcome : return operand . is_even () return self . umap ( _is_even ) is_odd ( self ) -> UnarySumOpRoller Shorthand for: self . umap ( lambda operand : operand . is_odd ()) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_odd())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_odd ( operand : RollOutcome ) -> RollOutcome : return operand . is_odd () return self . umap ( _is_odd ) le ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . le ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def le ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.le(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _le ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . le ( right_operand ) return self . map ( _le , other ) lt ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . lt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def lt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.lt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _lt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . lt ( right_operand ) return self . map ( _lt , other ) map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = '' ) -> BinarySumOpRoller Creates and returns a BinarySumOpRoller for applying bin_op to this roller and right_operand as its sources. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . map ( operator . __pow__ , 2 ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = H ( 6 ), annotation = '' ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) >>> r_bin_op == R . from_value ( H ( 6 )) ** 2 True Source code in dyce/r.py @beartype def map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Creates and returns a [``BinarySumOpRoller``][dyce.r.BinarySumOpRoller] for applying *bin_op* to this roller and *right_operand* as its sources. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).map(operator.__pow__, 2) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=H(6), annotation=''), right_source=ValueRoller(value=2, annotation=''), annotation='', ) >>> r_bin_op == R.from_value(H(6)) ** 2 True ``` \"\"\" if isinstance ( right_operand , RealLike ): right_operand = ValueRoller ( right_operand ) if isinstance ( right_operand , ( R , RollOutcome )): return BinarySumOpRoller ( bin_op , self , right_operand , annotation = annotation ) else : raise NotImplementedError ne ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . ne ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ne ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ne(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ne ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ne ( right_operand ) return self . map ( _ne , other ) rmap ( self , left_operand : Union [ RealLike , 'RollOutcome' ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = '' ) -> BinarySumOpRoller Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . rmap ( 2 , operator . __pow__ ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = 2 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_bin_op == 2 ** R . from_value ( H ( 6 )) True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : Union [ RealLike , \"RollOutcome\" ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Analogous to the [``map`` method][dyce.r.R.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).rmap(2, operator.__pow__) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=2, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_bin_op == 2 ** R.from_value(H(6)) True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.R.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return BinarySumOpRoller ( bin_op , ValueRoller ( left_operand ), self , annotation = annotation ) elif isinstance ( left_operand , RollOutcome ): return BinarySumOpRoller ( bin_op , left_operand , self , annotation = annotation ) else : raise NotImplementedError roll ( self ) -> Roll Sub-classes should implement this method to return a new Roll object taking into account any sources . Note Implementors guarantee that all RollOutcome s in the returned Roll must be associated with a roll, including all roll outcomes\u2019 sources . Tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of None with the excluded roll outcome as its source. The RollOutcome.euthanize convenience method is provided for this purpose. See the section on \u201c Dropping dice from prior rolls \u2026 \u201d as well as the note in Roll.__init__ for additional color. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 >>> from itertools import chain >>> class AntonChigurhRoller ( R ): ... h_coin_toss = H (( 0 , 1 )) ... def roll ( self ) -> Roll : ... source_rolls = list ( self . source_rolls ()) ... def _roll_outcomes_gen (): ... for roll_outcome in chain . from_iterable ( source_rolls ): ... if roll_outcome . value is None : ... # Omit those already deceased ... continue ... elif self . h_coin_toss . roll (): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else : ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome . euthanize () ... return Roll ( self , roll_outcomes = _roll_outcomes_gen (), source_rolls = source_rolls ) >>> ac_r = AntonChigurhRoller ( sources = ( R . from_value ( 1 ), R . from_value ( 2 ), R . from_value ( 3 ))) >>> ac_r . roll () Roll ( r = AntonChigurhRoller ( sources = ( ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 2 , annotation = '' ), ValueRoller ( value = 3 , annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = 1 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 2 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Source code in dyce/r.py @abstractmethod def roll ( self ) -> Roll : r \"\"\" Sub-classes should implement this method to return a new [``Roll`` object][dyce.r.Roll] taking into account any [sources][dyce.r.R.sources]. !!! note Implementors guarantee that all [``RollOutcome``][dyce.r.RollOutcome]s in the returned [``Roll``][dyce.r.Roll] *must* be associated with a roll, *including all roll outcomes\u2019 [``sources``][dyce.r.RollOutcome.sources]*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633403927) -- END MONKEY PATCH --> !!! tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of ``#!python None`` with the excluded roll outcome as its source. The [``RollOutcome.euthanize``][dyce.r.RollOutcome.euthanize] convenience method is provided for this purpose. See the section on \u201c[Dropping dice from prior rolls \u2026](rollin.md#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8)\u201d as well as the note in [``Roll.__init__``][dyce.r.Roll.__init__] for additional color. ``` python >>> from itertools import chain >>> class AntonChigurhRoller(R): ... h_coin_toss = H((0, 1)) ... def roll(self) -> Roll: ... source_rolls = list(self.source_rolls()) ... def _roll_outcomes_gen(): ... for roll_outcome in chain.from_iterable(source_rolls): ... if roll_outcome.value is None: ... # Omit those already deceased ... continue ... elif self.h_coin_toss.roll(): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else: ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome.euthanize() ... return Roll(self, roll_outcomes=_roll_outcomes_gen(), source_rolls=source_rolls) >>> ac_r = AntonChigurhRoller(sources=(R.from_value(1), R.from_value(2), R.from_value(3))) >>> ac_r.roll() Roll( r=AntonChigurhRoller( sources=( ValueRoller(value=1, annotation=''), ValueRoller(value=2, annotation=''), ValueRoller(value=3, annotation=''), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=1, annotation=''), roll_outcomes=( RollOutcome( value=1, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=2, annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` \"\"\" ... select ( self , * which : _GetItemT , * , annotation : Any = '' ) -> SelectionRoller Shorthand for self . select_iterable ( which , annotation = annotation ) . See the select_iterable method . Source code in dyce/r.py @beartype def select ( self , * which : _GetItemT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python self.select_iterable(which, annotation=annotation)``. See the [``select_iterable`` method][dyce.r.R.select_iterable]. \"\"\" return self . select_iterable ( which , annotation = annotation ) select_from_sources ( which : Iterable [ _GetItemT ], * sources : _SourceT , * , annotation : Any = '' ) -> SelectionRoller classmethod Shorthand for cls . select_from_sources_iterable ( which , sources , annotation = annotation ) . See the select_from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_sources ( cls , which : Iterable [ _GetItemT ], * sources : _SourceT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable(which, sources, annotation=annotation)``. See the [``select_from_sources_iterable`` method][dyce.r.R.select_from_sources_iterable]. \"\"\" return cls . select_from_sources_iterable ( which , sources , annotation = annotation ) select_from_sources_iterable ( which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = '' ) -> SelectionRoller classmethod Creates and returns a SelectionRoller for applying selection which to sorted outcomes from sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_select = R . select_from_sources_iterable ( ... ( 0 , - 1 , slice ( 3 , 6 ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), ... ( R . from_value ( i ) for i in ( 5 , 4 , 6 , 3 , 7 , 2 , 8 , 1 , 9 , 0 )), ... ) ; r_select SelectionRoller ( which = ( 0 , - 1 , slice ( 3 , 6 , None ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), sources = ( ValueRoller ( value = 5 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ... , ValueRoller ( value = 9 , annotation = '' ), ValueRoller ( value = 0 , annotation = '' ), ), annotation = '' , ) >>> tuple ( r_select . roll () . outcomes ()) ( 0 , 9 , 3 , 4 , 5 , 6 , 5 , 4 , 9 , 0 ) Source code in dyce/r.py @classmethod @beartype def select_from_sources_iterable ( cls , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Creates and returns a [``SelectionRoller``][dyce.r.SelectionRoller] for applying selection *which* to sorted outcomes from *sources*. ``` python >>> r_select = R.select_from_sources_iterable( ... (0, -1, slice(3, 6), slice(6, 3, -1), -1, 0), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_select SelectionRoller( which=(0, -1, slice(3, 6, None), slice(6, 3, -1), -1, 0), sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_select.roll().outcomes()) (0, 9, 3, 4, 5, 6, 5, 4, 9, 0) ``` \"\"\" return SelectionRoller ( which , sources , annotation = annotation ) select_from_values ( which : Iterable [ _GetItemT ], * values : _ValueT , * , annotation : Any = '' ) -> SelectionRoller classmethod Shorthand for cls . select_from_values_iterable ( which , values , annotation = annotation ) . See the select_from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_values ( cls , which : Iterable [ _GetItemT ], * values : _ValueT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_values_iterable(which, values, annotation=annotation)``. See the [``select_from_values_iterable`` method][dyce.r.R.select_from_values_iterable]. \"\"\" return cls . select_from_values_iterable ( which , values , annotation = annotation ) select_from_values_iterable ( which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = '' ) -> SelectionRoller classmethod Shorthand for cls . select_from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and select_from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def select_from_values_iterable ( cls , which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``select_from_sources_iterable``][dyce.r.R.select_from_sources_iterable] methods. \"\"\" return cls . select_from_sources_iterable ( which , ( cls . from_value ( value ) for value in values ), annotation = annotation , ) select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = '' ) -> SelectionRoller Shorthand for type ( self ) . select_from_sources ( which , self , annotation = annotation ) . See the select_from_sources method . Source code in dyce/r.py @beartype def select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python type(self).select_from_sources(which, self, annotation=annotation)``. See the [``select_from_sources`` method][dyce.r.R.select_from_sources]. \"\"\" return type ( self ) . select_from_sources ( which , self , annotation = annotation ) source_rolls ( self ) -> Iterator [ 'Roll' ] Generates new rolls from all sources . Source code in dyce/r.py @beartype def source_rolls ( self ) -> Iterator [ \"Roll\" ]: r \"\"\" Generates new rolls from all [``sources``][dyce.r.R.sources]. \"\"\" for source in self . sources : yield source . roll () umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = '' ) -> UnarySumOpRoller Creates and returns a UnarySumOpRoller roller for applying un_op to this roller as its source. 1 2 3 4 5 6 7 8 9 >>> import operator >>> r_un_op = R . from_value ( H ( 6 )) . umap ( operator . __neg__ ) ; r_un_op UnarySumOpRoller ( un_op =< built - in function neg > , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_un_op == - R . from_value ( H ( 6 )) True Source code in dyce/r.py @beartype def umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = \"\" , ) -> UnarySumOpRoller : r \"\"\" Creates and returns a [``UnarySumOpRoller``][dyce.r.UnarySumOpRoller] roller for applying *un_op* to this roller as its source. ``` python >>> import operator >>> r_un_op = R.from_value(H(6)).umap(operator.__neg__) ; r_un_op UnarySumOpRoller( un_op=<built-in function neg>, source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_un_op == -R.from_value(H(6)) True ``` \"\"\" return UnarySumOpRoller ( un_op , self , annotation = annotation ) RepeatRoller ( R ) A roller to implement the __matmul__ operator. It is akin to a homogeneous PoolRoller containing n identical source s. 1 2 3 4 5 6 7 8 9 10 >>> d20 = H ( 20 ) >>> r_d20 = R . from_value ( d20 ) >>> r_d20_100 = 100 @r_d20 ; r_d20_100 RepeatRoller ( n = 100 , source = ValueRoller ( value = H ( 20 ), annotation = '' ), annotation = '' , ) >>> all ( outcome in d20 for outcome in r_d20_100 . roll () . outcomes ()) True Source code in dyce/r.py class RepeatRoller ( R ): r \"\"\" A [roller][dyce.r.R] to implement the ``#!python __matmul__`` operator. It is akin to a homogeneous [``PoolRoller``][dyce.r.PoolRoller] containing *n* identical *source*s. ``` python >>> d20 = H(20) >>> r_d20 = R.from_value(d20) >>> r_d20_100 = 100@r_d20 ; r_d20_100 RepeatRoller( n=100, source=ValueRoller(value=H(20), annotation=''), annotation='', ) >>> all(outcome in d20 for outcome in r_d20_100.roll().outcomes()) True ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_n\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , n : SupportsInt , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _n = as_int ( n ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( n= { self . n !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . n == other . n @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls : List [ Roll ] = [] for _ in range ( self . n ): source_rolls . extend ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def n ( self ) -> int : r \"\"\" The number of times to \u201crepeat\u201d the roller\u2019s sole source. \"\"\" return self . _n __slots__ : Union [ str , Iterable [ str ]] special n : int property readonly The number of times to \u201crepeat\u201d the roller\u2019s sole source. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . n == other . n __init__ ( self , n : SupportsInt , source : _SourceT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , n : SupportsInt , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _n = as_int ( n ) __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( n= { self . n !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls : List [ Roll ] = [] for _ in range ( self . n ): source_rolls . extend ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , ) Roll ( Sequence , Generic ) Experimental This class should be considered experimental and may change or disappear in future versions. An immutable roll result (or \u201croll\u201d for short). More specifically, the result of calling the R.roll method . Rolls are sequences of RollOutcome objects that can be assembled into trees. Source code in dyce/r.py class Roll ( Sequence [ RollOutcome ]): r \"\"\" !!! warning \"Experimental\" This class should be considered experimental and may change or disappear in future versions. An immutable roll result (or \u201croll\u201d for short). More specifically, the result of calling the [``R.roll`` method][dyce.r.R.roll]. Rolls are sequences of [``RollOutcome`` objects][dyce.r.RollOutcome] that can be assembled into trees. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_r\" , \"_roll_outcomes\" , \"_source_rolls\" ) # ---- Initializer ----------------------------------------------------------------- @experimental @beartype def __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ \"Roll\" ] = (), ): r \"\"\" Initializer. This initializer will associate each of *roll_outcomes* with the newly constructed roll if they do not already have a [``source_roll``][dyce.r.RollOutcome.source_roll]. ``` python >>> r_4 = ValueRoller(4) >>> roll = r_4.roll() >>> new_roll = Roll(r_4, roll) ; new_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) >>> roll[0].source_roll == roll True >>> roll[0].r == r_4 True ``` !!! note Technically, this violates the immutability of roll outcomes. ``dyce`` does not generally contemplate creation of rolls or roll outcomes outside the womb of [``R.roll``][dyce.r.R.roll] implementations. [``Roll``][dyce.r.Roll] and [``RollOutcome``][dyce.r.RollOutcome] objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the [``RollOutcome.source_roll`` property][dyce.r.RollOutcome.source_roll]. \"\"\" super () . __init__ () self . _r = r self . _roll_outcomes = tuple ( roll_outcomes ) self . _source_rolls = tuple ( source_rolls ) for roll_outcome in self . _roll_outcomes : if roll_outcome . _roll is None : roll_outcome . _roll = self # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( r= { indent ( repr ( self . r ), \" \" ) . strip () } , roll_outcomes=( { _seq_repr ( self ) } ), source_rolls=( { _seq_repr ( self . source_rolls ) } ), )\"\"\" @beartype def __len__ ( self ) -> int : return len ( self . _roll_outcomes ) @overload def __getitem__ ( self , key : SupportsIndex ) -> RollOutcome : ... @overload def __getitem__ ( self , key : slice ) -> Tuple [ RollOutcome , ... ]: ... @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( # type: ignore [override] self , key : _GetItemT , ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]]: if isinstance ( key , slice ): return self . _roll_outcomes [ key ] else : return self . _roll_outcomes [ __index__ ( key )] @beartype def __iter__ ( self ) -> Iterator [ RollOutcome ]: return iter ( self . _roll_outcomes ) # ---- Properties ------------------------------------------------------------------ @property def annotation ( self ) -> Any : r \"\"\" Shorthand for ``#!python self.r.annotation``. See the [``R.annotation`` property][dyce.r.R.annotation]. \"\"\" return self . r . annotation @property def r ( self ) -> R : r \"\"\" The roller that generated the roll. \"\"\" return self . _r @property def source_rolls ( self ) -> Tuple [ Roll , ... ]: r \"\"\" The source rolls from which this roll was generated. \"\"\" return self . _source_rolls # ---- Methods --------------------------------------------------------------------- @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> Roll : r \"\"\" Shorthand for ``#!python Roll(self.r, (roll_outcome.adopt(sources, coalesce_mode) for roll_outcome in self), self.source_rolls)``. \"\"\" return type ( self )( self . r , ( roll_outcome . adopt ( sources , coalesce_mode ) for roll_outcome in self ), self . source_rolls , ) @beartype def outcomes ( self ) -> Iterator [ RealLike ]: r \"\"\" Shorthand for ``#!python (roll_outcome.value for roll_outcome in self if roll_outcome.value is not None)``. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056410) -- END MONKEY PATCH --> !!! info Unlike [``H.roll``][dyce.h.H.roll] and [``P.roll``][dyce.p.P.roll], these outcomes are *not* sorted. Instead, they retain the ordering as passed to [``__init__``][dyce.r.Roll.__init__]. ``` python >>> r_3d6 = 3@R.from_value(H(6)) >>> r_3d6_neg = 3@-R.from_value(H(6)) >>> roll = R.from_sources(r_3d6, r_3d6_neg).roll() >>> tuple(roll.outcomes()) (1, 3, 1, -4, -6, -1) >>> len(roll) 6 ``` \"\"\" return ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) @beartype def total ( self ) -> RealLike : r \"\"\" Shorthand for ``#!python sum(self.outcomes())``. \"\"\" return sum ( self . outcomes ()) __slots__ : Union [ str , Iterable [ str ]] special annotation : Any property readonly Shorthand for self . r . annotation . See the R.annotation property . r : R property readonly The roller that generated the roll. source_rolls : Tuple [ Roll , ... ] property readonly The source rolls from which this roll was generated. __getitem__ ( self , key : _GetItemT ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]] special Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( # type: ignore [override] self , key : _GetItemT , ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]]: if isinstance ( key , slice ): return self . _roll_outcomes [ key ] else : return self . _roll_outcomes [ __index__ ( key )] __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ 'Roll' ] = ()) special Initializer. This initializer will associate each of roll_outcomes with the newly constructed roll if they do not already have a source_roll . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_4 = ValueRoller ( 4 ) >>> roll = r_4 . roll () >>> new_roll = Roll ( r_4 , roll ) ; new_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ) >>> roll [ 0 ] . source_roll == roll True >>> roll [ 0 ] . r == r_4 True Note Technically, this violates the immutability of roll outcomes. dyce does not generally contemplate creation of rolls or roll outcomes outside the womb of R.roll implementations. Roll and RollOutcome objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the RollOutcome.source_roll property . Source code in dyce/r.py @experimental @beartype def __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ \"Roll\" ] = (), ): r \"\"\" Initializer. This initializer will associate each of *roll_outcomes* with the newly constructed roll if they do not already have a [``source_roll``][dyce.r.RollOutcome.source_roll]. ``` python >>> r_4 = ValueRoller(4) >>> roll = r_4.roll() >>> new_roll = Roll(r_4, roll) ; new_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) >>> roll[0].source_roll == roll True >>> roll[0].r == r_4 True ``` !!! note Technically, this violates the immutability of roll outcomes. ``dyce`` does not generally contemplate creation of rolls or roll outcomes outside the womb of [``R.roll``][dyce.r.R.roll] implementations. [``Roll``][dyce.r.Roll] and [``RollOutcome``][dyce.r.RollOutcome] objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the [``RollOutcome.source_roll`` property][dyce.r.RollOutcome.source_roll]. \"\"\" super () . __init__ () self . _r = r self . _roll_outcomes = tuple ( roll_outcomes ) self . _source_rolls = tuple ( source_rolls ) for roll_outcome in self . _roll_outcomes : if roll_outcome . _roll is None : roll_outcome . _roll = self __iter__ ( self ) -> Iterator [ RollOutcome ] special Source code in dyce/r.py @beartype def __iter__ ( self ) -> Iterator [ RollOutcome ]: return iter ( self . _roll_outcomes ) __len__ ( self ) -> int special Source code in dyce/r.py @beartype def __len__ ( self ) -> int : return len ( self . _roll_outcomes ) __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( r= { indent ( repr ( self . r ), \" \" ) . strip () } , roll_outcomes=( { _seq_repr ( self ) } ), source_rolls=( { _seq_repr ( self . source_rolls ) } ), )\"\"\" adopt ( self , sources : Iterable [ 'RollOutcome' ] = (), coalesce_mode : CoalesceMode = < CoalesceMode . REPLACE : 1 > ) -> Roll Shorthand for Roll ( self . r , ( roll_outcome . adopt ( sources , coalesce_mode ) for roll_outcome in self ), self . source_rolls ) . Source code in dyce/r.py @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> Roll : r \"\"\" Shorthand for ``#!python Roll(self.r, (roll_outcome.adopt(sources, coalesce_mode) for roll_outcome in self), self.source_rolls)``. \"\"\" return type ( self )( self . r , ( roll_outcome . adopt ( sources , coalesce_mode ) for roll_outcome in self ), self . source_rolls , ) outcomes ( self ) -> Iterator [ RealLike ] Shorthand for ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) . Info Unlike H.roll and P.roll , these outcomes are not sorted. Instead, they retain the ordering as passed to __init__ . 1 2 3 4 5 6 7 >>> r_3d6 = 3 @R . from_value ( H ( 6 )) >>> r_3d6_neg = 3 @- R . from_value ( H ( 6 )) >>> roll = R . from_sources ( r_3d6 , r_3d6_neg ) . roll () >>> tuple ( roll . outcomes ()) ( 1 , 3 , 1 , - 4 , - 6 , - 1 ) >>> len ( roll ) 6 Source code in dyce/r.py @beartype def outcomes ( self ) -> Iterator [ RealLike ]: r \"\"\" Shorthand for ``#!python (roll_outcome.value for roll_outcome in self if roll_outcome.value is not None)``. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056410) -- END MONKEY PATCH --> !!! info Unlike [``H.roll``][dyce.h.H.roll] and [``P.roll``][dyce.p.P.roll], these outcomes are *not* sorted. Instead, they retain the ordering as passed to [``__init__``][dyce.r.Roll.__init__]. ``` python >>> r_3d6 = 3@R.from_value(H(6)) >>> r_3d6_neg = 3@-R.from_value(H(6)) >>> roll = R.from_sources(r_3d6, r_3d6_neg).roll() >>> tuple(roll.outcomes()) (1, 3, 1, -4, -6, -1) >>> len(roll) 6 ``` \"\"\" return ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) total ( self ) -> RealLike Shorthand for sum ( self . outcomes ()) . Source code in dyce/r.py @beartype def total ( self ) -> RealLike : r \"\"\" Shorthand for ``#!python sum(self.outcomes())``. \"\"\" return sum ( self . outcomes ()) RollOutcome Experimental This class should be considered experimental and may change or disappear in future versions. A single, ( mostly ) immutable outcome generated by a roll. Source code in dyce/r.py class RollOutcome : r \"\"\" !!! warning \"Experimental\" This class should be considered experimental and may change or disappear in future versions. A single, ([mostly][dyce.r.Roll.__init__]) immutable outcome generated by a roll. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_roll\" , \"_sources\" , \"_value\" ) # ---- Initializer ----------------------------------------------------------------- @experimental @beartype def __init__ ( self , value : Optional [ RealLike ], sources : Iterable [ \"RollOutcome\" ] = (), ): r \"Initializer.\" super () . __init__ () self . _value = value self . _sources = tuple ( sources ) self . _roll : Optional [ Roll ] = None if self . _value is None and not self . _sources : raise ValueError ( \"value can only be None if sources is non-empty\" ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( value= { repr ( self . value ) } , sources=( { _seq_repr ( self . sources ) } ), )\"\"\" @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __lt__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __lt__ ( self . value , other . value )) else : return NotImplemented @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __le__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __le__ ( self . value , other . value )) else : return NotImplemented @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __eq__ ( self . value , other . value )) else : return super () . __eq__ ( other ) @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ne__ ( self . value , other . value )) else : return super () . __ne__ ( other ) @beartype def __gt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __gt__ ( self . value , other . value )) else : return NotImplemented @beartype def __ge__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ge__ ( self . value , other . value )) else : return NotImplemented @beartype def __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented @beartype def __radd__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented @beartype def __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented @beartype def __rsub__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented @beartype def __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmul__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented @beartype def __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rtruediv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented @beartype def __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rfloordiv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented @beartype def __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmod__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented @beartype def __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented @beartype def __rpow__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented @beartype def __and__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __rand__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __xor__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __rxor__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __or__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __ror__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __neg__ ( self ) -> RollOutcome : return self . umap ( __neg__ ) @beartype def __pos__ ( self ) -> RollOutcome : return self . umap ( __pos__ ) @beartype def __abs__ ( self ) -> RollOutcome : return self . umap ( __abs__ ) @beartype def __invert__ ( self ) -> RollOutcome : return self . umap ( __invert__ ) # ---- Properties ------------------------------------------------------------------ @property def annotation ( self ) -> Any : r \"\"\" Shorthand for ``#!python self.source_roll.annotation``. See the [``source_roll``][dyce.r.RollOutcome.source_roll] and [``Roll.annotation``][dyce.r.Roll.annotation] properties. \"\"\" return self . source_roll . annotation @property def r ( self ) -> R : r \"\"\" Shorthand for ``#!python self.source_roll.r``. See the [``source_roll``][dyce.r.RollOutcome.source_roll] and [``Roll.r``][dyce.r.Roll.r] properties. \"\"\" return self . source_roll . r @property def source_roll ( self ) -> Roll : r \"\"\" Returns the roll if one has been associated with this roll outcome. Usually that happens by submitting the roll outcome to the [``Roll.__init__`` method][dyce.r.Roll.__init__] inside a [``R.roll`` method][dyce.r.R.roll] implementation. Accessing this property before the roll outcome has been associated with a roll is considered a programming error. ``` python >>> ro = RollOutcome(4) >>> ro.source_roll Traceback (most recent call last): ... AssertionError: RollOutcome.source_roll accessed before associating the roll outcome with a roll (usually via Roll.__init__) assert None is not None >>> roll = Roll(R.from_value(4), roll_outcomes=(ro,)) >>> ro.source_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) ``` \"\"\" assert ( self . _roll is not None ), \"RollOutcome.source_roll accessed before associating the roll outcome with a roll (usually via Roll.__init__)\" return self . _roll @property def sources ( self ) -> Tuple [ RollOutcome , ... ]: r \"\"\" The source roll outcomes from which this roll outcome was generated. \"\"\" return self . _sources @property def value ( self ) -> Optional [ RealLike ]: r \"\"\" The outcome value. A value of ``#!python None`` is used to signal that a source\u2019s roll outcome was excluded by the roller. \"\"\" return self . _value # ---- Methods --------------------------------------------------------------------- @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT , ) -> RollOutcome : r \"\"\" Applies *bin_op* to the value of this roll outcome as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.map(operator.__pow__, 10) RollOutcome( value=1024, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.map(operator.__pow__, 10) == two ** 10 True ``` \"\"\" if isinstance ( right_operand , RollOutcome ): sources : Tuple [ RollOutcome , ... ] = ( self , right_operand ) right_operand_value : Optional [ RealLike ] = right_operand . value else : sources = ( self ,) right_operand_value = right_operand if isinstance ( right_operand_value , RealLike ): return type ( self )( bin_op ( self . value , right_operand_value ), sources ) else : raise NotImplementedError @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> RollOutcome : r \"\"\" Analogous to the [``map`` method][dyce.r.RollOutcome.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.rmap(10, operator.__pow__) RollOutcome( value=100, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.rmap(10, operator.__pow__) == 10 ** two True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.RollOutcome.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return type ( self )( bin_op ( left_operand , self . value ), sources = ( self ,)) else : raise NotImplementedError @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> RollOutcome : r \"\"\" Applies *un_op* to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two_neg = RollOutcome(-2) >>> two_neg.umap(operator.__neg__) RollOutcome( value=2, sources=( RollOutcome( value=-2, sources=(), ), ), ) >>> two_neg.umap(operator.__neg__) == -two_neg True ``` \"\"\" return type ( self )( un_op ( self . value ), sources = ( self ,)) @beartype def lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __lt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __lt__ ( self . value , other )), sources = ( self ,)) @beartype def le ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __le__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __le__ ( self . value , other )), sources = ( self ,)) @beartype def eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __eq__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __eq__ ( self . value , other )), sources = ( self ,)) @beartype def ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ne__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ne__ ( self . value , other )), sources = ( self ,)) @beartype def gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __gt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __gt__ ( self . value , other )), sources = ( self ,)) @beartype def ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ge__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ge__ ( self . value , other )), sources = ( self ,)) @beartype def is_even ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_even ) @beartype def is_odd ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_odd ) @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> RollOutcome : r \"\"\" Creates and returns a new roll outcome identical to this roll outcome, but with *sources* replacing or appended to this roll outcome\u2019s sources in accordance with *coalesce_mode*. ``` python >>> from dyce.r import CoalesceMode >>> orig = RollOutcome(1, sources=(RollOutcome(2),)) ; orig RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.REPLACE) RollOutcome( value=1, sources=( RollOutcome( value=3, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.APPEND) RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), ) ``` \"\"\" if coalesce_mode is CoalesceMode . REPLACE : adopted_sources = sources elif coalesce_mode is CoalesceMode . APPEND : adopted_sources = chain ( self . sources , sources ) else : assert False , f \"unrecognized substitution mode { self . coalesce_mode !r} \" adopted_roll_outcome = type ( self )( self . value , adopted_sources ) adopted_roll_outcome . _roll = self . _roll return adopted_roll_outcome @beartype def euthanize ( self ) -> RollOutcome : r \"\"\" Shorthand for ``#!python self.umap(lambda operand: None)``. ``` python >>> two = RollOutcome(2) >>> two.euthanize() RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ) ``` See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" def _euthanize ( operand : Optional [ RealLike ]) -> Optional [ RealLike ]: return None return self . umap ( _euthanize ) __slots__ : Union [ str , Iterable [ str ]] special annotation : Any property readonly Shorthand for self . source_roll . annotation . See the source_roll and Roll.annotation properties. r : R property readonly Shorthand for self . source_roll . r . See the source_roll and Roll.r properties. source_roll : Roll property readonly Returns the roll if one has been associated with this roll outcome. Usually that happens by submitting the roll outcome to the Roll.__init__ method inside a R.roll method implementation. Accessing this property before the roll outcome has been associated with a roll is considered a programming error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> ro = RollOutcome ( 4 ) >>> ro . source_roll Traceback ( most recent call last ): ... AssertionError : RollOutcome . source_roll accessed before associating the roll outcome with a roll ( usually via Roll . __init__ ) assert None is not None >>> roll = Roll ( R . from_value ( 4 ), roll_outcomes = ( ro ,)) >>> ro . source_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ) sources : Tuple [ RollOutcome , ... ] property readonly The source roll outcomes from which this roll outcome was generated. value : Optional [ RealLike ] property readonly The outcome value. A value of None is used to signal that a source\u2019s roll outcome was excluded by the roller. __abs__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __abs__ ( self ) -> RollOutcome : return self . umap ( __abs__ ) __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented __and__ ( self , other : Union [ 'RollOutcome' , SupportsInt ]) -> RollOutcome special Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __eq__ ( self . value , other . value )) else : return super () . __eq__ ( other ) __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented __ge__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype def __ge__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ge__ ( self . value , other . value )) else : return NotImplemented __gt__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype def __gt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __gt__ ( self . value , other . value )) else : return NotImplemented __init__ ( self , value : Optional [ RealLike ], sources : Iterable [ 'RollOutcome' ] = ()) special Initializer. Source code in dyce/r.py @experimental @beartype def __init__ ( self , value : Optional [ RealLike ], sources : Iterable [ \"RollOutcome\" ] = (), ): r \"Initializer.\" super () . __init__ () self . _value = value self . _sources = tuple ( sources ) self . _roll : Optional [ Roll ] = None if self . _value is None and not self . _sources : raise ValueError ( \"value can only be None if sources is non-empty\" ) __invert__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __invert__ ( self ) -> RollOutcome : return self . umap ( __invert__ ) __le__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __le__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __le__ ( self . value , other . value )) else : return NotImplemented __lt__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __lt__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __lt__ ( self . value , other . value )) else : return NotImplemented __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented __ne__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ne__ ( self . value , other . value )) else : return super () . __ne__ ( other ) __neg__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __neg__ ( self ) -> RollOutcome : return self . umap ( __neg__ ) __or__ ( self , other : Union [ 'RollOutcome' , SupportsInt ]) -> RollOutcome special Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __pos__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __pos__ ( self ) -> RollOutcome : return self . umap ( __pos__ ) __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented __radd__ ( self , other : RealLike ) -> RollOutcome special Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented __rand__ ( self , other : SupportsInt ) -> RollOutcome special Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( value= { repr ( self . value ) } , sources=( { _seq_repr ( self . sources ) } ), )\"\"\" __rfloordiv__ ( self , other : RealLike ) -> RollOutcome special Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented __rmod__ ( self , other : RealLike ) -> RollOutcome special Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented __rmul__ ( self , other : RealLike ) -> RollOutcome special Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented __ror__ ( self , other : SupportsInt ) -> RollOutcome special Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented __rpow__ ( self , other : RealLike ) -> RollOutcome special Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented __rsub__ ( self , other : RealLike ) -> RollOutcome special Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented __rtruediv__ ( self , other : RealLike ) -> RollOutcome special Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented __rxor__ ( self , other : SupportsInt ) -> RollOutcome special Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented __xor__ ( self , other : Union [ 'RollOutcome' , SupportsInt ]) -> RollOutcome special Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented adopt ( self , sources : Iterable [ 'RollOutcome' ] = (), coalesce_mode : CoalesceMode = < CoalesceMode . REPLACE : 1 > ) -> RollOutcome Creates and returns a new roll outcome identical to this roll outcome, but with sources replacing or appended to this roll outcome\u2019s sources in accordance with coalesce_mode . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 >>> from dyce.r import CoalesceMode >>> orig = RollOutcome ( 1 , sources = ( RollOutcome ( 2 ),)) ; orig RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> orig . adopt (( RollOutcome ( 3 ),), coalesce_mode = CoalesceMode . REPLACE ) RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 3 , sources = (), ), ), ) >>> orig . adopt (( RollOutcome ( 3 ),), coalesce_mode = CoalesceMode . APPEND ) RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), ) Source code in dyce/r.py @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> RollOutcome : r \"\"\" Creates and returns a new roll outcome identical to this roll outcome, but with *sources* replacing or appended to this roll outcome\u2019s sources in accordance with *coalesce_mode*. ``` python >>> from dyce.r import CoalesceMode >>> orig = RollOutcome(1, sources=(RollOutcome(2),)) ; orig RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.REPLACE) RollOutcome( value=1, sources=( RollOutcome( value=3, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.APPEND) RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), ) ``` \"\"\" if coalesce_mode is CoalesceMode . REPLACE : adopted_sources = sources elif coalesce_mode is CoalesceMode . APPEND : adopted_sources = chain ( self . sources , sources ) else : assert False , f \"unrecognized substitution mode { self . coalesce_mode !r} \" adopted_roll_outcome = type ( self )( self . value , adopted_sources ) adopted_roll_outcome . _roll = self . _roll return adopted_roll_outcome eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __eq__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __eq__ ( self . value , other )), sources = ( self ,)) euthanize ( self ) -> RollOutcome Shorthand for self . umap ( lambda operand : None ) . 1 2 3 4 5 6 7 8 9 10 11 >>> two = RollOutcome ( 2 ) >>> two . euthanize () RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) See the umap method . Source code in dyce/r.py @beartype def euthanize ( self ) -> RollOutcome : r \"\"\" Shorthand for ``#!python self.umap(lambda operand: None)``. ``` python >>> two = RollOutcome(2) >>> two.euthanize() RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ) ``` See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" def _euthanize ( operand : Optional [ RealLike ]) -> Optional [ RealLike ]: return None return self . umap ( _euthanize ) ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ge__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ge__ ( self . value , other )), sources = ( self ,)) gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __gt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __gt__ ( self . value , other )), sources = ( self ,)) is_even ( self ) -> RollOutcome Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_even ) is_odd ( self ) -> RollOutcome Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_odd ) le ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def le ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __le__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __le__ ( self . value , other )), sources = ( self ,)) lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __lt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __lt__ ( self . value , other )), sources = ( self ,)) map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT ) -> RollOutcome Applies bin_op to the value of this roll outcome as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . map ( operator . __pow__ , 10 ) RollOutcome ( value = 1024 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . map ( operator . __pow__ , 10 ) == two ** 10 True Source code in dyce/r.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT , ) -> RollOutcome : r \"\"\" Applies *bin_op* to the value of this roll outcome as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.map(operator.__pow__, 10) RollOutcome( value=1024, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.map(operator.__pow__, 10) == two ** 10 True ``` \"\"\" if isinstance ( right_operand , RollOutcome ): sources : Tuple [ RollOutcome , ... ] = ( self , right_operand ) right_operand_value : Optional [ RealLike ] = right_operand . value else : sources = ( self ,) right_operand_value = right_operand if isinstance ( right_operand_value , RealLike ): return type ( self )( bin_op ( self . value , right_operand_value ), sources ) else : raise NotImplementedError ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ne__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ne__ ( self . value , other )), sources = ( self ,)) rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> RollOutcome Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . rmap ( 10 , operator . __pow__ ) RollOutcome ( value = 100 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . rmap ( 10 , operator . __pow__ ) == 10 ** two True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> RollOutcome : r \"\"\" Analogous to the [``map`` method][dyce.r.RollOutcome.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.rmap(10, operator.__pow__) RollOutcome( value=100, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.rmap(10, operator.__pow__) == 10 ** two True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.RollOutcome.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return type ( self )( bin_op ( left_operand , self . value ), sources = ( self ,)) else : raise NotImplementedError umap ( self , un_op : _UnaryOperatorT ) -> RollOutcome Applies un_op to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two_neg = RollOutcome ( - 2 ) >>> two_neg . umap ( operator . __neg__ ) RollOutcome ( value = 2 , sources = ( RollOutcome ( value =- 2 , sources = (), ), ), ) >>> two_neg . umap ( operator . __neg__ ) == - two_neg True Source code in dyce/r.py @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> RollOutcome : r \"\"\" Applies *un_op* to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two_neg = RollOutcome(-2) >>> two_neg.umap(operator.__neg__) RollOutcome( value=2, sources=( RollOutcome( value=-2, sources=(), ), ), ) >>> two_neg.umap(operator.__neg__) == -two_neg True ``` \"\"\" return type ( self )( un_op ( self . value ), sources = ( self ,)) RollWalkerVisitor Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each Roll object found. Source code in dyce/r.py class RollWalkerVisitor : r \"\"\" !!! warning \"Experimental\" This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with [``walk``][dyce.r.walk] called for each [``Roll`` object][dyce.r.Roll] found. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @abstractmethod def on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None : ... __slots__ : Union [ str , Iterable [ str ]] special on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None Source code in dyce/r.py @abstractmethod def on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None : ... RollerWalkerVisitor Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each R object found. Source code in dyce/r.py class RollerWalkerVisitor : r \"\"\" !!! warning \"Experimental\" This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with [``walk``][dyce.r.walk] called for each [``R`` object][dyce.r.R] found. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @abstractmethod def on_roller ( self , r : R , parents : Iterator [ R ]) -> None : ... __slots__ : Union [ str , Iterable [ str ]] special on_roller ( self , r : R , parents : Iterator [ R ]) -> None Source code in dyce/r.py @abstractmethod def on_roller ( self , r : R , parents : Iterator [ R ]) -> None : ... SelectionRoller ( R ) A roller for sorting outcomes from its sources and applying a selector which . Roll outcomes in created rolls are ordered according to the selections which . However, those selections are interpreted as indexes in a sorted view of the source\u2019s roll outcomes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 >>> r_values = R . from_values ( 10000 , 1 , 1000 , 10 , 100 ) >>> outcomes = tuple ( r_values . roll () . outcomes ()) ; outcomes ( 10000 , 1 , 1000 , 10 , 100 ) >>> sorted_outcomes = tuple ( sorted ( outcomes )) ; sorted_outcomes ( 1 , 10 , 100 , 1000 , 10000 ) >>> which = ( 3 , 1 , 3 , 2 ) >>> tuple ( sorted_outcomes [ i ] for i in which ) ( 1000 , 10 , 1000 , 100 ) >>> r_select = r_values . select_iterable ( which ) ; r_select SelectionRoller ( which = ( 3 , 1 , 3 , 2 ), sources = ( PoolRoller ( sources = ( ValueRoller ( value = 10000 , annotation = '' ), ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 1000 , annotation = '' ), ValueRoller ( value = 10 , annotation = '' ), ValueRoller ( value = 100 , annotation = '' ), ), annotation = '' , ), ), annotation = '' , ) >>> roll = r_select . roll () >>> tuple ( roll . outcomes ()) ( 1000 , 10 , 1000 , 100 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 10 , sources = (), ), RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 100 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 10000 , sources = (), ), ), ), ), source_rolls =... , ) Source code in dyce/r.py class SelectionRoller ( R ): r \"\"\" A [roller][dyce.r.R] for sorting outcomes from its *sources* and applying a selector *which*. Roll outcomes in created rolls are ordered according to the selections *which*. However, those selections are interpreted as indexes in a *sorted* view of the source\u2019s roll outcomes. ``` python >>> r_values = R.from_values(10000, 1, 1000, 10, 100) >>> outcomes = tuple(r_values.roll().outcomes()) ; outcomes (10000, 1, 1000, 10, 100) >>> sorted_outcomes = tuple(sorted(outcomes)) ; sorted_outcomes (1, 10, 100, 1000, 10000) >>> which = (3, 1, 3, 2) >>> tuple(sorted_outcomes[i] for i in which) (1000, 10, 1000, 100) >>> r_select = r_values.select_iterable(which) ; r_select SelectionRoller( which=(3, 1, 3, 2), sources=( PoolRoller( sources=( ValueRoller(value=10000, annotation=''), ValueRoller(value=1, annotation=''), ValueRoller(value=1000, annotation=''), ValueRoller(value=10, annotation=''), ValueRoller(value=100, annotation=''), ), annotation='', ), ), annotation='', ) >>> roll = r_select.roll() >>> tuple(roll.outcomes()) (1000, 10, 1000, 100) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=1000, sources=(), ), RollOutcome( value=10, sources=(), ), RollOutcome( value=1000, sources=(), ), RollOutcome( value=100, sources=(), ), RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=None, sources=( RollOutcome( value=10000, sources=(), ), ), ), ), source_rolls=..., ) ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_which\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _which = tuple ( which ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( which= { self . which !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . which == other . which @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) roll_outcomes = list ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ) roll_outcomes . sort ( key = attrgetter ( \"value\" )) all_indexes = tuple ( range ( len ( roll_outcomes ))) selected_indexes = tuple ( getitems ( all_indexes , self . which )) def _selected_roll_outcomes (): for selected_index in selected_indexes : selected_roll_outcome = roll_outcomes [ selected_index ] assert selected_roll_outcome . value is not None yield selected_roll_outcome for excluded_index in set ( all_indexes ) - set ( selected_indexes ): yield roll_outcomes [ excluded_index ] . euthanize () return Roll ( self , roll_outcomes = _selected_roll_outcomes (), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def which ( self ) -> Tuple [ _GetItemT , ... ]: r \"\"\" The selector this roller applies to the sorted outcomes of its sole source. \"\"\" return self . _which __slots__ : Union [ str , Iterable [ str ]] special which : Tuple [ _GetItemT , ... ] property readonly The selector this roller applies to the sorted outcomes of its sole source. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . which == other . which __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _which = tuple ( which ) __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( which= { self . which !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) roll_outcomes = list ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ) roll_outcomes . sort ( key = attrgetter ( \"value\" )) all_indexes = tuple ( range ( len ( roll_outcomes ))) selected_indexes = tuple ( getitems ( all_indexes , self . which )) def _selected_roll_outcomes (): for selected_index in selected_indexes : selected_roll_outcome = roll_outcomes [ selected_index ] assert selected_roll_outcome . value is not None yield selected_roll_outcome for excluded_index in set ( all_indexes ) - set ( selected_indexes ): yield roll_outcomes [ excluded_index ] . euthanize () return Roll ( self , roll_outcomes = _selected_roll_outcomes (), source_rolls = source_rolls , ) SubstitutionRoller ( R ) A roller for applying expansion_op to determine when to roll new values up to max_depth times for incorporation via coalesce_mode . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 >>> from dyce.r import SubstitutionRoller >>> r_d6 = R . from_value ( H ( 6 )) >>> r_replace = SubstitutionRoller ( ... lambda outcome : RollOutcome ( 0 ) if outcome . value is not None and outcome . value <= 3 else outcome , ... r_d6 , ... ) >>> ( 2 @r_replace ) . roll () Roll ( r = RepeatRoller ( n = 2 , source = SubstitutionRoller ( expansion_op =< function < lambda > at ...> , source = ValueRoller ( value = H ( 6 ), annotation = '' ), coalesce_mode =< CoalesceMode . REPLACE : 1 > , max_depth = 1 , annotation = '' , ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 0 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( ... ), ) See the section on \u201c Filtering and substitution \u201d more examples. Source code in dyce/r.py class SubstitutionRoller ( R ): r \"\"\" A [roller][dyce.r.R] for applying *expansion_op* to determine when to roll new values up to *max_depth* times for incorporation via *coalesce_mode*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1639580307) -- END MONKEY PATCH --> ``` python >>> from dyce.r import SubstitutionRoller >>> r_d6 = R.from_value(H(6)) >>> r_replace = SubstitutionRoller( ... lambda outcome: RollOutcome(0) if outcome.value is not None and outcome.value <= 3 else outcome, ... r_d6, ... ) >>> (2@r_replace).roll() Roll( r=RepeatRoller( n=2, source=SubstitutionRoller( expansion_op=<function <lambda> at ...>, source=ValueRoller(value=H(6), annotation=''), coalesce_mode=<CoalesceMode.REPLACE: 1>, max_depth=1, annotation='', ), annotation='', ), roll_outcomes=( RollOutcome( value=0, sources=( RollOutcome( value=2, sources=(), ), ), ), RollOutcome( value=5, sources=(), ), ), source_rolls=(...), ) ``` See the section on \u201c[Filtering and substitution](rollin.md#filtering-and-substitution)\u201d more examples. \"\"\" __slots__ : Tuple [ str , ... ] = ( \"_coalesce_mode\" , \"_expansion_op\" , \"_max_depth\" ) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , expansion_op : _ExpansionOperatorT , source : _SourceT , coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , max_depth : SupportsInt = 1 , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _expansion_op = expansion_op self . _coalesce_mode = coalesce_mode self . _max_depth = as_int ( max_depth ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( expansion_op= { self . expansion_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , coalesce_mode= { self . coalesce_mode !r} , max_depth= { self . max_depth !r} , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return ( super () . __eq__ ( other ) and _callable_cmp ( self . expansion_op , other . expansion_op ) and self . coalesce_mode == other . coalesce_mode and self . max_depth == other . max_depth ) @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" ( source_roll ,) = self . source_rolls () source_rolls : List [ Roll ] = [] def _expanded_roll_outcomes ( roll : Roll , depth : int = 0 , ) -> Iterator [ RollOutcome ]: source_rolls . append ( roll ) roll_outcomes = ( roll_outcome for roll_outcome in roll if roll_outcome . value is not None ) if depth >= self . max_depth : yield from roll_outcomes return for roll_outcome in roll_outcomes : expanded = self . expansion_op ( roll_outcome ) if isinstance ( expanded , RollOutcome ): if expanded is not roll_outcome : expanded = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield expanded elif isinstance ( expanded , Roll ): if self . coalesce_mode == CoalesceMode . REPLACE : yield roll_outcome . euthanize () elif self . coalesce_mode == CoalesceMode . APPEND : yield roll_outcome else : assert ( False ), f \"unrecognized substitution mode { self . coalesce_mode !r} \" expanded_roll = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield from _expanded_roll_outcomes ( expanded_roll , depth + 1 ) else : assert False , f \"unrecognized type for expanded value { expanded !r} \" return Roll ( self , roll_outcomes = _expanded_roll_outcomes ( source_roll ), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def max_depth ( self ) -> int : r \"\"\" The max number of times this roller will attempt to substitute an outcome satisfying its [``expansion_op``][dyce.r.SubstitutionRoller.expansion_op]. \"\"\" return self . _max_depth @property def expansion_op ( self ) -> _ExpansionOperatorT : r \"\"\" The expansion operator this roller applies to decide whether to substitute outcomes. \"\"\" return self . _expansion_op @property def coalesce_mode ( self ) -> CoalesceMode : r \"\"\" The coalesce mode this roller uses to incorporate substituted outcomes. \"\"\" return self . _coalesce_mode __slots__ : Tuple [ str , ... ] special coalesce_mode : CoalesceMode property readonly The coalesce mode this roller uses to incorporate substituted outcomes. expansion_op : _ExpansionOperatorT property readonly The expansion operator this roller applies to decide whether to substitute outcomes. max_depth : int property readonly The max number of times this roller will attempt to substitute an outcome satisfying its expansion_op . __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return ( super () . __eq__ ( other ) and _callable_cmp ( self . expansion_op , other . expansion_op ) and self . coalesce_mode == other . coalesce_mode and self . max_depth == other . max_depth ) __init__ ( self , expansion_op : _ExpansionOperatorT , source : _SourceT , coalesce_mode : CoalesceMode = < CoalesceMode . REPLACE : 1 > , max_depth : SupportsInt = 1 , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , expansion_op : _ExpansionOperatorT , source : _SourceT , coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , max_depth : SupportsInt = 1 , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _expansion_op = expansion_op self . _coalesce_mode = coalesce_mode self . _max_depth = as_int ( max_depth ) __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( expansion_op= { self . expansion_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , coalesce_mode= { self . coalesce_mode !r} , max_depth= { self . max_depth !r} , annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" ( source_roll ,) = self . source_rolls () source_rolls : List [ Roll ] = [] def _expanded_roll_outcomes ( roll : Roll , depth : int = 0 , ) -> Iterator [ RollOutcome ]: source_rolls . append ( roll ) roll_outcomes = ( roll_outcome for roll_outcome in roll if roll_outcome . value is not None ) if depth >= self . max_depth : yield from roll_outcomes return for roll_outcome in roll_outcomes : expanded = self . expansion_op ( roll_outcome ) if isinstance ( expanded , RollOutcome ): if expanded is not roll_outcome : expanded = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield expanded elif isinstance ( expanded , Roll ): if self . coalesce_mode == CoalesceMode . REPLACE : yield roll_outcome . euthanize () elif self . coalesce_mode == CoalesceMode . APPEND : yield roll_outcome else : assert ( False ), f \"unrecognized substitution mode { self . coalesce_mode !r} \" expanded_roll = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield from _expanded_roll_outcomes ( expanded_roll , depth + 1 ) else : assert False , f \"unrecognized type for expanded value { expanded !r} \" return Roll ( self , roll_outcomes = _expanded_roll_outcomes ( source_roll ), source_rolls = source_rolls , ) UnarySumOpRoller ( NarySumOpRoller ) An NarySumOpRoller for applying a unary operator un_op to the sum of all outcomes from its sole source . Source code in dyce/r.py class UnarySumOpRoller ( NarySumOpRoller ): r \"\"\" An [``NarySumOpRoller``][dyce.r.NarySumOpRoller] for applying a unary operator *un_op* to the sum of all outcomes from its sole *source*. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_un_op\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: ( operand ,) = roll_outcomes return un_op ( operand ) super () . __init__ ( op = _op , sources = ( source ,), annotation = annotation , ** kw ) self . _un_op = un_op # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( un_op= { self . un_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . un_op , other . un_op )) # ---- Properties ------------------------------------------------------------------ @property def un_op ( self ) -> _RollOutcomeUnaryOperatorT : r \"\"\" The operator this roller applies to its sources. \"\"\" return self . _un_op __slots__ : Union [ str , Iterable [ str ]] special un_op : _RollOutcomeUnaryOperatorT property readonly The operator this roller applies to its sources. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . un_op , other . un_op )) __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: ( operand ,) = roll_outcomes return un_op ( operand ) super () . __init__ ( op = _op , sources = ( source ,), annotation = annotation , ** kw ) self . _un_op = un_op __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( un_op= { self . un_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" ValueRoller ( R ) A roller whose roll outcomes are derived from scalars, H objects , P objects , RollOutcome objects , or even Roll objects , instead of other source rollers. Source code in dyce/r.py class ValueRoller ( R ): r \"\"\" A [roller][dyce.r.R] whose roll outcomes are derived from scalars, [``H`` objects][dyce.h.H], [``P`` objects][dyce.p.P], [``RollOutcome`` objects][dyce.r.RollOutcome], or even [``Roll`` objects][dyce.r.Roll], instead of other source rollers. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_value\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , value : _ValueT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = (), annotation = annotation , ** kw ) if isinstance ( value , P ) and not value . is_homogeneous : warnings . warn ( f \"using a heterogeneous pool ( { value } ) is not recommended where traceability is important\" , stacklevel = 2 , ) self . _value = value # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \" { type ( self ) . __name__ } (value= { self . value !r} , annotation= { self . annotation !r} )\" @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" if isinstance ( self . value , P ): return Roll ( self , roll_outcomes = ( RollOutcome ( outcome ) for outcome in self . value . roll ()), ) elif isinstance ( self . value , H ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value . roll ()),)) elif isinstance ( self . value , RealLike ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value ),)) else : assert False , f \"unrecognized value type { self . value !r} \" # ---- Properties ------------------------------------------------------------------ @property def value ( self ) -> _ValueT : r \"\"\" The value to be emitted by this roller via its [``ValueRoller.roll`` method][dyce.r.ValueRoller.roll]. \"\"\" return self . _value __slots__ : Union [ str , Iterable [ str ]] special value : _ValueT property readonly The value to be emitted by this roller via its ValueRoller.roll method . __init__ ( self , value : _ValueT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , value : _ValueT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = (), annotation = annotation , ** kw ) if isinstance ( value , P ) and not value . is_homogeneous : warnings . warn ( f \"using a heterogeneous pool ( { value } ) is not recommended where traceability is important\" , stacklevel = 2 , ) self . _value = value __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \" { type ( self ) . __name__ } (value= { self . value !r} , annotation= { self . annotation !r} )\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" if isinstance ( self . value , P ): return Roll ( self , roll_outcomes = ( RollOutcome ( outcome ) for outcome in self . value . roll ()), ) elif isinstance ( self . value , H ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value . roll ()),)) elif isinstance ( self . value , RealLike ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value ),)) else : assert False , f \"unrecognized value type { self . value !r} \" walk ( root : Union [ Roll , R , RollOutcome ], visitor : Union [ RollWalkerVisitor , RollerWalkerVisitor , RollOutcomeWalkerVisitor ]) -> None Experimental This function should be considered experimental and may change or disappear in future versions. Walks through root , calling visitor for each matching object. No ordering guarantees are made. On the current implementation walk performs a breadth-first traversal of root , assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. Source code in dyce/r.py @experimental @beartype def walk ( root : Union [ Roll , R , RollOutcome ], visitor : Union [ RollWalkerVisitor , RollerWalkerVisitor , RollOutcomeWalkerVisitor ], ) -> None : r \"\"\" !!! warning \"Experimental\" This function should be considered experimental and may change or disappear in future versions. Walks through *root*, calling *visitor* for each matching object. No ordering guarantees are made. !!! info \"On the current implementation\" ``#!python walk`` performs a breadth-first traversal of *root*, assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. \"\"\" rolls : Dict [ int , Roll ] = {} rollers : Dict [ int , R ] = {} roll_outcomes : Dict [ int , RollOutcome ] = {} roll_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roller_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roll_outcome_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) queue = deque (( root ,)) roll : Roll r : R roll_outcome : RollOutcome while queue : obj = queue . popleft () if isinstance ( obj , Roll ): roll = obj if id ( roll ) not in rolls : rolls [ id ( roll )] = roll queue . append ( roll . r ) for i , roll_outcome in enumerate ( roll ): queue . append ( roll_outcome ) for source_roll in roll . source_rolls : roll_parent_ids [ id ( source_roll )] . add ( id ( roll )) queue . append ( source_roll ) elif isinstance ( obj , R ): r = obj if id ( r ) not in rollers : rollers [ id ( r )] = r for source_r in r . sources : roller_parent_ids [ id ( source_r )] . add ( id ( r )) queue . append ( source_r ) elif isinstance ( obj , RollOutcome ): roll_outcome = obj if id ( roll_outcome ) not in roll_outcomes : roll_outcomes [ id ( roll_outcome )] = roll_outcome for source_roll_outcome in roll_outcome . sources : roll_outcome_parent_ids [ id ( source_roll_outcome )] . add ( id ( roll_outcome ) ) queue . append ( source_roll_outcome ) if rolls and isinstance ( visitor , RollWalkerVisitor ): for roll_id , roll in rolls . items (): visitor . on_roll ( roll , ( rolls [ i ] for i in roll_parent_ids [ roll_id ])) if rollers and isinstance ( visitor , RollerWalkerVisitor ): for r_id , r in rollers . items (): visitor . on_roller ( r , ( rollers [ i ] for i in roller_parent_ids [ r_id ])) if roll_outcomes and isinstance ( visitor , RollOutcomeWalkerVisitor ): for roll_outcome_id , roll_outcome in roll_outcomes . items (): visitor . on_roll_outcome ( roll_outcome , ( roll_outcomes [ i ] for i in roll_outcome_parent_ids [ roll_outcome_id ]), )","title":"<tt>dyce.r</tt>"},{"location":"dyce.r/#dycer-package-reference","text":"Experimental This package is an attempt to provide primitives for producing weighted randomized rolls without the overhead of enumeration. Rolls can be inspected to understand how specific values are derived. It should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Feedback, suggestions, and contributions are welcome and appreciated.","title":"dyce.r package reference"},{"location":"dyce.r/#roller-class-hierarchy","text":"","title":"Roller class hierarchy"},{"location":"dyce.r/#dyce.r.BasicOpRoller","text":"A roller for applying op to some variation of outcomes from sources . Any RollOutcome s returned by op are used directly in the creation of a new Roll . Source code in dyce/r.py class BasicOpRoller ( R ): r \"\"\" A [roller][dyce.r.R] for applying *op* to some variation of outcomes from *sources*. Any [``RollOutcome``][dyce.r.RollOutcome]s returned by *op* are used directly in the creation of a new [``Roll``][dyce.r.Roll]. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_op\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _op = op # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( op= { self . op !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . op , other . op )) @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) res = self . op ( self , ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), ) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def op ( self ) -> BasicOperatorT : r \"\"\" The operator this roller applies to its sources. \"\"\" return self . _op","title":"BasicOpRoller"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.BasicOpRoller.op","text":"The operator this roller applies to its sources.","title":"op"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . op , other . op ))","title":"__eq__()"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _op = op","title":"__init__()"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( op= { self . op !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.BasicOpRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) res = self . op ( self , ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), ) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller","text":"An NarySumOpRoller for applying a binary operator bin_op to the sum of all outcomes from its left_source and the sum of all outcomes from its right_source . Source code in dyce/r.py class BinarySumOpRoller ( NarySumOpRoller ): r \"\"\" An [``NarySumOpRoller``][dyce.r.NarySumOpRoller] for applying a binary operator *bin_op* to the sum of all outcomes from its *left_source* and the sum of all outcomes from its *right_source*. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_bin_op\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: left_operand , right_operand = roll_outcomes return bin_op ( left_operand , right_operand ) super () . __init__ ( op = _op , sources = ( left_source , right_source ), annotation = annotation , ** kw ) self . _bin_op = bin_op # ---- Properties ------------------------------------------------------------------ @property def bin_op ( self ) -> _RollOutcomeBinaryOperatorT : r \"\"\" The operator this roller applies to its sources. \"\"\" return self . _bin_op # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : def _source_repr ( source : _SourceT ) -> str : return indent ( repr ( source ), \" \" ) . strip () left_source , right_source = self . sources return f \"\"\" { type ( self ) . __name__ } ( bin_op= { self . bin_op !r} , left_source= { _source_repr ( left_source ) } , right_source= { _source_repr ( right_source ) } , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . bin_op , other . bin_op ))","title":"BinarySumOpRoller"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.bin_op","text":"The operator this roller applies to its sources.","title":"bin_op"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . bin_op , other . bin_op ))","title":"__eq__()"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: left_operand , right_operand = roll_outcomes return bin_op ( left_operand , right_operand ) super () . __init__ ( op = _op , sources = ( left_source , right_source ), annotation = annotation , ** kw ) self . _bin_op = bin_op","title":"__init__()"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : def _source_repr ( source : _SourceT ) -> str : return indent ( repr ( source ), \" \" ) . strip () left_source , right_source = self . sources return f \"\"\" { type ( self ) . __name__ } ( bin_op= { self . bin_op !r} , left_source= { _source_repr ( left_source ) } , right_source= { _source_repr ( right_source ) } , annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.FilterRoller","text":"A roller for applying predicate to filter outcomes its sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 >>> r_d6 = R . from_value ( H ( 6 )) >>> filter_r = ( 2 @r_d6 ) . filter ( ... lambda outcome : outcome . value is not None and outcome . value > 3 , # type: ignore [operator] ... ) >>> ( filter_r ) . roll () Roll ( r = FilterRoller ( predicate =< function < lambda > at ...> , sources = ( RepeatRoller ( n = 2 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( Roll ( r = RepeatRoller ( n = 2 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 5 , sources = (), ), ), source_rolls = (), ), ), ), ), ) See the section on \u201c Filtering and substitution \u201d more examples. Source code in dyce/r.py class FilterRoller ( R ): r \"\"\" A [roller][dyce.r.R] for applying *predicate* to filter outcomes its *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1639580307) -- END MONKEY PATCH --> ``` python >>> r_d6 = R.from_value(H(6)) >>> filter_r = (2@r_d6).filter( ... lambda outcome: outcome.value is not None and outcome.value > 3, # type: ignore [operator] ... ) >>> (filter_r).roll() Roll( r=FilterRoller( predicate=<function <lambda> at ...>, sources=( RepeatRoller( n=2, source=ValueRoller(value=H(6), annotation=''), annotation='', ), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ), RollOutcome( value=5, sources=(), ), ), source_rolls=( Roll( r=RepeatRoller( n=2, source=ValueRoller(value=H(6), annotation=''), annotation='', ), roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=5, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=H(6), annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=H(6), annotation=''), roll_outcomes=( RollOutcome( value=5, sources=(), ), ), source_rolls=(), ), ), ), ), ) ``` See the section on \u201c[Filtering and substitution](rollin.md#filtering-and-substitution)\u201d more examples. \"\"\" __slots__ : Tuple [ str , ... ] = ( \"_predicate\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , predicate : _PredicateT , sources : Iterable [ R ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _predicate = predicate # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( predicate= { self . predicate !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and _callable_cmp ( self . predicate , other . predicate ) @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _filtered_roll_outcomes () -> Iterator [ RollOutcome ]: for roll_outcome in chain . from_iterable ( source_rolls ): if roll_outcome . value is not None : if self . predicate ( roll_outcome ): yield roll_outcome else : yield roll_outcome . euthanize () return Roll ( self , roll_outcomes = _filtered_roll_outcomes (), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def predicate ( self ) -> _PredicateT : r \"\"\" The predicate this roller applies to filter its sources. \"\"\" return self . _predicate","title":"FilterRoller"},{"location":"dyce.r/#dyce.r.FilterRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.FilterRoller.predicate","text":"The predicate this roller applies to filter its sources.","title":"predicate"},{"location":"dyce.r/#dyce.r.FilterRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and _callable_cmp ( self . predicate , other . predicate )","title":"__eq__()"},{"location":"dyce.r/#dyce.r.FilterRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , predicate : _PredicateT , sources : Iterable [ R ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _predicate = predicate","title":"__init__()"},{"location":"dyce.r/#dyce.r.FilterRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( predicate= { self . predicate !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.FilterRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _filtered_roll_outcomes () -> Iterator [ RollOutcome ]: for roll_outcome in chain . from_iterable ( source_rolls ): if roll_outcome . value is not None : if self . predicate ( roll_outcome ): yield roll_outcome else : yield roll_outcome . euthanize () return Roll ( self , roll_outcomes = _filtered_roll_outcomes (), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.NarySumOpRoller","text":"A BasicOpRoller for applying op to the sum of outcomes grouped by each of sources . Source code in dyce/r.py class NarySumOpRoller ( BasicOpRoller ): r \"\"\" A [``BasicOpRoller``][dyce.r.BasicOpRoller] for applying *op* to the sum of outcomes grouped by each of *sources*. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _sum_roll_outcomes_by_rolls () -> Iterator [ RollOutcome ]: for source_roll in source_rolls : if len ( source_roll ) == 1 and source_roll [ 0 ] . value is not None : yield from source_roll else : yield RollOutcome ( sum ( source_roll . outcomes ()), sources = source_roll ) res = self . op ( self , _sum_roll_outcomes_by_rolls ()) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , )","title":"NarySumOpRoller"},{"location":"dyce.r/#dyce.r.NarySumOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.NarySumOpRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _sum_roll_outcomes_by_rolls () -> Iterator [ RollOutcome ]: for source_roll in source_rolls : if len ( source_roll ) == 1 and source_roll [ 0 ] . value is not None : yield from source_roll else : yield RollOutcome ( sum ( source_roll . outcomes ()), sources = source_roll ) res = self . op ( self , _sum_roll_outcomes_by_rolls ()) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore [assignment] # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.PoolRoller","text":"A roller for rolling flattened \u201cpools\u201d from all sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 >>> PoolRoller (( ... PoolRoller (( ... ValueRoller ( 11 ), ... ValueRoller ( 12 ), ... )), ... PoolRoller (( ... PoolRoller (( ... ValueRoller ( 211 ), ... ValueRoller ( 212 ), ... )), ... PoolRoller (( ... ValueRoller ( 221 ), ... ValueRoller ( 222 ), ... )), ... )), ... ValueRoller ( 3 ), ... )) . roll () Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 11 , sources =... , ), RollOutcome ( value = 12 , sources =... , ), RollOutcome ( value = 211 , sources =... , ), RollOutcome ( value = 212 , sources =... , ), RollOutcome ( value = 221 , sources =... , ), RollOutcome ( value = 222 , sources =... , ), RollOutcome ( value = 3 , sources =... , ), ), source_rolls =... , ) Source code in dyce/r.py class PoolRoller ( R ): r \"\"\" A [roller][dyce.r.R] for rolling flattened \u201cpools\u201d from all *sources*. ``` python >>> PoolRoller(( ... PoolRoller(( ... ValueRoller(11), ... ValueRoller(12), ... )), ... PoolRoller(( ... PoolRoller(( ... ValueRoller(211), ... ValueRoller(212), ... )), ... PoolRoller(( ... ValueRoller(221), ... ValueRoller(222), ... )), ... )), ... ValueRoller(3), ... )).roll() Roll( r=..., roll_outcomes=( RollOutcome( value=11, sources=..., ), RollOutcome( value=12, sources=..., ), RollOutcome( value=211, sources=..., ), RollOutcome( value=212, sources=..., ), RollOutcome( value=221, sources=..., ), RollOutcome( value=222, sources=..., ), RollOutcome( value=3, sources=..., ), ), source_rolls=..., ) ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , )","title":"PoolRoller"},{"location":"dyce.r/#dyce.r.PoolRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.PoolRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.R","text":"Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Where H objects and P objects are used primarily for enumerating weighted outcomes, R objects represent rollers. More specifically, they are immutable nodes assembled in tree-like structures to represent calculations. Unlike H or P objects, rollers generate rolls that conform to weighted outcomes without engaging in computationally expensive enumeration. Roller trees are typically composed from various R class methods and operators as well as arithmetic operations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> from dyce import H , P , R >>> d6 = H ( 6 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> (( 4 * r_d6 + 3 ) ** 2 % 5 ) . gt ( 2 ) BinarySumOpRoller ( bin_op =< function R . gt .< locals >. _gt at ...> , left_source = BinarySumOpRoller ( bin_op =< built - in function mod > , left_source = BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = BinarySumOpRoller ( bin_op =< built - in function add > , left_source = BinarySumOpRoller ( bin_op =< built - in function mul > , left_source = ValueRoller ( value = 4 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 3 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 5 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) Info No optimizations are made when initializing roller trees. They retain their exact structure, even where such structures could be trivially reduced. 1 2 3 4 5 6 7 >>> r_6 = R . from_value ( 6 ) >>> r_6_abs_3 = 3 @abs ( r_6 ) >>> r_6_abs_6_abs_6_abs = R . from_sources ( abs ( r_6 ), abs ( r_6 ), abs ( r_6 )) >>> tuple ( r_6_abs_3 . roll () . outcomes ()), tuple ( r_6_abs_6_abs_6_abs . roll () . outcomes ()) # they generate the same rolls (( 6 , 6 , 6 ), ( 6 , 6 , 6 )) >>> r_6_abs_3 == r_6_abs_6_abs_6_abs # and yet, they're different animals False This is because the structure itself contains information that might be required by certain contexts. If such information loss is permissible and reduction is desirable, consider using histograms instead. Roller trees can can be queried via the roll method , which produces Roll objects . 1 2 3 4 5 >>> roll = r_d6 . roll () >>> tuple ( roll . outcomes ()) ( 4 ,) >>> roll . total () 4 1 2 3 4 >>> d6 + 3 H ({ 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> ( r_d6 + 3 ) . roll () . total () in ( d6 + 3 ) True Roll objects are much richer than mere sequences of outcomes. They are also tree-like structures that mirror the roller trees used to produce them, capturing references to rollers and the outcomes generated at each node. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 >>> roll = ( r_d6 + 3 ) . roll () >>> roll . total () 8 >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 8 , sources = ( RollOutcome ( value = 5 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 5 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Rollers afford optional annotations as a convenience to callers. They are taken into account when comparing roller trees, but otherwise ignored, internally. One use is to capture references to nodes in an abstract syntax tree generated from parsing a proprietary grammar. Any provided annotation can be retrieved using the annotation property . The annotate method can be used to apply an annotation to existing roller. The R class itself acts as a base from which several computation-specific implementations derive (such as expressing operands like outcomes or histograms, unary operations, binary operations, pools, etc.). Source code in dyce/r.py class R : r \"\"\" !!! warning \"Experimental\" This class (and its descendants) should be considered experimental and may change or disappear in future versions. Where [``H`` objects][dyce.h.H] and [``P`` objects][dyce.p.P] are used primarily for enumerating weighted outcomes, ``#!python R`` objects represent rollers. More specifically, they are immutable nodes assembled in tree-like structures to represent calculations. Unlike [``H``][dyce.h.H] or [``P``][dyce.p.P] objects, rollers generate rolls that conform to weighted outcomes without engaging in computationally expensive enumeration. Roller trees are typically composed from various ``#!python R`` class methods and operators as well as arithmetic operations. ``` python >>> from dyce import H, P, R >>> d6 = H(6) >>> r_d6 = R.from_value(d6) ; r_d6 ValueRoller(value=H(6), annotation='') >>> ((4 * r_d6 + 3) ** 2 % 5).gt(2) BinarySumOpRoller( bin_op=<function R.gt.<locals>._gt at ...>, left_source=BinarySumOpRoller( bin_op=<built-in function mod>, left_source=BinarySumOpRoller( bin_op=<built-in function pow>, left_source=BinarySumOpRoller( bin_op=<built-in function add>, left_source=BinarySumOpRoller( bin_op=<built-in function mul>, left_source=ValueRoller(value=4, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ), right_source=ValueRoller(value=3, annotation=''), annotation='', ), right_source=ValueRoller(value=2, annotation=''), annotation='', ), right_source=ValueRoller(value=5, annotation=''), annotation='', ), right_source=ValueRoller(value=2, annotation=''), annotation='', ) ``` !!! info No optimizations are made when initializing roller trees. They retain their exact structure, even where such structures could be trivially reduced. ``` python >>> r_6 = R.from_value(6) >>> r_6_abs_3 = 3@abs(r_6) >>> r_6_abs_6_abs_6_abs = R.from_sources(abs(r_6), abs(r_6), abs(r_6)) >>> tuple(r_6_abs_3.roll().outcomes()), tuple(r_6_abs_6_abs_6_abs.roll().outcomes()) # they generate the same rolls ((6, 6, 6), (6, 6, 6)) >>> r_6_abs_3 == r_6_abs_6_abs_6_abs # and yet, they're different animals False ``` This is because the structure itself contains information that might be required by certain contexts. If such information loss is permissible and reduction is desirable, consider using [histograms][dyce.h.H] instead. Roller trees can can be queried via the [``roll`` method][dyce.r.R.roll], which produces [``Roll`` objects][dyce.r.Roll]. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056380) -- END MONKEY PATCH --> ``` python >>> roll = r_d6.roll() >>> tuple(roll.outcomes()) (4,) >>> roll.total() 4 ``` ``` python >>> d6 + 3 H({4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}) >>> (r_d6 + 3).roll().total() in (d6 + 3) True ``` [``Roll`` objects][dyce.r.Roll] are much richer than mere sequences of outcomes. They are also tree-like structures that mirror the roller trees used to produce them, capturing references to rollers and the outcomes generated at each node. ``` python >>> roll = (r_d6 + 3).roll() >>> roll.total() 8 >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=8, sources=( RollOutcome( value=5, sources=(), ), RollOutcome( value=3, sources=(), ), ), ), ), source_rolls=( Roll( r=ValueRoller(value=H(6), annotation=''), roll_outcomes=( RollOutcome( value=5, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` Rollers afford optional annotations as a convenience to callers. They are taken into account when comparing roller trees, but otherwise ignored, internally. One use is to capture references to nodes in an abstract syntax tree generated from parsing a proprietary grammar. Any provided *annotation* can be retrieved using the [``annotation`` property][dyce.r.R.annotation]. The [``annotate`` method][dyce.r.R.annotate] can be used to apply an annotation to existing roller. The ``#!python R`` class itself acts as a base from which several computation-specific implementations derive (such as expressing operands like outcomes or histograms, unary operations, binary operations, pools, etc.). <!-- BEGIN MONKEY PATCH -- For type-checking docstrings >>> from typing import Tuple, Union >>> from dyce.r import PoolRoller, Roll, RollOutcome, ValueRoller >>> which: Tuple[Union[int, slice], ...] -- END MONKEY PATCH --> \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_annotation\" , \"_sources\" ) # ---- Initializer ----------------------------------------------------------------- @experimental @beartype def __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ () self . _sources = tuple ( sources ) self . _annotation = annotation # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , R ): return ( ( isinstance ( self , type ( other )) or isinstance ( other , type ( self ))) and __eq__ ( self . sources , other . sources ) # order matters and __eq__ ( self . annotation , other . annotation ) ) else : return super () . __eq__ ( other ) @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , R ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) @beartype def __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented @beartype def __radd__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented @beartype def __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented @beartype def __rsub__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented @beartype def __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmul__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented @beartype def __matmul__ ( self , other : SupportsInt ) -> R : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return RepeatRoller ( other , self ) @beartype def __rmatmul__ ( self , other : SupportsInt ) -> R : return self . __matmul__ ( other ) @beartype def __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rtruediv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented @beartype def __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rfloordiv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented @beartype def __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmod__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented @beartype def __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented @beartype def __rpow__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented @beartype def __and__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __and__ , other ) else : return self . map ( __and__ , as_int ( other )) except NotImplementedError : return NotImplemented @beartype def __rand__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __and__ ) except NotImplementedError : return NotImplemented @beartype def __xor__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __xor__ , other ) else : return self . map ( __xor__ , as_int ( other )) except NotImplementedError : return NotImplemented @beartype def __rxor__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __xor__ ) except NotImplementedError : return NotImplemented @beartype def __or__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __or__ , other ) else : return self . map ( __or__ , as_int ( other )) except NotImplementedError : return NotImplemented @beartype def __ror__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __or__ ) except NotImplementedError : return NotImplemented @beartype def __neg__ ( self ) -> UnarySumOpRoller : return self . umap ( __neg__ ) @beartype def __pos__ ( self ) -> UnarySumOpRoller : return self . umap ( __pos__ ) @beartype def __abs__ ( self ) -> UnarySumOpRoller : return self . umap ( __abs__ ) @beartype def __invert__ ( self ) -> UnarySumOpRoller : return self . umap ( __invert__ ) @abstractmethod def roll ( self ) -> Roll : r \"\"\" Sub-classes should implement this method to return a new [``Roll`` object][dyce.r.Roll] taking into account any [sources][dyce.r.R.sources]. !!! note Implementors guarantee that all [``RollOutcome``][dyce.r.RollOutcome]s in the returned [``Roll``][dyce.r.Roll] *must* be associated with a roll, *including all roll outcomes\u2019 [``sources``][dyce.r.RollOutcome.sources]*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633403927) -- END MONKEY PATCH --> !!! tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of ``#!python None`` with the excluded roll outcome as its source. The [``RollOutcome.euthanize``][dyce.r.RollOutcome.euthanize] convenience method is provided for this purpose. See the section on \u201c[Dropping dice from prior rolls \u2026](rollin.md#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8)\u201d as well as the note in [``Roll.__init__``][dyce.r.Roll.__init__] for additional color. ``` python >>> from itertools import chain >>> class AntonChigurhRoller(R): ... h_coin_toss = H((0, 1)) ... def roll(self) -> Roll: ... source_rolls = list(self.source_rolls()) ... def _roll_outcomes_gen(): ... for roll_outcome in chain.from_iterable(source_rolls): ... if roll_outcome.value is None: ... # Omit those already deceased ... continue ... elif self.h_coin_toss.roll(): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else: ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome.euthanize() ... return Roll(self, roll_outcomes=_roll_outcomes_gen(), source_rolls=source_rolls) >>> ac_r = AntonChigurhRoller(sources=(R.from_value(1), R.from_value(2), R.from_value(3))) >>> ac_r.roll() Roll( r=AntonChigurhRoller( sources=( ValueRoller(value=1, annotation=''), ValueRoller(value=2, annotation=''), ValueRoller(value=3, annotation=''), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=1, annotation=''), roll_outcomes=( RollOutcome( value=1, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=2, annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` \"\"\" ... # ---- Properties ------------------------------------------------------------------ @property def annotation ( self ) -> Any : r \"\"\" Any provided annotation. \"\"\" return self . _annotation @property def sources ( self ) -> Tuple [ _SourceT , ... ]: r \"\"\" The roller\u2019s direct sources (if any). \"\"\" return self . _sources # ---- Methods --------------------------------------------------------------------- @classmethod @beartype def from_sources ( cls , * sources : _SourceT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable(rs, annotation=annotation)``. See the [``from_sources_iterable`` method][dyce.r.R.from_sources_iterable]. \"\"\" return cls . from_sources_iterable ( sources , annotation = annotation ) @classmethod @beartype def from_sources_iterable ( cls , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Creates and returns a roller for \u201cpooling\u201d zero or more *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056341) -- END MONKEY PATCH --> ``` python >>> r_pool = R.from_sources_iterable(R.from_value(h) for h in (H((1, 2)), H((3, 4)), H((5, 6)))) >>> roll = r_pool.roll() >>> tuple(roll.outcomes()) (2, 4, 6) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=4, sources=(), ), RollOutcome( value=6, sources=(), ), ), source_rolls=..., ) ``` \"\"\" return PoolRoller ( sources , annotation = annotation ) @classmethod @beartype def from_value ( cls , value : _ValueT , annotation : Any = \"\" , ) -> ValueRoller : r \"\"\" Creates and returns a [``ValueRoller``][dyce.r.ValueRoller] from *value*. ``` python >>> R.from_value(6) ValueRoller(value=6, annotation='') ``` ``` python >>> R.from_value(H(6)) ValueRoller(value=H(6), annotation='') ``` ``` python >>> R.from_value(P(6, 6)) ValueRoller(value=P(6, 6), annotation='') ``` \"\"\" return ValueRoller ( value , annotation = annotation ) @classmethod @beartype def from_values ( cls , * values : _ValueT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_values_iterable(values, annotation=annotation)``. See the [``from_values_iterable`` method][dyce.r.R.from_values_iterable]. \"\"\" return cls . from_values_iterable ( values , annotation = annotation ) @classmethod @beartype def from_values_iterable ( cls , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``from_sources_iterable``][dyce.r.R.from_sources_iterable] methods. \"\"\" return cls . from_sources_iterable ( ( cls . from_value ( value ) for value in values ), annotation = annotation , ) @classmethod @beartype def filter_from_sources ( cls , predicate : _PredicateT , * sources : _SourceT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable(predicate, sources, annotation=annotation)``. See the [``filter_from_sources_iterable`` method][dyce.r.R.filter_from_sources_iterable]. \"\"\" return cls . filter_from_sources_iterable ( predicate , sources , annotation = annotation ) @classmethod @beartype def filter_from_sources_iterable ( cls , predicate : _PredicateT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Creates and returns a [``FilterRoller``][dyce.r.FilterRoller] for applying filterion *predicate* to sorted outcomes from *sources*. ``` python >>> r_filter = R.filter_from_sources_iterable( ... lambda outcome: bool(outcome.is_even().value), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_filter FilterRoller( predicate=<function <lambda> at ...>, sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_filter.roll().outcomes()) (4, 6, 2, 8, 0) ``` \"\"\" return FilterRoller ( predicate , sources , annotation = annotation ) @classmethod @beartype def filter_from_values ( cls , predicate : _PredicateT , * values : _ValueT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_values_iterable(predicate, values, annotation=annotation)``. See the [``filter_from_values_iterable`` method][dyce.r.R.filter_from_values_iterable]. \"\"\" return cls . filter_from_values_iterable ( predicate , values , annotation = annotation ) @classmethod @beartype def filter_from_values_iterable ( cls , predicate : _PredicateT , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``filter_from_sources_iterable``][dyce.r.R.filter_from_sources_iterable] methods. \"\"\" return cls . filter_from_sources_iterable ( predicate , ( cls . from_value ( value ) for value in values ), annotation = annotation , ) @classmethod @beartype def select_from_sources ( cls , which : Iterable [ _GetItemT ], * sources : _SourceT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable(which, sources, annotation=annotation)``. See the [``select_from_sources_iterable`` method][dyce.r.R.select_from_sources_iterable]. \"\"\" return cls . select_from_sources_iterable ( which , sources , annotation = annotation ) @classmethod @beartype def select_from_sources_iterable ( cls , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Creates and returns a [``SelectionRoller``][dyce.r.SelectionRoller] for applying selection *which* to sorted outcomes from *sources*. ``` python >>> r_select = R.select_from_sources_iterable( ... (0, -1, slice(3, 6), slice(6, 3, -1), -1, 0), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_select SelectionRoller( which=(0, -1, slice(3, 6, None), slice(6, 3, -1), -1, 0), sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_select.roll().outcomes()) (0, 9, 3, 4, 5, 6, 5, 4, 9, 0) ``` \"\"\" return SelectionRoller ( which , sources , annotation = annotation ) @classmethod @beartype def select_from_values ( cls , which : Iterable [ _GetItemT ], * values : _ValueT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_values_iterable(which, values, annotation=annotation)``. See the [``select_from_values_iterable`` method][dyce.r.R.select_from_values_iterable]. \"\"\" return cls . select_from_values_iterable ( which , values , annotation = annotation ) @classmethod @beartype def select_from_values_iterable ( cls , which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``select_from_sources_iterable``][dyce.r.R.select_from_sources_iterable] methods. \"\"\" return cls . select_from_sources_iterable ( which , ( cls . from_value ( value ) for value in values ), annotation = annotation , ) @beartype def source_rolls ( self ) -> Iterator [ \"Roll\" ]: r \"\"\" Generates new rolls from all [``sources``][dyce.r.R.sources]. \"\"\" for source in self . sources : yield source . roll () @beartype def annotate ( self , annotation : Any = \"\" ) -> R : r \"\"\" Generates a copy of the roller with the desired annotation. ``` python >>> r_just_the_n_of_us = R.from_value(5, annotation=\"But I'm 42!\") ; r_just_the_n_of_us ValueRoller(value=5, annotation=\"But I'm 42!\") >>> r_just_the_n_of_us.annotate(\"I'm a 42-year-old investment banker!\") ValueRoller(value=5, annotation=\"I'm a 42-year-old investment banker!\") ``` \"\"\" r = copy ( self ) r . _annotation = annotation return r @beartype def map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Creates and returns a [``BinarySumOpRoller``][dyce.r.BinarySumOpRoller] for applying *bin_op* to this roller and *right_operand* as its sources. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).map(operator.__pow__, 2) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=H(6), annotation=''), right_source=ValueRoller(value=2, annotation=''), annotation='', ) >>> r_bin_op == R.from_value(H(6)) ** 2 True ``` \"\"\" if isinstance ( right_operand , RealLike ): right_operand = ValueRoller ( right_operand ) if isinstance ( right_operand , ( R , RollOutcome )): return BinarySumOpRoller ( bin_op , self , right_operand , annotation = annotation ) else : raise NotImplementedError @beartype def rmap ( self , left_operand : Union [ RealLike , \"RollOutcome\" ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Analogous to the [``map`` method][dyce.r.R.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).rmap(2, operator.__pow__) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=2, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_bin_op == 2 ** R.from_value(H(6)) True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.R.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return BinarySumOpRoller ( bin_op , ValueRoller ( left_operand ), self , annotation = annotation ) elif isinstance ( left_operand , RollOutcome ): return BinarySumOpRoller ( bin_op , left_operand , self , annotation = annotation ) else : raise NotImplementedError @beartype def umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = \"\" , ) -> UnarySumOpRoller : r \"\"\" Creates and returns a [``UnarySumOpRoller``][dyce.r.UnarySumOpRoller] roller for applying *un_op* to this roller as its source. ``` python >>> import operator >>> r_un_op = R.from_value(H(6)).umap(operator.__neg__) ; r_un_op UnarySumOpRoller( un_op=<built-in function neg>, source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_un_op == -R.from_value(H(6)) True ``` \"\"\" return UnarySumOpRoller ( un_op , self , annotation = annotation ) @beartype def lt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.lt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _lt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . lt ( right_operand ) return self . map ( _lt , other ) @beartype def le ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.le(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _le ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . le ( right_operand ) return self . map ( _le , other ) @beartype def eq ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.eq(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _eq ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . eq ( right_operand ) return self . map ( _eq , other ) @beartype def ne ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ne(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ne ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ne ( right_operand ) return self . map ( _ne , other ) @beartype def gt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.gt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _gt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . gt ( right_operand ) return self . map ( _gt , other ) @beartype def ge ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ge(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ge ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ge ( right_operand ) return self . map ( _ge , other ) @beartype def is_even ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_even())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_even ( operand : RollOutcome ) -> RollOutcome : return operand . is_even () return self . umap ( _is_even ) @beartype def is_odd ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_odd())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_odd ( operand : RollOutcome ) -> RollOutcome : return operand . is_odd () return self . umap ( _is_odd ) @beartype def filter ( self , predicate : _PredicateT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python type(self).filter_from_sources(predicate, self, annotation=annotation)``. See the [``filter_from_sources`` method][dyce.r.R.filter_from_sources]. \"\"\" return type ( self ) . filter_from_sources ( predicate , self , annotation = annotation ) @beartype def select ( self , * which : _GetItemT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python self.select_iterable(which, annotation=annotation)``. See the [``select_iterable`` method][dyce.r.R.select_iterable]. \"\"\" return self . select_iterable ( which , annotation = annotation ) @beartype def select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python type(self).select_from_sources(which, self, annotation=annotation)``. See the [``select_from_sources`` method][dyce.r.R.select_from_sources]. \"\"\" return type ( self ) . select_from_sources ( which , self , annotation = annotation )","title":"R"},{"location":"dyce.r/#dyce.r.R.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.R.annotation","text":"Any provided annotation.","title":"annotation"},{"location":"dyce.r/#dyce.r.R.sources","text":"The roller\u2019s direct sources (if any).","title":"sources"},{"location":"dyce.r/#dyce.r.R.__abs__","text":"Source code in dyce/r.py @beartype def __abs__ ( self ) -> UnarySumOpRoller : return self . umap ( __abs__ )","title":"__abs__()"},{"location":"dyce.r/#dyce.r.R.__add__","text":"Source code in dyce/r.py @beartype def __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented","title":"__add__()"},{"location":"dyce.r/#dyce.r.R.__and__","text":"Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __and__ , other ) else : return self . map ( __and__ , as_int ( other )) except NotImplementedError : return NotImplemented","title":"__and__()"},{"location":"dyce.r/#dyce.r.R.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , R ): return ( ( isinstance ( self , type ( other )) or isinstance ( other , type ( self ))) and __eq__ ( self . sources , other . sources ) # order matters and __eq__ ( self . annotation , other . annotation ) ) else : return super () . __eq__ ( other )","title":"__eq__()"},{"location":"dyce.r/#dyce.r.R.__floordiv__","text":"Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented","title":"__floordiv__()"},{"location":"dyce.r/#dyce.r.R.__init__","text":"Initializer. Source code in dyce/r.py @experimental @beartype def __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ () self . _sources = tuple ( sources ) self . _annotation = annotation","title":"__init__()"},{"location":"dyce.r/#dyce.r.R.__invert__","text":"Source code in dyce/r.py @beartype def __invert__ ( self ) -> UnarySumOpRoller : return self . umap ( __invert__ )","title":"__invert__()"},{"location":"dyce.r/#dyce.r.R.__matmul__","text":"Source code in dyce/r.py @beartype def __matmul__ ( self , other : SupportsInt ) -> R : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return RepeatRoller ( other , self )","title":"__matmul__()"},{"location":"dyce.r/#dyce.r.R.__mod__","text":"Source code in dyce/r.py @beartype def __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented","title":"__mod__()"},{"location":"dyce.r/#dyce.r.R.__mul__","text":"Source code in dyce/r.py @beartype def __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented","title":"__mul__()"},{"location":"dyce.r/#dyce.r.R.__ne__","text":"Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , R ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other )","title":"__ne__()"},{"location":"dyce.r/#dyce.r.R.__neg__","text":"Source code in dyce/r.py @beartype def __neg__ ( self ) -> UnarySumOpRoller : return self . umap ( __neg__ )","title":"__neg__()"},{"location":"dyce.r/#dyce.r.R.__or__","text":"Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __or__ , other ) else : return self . map ( __or__ , as_int ( other )) except NotImplementedError : return NotImplemented","title":"__or__()"},{"location":"dyce.r/#dyce.r.R.__pos__","text":"Source code in dyce/r.py @beartype def __pos__ ( self ) -> UnarySumOpRoller : return self . umap ( __pos__ )","title":"__pos__()"},{"location":"dyce.r/#dyce.r.R.__pow__","text":"Source code in dyce/r.py @beartype def __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented","title":"__pow__()"},{"location":"dyce.r/#dyce.r.R.__radd__","text":"Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented","title":"__radd__()"},{"location":"dyce.r/#dyce.r.R.__rand__","text":"Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __and__ ) except NotImplementedError : return NotImplemented","title":"__rand__()"},{"location":"dyce.r/#dyce.r.R.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.R.__rfloordiv__","text":"Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented","title":"__rfloordiv__()"},{"location":"dyce.r/#dyce.r.R.__rmatmul__","text":"Source code in dyce/r.py @beartype def __rmatmul__ ( self , other : SupportsInt ) -> R : return self . __matmul__ ( other )","title":"__rmatmul__()"},{"location":"dyce.r/#dyce.r.R.__rmod__","text":"Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented","title":"__rmod__()"},{"location":"dyce.r/#dyce.r.R.__rmul__","text":"Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented","title":"__rmul__()"},{"location":"dyce.r/#dyce.r.R.__ror__","text":"Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __or__ ) except NotImplementedError : return NotImplemented","title":"__ror__()"},{"location":"dyce.r/#dyce.r.R.__rpow__","text":"Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented","title":"__rpow__()"},{"location":"dyce.r/#dyce.r.R.__rsub__","text":"Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented","title":"__rsub__()"},{"location":"dyce.r/#dyce.r.R.__rtruediv__","text":"Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLike ) -> BinarySumOpRoller : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented","title":"__rtruediv__()"},{"location":"dyce.r/#dyce.r.R.__rxor__","text":"Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsInt ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __xor__ ) except NotImplementedError : return NotImplemented","title":"__rxor__()"},{"location":"dyce.r/#dyce.r.R.__sub__","text":"Source code in dyce/r.py @beartype def __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented","title":"__sub__()"},{"location":"dyce.r/#dyce.r.R.__truediv__","text":"Source code in dyce/r.py @beartype def __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented","title":"__truediv__()"},{"location":"dyce.r/#dyce.r.R.__xor__","text":"Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ _SourceT , SupportsInt ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __xor__ , other ) else : return self . map ( __xor__ , as_int ( other )) except NotImplementedError : return NotImplemented","title":"__xor__()"},{"location":"dyce.r/#dyce.r.R.annotate","text":"Generates a copy of the roller with the desired annotation. 1 2 3 4 >>> r_just_the_n_of_us = R . from_value ( 5 , annotation = \"But I'm 42!\" ) ; r_just_the_n_of_us ValueRoller ( value = 5 , annotation = \"But I'm 42!\" ) >>> r_just_the_n_of_us . annotate ( \"I'm a 42-year-old investment banker!\" ) ValueRoller ( value = 5 , annotation = \"I'm a 42-year-old investment banker!\" ) Source code in dyce/r.py @beartype def annotate ( self , annotation : Any = \"\" ) -> R : r \"\"\" Generates a copy of the roller with the desired annotation. ``` python >>> r_just_the_n_of_us = R.from_value(5, annotation=\"But I'm 42!\") ; r_just_the_n_of_us ValueRoller(value=5, annotation=\"But I'm 42!\") >>> r_just_the_n_of_us.annotate(\"I'm a 42-year-old investment banker!\") ValueRoller(value=5, annotation=\"I'm a 42-year-old investment banker!\") ``` \"\"\" r = copy ( self ) r . _annotation = annotation return r","title":"annotate()"},{"location":"dyce.r/#dyce.r.R.eq","text":"Shorthand for self . map ( lambda left , right : left . eq ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def eq ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.eq(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _eq ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . eq ( right_operand ) return self . map ( _eq , other )","title":"eq()"},{"location":"dyce.r/#dyce.r.R.filter","text":"Shorthand for type ( self ) . filter_from_sources ( predicate , self , annotation = annotation ) . See the filter_from_sources method . Source code in dyce/r.py @beartype def filter ( self , predicate : _PredicateT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python type(self).filter_from_sources(predicate, self, annotation=annotation)``. See the [``filter_from_sources`` method][dyce.r.R.filter_from_sources]. \"\"\" return type ( self ) . filter_from_sources ( predicate , self , annotation = annotation )","title":"filter()"},{"location":"dyce.r/#dyce.r.R.filter_from_sources","text":"Shorthand for cls . filter_from_sources_iterable ( predicate , sources , annotation = annotation ) . See the filter_from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def filter_from_sources ( cls , predicate : _PredicateT , * sources : _SourceT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable(predicate, sources, annotation=annotation)``. See the [``filter_from_sources_iterable`` method][dyce.r.R.filter_from_sources_iterable]. \"\"\" return cls . filter_from_sources_iterable ( predicate , sources , annotation = annotation )","title":"filter_from_sources()"},{"location":"dyce.r/#dyce.r.R.filter_from_sources_iterable","text":"Creates and returns a FilterRoller for applying filterion predicate to sorted outcomes from sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_filter = R . filter_from_sources_iterable ( ... lambda outcome : bool ( outcome . is_even () . value ), ... ( R . from_value ( i ) for i in ( 5 , 4 , 6 , 3 , 7 , 2 , 8 , 1 , 9 , 0 )), ... ) ; r_filter FilterRoller ( predicate =< function < lambda > at ...> , sources = ( ValueRoller ( value = 5 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ... , ValueRoller ( value = 9 , annotation = '' ), ValueRoller ( value = 0 , annotation = '' ), ), annotation = '' , ) >>> tuple ( r_filter . roll () . outcomes ()) ( 4 , 6 , 2 , 8 , 0 ) Source code in dyce/r.py @classmethod @beartype def filter_from_sources_iterable ( cls , predicate : _PredicateT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Creates and returns a [``FilterRoller``][dyce.r.FilterRoller] for applying filterion *predicate* to sorted outcomes from *sources*. ``` python >>> r_filter = R.filter_from_sources_iterable( ... lambda outcome: bool(outcome.is_even().value), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_filter FilterRoller( predicate=<function <lambda> at ...>, sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_filter.roll().outcomes()) (4, 6, 2, 8, 0) ``` \"\"\" return FilterRoller ( predicate , sources , annotation = annotation )","title":"filter_from_sources_iterable()"},{"location":"dyce.r/#dyce.r.R.filter_from_values","text":"Shorthand for cls . filter_from_values_iterable ( predicate , values , annotation = annotation ) . See the filter_from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def filter_from_values ( cls , predicate : _PredicateT , * values : _ValueT , annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_values_iterable(predicate, values, annotation=annotation)``. See the [``filter_from_values_iterable`` method][dyce.r.R.filter_from_values_iterable]. \"\"\" return cls . filter_from_values_iterable ( predicate , values , annotation = annotation )","title":"filter_from_values()"},{"location":"dyce.r/#dyce.r.R.filter_from_values_iterable","text":"Shorthand for cls . filter_from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and filter_from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def filter_from_values_iterable ( cls , predicate : _PredicateT , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> FilterRoller : r \"\"\" Shorthand for ``#!python cls.filter_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``filter_from_sources_iterable``][dyce.r.R.filter_from_sources_iterable] methods. \"\"\" return cls . filter_from_sources_iterable ( predicate , ( cls . from_value ( value ) for value in values ), annotation = annotation , )","title":"filter_from_values_iterable()"},{"location":"dyce.r/#dyce.r.R.from_sources","text":"Shorthand for cls . from_sources_iterable ( rs , annotation = annotation ) . See the from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def from_sources ( cls , * sources : _SourceT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable(rs, annotation=annotation)``. See the [``from_sources_iterable`` method][dyce.r.R.from_sources_iterable]. \"\"\" return cls . from_sources_iterable ( sources , annotation = annotation )","title":"from_sources()"},{"location":"dyce.r/#dyce.r.R.from_sources_iterable","text":"Creates and returns a roller for \u201cpooling\u201d zero or more sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> r_pool = R . from_sources_iterable ( R . from_value ( h ) for h in ( H (( 1 , 2 )), H (( 3 , 4 )), H (( 5 , 6 )))) >>> roll = r_pool . roll () >>> tuple ( roll . outcomes ()) ( 2 , 4 , 6 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), RollOutcome ( value = 6 , sources = (), ), ), source_rolls =... , ) Source code in dyce/r.py @classmethod @beartype def from_sources_iterable ( cls , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Creates and returns a roller for \u201cpooling\u201d zero or more *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056341) -- END MONKEY PATCH --> ``` python >>> r_pool = R.from_sources_iterable(R.from_value(h) for h in (H((1, 2)), H((3, 4)), H((5, 6)))) >>> roll = r_pool.roll() >>> tuple(roll.outcomes()) (2, 4, 6) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=4, sources=(), ), RollOutcome( value=6, sources=(), ), ), source_rolls=..., ) ``` \"\"\" return PoolRoller ( sources , annotation = annotation )","title":"from_sources_iterable()"},{"location":"dyce.r/#dyce.r.R.from_value","text":"Creates and returns a ValueRoller from value . 1 2 >>> R . from_value ( 6 ) ValueRoller ( value = 6 , annotation = '' ) 1 2 >>> R . from_value ( H ( 6 )) ValueRoller ( value = H ( 6 ), annotation = '' ) 1 2 >>> R . from_value ( P ( 6 , 6 )) ValueRoller ( value = P ( 6 , 6 ), annotation = '' ) Source code in dyce/r.py @classmethod @beartype def from_value ( cls , value : _ValueT , annotation : Any = \"\" , ) -> ValueRoller : r \"\"\" Creates and returns a [``ValueRoller``][dyce.r.ValueRoller] from *value*. ``` python >>> R.from_value(6) ValueRoller(value=6, annotation='') ``` ``` python >>> R.from_value(H(6)) ValueRoller(value=H(6), annotation='') ``` ``` python >>> R.from_value(P(6, 6)) ValueRoller(value=P(6, 6), annotation='') ``` \"\"\" return ValueRoller ( value , annotation = annotation )","title":"from_value()"},{"location":"dyce.r/#dyce.r.R.from_values","text":"Shorthand for cls . from_values_iterable ( values , annotation = annotation ) . See the from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def from_values ( cls , * values : _ValueT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_values_iterable(values, annotation=annotation)``. See the [``from_values_iterable`` method][dyce.r.R.from_values_iterable]. \"\"\" return cls . from_values_iterable ( values , annotation = annotation )","title":"from_values()"},{"location":"dyce.r/#dyce.r.R.from_values_iterable","text":"Shorthand for cls . from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def from_values_iterable ( cls , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``from_sources_iterable``][dyce.r.R.from_sources_iterable] methods. \"\"\" return cls . from_sources_iterable ( ( cls . from_value ( value ) for value in values ), annotation = annotation , )","title":"from_values_iterable()"},{"location":"dyce.r/#dyce.r.R.ge","text":"Shorthand for self . map ( lambda left , right : left . ge ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ge ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ge(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ge ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ge ( right_operand ) return self . map ( _ge , other )","title":"ge()"},{"location":"dyce.r/#dyce.r.R.gt","text":"Shorthand for self . map ( lambda left , right : left . gt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def gt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.gt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _gt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . gt ( right_operand ) return self . map ( _gt , other )","title":"gt()"},{"location":"dyce.r/#dyce.r.R.is_even","text":"Shorthand for: self . umap ( lambda operand : operand . is_even ()) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_even())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_even ( operand : RollOutcome ) -> RollOutcome : return operand . is_even () return self . umap ( _is_even )","title":"is_even()"},{"location":"dyce.r/#dyce.r.R.is_odd","text":"Shorthand for: self . umap ( lambda operand : operand . is_odd ()) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_odd())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_odd ( operand : RollOutcome ) -> RollOutcome : return operand . is_odd () return self . umap ( _is_odd )","title":"is_odd()"},{"location":"dyce.r/#dyce.r.R.le","text":"Shorthand for self . map ( lambda left , right : left . le ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def le ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.le(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _le ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . le ( right_operand ) return self . map ( _le , other )","title":"le()"},{"location":"dyce.r/#dyce.r.R.lt","text":"Shorthand for self . map ( lambda left , right : left . lt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def lt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.lt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _lt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . lt ( right_operand ) return self . map ( _lt , other )","title":"lt()"},{"location":"dyce.r/#dyce.r.R.map","text":"Creates and returns a BinarySumOpRoller for applying bin_op to this roller and right_operand as its sources. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . map ( operator . __pow__ , 2 ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = H ( 6 ), annotation = '' ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) >>> r_bin_op == R . from_value ( H ( 6 )) ** 2 True Source code in dyce/r.py @beartype def map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Creates and returns a [``BinarySumOpRoller``][dyce.r.BinarySumOpRoller] for applying *bin_op* to this roller and *right_operand* as its sources. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).map(operator.__pow__, 2) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=H(6), annotation=''), right_source=ValueRoller(value=2, annotation=''), annotation='', ) >>> r_bin_op == R.from_value(H(6)) ** 2 True ``` \"\"\" if isinstance ( right_operand , RealLike ): right_operand = ValueRoller ( right_operand ) if isinstance ( right_operand , ( R , RollOutcome )): return BinarySumOpRoller ( bin_op , self , right_operand , annotation = annotation ) else : raise NotImplementedError","title":"map()"},{"location":"dyce.r/#dyce.r.R.ne","text":"Shorthand for self . map ( lambda left , right : left . ne ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ne ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ne(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ne ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ne ( right_operand ) return self . map ( _ne , other )","title":"ne()"},{"location":"dyce.r/#dyce.r.R.rmap","text":"Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . rmap ( 2 , operator . __pow__ ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = 2 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_bin_op == 2 ** R . from_value ( H ( 6 )) True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : Union [ RealLike , \"RollOutcome\" ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Analogous to the [``map`` method][dyce.r.R.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).rmap(2, operator.__pow__) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=2, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_bin_op == 2 ** R.from_value(H(6)) True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.R.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return BinarySumOpRoller ( bin_op , ValueRoller ( left_operand ), self , annotation = annotation ) elif isinstance ( left_operand , RollOutcome ): return BinarySumOpRoller ( bin_op , left_operand , self , annotation = annotation ) else : raise NotImplementedError","title":"rmap()"},{"location":"dyce.r/#dyce.r.R.roll","text":"Sub-classes should implement this method to return a new Roll object taking into account any sources . Note Implementors guarantee that all RollOutcome s in the returned Roll must be associated with a roll, including all roll outcomes\u2019 sources . Tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of None with the excluded roll outcome as its source. The RollOutcome.euthanize convenience method is provided for this purpose. See the section on \u201c Dropping dice from prior rolls \u2026 \u201d as well as the note in Roll.__init__ for additional color. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 >>> from itertools import chain >>> class AntonChigurhRoller ( R ): ... h_coin_toss = H (( 0 , 1 )) ... def roll ( self ) -> Roll : ... source_rolls = list ( self . source_rolls ()) ... def _roll_outcomes_gen (): ... for roll_outcome in chain . from_iterable ( source_rolls ): ... if roll_outcome . value is None : ... # Omit those already deceased ... continue ... elif self . h_coin_toss . roll (): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else : ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome . euthanize () ... return Roll ( self , roll_outcomes = _roll_outcomes_gen (), source_rolls = source_rolls ) >>> ac_r = AntonChigurhRoller ( sources = ( R . from_value ( 1 ), R . from_value ( 2 ), R . from_value ( 3 ))) >>> ac_r . roll () Roll ( r = AntonChigurhRoller ( sources = ( ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 2 , annotation = '' ), ValueRoller ( value = 3 , annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = 1 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 2 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Source code in dyce/r.py @abstractmethod def roll ( self ) -> Roll : r \"\"\" Sub-classes should implement this method to return a new [``Roll`` object][dyce.r.Roll] taking into account any [sources][dyce.r.R.sources]. !!! note Implementors guarantee that all [``RollOutcome``][dyce.r.RollOutcome]s in the returned [``Roll``][dyce.r.Roll] *must* be associated with a roll, *including all roll outcomes\u2019 [``sources``][dyce.r.RollOutcome.sources]*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633403927) -- END MONKEY PATCH --> !!! tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of ``#!python None`` with the excluded roll outcome as its source. The [``RollOutcome.euthanize``][dyce.r.RollOutcome.euthanize] convenience method is provided for this purpose. See the section on \u201c[Dropping dice from prior rolls \u2026](rollin.md#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8)\u201d as well as the note in [``Roll.__init__``][dyce.r.Roll.__init__] for additional color. ``` python >>> from itertools import chain >>> class AntonChigurhRoller(R): ... h_coin_toss = H((0, 1)) ... def roll(self) -> Roll: ... source_rolls = list(self.source_rolls()) ... def _roll_outcomes_gen(): ... for roll_outcome in chain.from_iterable(source_rolls): ... if roll_outcome.value is None: ... # Omit those already deceased ... continue ... elif self.h_coin_toss.roll(): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else: ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome.euthanize() ... return Roll(self, roll_outcomes=_roll_outcomes_gen(), source_rolls=source_rolls) >>> ac_r = AntonChigurhRoller(sources=(R.from_value(1), R.from_value(2), R.from_value(3))) >>> ac_r.roll() Roll( r=AntonChigurhRoller( sources=( ValueRoller(value=1, annotation=''), ValueRoller(value=2, annotation=''), ValueRoller(value=3, annotation=''), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=1, annotation=''), roll_outcomes=( RollOutcome( value=1, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=2, annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` \"\"\" ...","title":"roll()"},{"location":"dyce.r/#dyce.r.R.select","text":"Shorthand for self . select_iterable ( which , annotation = annotation ) . See the select_iterable method . Source code in dyce/r.py @beartype def select ( self , * which : _GetItemT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python self.select_iterable(which, annotation=annotation)``. See the [``select_iterable`` method][dyce.r.R.select_iterable]. \"\"\" return self . select_iterable ( which , annotation = annotation )","title":"select()"},{"location":"dyce.r/#dyce.r.R.select_from_sources","text":"Shorthand for cls . select_from_sources_iterable ( which , sources , annotation = annotation ) . See the select_from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_sources ( cls , which : Iterable [ _GetItemT ], * sources : _SourceT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable(which, sources, annotation=annotation)``. See the [``select_from_sources_iterable`` method][dyce.r.R.select_from_sources_iterable]. \"\"\" return cls . select_from_sources_iterable ( which , sources , annotation = annotation )","title":"select_from_sources()"},{"location":"dyce.r/#dyce.r.R.select_from_sources_iterable","text":"Creates and returns a SelectionRoller for applying selection which to sorted outcomes from sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_select = R . select_from_sources_iterable ( ... ( 0 , - 1 , slice ( 3 , 6 ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), ... ( R . from_value ( i ) for i in ( 5 , 4 , 6 , 3 , 7 , 2 , 8 , 1 , 9 , 0 )), ... ) ; r_select SelectionRoller ( which = ( 0 , - 1 , slice ( 3 , 6 , None ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), sources = ( ValueRoller ( value = 5 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ... , ValueRoller ( value = 9 , annotation = '' ), ValueRoller ( value = 0 , annotation = '' ), ), annotation = '' , ) >>> tuple ( r_select . roll () . outcomes ()) ( 0 , 9 , 3 , 4 , 5 , 6 , 5 , 4 , 9 , 0 ) Source code in dyce/r.py @classmethod @beartype def select_from_sources_iterable ( cls , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Creates and returns a [``SelectionRoller``][dyce.r.SelectionRoller] for applying selection *which* to sorted outcomes from *sources*. ``` python >>> r_select = R.select_from_sources_iterable( ... (0, -1, slice(3, 6), slice(6, 3, -1), -1, 0), ... (R.from_value(i) for i in (5, 4, 6, 3, 7, 2, 8, 1, 9, 0)), ... ) ; r_select SelectionRoller( which=(0, -1, slice(3, 6, None), slice(6, 3, -1), -1, 0), sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_select.roll().outcomes()) (0, 9, 3, 4, 5, 6, 5, 4, 9, 0) ``` \"\"\" return SelectionRoller ( which , sources , annotation = annotation )","title":"select_from_sources_iterable()"},{"location":"dyce.r/#dyce.r.R.select_from_values","text":"Shorthand for cls . select_from_values_iterable ( which , values , annotation = annotation ) . See the select_from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_values ( cls , which : Iterable [ _GetItemT ], * values : _ValueT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_values_iterable(which, values, annotation=annotation)``. See the [``select_from_values_iterable`` method][dyce.r.R.select_from_values_iterable]. \"\"\" return cls . select_from_values_iterable ( which , values , annotation = annotation )","title":"select_from_values()"},{"location":"dyce.r/#dyce.r.R.select_from_values_iterable","text":"Shorthand for cls . select_from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and select_from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def select_from_values_iterable ( cls , which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``select_from_sources_iterable``][dyce.r.R.select_from_sources_iterable] methods. \"\"\" return cls . select_from_sources_iterable ( which , ( cls . from_value ( value ) for value in values ), annotation = annotation , )","title":"select_from_values_iterable()"},{"location":"dyce.r/#dyce.r.R.select_iterable","text":"Shorthand for type ( self ) . select_from_sources ( which , self , annotation = annotation ) . See the select_from_sources method . Source code in dyce/r.py @beartype def select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python type(self).select_from_sources(which, self, annotation=annotation)``. See the [``select_from_sources`` method][dyce.r.R.select_from_sources]. \"\"\" return type ( self ) . select_from_sources ( which , self , annotation = annotation )","title":"select_iterable()"},{"location":"dyce.r/#dyce.r.R.source_rolls","text":"Generates new rolls from all sources . Source code in dyce/r.py @beartype def source_rolls ( self ) -> Iterator [ \"Roll\" ]: r \"\"\" Generates new rolls from all [``sources``][dyce.r.R.sources]. \"\"\" for source in self . sources : yield source . roll ()","title":"source_rolls()"},{"location":"dyce.r/#dyce.r.R.umap","text":"Creates and returns a UnarySumOpRoller roller for applying un_op to this roller as its source. 1 2 3 4 5 6 7 8 9 >>> import operator >>> r_un_op = R . from_value ( H ( 6 )) . umap ( operator . __neg__ ) ; r_un_op UnarySumOpRoller ( un_op =< built - in function neg > , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_un_op == - R . from_value ( H ( 6 )) True Source code in dyce/r.py @beartype def umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = \"\" , ) -> UnarySumOpRoller : r \"\"\" Creates and returns a [``UnarySumOpRoller``][dyce.r.UnarySumOpRoller] roller for applying *un_op* to this roller as its source. ``` python >>> import operator >>> r_un_op = R.from_value(H(6)).umap(operator.__neg__) ; r_un_op UnarySumOpRoller( un_op=<built-in function neg>, source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_un_op == -R.from_value(H(6)) True ``` \"\"\" return UnarySumOpRoller ( un_op , self , annotation = annotation )","title":"umap()"},{"location":"dyce.r/#dyce.r.RepeatRoller","text":"A roller to implement the __matmul__ operator. It is akin to a homogeneous PoolRoller containing n identical source s. 1 2 3 4 5 6 7 8 9 10 >>> d20 = H ( 20 ) >>> r_d20 = R . from_value ( d20 ) >>> r_d20_100 = 100 @r_d20 ; r_d20_100 RepeatRoller ( n = 100 , source = ValueRoller ( value = H ( 20 ), annotation = '' ), annotation = '' , ) >>> all ( outcome in d20 for outcome in r_d20_100 . roll () . outcomes ()) True Source code in dyce/r.py class RepeatRoller ( R ): r \"\"\" A [roller][dyce.r.R] to implement the ``#!python __matmul__`` operator. It is akin to a homogeneous [``PoolRoller``][dyce.r.PoolRoller] containing *n* identical *source*s. ``` python >>> d20 = H(20) >>> r_d20 = R.from_value(d20) >>> r_d20_100 = 100@r_d20 ; r_d20_100 RepeatRoller( n=100, source=ValueRoller(value=H(20), annotation=''), annotation='', ) >>> all(outcome in d20 for outcome in r_d20_100.roll().outcomes()) True ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_n\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , n : SupportsInt , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _n = as_int ( n ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( n= { self . n !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . n == other . n @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls : List [ Roll ] = [] for _ in range ( self . n ): source_rolls . extend ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def n ( self ) -> int : r \"\"\" The number of times to \u201crepeat\u201d the roller\u2019s sole source. \"\"\" return self . _n","title":"RepeatRoller"},{"location":"dyce.r/#dyce.r.RepeatRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RepeatRoller.n","text":"The number of times to \u201crepeat\u201d the roller\u2019s sole source.","title":"n"},{"location":"dyce.r/#dyce.r.RepeatRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . n == other . n","title":"__eq__()"},{"location":"dyce.r/#dyce.r.RepeatRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , n : SupportsInt , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _n = as_int ( n )","title":"__init__()"},{"location":"dyce.r/#dyce.r.RepeatRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( n= { self . n !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.RepeatRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls : List [ Roll ] = [] for _ in range ( self . n ): source_rolls . extend ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.Roll","text":"Experimental This class should be considered experimental and may change or disappear in future versions. An immutable roll result (or \u201croll\u201d for short). More specifically, the result of calling the R.roll method . Rolls are sequences of RollOutcome objects that can be assembled into trees. Source code in dyce/r.py class Roll ( Sequence [ RollOutcome ]): r \"\"\" !!! warning \"Experimental\" This class should be considered experimental and may change or disappear in future versions. An immutable roll result (or \u201croll\u201d for short). More specifically, the result of calling the [``R.roll`` method][dyce.r.R.roll]. Rolls are sequences of [``RollOutcome`` objects][dyce.r.RollOutcome] that can be assembled into trees. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_r\" , \"_roll_outcomes\" , \"_source_rolls\" ) # ---- Initializer ----------------------------------------------------------------- @experimental @beartype def __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ \"Roll\" ] = (), ): r \"\"\" Initializer. This initializer will associate each of *roll_outcomes* with the newly constructed roll if they do not already have a [``source_roll``][dyce.r.RollOutcome.source_roll]. ``` python >>> r_4 = ValueRoller(4) >>> roll = r_4.roll() >>> new_roll = Roll(r_4, roll) ; new_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) >>> roll[0].source_roll == roll True >>> roll[0].r == r_4 True ``` !!! note Technically, this violates the immutability of roll outcomes. ``dyce`` does not generally contemplate creation of rolls or roll outcomes outside the womb of [``R.roll``][dyce.r.R.roll] implementations. [``Roll``][dyce.r.Roll] and [``RollOutcome``][dyce.r.RollOutcome] objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the [``RollOutcome.source_roll`` property][dyce.r.RollOutcome.source_roll]. \"\"\" super () . __init__ () self . _r = r self . _roll_outcomes = tuple ( roll_outcomes ) self . _source_rolls = tuple ( source_rolls ) for roll_outcome in self . _roll_outcomes : if roll_outcome . _roll is None : roll_outcome . _roll = self # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( r= { indent ( repr ( self . r ), \" \" ) . strip () } , roll_outcomes=( { _seq_repr ( self ) } ), source_rolls=( { _seq_repr ( self . source_rolls ) } ), )\"\"\" @beartype def __len__ ( self ) -> int : return len ( self . _roll_outcomes ) @overload def __getitem__ ( self , key : SupportsIndex ) -> RollOutcome : ... @overload def __getitem__ ( self , key : slice ) -> Tuple [ RollOutcome , ... ]: ... @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( # type: ignore [override] self , key : _GetItemT , ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]]: if isinstance ( key , slice ): return self . _roll_outcomes [ key ] else : return self . _roll_outcomes [ __index__ ( key )] @beartype def __iter__ ( self ) -> Iterator [ RollOutcome ]: return iter ( self . _roll_outcomes ) # ---- Properties ------------------------------------------------------------------ @property def annotation ( self ) -> Any : r \"\"\" Shorthand for ``#!python self.r.annotation``. See the [``R.annotation`` property][dyce.r.R.annotation]. \"\"\" return self . r . annotation @property def r ( self ) -> R : r \"\"\" The roller that generated the roll. \"\"\" return self . _r @property def source_rolls ( self ) -> Tuple [ Roll , ... ]: r \"\"\" The source rolls from which this roll was generated. \"\"\" return self . _source_rolls # ---- Methods --------------------------------------------------------------------- @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> Roll : r \"\"\" Shorthand for ``#!python Roll(self.r, (roll_outcome.adopt(sources, coalesce_mode) for roll_outcome in self), self.source_rolls)``. \"\"\" return type ( self )( self . r , ( roll_outcome . adopt ( sources , coalesce_mode ) for roll_outcome in self ), self . source_rolls , ) @beartype def outcomes ( self ) -> Iterator [ RealLike ]: r \"\"\" Shorthand for ``#!python (roll_outcome.value for roll_outcome in self if roll_outcome.value is not None)``. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056410) -- END MONKEY PATCH --> !!! info Unlike [``H.roll``][dyce.h.H.roll] and [``P.roll``][dyce.p.P.roll], these outcomes are *not* sorted. Instead, they retain the ordering as passed to [``__init__``][dyce.r.Roll.__init__]. ``` python >>> r_3d6 = 3@R.from_value(H(6)) >>> r_3d6_neg = 3@-R.from_value(H(6)) >>> roll = R.from_sources(r_3d6, r_3d6_neg).roll() >>> tuple(roll.outcomes()) (1, 3, 1, -4, -6, -1) >>> len(roll) 6 ``` \"\"\" return ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) @beartype def total ( self ) -> RealLike : r \"\"\" Shorthand for ``#!python sum(self.outcomes())``. \"\"\" return sum ( self . outcomes ())","title":"Roll"},{"location":"dyce.r/#dyce.r.Roll.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.Roll.annotation","text":"Shorthand for self . r . annotation . See the R.annotation property .","title":"annotation"},{"location":"dyce.r/#dyce.r.Roll.r","text":"The roller that generated the roll.","title":"r"},{"location":"dyce.r/#dyce.r.Roll.source_rolls","text":"The source rolls from which this roll was generated.","title":"source_rolls"},{"location":"dyce.r/#dyce.r.Roll.__getitem__","text":"Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( # type: ignore [override] self , key : _GetItemT , ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]]: if isinstance ( key , slice ): return self . _roll_outcomes [ key ] else : return self . _roll_outcomes [ __index__ ( key )]","title":"__getitem__()"},{"location":"dyce.r/#dyce.r.Roll.__init__","text":"Initializer. This initializer will associate each of roll_outcomes with the newly constructed roll if they do not already have a source_roll . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_4 = ValueRoller ( 4 ) >>> roll = r_4 . roll () >>> new_roll = Roll ( r_4 , roll ) ; new_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ) >>> roll [ 0 ] . source_roll == roll True >>> roll [ 0 ] . r == r_4 True Note Technically, this violates the immutability of roll outcomes. dyce does not generally contemplate creation of rolls or roll outcomes outside the womb of R.roll implementations. Roll and RollOutcome objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the RollOutcome.source_roll property . Source code in dyce/r.py @experimental @beartype def __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ \"Roll\" ] = (), ): r \"\"\" Initializer. This initializer will associate each of *roll_outcomes* with the newly constructed roll if they do not already have a [``source_roll``][dyce.r.RollOutcome.source_roll]. ``` python >>> r_4 = ValueRoller(4) >>> roll = r_4.roll() >>> new_roll = Roll(r_4, roll) ; new_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) >>> roll[0].source_roll == roll True >>> roll[0].r == r_4 True ``` !!! note Technically, this violates the immutability of roll outcomes. ``dyce`` does not generally contemplate creation of rolls or roll outcomes outside the womb of [``R.roll``][dyce.r.R.roll] implementations. [``Roll``][dyce.r.Roll] and [``RollOutcome``][dyce.r.RollOutcome] objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the [``RollOutcome.source_roll`` property][dyce.r.RollOutcome.source_roll]. \"\"\" super () . __init__ () self . _r = r self . _roll_outcomes = tuple ( roll_outcomes ) self . _source_rolls = tuple ( source_rolls ) for roll_outcome in self . _roll_outcomes : if roll_outcome . _roll is None : roll_outcome . _roll = self","title":"__init__()"},{"location":"dyce.r/#dyce.r.Roll.__iter__","text":"Source code in dyce/r.py @beartype def __iter__ ( self ) -> Iterator [ RollOutcome ]: return iter ( self . _roll_outcomes )","title":"__iter__()"},{"location":"dyce.r/#dyce.r.Roll.__len__","text":"Source code in dyce/r.py @beartype def __len__ ( self ) -> int : return len ( self . _roll_outcomes )","title":"__len__()"},{"location":"dyce.r/#dyce.r.Roll.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( r= { indent ( repr ( self . r ), \" \" ) . strip () } , roll_outcomes=( { _seq_repr ( self ) } ), source_rolls=( { _seq_repr ( self . source_rolls ) } ), )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.Roll.adopt","text":"Shorthand for Roll ( self . r , ( roll_outcome . adopt ( sources , coalesce_mode ) for roll_outcome in self ), self . source_rolls ) . Source code in dyce/r.py @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> Roll : r \"\"\" Shorthand for ``#!python Roll(self.r, (roll_outcome.adopt(sources, coalesce_mode) for roll_outcome in self), self.source_rolls)``. \"\"\" return type ( self )( self . r , ( roll_outcome . adopt ( sources , coalesce_mode ) for roll_outcome in self ), self . source_rolls , )","title":"adopt()"},{"location":"dyce.r/#dyce.r.Roll.outcomes","text":"Shorthand for ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) . Info Unlike H.roll and P.roll , these outcomes are not sorted. Instead, they retain the ordering as passed to __init__ . 1 2 3 4 5 6 7 >>> r_3d6 = 3 @R . from_value ( H ( 6 )) >>> r_3d6_neg = 3 @- R . from_value ( H ( 6 )) >>> roll = R . from_sources ( r_3d6 , r_3d6_neg ) . roll () >>> tuple ( roll . outcomes ()) ( 1 , 3 , 1 , - 4 , - 6 , - 1 ) >>> len ( roll ) 6 Source code in dyce/r.py @beartype def outcomes ( self ) -> Iterator [ RealLike ]: r \"\"\" Shorthand for ``#!python (roll_outcome.value for roll_outcome in self if roll_outcome.value is not None)``. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056410) -- END MONKEY PATCH --> !!! info Unlike [``H.roll``][dyce.h.H.roll] and [``P.roll``][dyce.p.P.roll], these outcomes are *not* sorted. Instead, they retain the ordering as passed to [``__init__``][dyce.r.Roll.__init__]. ``` python >>> r_3d6 = 3@R.from_value(H(6)) >>> r_3d6_neg = 3@-R.from_value(H(6)) >>> roll = R.from_sources(r_3d6, r_3d6_neg).roll() >>> tuple(roll.outcomes()) (1, 3, 1, -4, -6, -1) >>> len(roll) 6 ``` \"\"\" return ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None )","title":"outcomes()"},{"location":"dyce.r/#dyce.r.Roll.total","text":"Shorthand for sum ( self . outcomes ()) . Source code in dyce/r.py @beartype def total ( self ) -> RealLike : r \"\"\" Shorthand for ``#!python sum(self.outcomes())``. \"\"\" return sum ( self . outcomes ())","title":"total()"},{"location":"dyce.r/#dyce.r.RollOutcome","text":"Experimental This class should be considered experimental and may change or disappear in future versions. A single, ( mostly ) immutable outcome generated by a roll. Source code in dyce/r.py class RollOutcome : r \"\"\" !!! warning \"Experimental\" This class should be considered experimental and may change or disappear in future versions. A single, ([mostly][dyce.r.Roll.__init__]) immutable outcome generated by a roll. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_roll\" , \"_sources\" , \"_value\" ) # ---- Initializer ----------------------------------------------------------------- @experimental @beartype def __init__ ( self , value : Optional [ RealLike ], sources : Iterable [ \"RollOutcome\" ] = (), ): r \"Initializer.\" super () . __init__ () self . _value = value self . _sources = tuple ( sources ) self . _roll : Optional [ Roll ] = None if self . _value is None and not self . _sources : raise ValueError ( \"value can only be None if sources is non-empty\" ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( value= { repr ( self . value ) } , sources=( { _seq_repr ( self . sources ) } ), )\"\"\" @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __lt__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __lt__ ( self . value , other . value )) else : return NotImplemented @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __le__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __le__ ( self . value , other . value )) else : return NotImplemented @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __eq__ ( self . value , other . value )) else : return super () . __eq__ ( other ) @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ne__ ( self . value , other . value )) else : return super () . __ne__ ( other ) @beartype def __gt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __gt__ ( self . value , other . value )) else : return NotImplemented @beartype def __ge__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ge__ ( self . value , other . value )) else : return NotImplemented @beartype def __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented @beartype def __radd__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented @beartype def __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented @beartype def __rsub__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented @beartype def __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmul__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented @beartype def __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rtruediv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented @beartype def __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented @beartype def __rfloordiv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented @beartype def __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented @beartype def __rmod__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented @beartype def __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented @beartype def __rpow__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented @beartype def __and__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __rand__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __xor__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __rxor__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __or__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __ror__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented @beartype def __neg__ ( self ) -> RollOutcome : return self . umap ( __neg__ ) @beartype def __pos__ ( self ) -> RollOutcome : return self . umap ( __pos__ ) @beartype def __abs__ ( self ) -> RollOutcome : return self . umap ( __abs__ ) @beartype def __invert__ ( self ) -> RollOutcome : return self . umap ( __invert__ ) # ---- Properties ------------------------------------------------------------------ @property def annotation ( self ) -> Any : r \"\"\" Shorthand for ``#!python self.source_roll.annotation``. See the [``source_roll``][dyce.r.RollOutcome.source_roll] and [``Roll.annotation``][dyce.r.Roll.annotation] properties. \"\"\" return self . source_roll . annotation @property def r ( self ) -> R : r \"\"\" Shorthand for ``#!python self.source_roll.r``. See the [``source_roll``][dyce.r.RollOutcome.source_roll] and [``Roll.r``][dyce.r.Roll.r] properties. \"\"\" return self . source_roll . r @property def source_roll ( self ) -> Roll : r \"\"\" Returns the roll if one has been associated with this roll outcome. Usually that happens by submitting the roll outcome to the [``Roll.__init__`` method][dyce.r.Roll.__init__] inside a [``R.roll`` method][dyce.r.R.roll] implementation. Accessing this property before the roll outcome has been associated with a roll is considered a programming error. ``` python >>> ro = RollOutcome(4) >>> ro.source_roll Traceback (most recent call last): ... AssertionError: RollOutcome.source_roll accessed before associating the roll outcome with a roll (usually via Roll.__init__) assert None is not None >>> roll = Roll(R.from_value(4), roll_outcomes=(ro,)) >>> ro.source_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) ``` \"\"\" assert ( self . _roll is not None ), \"RollOutcome.source_roll accessed before associating the roll outcome with a roll (usually via Roll.__init__)\" return self . _roll @property def sources ( self ) -> Tuple [ RollOutcome , ... ]: r \"\"\" The source roll outcomes from which this roll outcome was generated. \"\"\" return self . _sources @property def value ( self ) -> Optional [ RealLike ]: r \"\"\" The outcome value. A value of ``#!python None`` is used to signal that a source\u2019s roll outcome was excluded by the roller. \"\"\" return self . _value # ---- Methods --------------------------------------------------------------------- @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT , ) -> RollOutcome : r \"\"\" Applies *bin_op* to the value of this roll outcome as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.map(operator.__pow__, 10) RollOutcome( value=1024, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.map(operator.__pow__, 10) == two ** 10 True ``` \"\"\" if isinstance ( right_operand , RollOutcome ): sources : Tuple [ RollOutcome , ... ] = ( self , right_operand ) right_operand_value : Optional [ RealLike ] = right_operand . value else : sources = ( self ,) right_operand_value = right_operand if isinstance ( right_operand_value , RealLike ): return type ( self )( bin_op ( self . value , right_operand_value ), sources ) else : raise NotImplementedError @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> RollOutcome : r \"\"\" Analogous to the [``map`` method][dyce.r.RollOutcome.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.rmap(10, operator.__pow__) RollOutcome( value=100, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.rmap(10, operator.__pow__) == 10 ** two True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.RollOutcome.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return type ( self )( bin_op ( left_operand , self . value ), sources = ( self ,)) else : raise NotImplementedError @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> RollOutcome : r \"\"\" Applies *un_op* to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two_neg = RollOutcome(-2) >>> two_neg.umap(operator.__neg__) RollOutcome( value=2, sources=( RollOutcome( value=-2, sources=(), ), ), ) >>> two_neg.umap(operator.__neg__) == -two_neg True ``` \"\"\" return type ( self )( un_op ( self . value ), sources = ( self ,)) @beartype def lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __lt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __lt__ ( self . value , other )), sources = ( self ,)) @beartype def le ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __le__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __le__ ( self . value , other )), sources = ( self ,)) @beartype def eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __eq__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __eq__ ( self . value , other )), sources = ( self ,)) @beartype def ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ne__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ne__ ( self . value , other )), sources = ( self ,)) @beartype def gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __gt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __gt__ ( self . value , other )), sources = ( self ,)) @beartype def ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ge__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ge__ ( self . value , other )), sources = ( self ,)) @beartype def is_even ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_even ) @beartype def is_odd ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_odd ) @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> RollOutcome : r \"\"\" Creates and returns a new roll outcome identical to this roll outcome, but with *sources* replacing or appended to this roll outcome\u2019s sources in accordance with *coalesce_mode*. ``` python >>> from dyce.r import CoalesceMode >>> orig = RollOutcome(1, sources=(RollOutcome(2),)) ; orig RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.REPLACE) RollOutcome( value=1, sources=( RollOutcome( value=3, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.APPEND) RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), ) ``` \"\"\" if coalesce_mode is CoalesceMode . REPLACE : adopted_sources = sources elif coalesce_mode is CoalesceMode . APPEND : adopted_sources = chain ( self . sources , sources ) else : assert False , f \"unrecognized substitution mode { self . coalesce_mode !r} \" adopted_roll_outcome = type ( self )( self . value , adopted_sources ) adopted_roll_outcome . _roll = self . _roll return adopted_roll_outcome @beartype def euthanize ( self ) -> RollOutcome : r \"\"\" Shorthand for ``#!python self.umap(lambda operand: None)``. ``` python >>> two = RollOutcome(2) >>> two.euthanize() RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ) ``` See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" def _euthanize ( operand : Optional [ RealLike ]) -> Optional [ RealLike ]: return None return self . umap ( _euthanize )","title":"RollOutcome"},{"location":"dyce.r/#dyce.r.RollOutcome.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RollOutcome.annotation","text":"Shorthand for self . source_roll . annotation . See the source_roll and Roll.annotation properties.","title":"annotation"},{"location":"dyce.r/#dyce.r.RollOutcome.r","text":"Shorthand for self . source_roll . r . See the source_roll and Roll.r properties.","title":"r"},{"location":"dyce.r/#dyce.r.RollOutcome.source_roll","text":"Returns the roll if one has been associated with this roll outcome. Usually that happens by submitting the roll outcome to the Roll.__init__ method inside a R.roll method implementation. Accessing this property before the roll outcome has been associated with a roll is considered a programming error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> ro = RollOutcome ( 4 ) >>> ro . source_roll Traceback ( most recent call last ): ... AssertionError : RollOutcome . source_roll accessed before associating the roll outcome with a roll ( usually via Roll . __init__ ) assert None is not None >>> roll = Roll ( R . from_value ( 4 ), roll_outcomes = ( ro ,)) >>> ro . source_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), )","title":"source_roll"},{"location":"dyce.r/#dyce.r.RollOutcome.sources","text":"The source roll outcomes from which this roll outcome was generated.","title":"sources"},{"location":"dyce.r/#dyce.r.RollOutcome.value","text":"The outcome value. A value of None is used to signal that a source\u2019s roll outcome was excluded by the roller.","title":"value"},{"location":"dyce.r/#dyce.r.RollOutcome.__abs__","text":"Source code in dyce/r.py @beartype def __abs__ ( self ) -> RollOutcome : return self . umap ( __abs__ )","title":"__abs__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__add__","text":"Source code in dyce/r.py @beartype def __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented","title":"__add__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__and__","text":"Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__and__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __eq__ ( self . value , other . value )) else : return super () . __eq__ ( other )","title":"__eq__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__floordiv__","text":"Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented","title":"__floordiv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__ge__","text":"Source code in dyce/r.py @beartype def __ge__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ge__ ( self . value , other . value )) else : return NotImplemented","title":"__ge__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__gt__","text":"Source code in dyce/r.py @beartype def __gt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __gt__ ( self . value , other . value )) else : return NotImplemented","title":"__gt__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__init__","text":"Initializer. Source code in dyce/r.py @experimental @beartype def __init__ ( self , value : Optional [ RealLike ], sources : Iterable [ \"RollOutcome\" ] = (), ): r \"Initializer.\" super () . __init__ () self . _value = value self . _sources = tuple ( sources ) self . _roll : Optional [ Roll ] = None if self . _value is None and not self . _sources : raise ValueError ( \"value can only be None if sources is non-empty\" )","title":"__init__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__invert__","text":"Source code in dyce/r.py @beartype def __invert__ ( self ) -> RollOutcome : return self . umap ( __invert__ )","title":"__invert__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__le__","text":"Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __le__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __le__ ( self . value , other . value )) else : return NotImplemented","title":"__le__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__lt__","text":"Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/10943> def __lt__ ( self , other : _RollOutcomeOperandT ) -> bool : # type: ignore [has-type] if isinstance ( other , RollOutcome ): return bool ( __lt__ ( self . value , other . value )) else : return NotImplemented","title":"__lt__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__mod__","text":"Source code in dyce/r.py @beartype def __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented","title":"__mod__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__mul__","text":"Source code in dyce/r.py @beartype def __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented","title":"__mul__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__ne__","text":"Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ne__ ( self . value , other . value )) else : return super () . __ne__ ( other )","title":"__ne__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__neg__","text":"Source code in dyce/r.py @beartype def __neg__ ( self ) -> RollOutcome : return self . umap ( __neg__ )","title":"__neg__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__or__","text":"Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__or__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__pos__","text":"Source code in dyce/r.py @beartype def __pos__ ( self ) -> RollOutcome : return self . umap ( __pos__ )","title":"__pos__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__pow__","text":"Source code in dyce/r.py @beartype def __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented","title":"__pow__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__radd__","text":"Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented","title":"__radd__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rand__","text":"Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rand__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( value= { repr ( self . value ) } , sources=( { _seq_repr ( self . sources ) } ), )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rfloordiv__","text":"Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented","title":"__rfloordiv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rmod__","text":"Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented","title":"__rmod__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rmul__","text":"Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented","title":"__rmul__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__ror__","text":"Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__ror__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rpow__","text":"Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented","title":"__rpow__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rsub__","text":"Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented","title":"__rsub__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rtruediv__","text":"Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLike ) -> RollOutcome : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented","title":"__rtruediv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rxor__","text":"Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsInt ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rxor__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__sub__","text":"Source code in dyce/r.py @beartype def __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented","title":"__sub__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__truediv__","text":"Source code in dyce/r.py @beartype def __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented","title":"__truediv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__xor__","text":"Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ \"RollOutcome\" , SupportsInt ]) -> RollOutcome : try : if isinstance ( other , SupportsInt ): other = as_int ( other ) return self . map ( __xor__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__xor__()"},{"location":"dyce.r/#dyce.r.RollOutcome.adopt","text":"Creates and returns a new roll outcome identical to this roll outcome, but with sources replacing or appended to this roll outcome\u2019s sources in accordance with coalesce_mode . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 >>> from dyce.r import CoalesceMode >>> orig = RollOutcome ( 1 , sources = ( RollOutcome ( 2 ),)) ; orig RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> orig . adopt (( RollOutcome ( 3 ),), coalesce_mode = CoalesceMode . REPLACE ) RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 3 , sources = (), ), ), ) >>> orig . adopt (( RollOutcome ( 3 ),), coalesce_mode = CoalesceMode . APPEND ) RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), ) Source code in dyce/r.py @beartype def adopt ( self , sources : Iterable [ \"RollOutcome\" ] = (), coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , ) -> RollOutcome : r \"\"\" Creates and returns a new roll outcome identical to this roll outcome, but with *sources* replacing or appended to this roll outcome\u2019s sources in accordance with *coalesce_mode*. ``` python >>> from dyce.r import CoalesceMode >>> orig = RollOutcome(1, sources=(RollOutcome(2),)) ; orig RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.REPLACE) RollOutcome( value=1, sources=( RollOutcome( value=3, sources=(), ), ), ) >>> orig.adopt((RollOutcome(3),), coalesce_mode=CoalesceMode.APPEND) RollOutcome( value=1, sources=( RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), ) ``` \"\"\" if coalesce_mode is CoalesceMode . REPLACE : adopted_sources = sources elif coalesce_mode is CoalesceMode . APPEND : adopted_sources = chain ( self . sources , sources ) else : assert False , f \"unrecognized substitution mode { self . coalesce_mode !r} \" adopted_roll_outcome = type ( self )( self . value , adopted_sources ) adopted_roll_outcome . _roll = self . _roll return adopted_roll_outcome","title":"adopt()"},{"location":"dyce.r/#dyce.r.RollOutcome.eq","text":"Source code in dyce/r.py @beartype def eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __eq__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __eq__ ( self . value , other )), sources = ( self ,))","title":"eq()"},{"location":"dyce.r/#dyce.r.RollOutcome.euthanize","text":"Shorthand for self . umap ( lambda operand : None ) . 1 2 3 4 5 6 7 8 9 10 11 >>> two = RollOutcome ( 2 ) >>> two . euthanize () RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) See the umap method . Source code in dyce/r.py @beartype def euthanize ( self ) -> RollOutcome : r \"\"\" Shorthand for ``#!python self.umap(lambda operand: None)``. ``` python >>> two = RollOutcome(2) >>> two.euthanize() RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ) ``` See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" def _euthanize ( operand : Optional [ RealLike ]) -> Optional [ RealLike ]: return None return self . umap ( _euthanize )","title":"euthanize()"},{"location":"dyce.r/#dyce.r.RollOutcome.ge","text":"Source code in dyce/r.py @beartype def ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ge__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ge__ ( self . value , other )), sources = ( self ,))","title":"ge()"},{"location":"dyce.r/#dyce.r.RollOutcome.gt","text":"Source code in dyce/r.py @beartype def gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __gt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __gt__ ( self . value , other )), sources = ( self ,))","title":"gt()"},{"location":"dyce.r/#dyce.r.RollOutcome.is_even","text":"Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_even )","title":"is_even()"},{"location":"dyce.r/#dyce.r.RollOutcome.is_odd","text":"Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_odd )","title":"is_odd()"},{"location":"dyce.r/#dyce.r.RollOutcome.le","text":"Source code in dyce/r.py @beartype def le ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __le__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __le__ ( self . value , other )), sources = ( self ,))","title":"le()"},{"location":"dyce.r/#dyce.r.RollOutcome.lt","text":"Source code in dyce/r.py @beartype def lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __lt__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __lt__ ( self . value , other )), sources = ( self ,))","title":"lt()"},{"location":"dyce.r/#dyce.r.RollOutcome.map","text":"Applies bin_op to the value of this roll outcome as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . map ( operator . __pow__ , 10 ) RollOutcome ( value = 1024 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . map ( operator . __pow__ , 10 ) == two ** 10 True Source code in dyce/r.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT , ) -> RollOutcome : r \"\"\" Applies *bin_op* to the value of this roll outcome as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.map(operator.__pow__, 10) RollOutcome( value=1024, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.map(operator.__pow__, 10) == two ** 10 True ``` \"\"\" if isinstance ( right_operand , RollOutcome ): sources : Tuple [ RollOutcome , ... ] = ( self , right_operand ) right_operand_value : Optional [ RealLike ] = right_operand . value else : sources = ( self ,) right_operand_value = right_operand if isinstance ( right_operand_value , RealLike ): return type ( self )( bin_op ( self . value , right_operand_value ), sources ) else : raise NotImplementedError","title":"map()"},{"location":"dyce.r/#dyce.r.RollOutcome.ne","text":"Source code in dyce/r.py @beartype def ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return type ( self )( bool ( __ne__ ( self . value , other . value )), sources = ( self , other ) ) else : return type ( self )( bool ( __ne__ ( self . value , other )), sources = ( self ,))","title":"ne()"},{"location":"dyce.r/#dyce.r.RollOutcome.rmap","text":"Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . rmap ( 10 , operator . __pow__ ) RollOutcome ( value = 100 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . rmap ( 10 , operator . __pow__ ) == 10 ** two True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : RealLike , bin_op : _BinaryOperatorT ) -> RollOutcome : r \"\"\" Analogous to the [``map`` method][dyce.r.RollOutcome.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.rmap(10, operator.__pow__) RollOutcome( value=100, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.rmap(10, operator.__pow__) == 10 ** two True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.RollOutcome.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLike ): return type ( self )( bin_op ( left_operand , self . value ), sources = ( self ,)) else : raise NotImplementedError","title":"rmap()"},{"location":"dyce.r/#dyce.r.RollOutcome.umap","text":"Applies un_op to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two_neg = RollOutcome ( - 2 ) >>> two_neg . umap ( operator . __neg__ ) RollOutcome ( value = 2 , sources = ( RollOutcome ( value =- 2 , sources = (), ), ), ) >>> two_neg . umap ( operator . __neg__ ) == - two_neg True Source code in dyce/r.py @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> RollOutcome : r \"\"\" Applies *un_op* to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two_neg = RollOutcome(-2) >>> two_neg.umap(operator.__neg__) RollOutcome( value=2, sources=( RollOutcome( value=-2, sources=(), ), ), ) >>> two_neg.umap(operator.__neg__) == -two_neg True ``` \"\"\" return type ( self )( un_op ( self . value ), sources = ( self ,))","title":"umap()"},{"location":"dyce.r/#dyce.r.RollWalkerVisitor","text":"Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each Roll object found. Source code in dyce/r.py class RollWalkerVisitor : r \"\"\" !!! warning \"Experimental\" This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with [``walk``][dyce.r.walk] called for each [``Roll`` object][dyce.r.Roll] found. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @abstractmethod def on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None : ...","title":"RollWalkerVisitor"},{"location":"dyce.r/#dyce.r.RollWalkerVisitor.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RollWalkerVisitor.on_roll","text":"Source code in dyce/r.py @abstractmethod def on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None : ...","title":"on_roll()"},{"location":"dyce.r/#dyce.r.RollerWalkerVisitor","text":"Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each R object found. Source code in dyce/r.py class RollerWalkerVisitor : r \"\"\" !!! warning \"Experimental\" This class (and its descendants) should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with [``walk``][dyce.r.walk] called for each [``R`` object][dyce.r.R] found. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = () # ---- Overrides ------------------------------------------------------------------- @abstractmethod def on_roller ( self , r : R , parents : Iterator [ R ]) -> None : ...","title":"RollerWalkerVisitor"},{"location":"dyce.r/#dyce.r.RollerWalkerVisitor.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RollerWalkerVisitor.on_roller","text":"Source code in dyce/r.py @abstractmethod def on_roller ( self , r : R , parents : Iterator [ R ]) -> None : ...","title":"on_roller()"},{"location":"dyce.r/#dyce.r.SelectionRoller","text":"A roller for sorting outcomes from its sources and applying a selector which . Roll outcomes in created rolls are ordered according to the selections which . However, those selections are interpreted as indexes in a sorted view of the source\u2019s roll outcomes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 >>> r_values = R . from_values ( 10000 , 1 , 1000 , 10 , 100 ) >>> outcomes = tuple ( r_values . roll () . outcomes ()) ; outcomes ( 10000 , 1 , 1000 , 10 , 100 ) >>> sorted_outcomes = tuple ( sorted ( outcomes )) ; sorted_outcomes ( 1 , 10 , 100 , 1000 , 10000 ) >>> which = ( 3 , 1 , 3 , 2 ) >>> tuple ( sorted_outcomes [ i ] for i in which ) ( 1000 , 10 , 1000 , 100 ) >>> r_select = r_values . select_iterable ( which ) ; r_select SelectionRoller ( which = ( 3 , 1 , 3 , 2 ), sources = ( PoolRoller ( sources = ( ValueRoller ( value = 10000 , annotation = '' ), ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 1000 , annotation = '' ), ValueRoller ( value = 10 , annotation = '' ), ValueRoller ( value = 100 , annotation = '' ), ), annotation = '' , ), ), annotation = '' , ) >>> roll = r_select . roll () >>> tuple ( roll . outcomes ()) ( 1000 , 10 , 1000 , 100 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 10 , sources = (), ), RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 100 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 10000 , sources = (), ), ), ), ), source_rolls =... , ) Source code in dyce/r.py class SelectionRoller ( R ): r \"\"\" A [roller][dyce.r.R] for sorting outcomes from its *sources* and applying a selector *which*. Roll outcomes in created rolls are ordered according to the selections *which*. However, those selections are interpreted as indexes in a *sorted* view of the source\u2019s roll outcomes. ``` python >>> r_values = R.from_values(10000, 1, 1000, 10, 100) >>> outcomes = tuple(r_values.roll().outcomes()) ; outcomes (10000, 1, 1000, 10, 100) >>> sorted_outcomes = tuple(sorted(outcomes)) ; sorted_outcomes (1, 10, 100, 1000, 10000) >>> which = (3, 1, 3, 2) >>> tuple(sorted_outcomes[i] for i in which) (1000, 10, 1000, 100) >>> r_select = r_values.select_iterable(which) ; r_select SelectionRoller( which=(3, 1, 3, 2), sources=( PoolRoller( sources=( ValueRoller(value=10000, annotation=''), ValueRoller(value=1, annotation=''), ValueRoller(value=1000, annotation=''), ValueRoller(value=10, annotation=''), ValueRoller(value=100, annotation=''), ), annotation='', ), ), annotation='', ) >>> roll = r_select.roll() >>> tuple(roll.outcomes()) (1000, 10, 1000, 100) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=1000, sources=(), ), RollOutcome( value=10, sources=(), ), RollOutcome( value=1000, sources=(), ), RollOutcome( value=100, sources=(), ), RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=None, sources=( RollOutcome( value=10000, sources=(), ), ), ), ), source_rolls=..., ) ``` \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_which\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _which = tuple ( which ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( which= { self . which !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . which == other . which @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) roll_outcomes = list ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ) roll_outcomes . sort ( key = attrgetter ( \"value\" )) all_indexes = tuple ( range ( len ( roll_outcomes ))) selected_indexes = tuple ( getitems ( all_indexes , self . which )) def _selected_roll_outcomes (): for selected_index in selected_indexes : selected_roll_outcome = roll_outcomes [ selected_index ] assert selected_roll_outcome . value is not None yield selected_roll_outcome for excluded_index in set ( all_indexes ) - set ( selected_indexes ): yield roll_outcomes [ excluded_index ] . euthanize () return Roll ( self , roll_outcomes = _selected_roll_outcomes (), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def which ( self ) -> Tuple [ _GetItemT , ... ]: r \"\"\" The selector this roller applies to the sorted outcomes of its sole source. \"\"\" return self . _which","title":"SelectionRoller"},{"location":"dyce.r/#dyce.r.SelectionRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.SelectionRoller.which","text":"The selector this roller applies to the sorted outcomes of its sole source.","title":"which"},{"location":"dyce.r/#dyce.r.SelectionRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . which == other . which","title":"__eq__()"},{"location":"dyce.r/#dyce.r.SelectionRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _which = tuple ( which )","title":"__init__()"},{"location":"dyce.r/#dyce.r.SelectionRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( which= { self . which !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.SelectionRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) roll_outcomes = list ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ) roll_outcomes . sort ( key = attrgetter ( \"value\" )) all_indexes = tuple ( range ( len ( roll_outcomes ))) selected_indexes = tuple ( getitems ( all_indexes , self . which )) def _selected_roll_outcomes (): for selected_index in selected_indexes : selected_roll_outcome = roll_outcomes [ selected_index ] assert selected_roll_outcome . value is not None yield selected_roll_outcome for excluded_index in set ( all_indexes ) - set ( selected_indexes ): yield roll_outcomes [ excluded_index ] . euthanize () return Roll ( self , roll_outcomes = _selected_roll_outcomes (), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.SubstitutionRoller","text":"A roller for applying expansion_op to determine when to roll new values up to max_depth times for incorporation via coalesce_mode . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 >>> from dyce.r import SubstitutionRoller >>> r_d6 = R . from_value ( H ( 6 )) >>> r_replace = SubstitutionRoller ( ... lambda outcome : RollOutcome ( 0 ) if outcome . value is not None and outcome . value <= 3 else outcome , ... r_d6 , ... ) >>> ( 2 @r_replace ) . roll () Roll ( r = RepeatRoller ( n = 2 , source = SubstitutionRoller ( expansion_op =< function < lambda > at ...> , source = ValueRoller ( value = H ( 6 ), annotation = '' ), coalesce_mode =< CoalesceMode . REPLACE : 1 > , max_depth = 1 , annotation = '' , ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 0 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( ... ), ) See the section on \u201c Filtering and substitution \u201d more examples. Source code in dyce/r.py class SubstitutionRoller ( R ): r \"\"\" A [roller][dyce.r.R] for applying *expansion_op* to determine when to roll new values up to *max_depth* times for incorporation via *coalesce_mode*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes. >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1639580307) -- END MONKEY PATCH --> ``` python >>> from dyce.r import SubstitutionRoller >>> r_d6 = R.from_value(H(6)) >>> r_replace = SubstitutionRoller( ... lambda outcome: RollOutcome(0) if outcome.value is not None and outcome.value <= 3 else outcome, ... r_d6, ... ) >>> (2@r_replace).roll() Roll( r=RepeatRoller( n=2, source=SubstitutionRoller( expansion_op=<function <lambda> at ...>, source=ValueRoller(value=H(6), annotation=''), coalesce_mode=<CoalesceMode.REPLACE: 1>, max_depth=1, annotation='', ), annotation='', ), roll_outcomes=( RollOutcome( value=0, sources=( RollOutcome( value=2, sources=(), ), ), ), RollOutcome( value=5, sources=(), ), ), source_rolls=(...), ) ``` See the section on \u201c[Filtering and substitution](rollin.md#filtering-and-substitution)\u201d more examples. \"\"\" __slots__ : Tuple [ str , ... ] = ( \"_coalesce_mode\" , \"_expansion_op\" , \"_max_depth\" ) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , expansion_op : _ExpansionOperatorT , source : _SourceT , coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , max_depth : SupportsInt = 1 , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _expansion_op = expansion_op self . _coalesce_mode = coalesce_mode self . _max_depth = as_int ( max_depth ) # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( expansion_op= { self . expansion_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , coalesce_mode= { self . coalesce_mode !r} , max_depth= { self . max_depth !r} , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return ( super () . __eq__ ( other ) and _callable_cmp ( self . expansion_op , other . expansion_op ) and self . coalesce_mode == other . coalesce_mode and self . max_depth == other . max_depth ) @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" ( source_roll ,) = self . source_rolls () source_rolls : List [ Roll ] = [] def _expanded_roll_outcomes ( roll : Roll , depth : int = 0 , ) -> Iterator [ RollOutcome ]: source_rolls . append ( roll ) roll_outcomes = ( roll_outcome for roll_outcome in roll if roll_outcome . value is not None ) if depth >= self . max_depth : yield from roll_outcomes return for roll_outcome in roll_outcomes : expanded = self . expansion_op ( roll_outcome ) if isinstance ( expanded , RollOutcome ): if expanded is not roll_outcome : expanded = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield expanded elif isinstance ( expanded , Roll ): if self . coalesce_mode == CoalesceMode . REPLACE : yield roll_outcome . euthanize () elif self . coalesce_mode == CoalesceMode . APPEND : yield roll_outcome else : assert ( False ), f \"unrecognized substitution mode { self . coalesce_mode !r} \" expanded_roll = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield from _expanded_roll_outcomes ( expanded_roll , depth + 1 ) else : assert False , f \"unrecognized type for expanded value { expanded !r} \" return Roll ( self , roll_outcomes = _expanded_roll_outcomes ( source_roll ), source_rolls = source_rolls , ) # ---- Properties ------------------------------------------------------------------ @property def max_depth ( self ) -> int : r \"\"\" The max number of times this roller will attempt to substitute an outcome satisfying its [``expansion_op``][dyce.r.SubstitutionRoller.expansion_op]. \"\"\" return self . _max_depth @property def expansion_op ( self ) -> _ExpansionOperatorT : r \"\"\" The expansion operator this roller applies to decide whether to substitute outcomes. \"\"\" return self . _expansion_op @property def coalesce_mode ( self ) -> CoalesceMode : r \"\"\" The coalesce mode this roller uses to incorporate substituted outcomes. \"\"\" return self . _coalesce_mode","title":"SubstitutionRoller"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.coalesce_mode","text":"The coalesce mode this roller uses to incorporate substituted outcomes.","title":"coalesce_mode"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.expansion_op","text":"The expansion operator this roller applies to decide whether to substitute outcomes.","title":"expansion_op"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.max_depth","text":"The max number of times this roller will attempt to substitute an outcome satisfying its expansion_op .","title":"max_depth"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return ( super () . __eq__ ( other ) and _callable_cmp ( self . expansion_op , other . expansion_op ) and self . coalesce_mode == other . coalesce_mode and self . max_depth == other . max_depth )","title":"__eq__()"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , expansion_op : _ExpansionOperatorT , source : _SourceT , coalesce_mode : CoalesceMode = CoalesceMode . REPLACE , max_depth : SupportsInt = 1 , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _expansion_op = expansion_op self . _coalesce_mode = coalesce_mode self . _max_depth = as_int ( max_depth )","title":"__init__()"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( expansion_op= { self . expansion_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , coalesce_mode= { self . coalesce_mode !r} , max_depth= { self . max_depth !r} , annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.SubstitutionRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" ( source_roll ,) = self . source_rolls () source_rolls : List [ Roll ] = [] def _expanded_roll_outcomes ( roll : Roll , depth : int = 0 , ) -> Iterator [ RollOutcome ]: source_rolls . append ( roll ) roll_outcomes = ( roll_outcome for roll_outcome in roll if roll_outcome . value is not None ) if depth >= self . max_depth : yield from roll_outcomes return for roll_outcome in roll_outcomes : expanded = self . expansion_op ( roll_outcome ) if isinstance ( expanded , RollOutcome ): if expanded is not roll_outcome : expanded = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield expanded elif isinstance ( expanded , Roll ): if self . coalesce_mode == CoalesceMode . REPLACE : yield roll_outcome . euthanize () elif self . coalesce_mode == CoalesceMode . APPEND : yield roll_outcome else : assert ( False ), f \"unrecognized substitution mode { self . coalesce_mode !r} \" expanded_roll = expanded . adopt (( roll_outcome ,), CoalesceMode . APPEND ) yield from _expanded_roll_outcomes ( expanded_roll , depth + 1 ) else : assert False , f \"unrecognized type for expanded value { expanded !r} \" return Roll ( self , roll_outcomes = _expanded_roll_outcomes ( source_roll ), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller","text":"An NarySumOpRoller for applying a unary operator un_op to the sum of all outcomes from its sole source . Source code in dyce/r.py class UnarySumOpRoller ( NarySumOpRoller ): r \"\"\" An [``NarySumOpRoller``][dyce.r.NarySumOpRoller] for applying a unary operator *un_op* to the sum of all outcomes from its sole *source*. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_un_op\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: ( operand ,) = roll_outcomes return un_op ( operand ) super () . __init__ ( op = _op , sources = ( source ,), annotation = annotation , ** kw ) self . _un_op = un_op # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( un_op= { self . un_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . un_op , other . un_op )) # ---- Properties ------------------------------------------------------------------ @property def un_op ( self ) -> _RollOutcomeUnaryOperatorT : r \"\"\" The operator this roller applies to its sources. \"\"\" return self . _un_op","title":"UnarySumOpRoller"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.un_op","text":"The operator this roller applies to its sources.","title":"un_op"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . un_op , other . un_op ))","title":"__eq__()"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: ( operand ,) = roll_outcomes return un_op ( operand ) super () . __init__ ( op = _op , sources = ( source ,), annotation = annotation , ** kw ) self . _un_op = un_op","title":"__init__()"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( un_op= { self . un_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.ValueRoller","text":"A roller whose roll outcomes are derived from scalars, H objects , P objects , RollOutcome objects , or even Roll objects , instead of other source rollers. Source code in dyce/r.py class ValueRoller ( R ): r \"\"\" A [roller][dyce.r.R] whose roll outcomes are derived from scalars, [``H`` objects][dyce.h.H], [``P`` objects][dyce.p.P], [``RollOutcome`` objects][dyce.r.RollOutcome], or even [``Roll`` objects][dyce.r.Roll], instead of other source rollers. \"\"\" __slots__ : Union [ str , Iterable [ str ]] = ( \"_value\" ,) # ---- Initializer ----------------------------------------------------------------- @beartype def __init__ ( self , value : _ValueT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = (), annotation = annotation , ** kw ) if isinstance ( value , P ) and not value . is_homogeneous : warnings . warn ( f \"using a heterogeneous pool ( { value } ) is not recommended where traceability is important\" , stacklevel = 2 , ) self . _value = value # ---- Overrides ------------------------------------------------------------------- @beartype def __repr__ ( self ) -> str : return f \" { type ( self ) . __name__ } (value= { self . value !r} , annotation= { self . annotation !r} )\" @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" if isinstance ( self . value , P ): return Roll ( self , roll_outcomes = ( RollOutcome ( outcome ) for outcome in self . value . roll ()), ) elif isinstance ( self . value , H ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value . roll ()),)) elif isinstance ( self . value , RealLike ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value ),)) else : assert False , f \"unrecognized value type { self . value !r} \" # ---- Properties ------------------------------------------------------------------ @property def value ( self ) -> _ValueT : r \"\"\" The value to be emitted by this roller via its [``ValueRoller.roll`` method][dyce.r.ValueRoller.roll]. \"\"\" return self . _value","title":"ValueRoller"},{"location":"dyce.r/#dyce.r.ValueRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.ValueRoller.value","text":"The value to be emitted by this roller via its ValueRoller.roll method .","title":"value"},{"location":"dyce.r/#dyce.r.ValueRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , value : _ValueT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = (), annotation = annotation , ** kw ) if isinstance ( value , P ) and not value . is_homogeneous : warnings . warn ( f \"using a heterogeneous pool ( { value } ) is not recommended where traceability is important\" , stacklevel = 2 , ) self . _value = value","title":"__init__()"},{"location":"dyce.r/#dyce.r.ValueRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \" { type ( self ) . __name__ } (value= { self . value !r} , annotation= { self . annotation !r} )\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.ValueRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" if isinstance ( self . value , P ): return Roll ( self , roll_outcomes = ( RollOutcome ( outcome ) for outcome in self . value . roll ()), ) elif isinstance ( self . value , H ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value . roll ()),)) elif isinstance ( self . value , RealLike ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value ),)) else : assert False , f \"unrecognized value type { self . value !r} \"","title":"roll()"},{"location":"dyce.r/#dyce.r.walk","text":"Experimental This function should be considered experimental and may change or disappear in future versions. Walks through root , calling visitor for each matching object. No ordering guarantees are made. On the current implementation walk performs a breadth-first traversal of root , assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. Source code in dyce/r.py @experimental @beartype def walk ( root : Union [ Roll , R , RollOutcome ], visitor : Union [ RollWalkerVisitor , RollerWalkerVisitor , RollOutcomeWalkerVisitor ], ) -> None : r \"\"\" !!! warning \"Experimental\" This function should be considered experimental and may change or disappear in future versions. Walks through *root*, calling *visitor* for each matching object. No ordering guarantees are made. !!! info \"On the current implementation\" ``#!python walk`` performs a breadth-first traversal of *root*, assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. \"\"\" rolls : Dict [ int , Roll ] = {} rollers : Dict [ int , R ] = {} roll_outcomes : Dict [ int , RollOutcome ] = {} roll_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roller_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roll_outcome_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) queue = deque (( root ,)) roll : Roll r : R roll_outcome : RollOutcome while queue : obj = queue . popleft () if isinstance ( obj , Roll ): roll = obj if id ( roll ) not in rolls : rolls [ id ( roll )] = roll queue . append ( roll . r ) for i , roll_outcome in enumerate ( roll ): queue . append ( roll_outcome ) for source_roll in roll . source_rolls : roll_parent_ids [ id ( source_roll )] . add ( id ( roll )) queue . append ( source_roll ) elif isinstance ( obj , R ): r = obj if id ( r ) not in rollers : rollers [ id ( r )] = r for source_r in r . sources : roller_parent_ids [ id ( source_r )] . add ( id ( r )) queue . append ( source_r ) elif isinstance ( obj , RollOutcome ): roll_outcome = obj if id ( roll_outcome ) not in roll_outcomes : roll_outcomes [ id ( roll_outcome )] = roll_outcome for source_roll_outcome in roll_outcome . sources : roll_outcome_parent_ids [ id ( source_roll_outcome )] . add ( id ( roll_outcome ) ) queue . append ( source_roll_outcome ) if rolls and isinstance ( visitor , RollWalkerVisitor ): for roll_id , roll in rolls . items (): visitor . on_roll ( roll , ( rolls [ i ] for i in roll_parent_ids [ roll_id ])) if rollers and isinstance ( visitor , RollerWalkerVisitor ): for r_id , r in rollers . items (): visitor . on_roller ( r , ( rollers [ i ] for i in roller_parent_ids [ r_id ])) if roll_outcomes and isinstance ( visitor , RollOutcomeWalkerVisitor ): for roll_outcome_id , roll_outcome in roll_outcomes . items (): visitor . on_roll_outcome ( roll_outcome , ( roll_outcomes [ i ] for i in roll_outcome_parent_ids [ roll_outcome_id ]), )","title":"walk()"},{"location":"license/","text":"License and credits The MIT License (MIT) Copyright \u00a9 2015-2022 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contributors The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub \u2013 @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"License"},{"location":"license/#license-and-credits","text":"","title":"License and credits"},{"location":"license/#the-mit-license-mit","text":"Copyright \u00a9 2015-2022 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"license/#contributors","text":"The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub \u2013 @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"Contributors"},{"location":"notes/","text":"dyce release notes 0.5.1 Fixes broken binder links in docs. Adds precision_limit argument to H.substitute and H.explode . 0.5.0 Breaks dyce.viz out into anydyce . Removes use of numerary . types . \u2026 SCU types. Adds the H.foreach and P.foreach class methods. Migrates resolve_dependent_probability to the H.foreach class method. 0.4.5 Fixes this bullshit (no, really, I\u2019m serious this time). Adds FilterRoller . Adds SubstitutionRoller . 0.4.4 Removes \u2026_gh.png hack now that this dumpster fire is at least partially resolved. Refines Tension Pool example. Adds Ironsworn example. Removes faulty (correctly-derived, but misapplied) math in Risus \u201cEvens Up\u201d example. Adds detail around dependent probabilities. Adds experimental dyce.h.resolve_dependent_probability function. 0.4.3 Removes dependencies on deprecated numerary . types . \u2026 SCT tuples Adds Angry GM Tension Pool mechanic translation. 0.4.2 Removes calls to os . get_terminal_size to retain utility in environments without terminals. Fixes #5 . Thanks @sudo-simon! ! 0.4.1 Splits out protocol checking into its own fancy library: numerary ! Is now available on PyPI as dyce _ , thanks to the generosity of David Eyk ! Introduces experimental generic walk function and supporting visitor data structures. Uses pygraphviz to automate class diagram generation. (See the note on special considerations for regenerating class diagrams in the hacking quick start .) Introduces experimental use of numpy for RNG, if present. Migrates to using pyproject.toml and setup.cfg . Adds missing py.typed to ensure clients get type checking . (Whoops.) 0.4.0 Breaking changes Warning The following changes are not backward compatible. Please review before upgrading. Renames HAbleT and HAbleOpsMixin to HableT and HableOpsMixin . Uses alternate spellings. Removes deprecated non-flattening unary operation methods P . __neg__ and P . __pos__ . Uses, e.g., P . umap ( operator . __neg__ ) or P ( - h for h in p ) instead. Removes deprecated synonym methods H . even and H . odd . Uses H.is_even and H.is_odd instead. Removes deprecated synonym package dyce . plt . Uses dyce.viz instead. Removes special case handling of H ({}) for addition and subtraction. Check for code that relied on, e.g., h + H ({}) resolving to h . It is probably not correct. If the behavior is desired, consider eliminating empty histograms before performing calculations. E.G., h1 + h2 if h2 else h1 . See also the sum_h function , which ensures the result is always a histogram: 1 2 3 4 5 >>> from dyce.h import sum_h >>> sum (()) 0 >>> sum_h (()) H ({}) Note, however, that sums including empty histograms will be always result in empty histograms: 1 2 3 4 >>> from dyce import H >>> hs = ( H ( 6 ), H ( 6 ), H ( 6 ), H ({})) >>> sum_h ( hs ) H ({}) If a different result was desired, adapting our advice from above would yield something like: 1 2 >>> sum_h ( h for h in hs if h ) H ({ 3 : 1 , 4 : 3 , 5 : 6 , 6 : 10 , ... , 16 : 6 , 17 : 3 , 18 : 1 }) Other changes Documentation overhaul including augmented examples and reorganized images and JavaScript. Fixes H ({}) . format () bug. Adds beartype runtime type checking. Maintains support for Python 3.7 (for now). 0.3.2 Emergency release to cover up address this embarrassment typo . \ud83d\ude2c\ud83d\ude05 0.3.1 Adds these release notes. Boosts isinstance performance with dyce \u2019s proprietary numeric Protocol s. Reinstates support for Python 3.7 (for now) . Adds H.is_even and H.is_odd . Deprecates synonym methods H . even and H . odd . Introduces experimental H.total property. Removes incorrectly non-flattening unary operation methods P . __abs__ and P . __invert__ . Deprecates non-flattening unary operation methods P . __neg__ and P . __pos__ . Renames experimental P . homogeneous property to P.is_homogeneous . Introduces experimental R and Roll primitives. Removes coerce parameter from H.map , H.rmap , and H.umap . Renames dyce . plt to dyce.viz . Deprecates synonym package dyce . plt . 0.3.0 dyce goes beta! Non-experimental features should be considered stable.","title":"Release notes"},{"location":"notes/#dyce-release-notes","text":"","title":"dyce release notes"},{"location":"notes/#051","text":"Fixes broken binder links in docs. Adds precision_limit argument to H.substitute and H.explode .","title":"0.5.1"},{"location":"notes/#050","text":"Breaks dyce.viz out into anydyce . Removes use of numerary . types . \u2026 SCU types. Adds the H.foreach and P.foreach class methods. Migrates resolve_dependent_probability to the H.foreach class method.","title":"0.5.0"},{"location":"notes/#045","text":"Fixes this bullshit (no, really, I\u2019m serious this time). Adds FilterRoller . Adds SubstitutionRoller .","title":"0.4.5"},{"location":"notes/#044","text":"Removes \u2026_gh.png hack now that this dumpster fire is at least partially resolved. Refines Tension Pool example. Adds Ironsworn example. Removes faulty (correctly-derived, but misapplied) math in Risus \u201cEvens Up\u201d example. Adds detail around dependent probabilities. Adds experimental dyce.h.resolve_dependent_probability function.","title":"0.4.4"},{"location":"notes/#043","text":"Removes dependencies on deprecated numerary . types . \u2026 SCT tuples Adds Angry GM Tension Pool mechanic translation.","title":"0.4.3"},{"location":"notes/#042","text":"Removes calls to os . get_terminal_size to retain utility in environments without terminals. Fixes #5 . Thanks @sudo-simon! !","title":"0.4.2"},{"location":"notes/#041","text":"Splits out protocol checking into its own fancy library: numerary ! Is now available on PyPI as dyce _ , thanks to the generosity of David Eyk ! Introduces experimental generic walk function and supporting visitor data structures. Uses pygraphviz to automate class diagram generation. (See the note on special considerations for regenerating class diagrams in the hacking quick start .) Introduces experimental use of numpy for RNG, if present. Migrates to using pyproject.toml and setup.cfg . Adds missing py.typed to ensure clients get type checking . (Whoops.)","title":"0.4.1"},{"location":"notes/#040","text":"","title":"0.4.0"},{"location":"notes/#breaking-changes","text":"Warning The following changes are not backward compatible. Please review before upgrading. Renames HAbleT and HAbleOpsMixin to HableT and HableOpsMixin . Uses alternate spellings. Removes deprecated non-flattening unary operation methods P . __neg__ and P . __pos__ . Uses, e.g., P . umap ( operator . __neg__ ) or P ( - h for h in p ) instead. Removes deprecated synonym methods H . even and H . odd . Uses H.is_even and H.is_odd instead. Removes deprecated synonym package dyce . plt . Uses dyce.viz instead. Removes special case handling of H ({}) for addition and subtraction. Check for code that relied on, e.g., h + H ({}) resolving to h . It is probably not correct. If the behavior is desired, consider eliminating empty histograms before performing calculations. E.G., h1 + h2 if h2 else h1 . See also the sum_h function , which ensures the result is always a histogram: 1 2 3 4 5 >>> from dyce.h import sum_h >>> sum (()) 0 >>> sum_h (()) H ({}) Note, however, that sums including empty histograms will be always result in empty histograms: 1 2 3 4 >>> from dyce import H >>> hs = ( H ( 6 ), H ( 6 ), H ( 6 ), H ({})) >>> sum_h ( hs ) H ({}) If a different result was desired, adapting our advice from above would yield something like: 1 2 >>> sum_h ( h for h in hs if h ) H ({ 3 : 1 , 4 : 3 , 5 : 6 , 6 : 10 , ... , 16 : 6 , 17 : 3 , 18 : 1 })","title":"Breaking changes"},{"location":"notes/#other-changes","text":"Documentation overhaul including augmented examples and reorganized images and JavaScript. Fixes H ({}) . format () bug. Adds beartype runtime type checking. Maintains support for Python 3.7 (for now).","title":"Other changes"},{"location":"notes/#032","text":"Emergency release to cover up address this embarrassment typo . \ud83d\ude2c\ud83d\ude05","title":"0.3.2"},{"location":"notes/#031","text":"Adds these release notes. Boosts isinstance performance with dyce \u2019s proprietary numeric Protocol s. Reinstates support for Python 3.7 (for now) . Adds H.is_even and H.is_odd . Deprecates synonym methods H . even and H . odd . Introduces experimental H.total property. Removes incorrectly non-flattening unary operation methods P . __abs__ and P . __invert__ . Deprecates non-flattening unary operation methods P . __neg__ and P . __pos__ . Renames experimental P . homogeneous property to P.is_homogeneous . Introduces experimental R and Roll primitives. Removes coerce parameter from H.map , H.rmap , and H.umap . Renames dyce . plt to dyce.viz . Deprecates synonym package dyce . plt .","title":"0.3.1"},{"location":"notes/#030","text":"dyce goes beta! Non-experimental features should be considered stable.","title":"0.3.0"},{"location":"rollin/","text":"Experimental This functionality should be considered experimental. Be warned that future release may introduce incompatibilities or remove it altogether. Feedback, suggestions, and contributions are welcome and appreciated. dyce provides additional primitives for generating and inspecting rolls of weighted random outcomes without requiring the overhead of enumeration. 1 >>> from dyce import R R objects represent rollers. Rollers produce Roll objects . Roll objects are sequences of RollOutcome objects , which represent weighted random values. Each object can be a node in a tree-like structure. Rollers, for example, can represent scalars, histograms, pools, operators, etc., and can be assembled into trees representing more complex calculations. Rolls can derive from other rolls, forming trees that are generally analogous to the roller trees that generated them. Similarly, roll outcomes can derive from other roll outcomes. The simplest roller we can create represents a single value. Each roll it generates has that value as its sole outcome. Let\u2019s see what that looks like (now with tasty entity relationship diagrams). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> from dyce.r import ValueRoller >>> r_1 = ValueRoller ( 1 ) >>> roll = r_1 . roll () >>> roll . total () 1 >>> tuple ( roll . outcomes ()) ( 1 ,) >>> roll Roll ( r = ValueRoller ( value = 1 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), ), source_rolls = (), ) Hopefully, that\u2019s relatively straightforward. Let\u2019s look at some more substantial examples. Emulating a hundred-sided die using two ten-sided dice In many games it is common to emulate a hundred-sided die using a \u201cones\u201d ten-sided die (faces numbered \\([{ {0}, {1}, \\ldots , {9} }]\\) ) and a \u201ctens\u201d ten-sided die (faces numbered \\([{ {00}, {10}, \\ldots , {90} }]\\) ). Let\u2019s try to model that as a roller and use it to generate a roll. We start by creating two histograms 1 representing our two ten-sided dice ( d00 for our \u201ctens\u201d die and d10 for our \u201cones\u201c die). 1 2 3 >>> from dyce import H >>> d10 = H ( 10 ) - 1 >>> d00 = 10 * d10 Next, we create a roller using the R.from_values class method . 1 2 3 4 5 6 7 8 >>> r_d100 = R . from_values ( d00 , d10 ) ; r_d100 PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ) Well, wouldya look at that? That durned class method created a whole roller tree , which is actually three rollers. One ValueRoller for the d00 histogram; Another for the d10 histogram; and A PoolRoller for aggregating them both. Tip We could have also composed an identical tree using roller implementations from dyce.r instead of the R.from_values convenience method. 1 2 3 >>> from dyce.r import PoolRoller , ValueRoller >>> r_d100 == PoolRoller ( sources = ( ValueRoller ( d00 ), ValueRoller ( d10 ))) True Let\u2019s use our new roller to create a roll and retrieve its total. 1 2 3 >>> roll = r_d100 . roll () >>> roll . total () 69 No surprises there. Let\u2019s dig a little deeper and ask for the roll\u2019s outcome values. 1 2 >>> tuple ( roll . outcomes ()) ( 60 , 9 ) As we mentioned before, the top level of our roller tree is a PoolRoller , which aggregates (or \u201cpools\u201d) rolls from its sources. For our roll, the aggregated outcomes are 60 are 9 . What does our pooled roll look like? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 >>> roll Roll ( r = PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), RollOutcome ( value = 9 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 9 , sources = (), ), ), source_rolls = (), ), ), ) Let\u2019s break that down so it doesn\u2019t feel like trying to drink from a fire hose. Calling the R.roll method on our PoolRoller resulted in a Roll object . Actually, it resulted in a roll tree (analogous to our roller tree). Each Roll object in that tree has: A reference to the R object in the roller tree that generated it, retrieved via its r property ; Zero or more RollOutcome objects , retrieved by accessing the roll as a sequence (i.e., via __getitem__ , __len__ ); and Zero or more source rolls, retrieved via its source_rolls property . The RollOutcome objects also form trees (in our case, simple ones). Each one has: A single value, retrieved via its value property ; Zero or more source outcomes from which the value was derived, retrieved via its sources property ; and A reference back to the roll that generated it, retrieved via its source_roll property (omitted from the diagram for the sake of readability). Tip You might be wondering to yourself, \u201cSelf, one wonders, can one have a pool of pools?\u201d Such questions command the response, \u201cWhy the heck not? Try it!\u201d 1 2 3 4 5 6 >>> two_r_d100s = PoolRoller ( sources = ( r_d100 , r_d100 )) >>> roll_two = two_r_d100s . roll () >>> roll_two . total () 63 >>> tuple ( roll_two . outcomes ()) ( 40 , 2 , 20 , 1 ) So the answer is a resounding, \u201cOf course. What devious entity would prohibit such a thing? Please identify that creature so we may flog it until it achieves enlightenment,\u201d \u201cYes.\u201d Composing rollers with arithmetic Rollers support arithmetic operators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 >>> d12 = H ( 12 ) >>> r_d12_add_4 = ValueRoller ( d12 ) + 4 ; r_d12_add_4 BinarySumOpRoller ( bin_op =< built - in function add > , left_source = ValueRoller ( value = H ( 12 ), annotation = '' ), right_source = ValueRoller ( value = 4 , annotation = '' ), annotation = '' , ) >>> r_d12_add_4 . roll () Roll ( r = BinarySumOpRoller ( ... ), roll_outcomes = ( RollOutcome ( value = 11 , sources = ( RollOutcome ( value = 7 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 12 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 7 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ), ), ) Dropping dice from prior rolls \u2013 keeping the best three of 3d6 and 1d8 The trifecta of roller trees, roll trees, and outcome trees might appear complicated or redundant. Everything serves a purpose. 2 Consider excluding (or \u201cdropping\u201d) dice from a roll. How would we account for that? Let\u2019s see how to generate rolls that keep the best three outcomes from rolling three six-sided dice and one eight-sided die. We start by using the R.from_value class method to create ValueRoller s for histograms representing our six- and eight-sided dice. 1 2 3 4 5 6 >>> d6 = H ( 6 ) >>> d8 = H ( 8 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> r_d8 = R . from_value ( d8 ) ; r_d8 ValueRoller ( value = H ( 8 ), annotation = '' ) For homogeneous pools, we can use the matrix multiplication operator. 1 2 3 4 5 6 >>> r_3d6 = 3 @r_d6 ; r_3d6 RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) Finally, we\u2019ll create a SelectionRoller by calling the R.select_from_sources method on our other rollers. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> r_best_3_of_3d6_d8 = R . select_from_sources (( slice ( 1 , None ),), r_3d6 , r_d8 ) ; r_best_3_of_3d6_d8 SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ) Oh boy! Aren\u2019t you super excited to try this thing out? 1 2 3 >>> roll = r_best_3_of_3d6_d8 . roll () >>> tuple ( roll . outcomes ()) ( 1 , 5 , 6 ) There are indeed three values, despite starting with four dice. Given that the lowest value we see is a 1 , we might assume that the eliminated value is also a 1 . But, we all know what happens when one assumes. Recall that in roll trees, a roll may have references to other rolls (its \u201csource rolls\u201d) from which it derives. We should be able to get information about the dropped die by traversing that tree. Let\u2019s see if we can validate our assumption by looking at the outcomes from our roll\u2019s direct source. 1 2 3 >>> from itertools import chain >>> tuple ( chain . from_iterable ( source_roll . outcomes () for source_roll in roll . source_rolls )) ( 6 , 1 , 1 , 5 ) Yup! We were right! There\u2019s the other 1 , plain as day. Our work here is do\u2014 What? You want to know which die we eliminated? We can see that, too! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> roll Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 147 148 ), ) Oof. \u261d\ufe0f That was \u2026 a lot . Let\u2019s visualize! Holy entangled relationship diagrams, Batman! One thing you may notice about our top-level roll is that it has four outcomes. One of those kids is not like the others. Specifically, it has a value of None . That\u2019s our dropped outcome! 1 2 3 4 5 6 >>> len ( roll ) == 4 True >>> roll [ - 1 ] . value is None True >>> tuple ( roll_outcome . value for roll_outcome in roll ) ( 1 , 5 , 6 , None ) Info A roll outcome with a value of None is akin to a \u201ctombstone\u201d. It conveys one whose sources were present in immediately prior rolls but excluded from the current roll. Such roll outcomes must have at least one source. 1 2 3 4 5 >>> from dyce.r import RollOutcome >>> RollOutcome ( value = None ) Traceback ( most recent call last ): ... ValueError : value can only be None if sources is non - empty The RollOutcome.euthanize method provides a convenient shorthand. 1 2 3 4 5 6 7 8 9 10 >>> RollOutcome ( 42 ) . euthanize () RollOutcome ( value = None , sources = ( RollOutcome ( value = 42 , sources = (), ), ), ) However, because such a roll signals its absence from the current roll, its value is not included by the Roll.outcomes method . We can programmatically verify that the excluded outcome originated from one of the six-sided dice. 1 2 3 4 5 6 7 >>> excluded = roll [ - 1 ] >>> excluded . value is None True >>> excluded . sources [ 0 ] . value 1 >>> excluded . sources [ 0 ] . r is r_d6 True We can also verify that the 5 came from the eight-sided die. 1 2 3 4 5 >>> five = roll [ 1 ] >>> five . value 5 >>> five . r is r_d8 True Alternatively, could have also used our old friend the P object to eliminate the RepeatRoller for a similar, but structurally simpler result. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from dyce import P >>> R . select_from_values (( slice ( 1 , None ),), 3 @P ( d6 ), d8 ) . roll () Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( ValueRoller ( value = P ( 6 , 6 , 6 ), annotation = '' ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 79 80 ), ) In this case, our results are still mostly traceable, since our pool is homogeneous. However, results from P.roll are sorted, meaning they lose association with their source histograms. This risks ambiguity. Consider: 1 2 >>> P ( 6 , 8 ) . roll () ( 4 , 6 ) Is the 4 from the d6 or d8 ? \ud83e\udd14\ud83d\udcad No one knows. 1 2 3 4 >>> R . from_value ( P ( 6 , 8 )) # doctest: +SKIP \u2026 : UserWarning : using a heterogeneous pool ( P ( 6 , 8 )) is not recommended where traceability is important ... ValueRoller ( value = P ( 6 , 8 ), annotation = '' ) Filtering and substitution dyce provides two additional rollers for outcome manipulation. FilterRoller s euthanize outcomes that don\u2019t meet provided criteria. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 >>> r_filter = R . filter_from_values_iterable ( ... lambda outcome : bool ( outcome . is_odd () . value ), ... range ( 6 ), ... ) ; r_filter FilterRoller ( predicate =< function < lambda > at ...> , sources = ( ValueRoller ( value = 0 , annotation = '' ), ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 2 , annotation = '' ), ValueRoller ( value = 3 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ValueRoller ( value = 5 , annotation = '' ), ), annotation = '' , ) >>> roll = r_filter . roll () >>> tuple ( roll . outcomes ()) ( 1 , 3 , 5 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 0 , sources = (), ), ), ), RollOutcome ( value = 1 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ), RollOutcome ( value = 3 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 4 , sources = (), ), ), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( ... ), ) SubstitutionRoller s replace or append outcomes based on existing ones. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 >>> from dyce.r import CoalesceMode , SubstitutionRoller >>> r_d6 = R . from_value ( H ( 6 )) >>> r_replace = SubstitutionRoller ( ... lambda outcome : r_d6 . roll () if outcome . value == 1 else outcome , ... r_d6 , ... max_depth = 2 , ... ) >>> r_replace . roll () Roll ( r = SubstitutionRoller ( expansion_op =< function < lambda > at ...> , source = ValueRoller ( value = H ( 6 ), annotation = '' ), coalesce_mode =< CoalesceMode . REPLACE : 1 > , max_depth = 2 , annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), ), ), RollOutcome ( value = 2 , sources = ( RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), ), ), ), source_rolls = ( ... ), ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 >>> r_append = SubstitutionRoller ( ... lambda outcome : r_d6 . roll () if outcome . value == 1 else outcome , ... r_d6 , ... coalesce_mode = CoalesceMode . APPEND , ... max_depth = 2 , ... ) >>> r_append . roll () Roll ( r = SubstitutionRoller ( expansion_op =< function < lambda > at ...> , source = ValueRoller ( value = H ( 6 ), annotation = '' ), coalesce_mode =< CoalesceMode . APPEND : 2 > , max_depth = 2 , annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = 2 , sources = ( RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), ), ), ), source_rolls = ( ... ), ) Performance How much overhead do all these data structures contribute? It obviously depends on the complexity of the structure. Consider a simple example d20 + d12 + 4 . Let\u2019s do that 5,000 times, sort the results, and take every other one starting with the highest. We might use a pool, if we didn\u2019t care about traceability. Let\u2019s compare that to our roller. 1 2 3 4 5 % timeit ( 5000 @P ( H ( 20 ) + H ( 12 ) + 4 )) . roll ()[:: - 2 ] 58.7 ms \u00b1 14.8 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) % timeit ( 5000 @ ( R . select_from_values (( slice ( None , None , - 2 ),), H ( 20 ), H ( 12 ), 4 ))) . roll () 662 ms \u00b1 23.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source: perf_pools_vs_rollers.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 from dyce import H , P , R d20 , d12 = H ( 20 ), H ( 12 ) print ( f \"%timeit (5000@P( { d20 } + { d12 } + 4)).roll()[::-2]\" ) p = 5000 @P ( d20 + d12 + 4 ) % timeit p . roll ()[:: - 2 ] print () print ( f \"%timeit (5000@(R.select_from_values((slice(None, None, -2),), { d20 } , { d12 } , 4))).roll()\" ) r = 5000 @ ( R . select_from_values (( slice ( None , None , - 2 ),), d20 , d12 , 4 )) % timeit r . roll () print () In this particular case, our roller takes over ten times longer than our histogram pool. It is unsurprising that a simple roller is slower than a simple pool, at least in part because the math is deferred until R.roll time. In more sophisticated cases, rollers may be more competitive with (or even surpass) their histogram or pool analogies, especially when initialization time is taken into account. All that being said, for periodic rolls simulating handfuls (not thousands) of operations or dice, such performance disparities probably won\u2019t matter that much. Just use the primitives whose semantics work best for you. If ever performance becomes an issue, let me know , and we can collaborate on how to improve it. Further exploration Consider reviewing the roller API . If you\u2019re not already familiar with histograms, consider skimming the counting tutorial . \u21a9 We may still be discovering what those purposes are. We have the utmost faith they exist, even if they have yet to reveal themselves. If you discover one, consider contributing an example. \u21a9","title":"Rollin\u2019 with rollers and rolls"},{"location":"rollin/#emulating-a-hundred-sided-die-using-two-ten-sided-dice","text":"In many games it is common to emulate a hundred-sided die using a \u201cones\u201d ten-sided die (faces numbered \\([{ {0}, {1}, \\ldots , {9} }]\\) ) and a \u201ctens\u201d ten-sided die (faces numbered \\([{ {00}, {10}, \\ldots , {90} }]\\) ). Let\u2019s try to model that as a roller and use it to generate a roll. We start by creating two histograms 1 representing our two ten-sided dice ( d00 for our \u201ctens\u201d die and d10 for our \u201cones\u201c die). 1 2 3 >>> from dyce import H >>> d10 = H ( 10 ) - 1 >>> d00 = 10 * d10 Next, we create a roller using the R.from_values class method . 1 2 3 4 5 6 7 8 >>> r_d100 = R . from_values ( d00 , d10 ) ; r_d100 PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ) Well, wouldya look at that? That durned class method created a whole roller tree , which is actually three rollers. One ValueRoller for the d00 histogram; Another for the d10 histogram; and A PoolRoller for aggregating them both. Tip We could have also composed an identical tree using roller implementations from dyce.r instead of the R.from_values convenience method. 1 2 3 >>> from dyce.r import PoolRoller , ValueRoller >>> r_d100 == PoolRoller ( sources = ( ValueRoller ( d00 ), ValueRoller ( d10 ))) True Let\u2019s use our new roller to create a roll and retrieve its total. 1 2 3 >>> roll = r_d100 . roll () >>> roll . total () 69 No surprises there. Let\u2019s dig a little deeper and ask for the roll\u2019s outcome values. 1 2 >>> tuple ( roll . outcomes ()) ( 60 , 9 ) As we mentioned before, the top level of our roller tree is a PoolRoller , which aggregates (or \u201cpools\u201d) rolls from its sources. For our roll, the aggregated outcomes are 60 are 9 . What does our pooled roll look like? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 >>> roll Roll ( r = PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), RollOutcome ( value = 9 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 9 , sources = (), ), ), source_rolls = (), ), ), ) Let\u2019s break that down so it doesn\u2019t feel like trying to drink from a fire hose. Calling the R.roll method on our PoolRoller resulted in a Roll object . Actually, it resulted in a roll tree (analogous to our roller tree). Each Roll object in that tree has: A reference to the R object in the roller tree that generated it, retrieved via its r property ; Zero or more RollOutcome objects , retrieved by accessing the roll as a sequence (i.e., via __getitem__ , __len__ ); and Zero or more source rolls, retrieved via its source_rolls property . The RollOutcome objects also form trees (in our case, simple ones). Each one has: A single value, retrieved via its value property ; Zero or more source outcomes from which the value was derived, retrieved via its sources property ; and A reference back to the roll that generated it, retrieved via its source_roll property (omitted from the diagram for the sake of readability). Tip You might be wondering to yourself, \u201cSelf, one wonders, can one have a pool of pools?\u201d Such questions command the response, \u201cWhy the heck not? Try it!\u201d 1 2 3 4 5 6 >>> two_r_d100s = PoolRoller ( sources = ( r_d100 , r_d100 )) >>> roll_two = two_r_d100s . roll () >>> roll_two . total () 63 >>> tuple ( roll_two . outcomes ()) ( 40 , 2 , 20 , 1 ) So the answer is a resounding, \u201cOf course. What devious entity would prohibit such a thing? Please identify that creature so we may flog it until it achieves enlightenment,\u201d \u201cYes.\u201d","title":"Emulating a hundred-sided die using two ten-sided dice"},{"location":"rollin/#composing-rollers-with-arithmetic","text":"Rollers support arithmetic operators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 >>> d12 = H ( 12 ) >>> r_d12_add_4 = ValueRoller ( d12 ) + 4 ; r_d12_add_4 BinarySumOpRoller ( bin_op =< built - in function add > , left_source = ValueRoller ( value = H ( 12 ), annotation = '' ), right_source = ValueRoller ( value = 4 , annotation = '' ), annotation = '' , ) >>> r_d12_add_4 . roll () Roll ( r = BinarySumOpRoller ( ... ), roll_outcomes = ( RollOutcome ( value = 11 , sources = ( RollOutcome ( value = 7 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 12 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 7 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ), ), )","title":"Composing rollers with arithmetic"},{"location":"rollin/#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8","text":"The trifecta of roller trees, roll trees, and outcome trees might appear complicated or redundant. Everything serves a purpose. 2 Consider excluding (or \u201cdropping\u201d) dice from a roll. How would we account for that? Let\u2019s see how to generate rolls that keep the best three outcomes from rolling three six-sided dice and one eight-sided die. We start by using the R.from_value class method to create ValueRoller s for histograms representing our six- and eight-sided dice. 1 2 3 4 5 6 >>> d6 = H ( 6 ) >>> d8 = H ( 8 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> r_d8 = R . from_value ( d8 ) ; r_d8 ValueRoller ( value = H ( 8 ), annotation = '' ) For homogeneous pools, we can use the matrix multiplication operator. 1 2 3 4 5 6 >>> r_3d6 = 3 @r_d6 ; r_3d6 RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) Finally, we\u2019ll create a SelectionRoller by calling the R.select_from_sources method on our other rollers. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> r_best_3_of_3d6_d8 = R . select_from_sources (( slice ( 1 , None ),), r_3d6 , r_d8 ) ; r_best_3_of_3d6_d8 SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ) Oh boy! Aren\u2019t you super excited to try this thing out? 1 2 3 >>> roll = r_best_3_of_3d6_d8 . roll () >>> tuple ( roll . outcomes ()) ( 1 , 5 , 6 ) There are indeed three values, despite starting with four dice. Given that the lowest value we see is a 1 , we might assume that the eliminated value is also a 1 . But, we all know what happens when one assumes. Recall that in roll trees, a roll may have references to other rolls (its \u201csource rolls\u201d) from which it derives. We should be able to get information about the dropped die by traversing that tree. Let\u2019s see if we can validate our assumption by looking at the outcomes from our roll\u2019s direct source. 1 2 3 >>> from itertools import chain >>> tuple ( chain . from_iterable ( source_roll . outcomes () for source_roll in roll . source_rolls )) ( 6 , 1 , 1 , 5 ) Yup! We were right! There\u2019s the other 1 , plain as day. Our work here is do\u2014 What? You want to know which die we eliminated? We can see that, too! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> roll Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 147 148 ), ) Oof. \u261d\ufe0f That was \u2026 a lot . Let\u2019s visualize! Holy entangled relationship diagrams, Batman! One thing you may notice about our top-level roll is that it has four outcomes. One of those kids is not like the others. Specifically, it has a value of None . That\u2019s our dropped outcome! 1 2 3 4 5 6 >>> len ( roll ) == 4 True >>> roll [ - 1 ] . value is None True >>> tuple ( roll_outcome . value for roll_outcome in roll ) ( 1 , 5 , 6 , None ) Info A roll outcome with a value of None is akin to a \u201ctombstone\u201d. It conveys one whose sources were present in immediately prior rolls but excluded from the current roll. Such roll outcomes must have at least one source. 1 2 3 4 5 >>> from dyce.r import RollOutcome >>> RollOutcome ( value = None ) Traceback ( most recent call last ): ... ValueError : value can only be None if sources is non - empty The RollOutcome.euthanize method provides a convenient shorthand. 1 2 3 4 5 6 7 8 9 10 >>> RollOutcome ( 42 ) . euthanize () RollOutcome ( value = None , sources = ( RollOutcome ( value = 42 , sources = (), ), ), ) However, because such a roll signals its absence from the current roll, its value is not included by the Roll.outcomes method . We can programmatically verify that the excluded outcome originated from one of the six-sided dice. 1 2 3 4 5 6 7 >>> excluded = roll [ - 1 ] >>> excluded . value is None True >>> excluded . sources [ 0 ] . value 1 >>> excluded . sources [ 0 ] . r is r_d6 True We can also verify that the 5 came from the eight-sided die. 1 2 3 4 5 >>> five = roll [ 1 ] >>> five . value 5 >>> five . r is r_d8 True Alternatively, could have also used our old friend the P object to eliminate the RepeatRoller for a similar, but structurally simpler result. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from dyce import P >>> R . select_from_values (( slice ( 1 , None ),), 3 @P ( d6 ), d8 ) . roll () Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( ValueRoller ( value = P ( 6 , 6 , 6 ), annotation = '' ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 79 80 ), ) In this case, our results are still mostly traceable, since our pool is homogeneous. However, results from P.roll are sorted, meaning they lose association with their source histograms. This risks ambiguity. Consider: 1 2 >>> P ( 6 , 8 ) . roll () ( 4 , 6 ) Is the 4 from the d6 or d8 ? \ud83e\udd14\ud83d\udcad No one knows. 1 2 3 4 >>> R . from_value ( P ( 6 , 8 )) # doctest: +SKIP \u2026 : UserWarning : using a heterogeneous pool ( P ( 6 , 8 )) is not recommended where traceability is important ... ValueRoller ( value = P ( 6 , 8 ), annotation = '' )","title":"Dropping dice from prior rolls \u2013 keeping the best three of 3d6 and 1d8"},{"location":"rollin/#filtering-and-substitution","text":"dyce provides two additional rollers for outcome manipulation. FilterRoller s euthanize outcomes that don\u2019t meet provided criteria. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 >>> r_filter = R . filter_from_values_iterable ( ... lambda outcome : bool ( outcome . is_odd () . value ), ... range ( 6 ), ... ) ; r_filter FilterRoller ( predicate =< function < lambda > at ...> , sources = ( ValueRoller ( value = 0 , annotation = '' ), ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 2 , annotation = '' ), ValueRoller ( value = 3 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ValueRoller ( value = 5 , annotation = '' ), ), annotation = '' , ) >>> roll = r_filter . roll () >>> tuple ( roll . outcomes ()) ( 1 , 3 , 5 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 0 , sources = (), ), ), ), RollOutcome ( value = 1 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ), RollOutcome ( value = 3 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 4 , sources = (), ), ), ), RollOutcome ( value = 5 , sources = (), ), ), source_rolls = ( ... ), ) SubstitutionRoller s replace or append outcomes based on existing ones. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 >>> from dyce.r import CoalesceMode , SubstitutionRoller >>> r_d6 = R . from_value ( H ( 6 )) >>> r_replace = SubstitutionRoller ( ... lambda outcome : r_d6 . roll () if outcome . value == 1 else outcome , ... r_d6 , ... max_depth = 2 , ... ) >>> r_replace . roll () Roll ( r = SubstitutionRoller ( expansion_op =< function < lambda > at ...> , source = ValueRoller ( value = H ( 6 ), annotation = '' ), coalesce_mode =< CoalesceMode . REPLACE : 1 > , max_depth = 2 , annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), ), ), RollOutcome ( value = 2 , sources = ( RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), ), ), ), source_rolls = ( ... ), ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 >>> r_append = SubstitutionRoller ( ... lambda outcome : r_d6 . roll () if outcome . value == 1 else outcome , ... r_d6 , ... coalesce_mode = CoalesceMode . APPEND , ... max_depth = 2 , ... ) >>> r_append . roll () Roll ( r = SubstitutionRoller ( expansion_op =< function < lambda > at ...> , source = ValueRoller ( value = H ( 6 ), annotation = '' ), coalesce_mode =< CoalesceMode . APPEND : 2 > , max_depth = 2 , annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = 2 , sources = ( RollOutcome ( value = 1 , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), ), ), ), source_rolls = ( ... ), )","title":"Filtering and substitution"},{"location":"rollin/#performance","text":"How much overhead do all these data structures contribute? It obviously depends on the complexity of the structure. Consider a simple example d20 + d12 + 4 . Let\u2019s do that 5,000 times, sort the results, and take every other one starting with the highest. We might use a pool, if we didn\u2019t care about traceability. Let\u2019s compare that to our roller. 1 2 3 4 5 % timeit ( 5000 @P ( H ( 20 ) + H ( 12 ) + 4 )) . roll ()[:: - 2 ] 58.7 ms \u00b1 14.8 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) % timeit ( 5000 @ ( R . select_from_values (( slice ( None , None , - 2 ),), H ( 20 ), H ( 12 ), 4 ))) . roll () 662 ms \u00b1 23.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source: perf_pools_vs_rollers.ipy 1 2 3 4 5 6 7 8 9 10 11 12 13 from dyce import H , P , R d20 , d12 = H ( 20 ), H ( 12 ) print ( f \"%timeit (5000@P( { d20 } + { d12 } + 4)).roll()[::-2]\" ) p = 5000 @P ( d20 + d12 + 4 ) % timeit p . roll ()[:: - 2 ] print () print ( f \"%timeit (5000@(R.select_from_values((slice(None, None, -2),), { d20 } , { d12 } , 4))).roll()\" ) r = 5000 @ ( R . select_from_values (( slice ( None , None , - 2 ),), d20 , d12 , 4 )) % timeit r . roll () print () In this particular case, our roller takes over ten times longer than our histogram pool. It is unsurprising that a simple roller is slower than a simple pool, at least in part because the math is deferred until R.roll time. In more sophisticated cases, rollers may be more competitive with (or even surpass) their histogram or pool analogies, especially when initialization time is taken into account. All that being said, for periodic rolls simulating handfuls (not thousands) of operations or dice, such performance disparities probably won\u2019t matter that much. Just use the primitives whose semantics work best for you. If ever performance becomes an issue, let me know , and we can collaborate on how to improve it.","title":"Performance"},{"location":"rollin/#further-exploration","text":"Consider reviewing the roller API . If you\u2019re not already familiar with histograms, consider skimming the counting tutorial . \u21a9 We may still be discovering what those purposes are. We have the utmost faith they exist, even if they have yet to reveal themselves. If you discover one, consider contributing an example. \u21a9","title":"Further exploration"},{"location":"translations/","text":"The following examples and translations are intended to showcase dyce \u2019s flexibility. If you have exposure to another tool, they may also help with transition. Checking Angry\u2019s math on the Tension Pool In the Angry GM \u2019s publication of the PDF version of his Tension Pool mechanic , he includes some probabilities. Can dyce check his work? You bet! Let\u2019s reproduce his tables (with slightly different names to provide context). d6s in pool Angry\u2019s probability of at least one 1 showing 1 16.7% 2 30.6% 3 42.1% 4 51.8% 5 59.8% 6 66.5% How do we do compute these results using dyce ? 1 2 3 4 5 6 7 8 9 10 11 12 >>> from dyce import H >>> one_in_d6 = H ( 6 ) . eq ( 1 ) >>> for n in range ( 1 , 7 ): ... ones_in_nd6 = n @one_in_d6 ... at_least_one_one_in_nd6 = ones_in_nd6 . ge ( 1 ) ... print ( f \" { n } : { at_least_one_one_in_nd6 [ 1 ] / at_least_one_one_in_nd6 . total : 6.2% } \" ) 1 : 16.67 % 2 : 30.56 % 3 : 42.13 % 4 : 51.77 % 5 : 59.81 % 6 : 66.51 % So far so good. Let\u2019s keep going. 1d8 + 1d12 Rarity or Severity 2-4 Very Rare or Extreme 5-6 Rare or Major 7-8 Uncommon or Moderate 9-13 Common or Minor 14-15 Uncommon or Moderate 16-17 Rare or Major 18-20 Very Rare or Extreme We need to map semantic outcomes to numbers (and back again). How can we represent those in dyce ? One way is IntEnum s. IntEnum s have a property that allows them to substitute directly for int s, which, with a little nudging, is very convenient. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 >>> from enum import IntEnum >>> class Complication ( IntEnum ): ... NONE = 0 # this will come in handy later ... COMMON = 1 ... UNCOMMON = 2 ... RARE = 3 ... VERY_RARE = 4 >>> OUTCOME_TO_RARITY_MAP = { ... 2 : Complication . VERY_RARE , ... 3 : Complication . VERY_RARE , ... 4 : Complication . VERY_RARE , ... 5 : Complication . RARE , ... 6 : Complication . RARE , ... 7 : Complication . UNCOMMON , ... 8 : Complication . UNCOMMON , ... 9 : Complication . COMMON , ... 10 : Complication . COMMON , ... 11 : Complication . COMMON , ... 12 : Complication . COMMON , ... 13 : Complication . COMMON , ... 14 : Complication . UNCOMMON , ... 15 : Complication . UNCOMMON , ... 16 : Complication . RARE , ... 17 : Complication . RARE , ... 18 : Complication . VERY_RARE , ... 19 : Complication . VERY_RARE , ... 20 : Complication . VERY_RARE , ... } Now let\u2019s use our map to validate the probabilities of a particular outcome using that d8 and d12. Rarity or impact Angry\u2019s probability of a Complication arising Common or Minor 41.7% Uncommon or Moderate 27.1% Rare or Major 18.8% Very Rare or Extreme 12.5% 1 2 3 4 5 6 7 8 9 >>> prob_of_complication = H . foreach ( ... lambda outcome : OUTCOME_TO_RARITY_MAP [ outcome ], ... outcome = H ( 8 ) + H ( 12 ), ... ) >>> { outcome : f \" { float ( prob ) : 6.2% } \" for outcome , prob in prob_of_complication . distribution ()} { < Complication . COMMON : 1 > : '41.67%' , < Complication . UNCOMMON : 2 > : '27.08%' , < Complication . RARE : 3 > : '18.75%' , < Complication . VERY_RARE : 4 > : '12.50%' } Lookin\u2019 good! Now let\u2019s put everything together. d6s in pool None Common Uncommon Rare Very Rare 1 83.3% 7.0% 4.5% 3.1% 2.1% 2 69.4% 12.7% 8.3% 5.7% 3.8% 3 57.9% 17.6% 11.4% 7.9% 5.3% 4 48.2% 21.6% 14.0% 9.7% 6.5% 5 40.2% 24.9% 16.2% 11.2% 7.5% 6 33.5% 27.7% 18.0% 12.5% 8.3% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> from typing import cast >>> for n in range ( 1 , 7 ): ... ones_in_nd6 = n @one_in_d6 ... at_least_one_one_in_nd6 = ones_in_nd6 . ge ( 1 ) ... prob_complication_in_nd6 = at_least_one_one_in_nd6 * prob_of_complication ... complications_for_nd6 = { ... Complication ( cast ( int , outcome )) . name : f \" { float ( prob ) : 6.2% } \" ... for outcome , prob in ( prob_complication_in_nd6 ) . distribution () ... } ... print ( \" {} -> {} \" . format ( n , complications_for_nd6 )) 1 -> { 'NONE' : '83.33%' , 'COMMON' : ' 6.94%' , 'UNCOMMON' : ' 4.51%' , 'RARE' : ' 3.12%' , 'VERY_RARE' : ' 2.08%' } 2 -> { 'NONE' : '69.44%' , 'COMMON' : '12.73%' , 'UNCOMMON' : ' 8.28%' , 'RARE' : ' 5.73%' , 'VERY_RARE' : ' 3.82%' } 3 -> { 'NONE' : '57.87%' , 'COMMON' : '17.55%' , 'UNCOMMON' : '11.41%' , 'RARE' : ' 7.90%' , 'VERY_RARE' : ' 5.27%' } 4 -> { 'NONE' : '48.23%' , 'COMMON' : '21.57%' , 'UNCOMMON' : '14.02%' , 'RARE' : ' 9.71%' , 'VERY_RARE' : ' 6.47%' } 5 -> { 'NONE' : '40.19%' , 'COMMON' : '24.92%' , 'UNCOMMON' : '16.20%' , 'RARE' : '11.21%' , 'VERY_RARE' : ' 7.48%' } 6 -> { 'NONE' : '33.49%' , 'COMMON' : '27.71%' , 'UNCOMMON' : '18.01%' , 'RARE' : '12.47%' , 'VERY_RARE' : ' 8.31%' } Well butter my butt, and call me a biscuit! That Angry guy sure knows his math! Modeling Ironsworn \u2019s core mechanic Shawn Tomlin\u2019s Ironsworn melds a number of different influences in a fresh way. Its core mechanic involves rolling an action die (a d6), adding a modifier, and comparing the resulting value to two challenge dice (d10s). If the modified value from the action die is strictly greater than both challenge dice, the result is a strong success. If it is strictly greater than only one challenge die, the result is a weak success. If it is equal to or less than both challenge dice, it\u2019s a failure. A verbose way to model this is to enumerate the product of the three dice and then perform logical comparisons. However, if we recognize that our problem involves a dependent probability , we can craft a solution in terms of H.foreach . We can also deploy a counting trick with the two d10s. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from dyce import H , as_int >>> from numerary.types import RealLike >>> from enum import IntEnum , auto >>> from typing import Iterator , Tuple , cast >>> d6 = H ( 6 ) >>> d10 = H ( 10 ) >>> class IronResult ( IntEnum ): ... FAILURE = 0 ... WEAK_SUCCESS = auto () ... STRONG_SUCCESS = auto () >>> iron_distributions_by_mod = { ... mod : H . foreach ( lambda action : 2 @ ( d10 . lt ( action )), action = d6 + mod ) ... for mod in range ( 5 ) ... } >>> for mod , iron_distribution in iron_distributions_by_mod . items (): ... print ( \" {:+} -> {} \" . format ( mod , { ... IronResult ( cast ( int , outcome )) . name : f \" { float ( prob ) : 6.2% } \" ... for outcome , prob in iron_distribution . distribution () ... })) + 0 -> { 'FAILURE' : '59.17%' , 'WEAK_SUCCESS' : '31.67%' , 'STRONG_SUCCESS' : ' 9.17%' } + 1 -> { 'FAILURE' : '45.17%' , 'WEAK_SUCCESS' : '39.67%' , 'STRONG_SUCCESS' : '15.17%' } + 2 -> { 'FAILURE' : '33.17%' , 'WEAK_SUCCESS' : '43.67%' , 'STRONG_SUCCESS' : '23.17%' } + 3 -> { 'FAILURE' : '23.17%' , 'WEAK_SUCCESS' : '43.67%' , 'STRONG_SUCCESS' : '33.17%' } + 4 -> { 'FAILURE' : '15.17%' , 'WEAK_SUCCESS' : '39.67%' , 'STRONG_SUCCESS' : '45.17%' } What\u2019s with that 2 @ ( d10 . lt ( action )) ? Let\u2019s break it down. H ( 10 ) . lt ( value ) will tell us how often a single d10 is less than value . 1 2 >>> H ( 10 ) . lt ( 5 ) # how often a d10 is strictly less than 5 H ({ False : 6 , True : 4 }) By summing those results (and taking advantage of the fact that, in Python, bool s act like int s when it comes to arithmetic operators), we can count how often that happens with more than one interchangeable d10. 1 2 3 4 >>> h = H ( 10 ) . lt ( 5 ) + H ( 10 ) . lt ( 5 ) ; h H ({ 0 : 36 , 1 : 48 , 2 : 16 }) >>> h . total 100 How do we interpret those results? 36 times out of a hundred, neither d10 will be strictly less than five. 48 times out of a hundred, exactly one of the d10s will be strictly less than five. 16 times out of a hundred, both d10s will be strictly less than five. H \u2019s @ operator provides a shorthand. 1 2 3 >>> # The parentheses are technically redundant, but clarify the intention >>> 2 @ ( H ( 10 ) . lt ( 5 )) == H ( 10 ) . lt ( 5 ) + H ( 10 ) . lt ( 5 ) True Why doesn\u2019t 2 @ ( H ( 6 ) . gt ( H ( 10 )) work? H ( 6 ) . gt ( H ( 10 )) will compute how often a six-sided die is strictly greater than a ten-sided die. 2 @ ( H ( 6 ) . gt ( H ( 10 ))) will show the frequencies that a first six-sided die is strictly greater than a first ten-sided die and a second six-sided die is strictly greater than a second ten-sided die. This isn\u2019t quite what we want, since the mechanic calls for rolling a single six-sided die and comparing that result to each of two ten-sided dice. Now for a twist . In cooperative or solo play, a failure or success is particularly spectacular when the d10s come up doubles. The key to mapping that to dyce internals is recognizing that we have a dependent probability that involves three independent variables: the (modded) d6, a first d10, and a second d10. H.foreach is especially useful where there are multiple independent terms. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 >>> class IronSoloResult ( IntEnum ): ... FAILURE = 0 ... WEAK_SUCCESS = auto () ... STRONG_SUCCESS = auto () ... SPECTACULAR_SUCCESS = auto () ... SPECTACULAR_FAILURE = - 1 >>> def iron_solo_dependent_term ( action , first_challenge , second_challenge , mod = 0 ): ... modded_action = action + mod ... beats_first_challenge = modded_action > first_challenge ... beats_second_challenge = modded_action > second_challenge ... doubles = first_challenge == second_challenge ... if beats_first_challenge and beats_second_challenge : ... return IronSoloResult . SPECTACULAR_SUCCESS if doubles else IronSoloResult . STRONG_SUCCESS ... elif beats_first_challenge or beats_second_challenge : ... return IronSoloResult . WEAK_SUCCESS ... else : ... return IronSoloResult . SPECTACULAR_FAILURE if doubles else IronSoloResult . FAILURE >>> H . foreach ( ... iron_solo_dependent_term , # mod defaults to 0 ... action = d6 , ... first_challenge = d10 , ... second_challenge = d10 , ... ) H ({ < IronSoloResult . SPECTACULAR_FAILURE : - 1 > : 9 , < IronSoloResult . FAILURE : 0 > : 62 , < IronSoloResult . WEAK_SUCCESS : 1 > : 38 , < IronSoloResult . STRONG_SUCCESS : 2 > : 8 , < IronSoloResult . SPECTACULAR_SUCCESS : 3 > : 3 }) By defining our dependent term function to include mod as a parameter with a default argument, we can use partial to manipulate it, which is helpful for visualization. Source: plot_ironsworn.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from collections import defaultdict from enum import IntEnum , auto from functools import partial from dyce import H class IronSoloResult ( IntEnum ): SPECTACULAR_FAILURE = - 1 FAILURE = auto () WEAK_SUCCESS = auto () STRONG_SUCCESS = auto () SPECTACULAR_SUCCESS = auto () def do_it ( style : str ) -> None : import matplotlib.pyplot import matplotlib.ticker d6 = H ( 6 ) d10 = H ( 10 ) def iron_solo_dependent_term ( action , first_challenge , second_challenge , mod = 0 ): modded_action = action + mod beats_first = modded_action > first_challenge beats_second = modded_action > second_challenge doubles = first_challenge == second_challenge if beats_first and beats_second : return ( IronSoloResult . SPECTACULAR_SUCCESS if doubles else IronSoloResult . STRONG_SUCCESS ) elif beats_first or beats_second : return IronSoloResult . WEAK_SUCCESS else : return ( IronSoloResult . SPECTACULAR_FAILURE if doubles else IronSoloResult . FAILURE ) ax = matplotlib . pyplot . axes () by_result = defaultdict ( list ) mods = list ( range ( 0 , 5 )) text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) ax . yaxis . set_major_formatter ( matplotlib . ticker . PercentFormatter ( xmax = 1 )) for mod in mods : results_for_mod = H . foreach ( partial ( iron_solo_dependent_term , mod = mod ), action = d6 , first_challenge = d10 , second_challenge = d10 , ) distribution_for_mod = dict ( results_for_mod . distribution ()) for result in IronSoloResult : result_val = float ( distribution_for_mod . get ( result , 0 )) by_result [ result ] . append ( result_val ) labels = [ str ( mod ) for mod in mods ] bottoms = [ 0.0 for _ in mods ] for result in IronSoloResult : result_vals = by_result [ result ] assert len ( result_vals ) == len ( mods ) ax . bar ( labels , result_vals , bottom = bottoms , label = result . name ) bottoms = [ bottom + result_val for bottom , result_val in zip ( bottoms , result_vals ) ] ax . legend () ax . set_xlabel ( \"Modifier\" , color = text_color ) ax . set_title ( \"Ironsworn distributions\" , color = text_color ) Advanced topic \u2013 modeling Risis Risus and its many community-developed alternative rules not only make for entertaining reading, but are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model the first round of its opposed combat system for various starting configurations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map. Source: plot_risus_first_round.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from typing import List , Tuple from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] col_ticks = list ( range ( len ( col_names ))) num_scenarios = 3 text_color = \"white\" if style == \"dark\" else \"black\" for i , them in enumerate ( range ( 3 , 3 + num_scenarios )): ax = matplotlib . pyplot . subplot ( 1 , num_scenarios , i + 1 ) row_names : List [ str ] = [] rows : List [ Tuple [ float , ... ]] = [] num_rows = 3 for us in range ( them , them + num_rows ): row_names . append ( f \" { us } d6 \u2026\" ) rows . append (( us @ H ( 6 )) . vs ( them @ H ( 6 )) . distribution_xy ()[ - 1 ]) ax . imshow ( rows ) ax . set_title ( f \"\u2026 vs { them } d6\" , color = text_color ) ax . set_xticks ( col_ticks ) ax . set_xticklabels ( col_names , color = text_color , rotation = 90 ) ax . set_yticks ( list ( range ( len ( rows )))) ax . set_yticklabels ( row_names , color = text_color ) for y in range ( len ( row_names )): for x in range ( len ( col_names )): ax . text ( x , y , f \" { rows [ y ][ x ] : .0% } \" , ha = \"center\" , va = \"center\" , color = \"w\" , ) Modeling entire multi-round combats With a little elbow finger grease, we can roll up our \u2026 erm \u2026 fingerless gloves and even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 >>> from dyce import H , P >>> import sys >>> from enum import IntEnum , auto >>> from typing import Callable , Dict , Tuple >>> if sys . version_info >= ( 3 , 9 ): ... from functools import cache ... else : ... from functools import lru_cache ... cache = lru_cache ( maxsize = None ) >>> class Risus ( IntEnum ): ... LOSS = - 1 ... DRAW = auto () ... WIN = auto () >>> @cache ... def risus_combat_driver ( ... us : int , # number of dice we still have ... them : int , # number of dice they still have ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... ... def _resolve ( us : int , them : int ) -> H : ... if us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... if them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( this_round_outcome ) -> H : ... if this_round_outcome == Risus . LOSS : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif this_round_outcome == Risus . WIN : return _resolve ( us , them - 1 ) # they lost this round, and one die ... elif this_round_outcome == Risus . DRAW : return H ({}) # ignore (immediately re-roll) all ties ... else : assert False , f \"unrecognized this_round_outcome { this_round_outcome } \" ... ... return H . foreach ( _next_round , this_round_outcome = this_round ) ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } There\u2019s lot going on there. Let\u2019s dissect it. 16 17 18 19 20 21 22 @cache def risus_combat_driver ( us : int , # number of dice we still have them : int , # number of dice they still have us_vs_them_func : Callable [[ int , int ], H ], ) -> H : ... Our \u201cdriver\u201d takes three arguments: How many dice we have left ( us ); How many dice the opposition has left ( them ); and A resolution function ( us_vs_them_func ) that takes counts of each party\u2019s remaining dice and returns a histogram encoding the probability of winning or losing a single round akin to the H.vs method : An outcome of - 1 signals the opposition\u2019s victory An outcome of 1 signals our victory. An outcome of 0 signals a tie. The @cache decorator does simple memoization for us because there are redundancies. For example, we might compute a case where we lose a die, then our opposition loses a die. We arrive at a similar case where our opposition loses a die, then we lose a die. Both cases would be identical from that point on. In this context, @cache helps us avoid recomputing redundant sub-trees. 22 23 24 25 if us < 0 or them < 0 : raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) if us == 0 and them == 0 : return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start We make some preliminary checks that guard access to our recursive implementation so that it can be a little cleaner. 27 28 def _resolve ( us : int , them : int ) -> H : ... 39 return _resolve ( us , them ) Skipping over its implementation for now, we define a our memoized recursive implementation ( _resolve ) and then call it with our initial arguments. 27 28 29 def _resolve ( us : int , them : int ) -> H : if us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win if them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win Getting back to that implementation, these are our base cases. We check whether either party has run out of dice, in which case the combat is over. If we have none of those cases, we get to work. Note In this function, we do not check for the case where both parties are at zero. Because only one party can lose a die during each round, the only way both parties can be at zero simultaneously is if they both started at zero. Since we guard against that case in the enclosing function, we don\u2019t have to worry about it here. Either us is zero, them is zero, or neither is zero. 30 this_round = us_vs_them_func ( us , them ) Then, we compute the outcomes for this round using the provided resolution function. 32 33 def _next_round ( this_round_outcome ) -> H : ... 38 return H . foreach ( _next_round , this_round_outcome = this_round ) Keeping in mind that we\u2019re inside our recursive implementation, we define a dependent term specifically for use with H.foreach . This allows us to take our computation for this round, and \u201cfold in\u201d subsequent rounds. 32 33 34 35 def _next_round ( this_round_outcome ) -> H : if this_round_outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die elif this_round_outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die else : return H ({}) # ignore (immediately re-roll) all ties Our substitution function is pretty straightforward. Where we are asked whether we want to provide a substitution for a round we lost, we lose a die and recurse. Where we are asked for a substitution for a round we won, our opposition loses a die and we recurse. We ignore ties (simulating that we re-roll them in place until they are no longer ties). 44 45 46 47 ... risus_combat_driver ( u , t , lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ) ... At this point, we can define a simple lambda that wraps H.vs and submit it to our driver to enumerate resolution outcomes from various starting positions. Note This is a complicated example that involves some fairly sophisticated programming techniques (recursion, memoization, nested functions, etc.). The point is not to suggest that such techniques are required to be productive. However, it is useful to show that dyce is flexible enough to model these types of outcomes in a couple dozen lines of code. It is high-level enough to lean on for nuanced number crunching without a lot of detailed knowledge, while still being low-level enough that authors knowledgeable of advanced programming techniques are not precluded from using them. Modeling different combat resolution methods Using our risus_combat_driver from above, we can craft a alternative resolution function to model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d for resolving ties. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath Rule: tie goes to the party with fewer dice in this round ... h = H . foreach ( ... lambda outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome , ... outcome = h , ... ) ... return h >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 44.13 % , 1 : 55.87 % } 7 d6 vs 5 d6 : { ... , - 1 : 36.89 % , 1 : 63.11 % } The \u201c Evens Up \u201d alternative dice mechanic presents some challenges. First, dyce \u2019s substitution mechanism only resolves outcomes through a fixed number of iterations, so it can only approximate probabilities for infinite series. Most of the time, the implications are largely theoretical with a sufficient number of iterations. This is no exception. Second, with one narrow exception , dyce only provides a mechanism to directly substitute outcomes, not counts. This means we can\u2019t arbitrarily increase the likelihood of achieving a particular outcome through replacement. With some creativity, we can work around that, too. In the case of \u201cEvens Up\u201d, we need to keep track of whether an even number was rolled, but we also need to keep rolling (and accumulating) as long as sixes are rolled. This behaves a lot like an exploding die with three values (miss, hit, and hit-and-explode). Further, we can observe that every \u201crun\u201d will be zero or more exploding hits terminated by either a miss or a non-exploding hit. If we choose our values carefully, we can encode how many times we\u2019ve encountered relevant events as we explode. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> import operator >>> MISS = 0 >>> HIT = 1 >>> HIT_EXPLODE = 2 >>> d_evens_up_raw = H (( ... MISS , # 1 ... HIT , # 2 ... MISS , # 3 ... HIT , # 4 ... MISS , # 5 ... HIT_EXPLODE , # 6 ... )) >>> d_evens_up_exploded = d_evens_up_raw . explode ( max_depth = 3 ) ; d_evens_up_exploded H ({ 0 : 648 , 1 : 432 , 2 : 108 , 3 : 72 , 4 : 18 , 5 : 12 , 6 : 3 , 7 : 2 , 8 : 1 }) For every value that is even, we ended in a miss. For every value that is odd, we ended in a hit that will need to be tallied. Dividing by two and ignoring any remainder will tell us how many exploding hits we had along the way. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> def decode_hits ( outcome ): ... return ( outcome + 1 ) // 2 # equivalent to outcome // 2 + outcome % 2 >>> d_evens_up = H . foreach ( decode_hits , outcome = d_evens_up_exploded ) >>> print ( d_evens_up . format ()) avg | 0.60 std | 0.69 var | 0.48 0 | 50.00 % | ######################### 1 | 41.67 % | #################### 2 | 6.94 % | ### 3 | 1.16 % | 4 | 0.23 % | We can now approximate a complete \u201cEvens Up\u201d combat using our risus_combat_driver from above. We can also deploy a trick using partial to parameterize use of the Goliath Rule. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from functools import partial >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d_evens_up ) . vs ( them @d_evens_up ) ... if goliath : ... h = H . foreach ( lambda outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome , outcome = h ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"----------- ---- With Goliath Rule ----- --- Without Goliath Rule ---\" ) ... for u in range ( t , t + 3 ): ... goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... no_goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = False )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { goliath_results } { no_goliath_results } \" ) ----------- ---- With Goliath Rule ----- --- Without Goliath Rule --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 29.51 % , 1 : 70.49 % } { ... , - 1 : 19.08 % , 1 : 80.92 % } 5 d6 vs 3 d6 : { ... , - 1 : 12.32 % , 1 : 87.68 % } { ... , - 1 : 4.57 % , 1 : 95.43 % } ----------- ---- With Goliath Rule ----- --- Without Goliath Rule --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 30.52 % , 1 : 69.48 % } { ... , - 1 : 21.04 % , 1 : 78.96 % } 6 d6 vs 4 d6 : { ... , - 1 : 13.68 % , 1 : 86.32 % } { ... , - 1 : 5.88 % , 1 : 94.12 % } Modeling \u201c The Probability of 4d6, Drop the Lowest, Reroll 1s \u201d 1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H , P >>> res1 = 3 @H ( 6 ) >>> p_4d6 = 4 @P ( 6 ) >>> res2 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : h if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res3 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H (( 2 , 3 , 4 , 5 , 6 ))) >>> res4 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest >>> res5 = 2 @H ( 6 ) + 6 >>> res6 = 4 @H ( 4 ) + 2 Visualization: Source: plot_4d6_variants.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot res1 = 3 @ H ( 6 ) p_4d6 = 4 @ P ( 6 ) res2 = p_4d6 . h ( slice ( 1 , None )) d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : h if outcome == 1 else outcome ) p_4d6_reroll_first_one = 4 @ P ( d6_reroll_first_one ) res3 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) p_4d6_reroll_all_ones = 4 @ P ( H ( 5 ) + 1 ) res4 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) res5 = 2 @ H ( 6 ) + 6 res6 = 4 @ H ( 4 ) + 2 ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [ ( \"3d6\" , res1 ), # marker=\"D\" ( \"4d6 - discard lowest\" , res2 ), # marker=\"s\" ( \"4d6 - re-roll first 1, discard lowest\" , res3 ), # marker=\"^\" ( \"4d6 - re-roll all 1s (i.e., 4d5 + 1), discard lowest\" , res4 , ), # marker=\"*\" ( \"2d6 + 6\" , res5 ), # marker=\"x\" ( \"4d4 + 2\" , res6 ), # marker=\"o\" ], ) for line , marker in zip ( ax . lines , \"Ds^*xo\" ): line . set_marker ( marker ) ax . legend () ax . set_title ( \"Comparing various take-three-of-4d6 methods\" , color = text_color ) Translating one example from markbrockettrobson/python_dice Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 5 >>> from dyce import H >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: Source: plot_burning_arch.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot save_roll = H ( 20 ) burning_arch_damage = 10 @ H ( 6 ) + 10 pass_save = save_roll . ge ( 10 ) damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [( \"\" , damage_half_on_save )]) ax . set_title ( \"Attack with saving throw for half damage\" , color = text_color ) An alternative using the H.foreach class method : 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> H . foreach ( ... lambda outcome : ( ... burning_arch_damage // 2 ... if operator . __ge__ ( outcome , 10 ) ... else burning_arch_damage ... ), ... outcome = save_roll , ... ) == damage_half_on_save True More translations from markbrockettrobson/python_dice 1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_h = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_h . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> max_h = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( max_h . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> min_h = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( min_h . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % } Translations from LordSembor/DnDice Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { ... , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { ... , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: Source: plot_great_weapon_fighting.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_burst , plot_line from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot single_attack = 2 @ H ( 6 ) + 5 def gwf ( h : H , outcome ): return h if outcome in ( 1 , 2 ) else outcome great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 text_color = \"white\" if style == \"dark\" else \"black\" label_sa = \"Normal attack\" label_gwf = \"\u201cGreat Weapon Fighting\u201d\" ax_plot = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 0 )) ax_plot . tick_params ( axis = \"x\" , colors = text_color ) ax_plot . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax_plot , [( label_sa , single_attack ), ( label_gwf , great_weapon_fighting )]) ax_plot . lines [ 0 ] . set_color ( \"tab:green\" ) ax_plot . lines [ 1 ] . set_color ( \"tab:blue\" ) ax_plot . legend () ax_burst = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 1 )) plot_burst ( ax_burst , h_inner = great_weapon_fighting , h_outer = single_attack , title = f \" { label_sa } \\n vs. \\n { label_gwf } \" , inner_color = \"RdYlBu_r\" , outer_color = \"RdYlGn_r\" , text_color = text_color , ) Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = H . foreach ( crit , outcome = advantage ) Example 2 visualization: Source: plot_advantage.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot normal_hit = H ( 12 ) + 5 critical_hit = 3 @ H ( 12 ) + 5 advantage = ( 2 @ P ( 20 )) . h ( - 1 ) def crit ( outcome ): if outcome == 20 : return critical_hit elif outcome + 5 >= 14 : return normal_hit else : return 0 advantage_weighted = H . foreach ( crit , outcome = advantage ) ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [ ( \"Normal hit\" , normal_hit ), ( \"Critical hit\" , critical_hit ), ( \"Advantage-weighted\" , advantage_weighted ), ], ) ax . legend () ax . set_title ( \"Advantage-weighted attack with critical hits\" , color = text_color ) Translation of the accepted answer to \u201c Roll and Keep in Anydice? \u201d Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 2 >>> from dyce import H , P >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: Source: plot_d10_explode.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [ ( f \" { depth } rerolls\" , ( 10 @ P ( H ( 10 ) . explode ( max_depth = depth ))) . h ( slice ( - 3 , None )), ) for depth in range ( 5 , - 1 , - 1 ) ], ) for line in ax . lines : line . set_marker ( \"\" ) ax . legend () ax . set_title ( \"Taking the three highest of ten exploding d10s\" , color = text_color ) Translation of the accepted answer to \u201c How do I count the number of duplicates in anydice? \u201d Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 11 12 >>> from dyce import P >>> from dyce.p import RollT >>> def dupes ( roll : RollT ): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... return dupes >>> res_15d6 = P . foreach ( dupes , roll = 15 @P ( 6 )) >>> res_8d10 = P . foreach ( dupes , roll = 8 @P ( 10 )) Visualization: Source: plot_dupes.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_scatter from dyce import P from dyce.p import RollT def do_it ( style : str ) -> None : import matplotlib.pyplot def dupes ( roll : RollT ): dupes = 0 for i in range ( 1 , len ( roll )): if roll [ i ] == roll [ i - 1 ]: dupes += 1 return dupes res_15d6 = P . foreach ( dupes , roll = 15 @ P ( 6 )) res_8d10 = P . foreach ( dupes , roll = 8 @ P ( 10 )) matplotlib . pyplot . rcParams [ \"lines.markersize\" ] *= 2 ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_scatter ( ax , [( \"15d6\" , res_15d6 ), ( \"8d10\" , res_8d10 )], alpha = 1.0 ) ax . legend () ax . set_title ( \"Chances of rolling $n$ duplicates\" , color = text_color ) Translation of \u201c How do I implement this specialized roll-and-keep mechanic in AnyDice? \u201d Source: 1 2 3 4 5 6 7 8 9 function: N:n of SIZE:n keep K:n extras add { result: [helper NdSIZE SIZE K] } function: helper ROLL:s SIZE:n K:n { COUNT: [count SIZE in ROLL] if COUNT > K { result: K*SIZE - K + COUNT } result: {1..K}@ROLL } Translation: 1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H , P >>> def roll_and_keep ( p : P , k : int ): ... assert p . is_homogeneous ... max_d = max ( p [ - 1 ]) if p else 0 ... for roll , count in p . rolls_with_counts (): ... total = sum ( roll [ - k :]) + sum ( 1 for outcome in roll [: - k ] if outcome == max_d ) ... yield total , count >>> H ( roll_and_keep ( 6 @P ( 6 ), 3 )) H ({ 3 : 1 , 4 : 6 , 5 : 21 , 6 : 78 , 7 : 207 , ... , 17 : 5535 , 18 : 2500 , 19 : 375 , 20 : 30 , 21 : 1 }) Visualization: Source: plot_roll_and_keep.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from typing import Iterator , Tuple from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot def roll_and_keep ( p : P , k : int ): assert p . is_homogeneous max_d = max ( p [ - 1 ]) if p else 0 for roll , count in p . rolls_with_counts (): total = sum ( roll [ - k :]) + sum ( 1 for outcome in roll [: - k ] if outcome == max_d ) yield total , count d , k = 6 , 3 ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) marker_start = 0 def _roll_and_keep_hs () -> Iterator [ Tuple [ str , H ]]: for n in range ( k + 1 , k + 9 ): p = n @ P ( d ) yield f \" { n } d { d } keep { k } add +1\" , H ( roll_and_keep ( p , k )) plot_line ( ax , tuple ( _roll_and_keep_hs ()), alpha = 0.75 ) for i in range ( marker_start , len ( ax . lines )): ax . lines [ i ] . set_marker ( \".\" ) marker_start = len ( ax . lines ) def _normal () -> Iterator [ Tuple [ str , H ]]: for n in range ( k + 1 , k + 9 ): p = n @ P ( d ) yield f \" { n } d { d } keep { k } \" , p . h ( slice ( - k , None )) plot_line ( ax , tuple ( _normal ()), alpha = 0.25 ) for i in range ( marker_start , len ( ax . lines )): ax . lines [ i ] . set_marker ( \"o\" ) ax . legend ( loc = \"upper left\" ) ax . set_title ( \"Roll-and-keep mechanic comparison\" , color = text_color ) Translation of the accepted answer to \u201c Modelling opposed dice pools with a swap \u201d Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 >>> from dyce.p import RollT >>> def brawl ( roll_a : RollT , roll_b : RollT ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... return a_successes - b_successes Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from dyce import P >>> res = P . foreach ( brawl , roll_a = 3 @P ( 6 ), roll_b = 3 @P ( 6 )) >>> print ( res . format ()) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> def brawl_w_optional_swap ( roll_a : RollT , roll_b : RollT ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... # Sort greatest-to-least after the swap ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... else : ... # Reverse to be greatest-to-least ... roll_a = roll_a [:: - 1 ] ... roll_b = roll_b [:: - 1 ] ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... return result Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> res = P . foreach ( brawl_w_optional_swap , roll_a = 3 @P ( 6 ), roll_b = 3 @P ( 6 )) >>> print ( res . format ()) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = P . foreach ( brawl_w_optional_swap , roll_a = 4 @P ( 6 ), roll_b = 4 @P ( 6 )) >>> print ( res . format ()) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Applications and translations"},{"location":"translations/#checking-angrys-math-on-the-tension-pool","text":"In the Angry GM \u2019s publication of the PDF version of his Tension Pool mechanic , he includes some probabilities. Can dyce check his work? You bet! Let\u2019s reproduce his tables (with slightly different names to provide context). d6s in pool Angry\u2019s probability of at least one 1 showing 1 16.7% 2 30.6% 3 42.1% 4 51.8% 5 59.8% 6 66.5% How do we do compute these results using dyce ? 1 2 3 4 5 6 7 8 9 10 11 12 >>> from dyce import H >>> one_in_d6 = H ( 6 ) . eq ( 1 ) >>> for n in range ( 1 , 7 ): ... ones_in_nd6 = n @one_in_d6 ... at_least_one_one_in_nd6 = ones_in_nd6 . ge ( 1 ) ... print ( f \" { n } : { at_least_one_one_in_nd6 [ 1 ] / at_least_one_one_in_nd6 . total : 6.2% } \" ) 1 : 16.67 % 2 : 30.56 % 3 : 42.13 % 4 : 51.77 % 5 : 59.81 % 6 : 66.51 % So far so good. Let\u2019s keep going. 1d8 + 1d12 Rarity or Severity 2-4 Very Rare or Extreme 5-6 Rare or Major 7-8 Uncommon or Moderate 9-13 Common or Minor 14-15 Uncommon or Moderate 16-17 Rare or Major 18-20 Very Rare or Extreme We need to map semantic outcomes to numbers (and back again). How can we represent those in dyce ? One way is IntEnum s. IntEnum s have a property that allows them to substitute directly for int s, which, with a little nudging, is very convenient. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 >>> from enum import IntEnum >>> class Complication ( IntEnum ): ... NONE = 0 # this will come in handy later ... COMMON = 1 ... UNCOMMON = 2 ... RARE = 3 ... VERY_RARE = 4 >>> OUTCOME_TO_RARITY_MAP = { ... 2 : Complication . VERY_RARE , ... 3 : Complication . VERY_RARE , ... 4 : Complication . VERY_RARE , ... 5 : Complication . RARE , ... 6 : Complication . RARE , ... 7 : Complication . UNCOMMON , ... 8 : Complication . UNCOMMON , ... 9 : Complication . COMMON , ... 10 : Complication . COMMON , ... 11 : Complication . COMMON , ... 12 : Complication . COMMON , ... 13 : Complication . COMMON , ... 14 : Complication . UNCOMMON , ... 15 : Complication . UNCOMMON , ... 16 : Complication . RARE , ... 17 : Complication . RARE , ... 18 : Complication . VERY_RARE , ... 19 : Complication . VERY_RARE , ... 20 : Complication . VERY_RARE , ... } Now let\u2019s use our map to validate the probabilities of a particular outcome using that d8 and d12. Rarity or impact Angry\u2019s probability of a Complication arising Common or Minor 41.7% Uncommon or Moderate 27.1% Rare or Major 18.8% Very Rare or Extreme 12.5% 1 2 3 4 5 6 7 8 9 >>> prob_of_complication = H . foreach ( ... lambda outcome : OUTCOME_TO_RARITY_MAP [ outcome ], ... outcome = H ( 8 ) + H ( 12 ), ... ) >>> { outcome : f \" { float ( prob ) : 6.2% } \" for outcome , prob in prob_of_complication . distribution ()} { < Complication . COMMON : 1 > : '41.67%' , < Complication . UNCOMMON : 2 > : '27.08%' , < Complication . RARE : 3 > : '18.75%' , < Complication . VERY_RARE : 4 > : '12.50%' } Lookin\u2019 good! Now let\u2019s put everything together. d6s in pool None Common Uncommon Rare Very Rare 1 83.3% 7.0% 4.5% 3.1% 2.1% 2 69.4% 12.7% 8.3% 5.7% 3.8% 3 57.9% 17.6% 11.4% 7.9% 5.3% 4 48.2% 21.6% 14.0% 9.7% 6.5% 5 40.2% 24.9% 16.2% 11.2% 7.5% 6 33.5% 27.7% 18.0% 12.5% 8.3% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> from typing import cast >>> for n in range ( 1 , 7 ): ... ones_in_nd6 = n @one_in_d6 ... at_least_one_one_in_nd6 = ones_in_nd6 . ge ( 1 ) ... prob_complication_in_nd6 = at_least_one_one_in_nd6 * prob_of_complication ... complications_for_nd6 = { ... Complication ( cast ( int , outcome )) . name : f \" { float ( prob ) : 6.2% } \" ... for outcome , prob in ( prob_complication_in_nd6 ) . distribution () ... } ... print ( \" {} -> {} \" . format ( n , complications_for_nd6 )) 1 -> { 'NONE' : '83.33%' , 'COMMON' : ' 6.94%' , 'UNCOMMON' : ' 4.51%' , 'RARE' : ' 3.12%' , 'VERY_RARE' : ' 2.08%' } 2 -> { 'NONE' : '69.44%' , 'COMMON' : '12.73%' , 'UNCOMMON' : ' 8.28%' , 'RARE' : ' 5.73%' , 'VERY_RARE' : ' 3.82%' } 3 -> { 'NONE' : '57.87%' , 'COMMON' : '17.55%' , 'UNCOMMON' : '11.41%' , 'RARE' : ' 7.90%' , 'VERY_RARE' : ' 5.27%' } 4 -> { 'NONE' : '48.23%' , 'COMMON' : '21.57%' , 'UNCOMMON' : '14.02%' , 'RARE' : ' 9.71%' , 'VERY_RARE' : ' 6.47%' } 5 -> { 'NONE' : '40.19%' , 'COMMON' : '24.92%' , 'UNCOMMON' : '16.20%' , 'RARE' : '11.21%' , 'VERY_RARE' : ' 7.48%' } 6 -> { 'NONE' : '33.49%' , 'COMMON' : '27.71%' , 'UNCOMMON' : '18.01%' , 'RARE' : '12.47%' , 'VERY_RARE' : ' 8.31%' } Well butter my butt, and call me a biscuit! That Angry guy sure knows his math!","title":"Checking Angry\u2019s math on the Tension Pool"},{"location":"translations/#modeling-ironsworns-core-mechanic","text":"Shawn Tomlin\u2019s Ironsworn melds a number of different influences in a fresh way. Its core mechanic involves rolling an action die (a d6), adding a modifier, and comparing the resulting value to two challenge dice (d10s). If the modified value from the action die is strictly greater than both challenge dice, the result is a strong success. If it is strictly greater than only one challenge die, the result is a weak success. If it is equal to or less than both challenge dice, it\u2019s a failure. A verbose way to model this is to enumerate the product of the three dice and then perform logical comparisons. However, if we recognize that our problem involves a dependent probability , we can craft a solution in terms of H.foreach . We can also deploy a counting trick with the two d10s. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from dyce import H , as_int >>> from numerary.types import RealLike >>> from enum import IntEnum , auto >>> from typing import Iterator , Tuple , cast >>> d6 = H ( 6 ) >>> d10 = H ( 10 ) >>> class IronResult ( IntEnum ): ... FAILURE = 0 ... WEAK_SUCCESS = auto () ... STRONG_SUCCESS = auto () >>> iron_distributions_by_mod = { ... mod : H . foreach ( lambda action : 2 @ ( d10 . lt ( action )), action = d6 + mod ) ... for mod in range ( 5 ) ... } >>> for mod , iron_distribution in iron_distributions_by_mod . items (): ... print ( \" {:+} -> {} \" . format ( mod , { ... IronResult ( cast ( int , outcome )) . name : f \" { float ( prob ) : 6.2% } \" ... for outcome , prob in iron_distribution . distribution () ... })) + 0 -> { 'FAILURE' : '59.17%' , 'WEAK_SUCCESS' : '31.67%' , 'STRONG_SUCCESS' : ' 9.17%' } + 1 -> { 'FAILURE' : '45.17%' , 'WEAK_SUCCESS' : '39.67%' , 'STRONG_SUCCESS' : '15.17%' } + 2 -> { 'FAILURE' : '33.17%' , 'WEAK_SUCCESS' : '43.67%' , 'STRONG_SUCCESS' : '23.17%' } + 3 -> { 'FAILURE' : '23.17%' , 'WEAK_SUCCESS' : '43.67%' , 'STRONG_SUCCESS' : '33.17%' } + 4 -> { 'FAILURE' : '15.17%' , 'WEAK_SUCCESS' : '39.67%' , 'STRONG_SUCCESS' : '45.17%' } What\u2019s with that 2 @ ( d10 . lt ( action )) ? Let\u2019s break it down. H ( 10 ) . lt ( value ) will tell us how often a single d10 is less than value . 1 2 >>> H ( 10 ) . lt ( 5 ) # how often a d10 is strictly less than 5 H ({ False : 6 , True : 4 }) By summing those results (and taking advantage of the fact that, in Python, bool s act like int s when it comes to arithmetic operators), we can count how often that happens with more than one interchangeable d10. 1 2 3 4 >>> h = H ( 10 ) . lt ( 5 ) + H ( 10 ) . lt ( 5 ) ; h H ({ 0 : 36 , 1 : 48 , 2 : 16 }) >>> h . total 100 How do we interpret those results? 36 times out of a hundred, neither d10 will be strictly less than five. 48 times out of a hundred, exactly one of the d10s will be strictly less than five. 16 times out of a hundred, both d10s will be strictly less than five. H \u2019s @ operator provides a shorthand. 1 2 3 >>> # The parentheses are technically redundant, but clarify the intention >>> 2 @ ( H ( 10 ) . lt ( 5 )) == H ( 10 ) . lt ( 5 ) + H ( 10 ) . lt ( 5 ) True Why doesn\u2019t 2 @ ( H ( 6 ) . gt ( H ( 10 )) work? H ( 6 ) . gt ( H ( 10 )) will compute how often a six-sided die is strictly greater than a ten-sided die. 2 @ ( H ( 6 ) . gt ( H ( 10 ))) will show the frequencies that a first six-sided die is strictly greater than a first ten-sided die and a second six-sided die is strictly greater than a second ten-sided die. This isn\u2019t quite what we want, since the mechanic calls for rolling a single six-sided die and comparing that result to each of two ten-sided dice. Now for a twist . In cooperative or solo play, a failure or success is particularly spectacular when the d10s come up doubles. The key to mapping that to dyce internals is recognizing that we have a dependent probability that involves three independent variables: the (modded) d6, a first d10, and a second d10. H.foreach is especially useful where there are multiple independent terms. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 >>> class IronSoloResult ( IntEnum ): ... FAILURE = 0 ... WEAK_SUCCESS = auto () ... STRONG_SUCCESS = auto () ... SPECTACULAR_SUCCESS = auto () ... SPECTACULAR_FAILURE = - 1 >>> def iron_solo_dependent_term ( action , first_challenge , second_challenge , mod = 0 ): ... modded_action = action + mod ... beats_first_challenge = modded_action > first_challenge ... beats_second_challenge = modded_action > second_challenge ... doubles = first_challenge == second_challenge ... if beats_first_challenge and beats_second_challenge : ... return IronSoloResult . SPECTACULAR_SUCCESS if doubles else IronSoloResult . STRONG_SUCCESS ... elif beats_first_challenge or beats_second_challenge : ... return IronSoloResult . WEAK_SUCCESS ... else : ... return IronSoloResult . SPECTACULAR_FAILURE if doubles else IronSoloResult . FAILURE >>> H . foreach ( ... iron_solo_dependent_term , # mod defaults to 0 ... action = d6 , ... first_challenge = d10 , ... second_challenge = d10 , ... ) H ({ < IronSoloResult . SPECTACULAR_FAILURE : - 1 > : 9 , < IronSoloResult . FAILURE : 0 > : 62 , < IronSoloResult . WEAK_SUCCESS : 1 > : 38 , < IronSoloResult . STRONG_SUCCESS : 2 > : 8 , < IronSoloResult . SPECTACULAR_SUCCESS : 3 > : 3 }) By defining our dependent term function to include mod as a parameter with a default argument, we can use partial to manipulate it, which is helpful for visualization. Source: plot_ironsworn.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from collections import defaultdict from enum import IntEnum , auto from functools import partial from dyce import H class IronSoloResult ( IntEnum ): SPECTACULAR_FAILURE = - 1 FAILURE = auto () WEAK_SUCCESS = auto () STRONG_SUCCESS = auto () SPECTACULAR_SUCCESS = auto () def do_it ( style : str ) -> None : import matplotlib.pyplot import matplotlib.ticker d6 = H ( 6 ) d10 = H ( 10 ) def iron_solo_dependent_term ( action , first_challenge , second_challenge , mod = 0 ): modded_action = action + mod beats_first = modded_action > first_challenge beats_second = modded_action > second_challenge doubles = first_challenge == second_challenge if beats_first and beats_second : return ( IronSoloResult . SPECTACULAR_SUCCESS if doubles else IronSoloResult . STRONG_SUCCESS ) elif beats_first or beats_second : return IronSoloResult . WEAK_SUCCESS else : return ( IronSoloResult . SPECTACULAR_FAILURE if doubles else IronSoloResult . FAILURE ) ax = matplotlib . pyplot . axes () by_result = defaultdict ( list ) mods = list ( range ( 0 , 5 )) text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) ax . yaxis . set_major_formatter ( matplotlib . ticker . PercentFormatter ( xmax = 1 )) for mod in mods : results_for_mod = H . foreach ( partial ( iron_solo_dependent_term , mod = mod ), action = d6 , first_challenge = d10 , second_challenge = d10 , ) distribution_for_mod = dict ( results_for_mod . distribution ()) for result in IronSoloResult : result_val = float ( distribution_for_mod . get ( result , 0 )) by_result [ result ] . append ( result_val ) labels = [ str ( mod ) for mod in mods ] bottoms = [ 0.0 for _ in mods ] for result in IronSoloResult : result_vals = by_result [ result ] assert len ( result_vals ) == len ( mods ) ax . bar ( labels , result_vals , bottom = bottoms , label = result . name ) bottoms = [ bottom + result_val for bottom , result_val in zip ( bottoms , result_vals ) ] ax . legend () ax . set_xlabel ( \"Modifier\" , color = text_color ) ax . set_title ( \"Ironsworn distributions\" , color = text_color )","title":"Modeling Ironsworn\u2019s core mechanic"},{"location":"translations/#advanced-topic-modeling-risis","text":"Risus and its many community-developed alternative rules not only make for entertaining reading, but are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model the first round of its opposed combat system for various starting configurations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map. Source: plot_risus_first_round.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from typing import List , Tuple from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] col_ticks = list ( range ( len ( col_names ))) num_scenarios = 3 text_color = \"white\" if style == \"dark\" else \"black\" for i , them in enumerate ( range ( 3 , 3 + num_scenarios )): ax = matplotlib . pyplot . subplot ( 1 , num_scenarios , i + 1 ) row_names : List [ str ] = [] rows : List [ Tuple [ float , ... ]] = [] num_rows = 3 for us in range ( them , them + num_rows ): row_names . append ( f \" { us } d6 \u2026\" ) rows . append (( us @ H ( 6 )) . vs ( them @ H ( 6 )) . distribution_xy ()[ - 1 ]) ax . imshow ( rows ) ax . set_title ( f \"\u2026 vs { them } d6\" , color = text_color ) ax . set_xticks ( col_ticks ) ax . set_xticklabels ( col_names , color = text_color , rotation = 90 ) ax . set_yticks ( list ( range ( len ( rows )))) ax . set_yticklabels ( row_names , color = text_color ) for y in range ( len ( row_names )): for x in range ( len ( col_names )): ax . text ( x , y , f \" { rows [ y ][ x ] : .0% } \" , ha = \"center\" , va = \"center\" , color = \"w\" , )","title":"Advanced topic \u2013 modeling Risis"},{"location":"translations/#modeling-entire-multi-round-combats","text":"With a little elbow finger grease, we can roll up our \u2026 erm \u2026 fingerless gloves and even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 >>> from dyce import H , P >>> import sys >>> from enum import IntEnum , auto >>> from typing import Callable , Dict , Tuple >>> if sys . version_info >= ( 3 , 9 ): ... from functools import cache ... else : ... from functools import lru_cache ... cache = lru_cache ( maxsize = None ) >>> class Risus ( IntEnum ): ... LOSS = - 1 ... DRAW = auto () ... WIN = auto () >>> @cache ... def risus_combat_driver ( ... us : int , # number of dice we still have ... them : int , # number of dice they still have ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... ... def _resolve ( us : int , them : int ) -> H : ... if us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... if them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( this_round_outcome ) -> H : ... if this_round_outcome == Risus . LOSS : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif this_round_outcome == Risus . WIN : return _resolve ( us , them - 1 ) # they lost this round, and one die ... elif this_round_outcome == Risus . DRAW : return H ({}) # ignore (immediately re-roll) all ties ... else : assert False , f \"unrecognized this_round_outcome { this_round_outcome } \" ... ... return H . foreach ( _next_round , this_round_outcome = this_round ) ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } There\u2019s lot going on there. Let\u2019s dissect it. 16 17 18 19 20 21 22 @cache def risus_combat_driver ( us : int , # number of dice we still have them : int , # number of dice they still have us_vs_them_func : Callable [[ int , int ], H ], ) -> H : ... Our \u201cdriver\u201d takes three arguments: How many dice we have left ( us ); How many dice the opposition has left ( them ); and A resolution function ( us_vs_them_func ) that takes counts of each party\u2019s remaining dice and returns a histogram encoding the probability of winning or losing a single round akin to the H.vs method : An outcome of - 1 signals the opposition\u2019s victory An outcome of 1 signals our victory. An outcome of 0 signals a tie. The @cache decorator does simple memoization for us because there are redundancies. For example, we might compute a case where we lose a die, then our opposition loses a die. We arrive at a similar case where our opposition loses a die, then we lose a die. Both cases would be identical from that point on. In this context, @cache helps us avoid recomputing redundant sub-trees. 22 23 24 25 if us < 0 or them < 0 : raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) if us == 0 and them == 0 : return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start We make some preliminary checks that guard access to our recursive implementation so that it can be a little cleaner. 27 28 def _resolve ( us : int , them : int ) -> H : ... 39 return _resolve ( us , them ) Skipping over its implementation for now, we define a our memoized recursive implementation ( _resolve ) and then call it with our initial arguments. 27 28 29 def _resolve ( us : int , them : int ) -> H : if us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win if them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win Getting back to that implementation, these are our base cases. We check whether either party has run out of dice, in which case the combat is over. If we have none of those cases, we get to work. Note In this function, we do not check for the case where both parties are at zero. Because only one party can lose a die during each round, the only way both parties can be at zero simultaneously is if they both started at zero. Since we guard against that case in the enclosing function, we don\u2019t have to worry about it here. Either us is zero, them is zero, or neither is zero. 30 this_round = us_vs_them_func ( us , them ) Then, we compute the outcomes for this round using the provided resolution function. 32 33 def _next_round ( this_round_outcome ) -> H : ... 38 return H . foreach ( _next_round , this_round_outcome = this_round ) Keeping in mind that we\u2019re inside our recursive implementation, we define a dependent term specifically for use with H.foreach . This allows us to take our computation for this round, and \u201cfold in\u201d subsequent rounds. 32 33 34 35 def _next_round ( this_round_outcome ) -> H : if this_round_outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die elif this_round_outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die else : return H ({}) # ignore (immediately re-roll) all ties Our substitution function is pretty straightforward. Where we are asked whether we want to provide a substitution for a round we lost, we lose a die and recurse. Where we are asked for a substitution for a round we won, our opposition loses a die and we recurse. We ignore ties (simulating that we re-roll them in place until they are no longer ties). 44 45 46 47 ... risus_combat_driver ( u , t , lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ) ... At this point, we can define a simple lambda that wraps H.vs and submit it to our driver to enumerate resolution outcomes from various starting positions. Note This is a complicated example that involves some fairly sophisticated programming techniques (recursion, memoization, nested functions, etc.). The point is not to suggest that such techniques are required to be productive. However, it is useful to show that dyce is flexible enough to model these types of outcomes in a couple dozen lines of code. It is high-level enough to lean on for nuanced number crunching without a lot of detailed knowledge, while still being low-level enough that authors knowledgeable of advanced programming techniques are not precluded from using them.","title":"Modeling entire multi-round combats"},{"location":"translations/#modeling-different-combat-resolution-methods","text":"Using our risus_combat_driver from above, we can craft a alternative resolution function to model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d for resolving ties. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath Rule: tie goes to the party with fewer dice in this round ... h = H . foreach ( ... lambda outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome , ... outcome = h , ... ) ... return h >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 44.13 % , 1 : 55.87 % } 7 d6 vs 5 d6 : { ... , - 1 : 36.89 % , 1 : 63.11 % } The \u201c Evens Up \u201d alternative dice mechanic presents some challenges. First, dyce \u2019s substitution mechanism only resolves outcomes through a fixed number of iterations, so it can only approximate probabilities for infinite series. Most of the time, the implications are largely theoretical with a sufficient number of iterations. This is no exception. Second, with one narrow exception , dyce only provides a mechanism to directly substitute outcomes, not counts. This means we can\u2019t arbitrarily increase the likelihood of achieving a particular outcome through replacement. With some creativity, we can work around that, too. In the case of \u201cEvens Up\u201d, we need to keep track of whether an even number was rolled, but we also need to keep rolling (and accumulating) as long as sixes are rolled. This behaves a lot like an exploding die with three values (miss, hit, and hit-and-explode). Further, we can observe that every \u201crun\u201d will be zero or more exploding hits terminated by either a miss or a non-exploding hit. If we choose our values carefully, we can encode how many times we\u2019ve encountered relevant events as we explode. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> import operator >>> MISS = 0 >>> HIT = 1 >>> HIT_EXPLODE = 2 >>> d_evens_up_raw = H (( ... MISS , # 1 ... HIT , # 2 ... MISS , # 3 ... HIT , # 4 ... MISS , # 5 ... HIT_EXPLODE , # 6 ... )) >>> d_evens_up_exploded = d_evens_up_raw . explode ( max_depth = 3 ) ; d_evens_up_exploded H ({ 0 : 648 , 1 : 432 , 2 : 108 , 3 : 72 , 4 : 18 , 5 : 12 , 6 : 3 , 7 : 2 , 8 : 1 }) For every value that is even, we ended in a miss. For every value that is odd, we ended in a hit that will need to be tallied. Dividing by two and ignoring any remainder will tell us how many exploding hits we had along the way. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> def decode_hits ( outcome ): ... return ( outcome + 1 ) // 2 # equivalent to outcome // 2 + outcome % 2 >>> d_evens_up = H . foreach ( decode_hits , outcome = d_evens_up_exploded ) >>> print ( d_evens_up . format ()) avg | 0.60 std | 0.69 var | 0.48 0 | 50.00 % | ######################### 1 | 41.67 % | #################### 2 | 6.94 % | ### 3 | 1.16 % | 4 | 0.23 % | We can now approximate a complete \u201cEvens Up\u201d combat using our risus_combat_driver from above. We can also deploy a trick using partial to parameterize use of the Goliath Rule. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from functools import partial >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d_evens_up ) . vs ( them @d_evens_up ) ... if goliath : ... h = H . foreach ( lambda outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome , outcome = h ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"----------- ---- With Goliath Rule ----- --- Without Goliath Rule ---\" ) ... for u in range ( t , t + 3 ): ... goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... no_goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = False )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { goliath_results } { no_goliath_results } \" ) ----------- ---- With Goliath Rule ----- --- Without Goliath Rule --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 29.51 % , 1 : 70.49 % } { ... , - 1 : 19.08 % , 1 : 80.92 % } 5 d6 vs 3 d6 : { ... , - 1 : 12.32 % , 1 : 87.68 % } { ... , - 1 : 4.57 % , 1 : 95.43 % } ----------- ---- With Goliath Rule ----- --- Without Goliath Rule --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 30.52 % , 1 : 69.48 % } { ... , - 1 : 21.04 % , 1 : 78.96 % } 6 d6 vs 4 d6 : { ... , - 1 : 13.68 % , 1 : 86.32 % } { ... , - 1 : 5.88 % , 1 : 94.12 % }","title":"Modeling different combat resolution methods"},{"location":"translations/#modeling-the-probability-of-4d6-drop-the-lowest-reroll-1s","text":"1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H , P >>> res1 = 3 @H ( 6 ) >>> p_4d6 = 4 @P ( 6 ) >>> res2 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : h if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res3 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H (( 2 , 3 , 4 , 5 , 6 ))) >>> res4 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest >>> res5 = 2 @H ( 6 ) + 6 >>> res6 = 4 @H ( 4 ) + 2 Visualization: Source: plot_4d6_variants.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot res1 = 3 @ H ( 6 ) p_4d6 = 4 @ P ( 6 ) res2 = p_4d6 . h ( slice ( 1 , None )) d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : h if outcome == 1 else outcome ) p_4d6_reroll_first_one = 4 @ P ( d6_reroll_first_one ) res3 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) p_4d6_reroll_all_ones = 4 @ P ( H ( 5 ) + 1 ) res4 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) res5 = 2 @ H ( 6 ) + 6 res6 = 4 @ H ( 4 ) + 2 ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [ ( \"3d6\" , res1 ), # marker=\"D\" ( \"4d6 - discard lowest\" , res2 ), # marker=\"s\" ( \"4d6 - re-roll first 1, discard lowest\" , res3 ), # marker=\"^\" ( \"4d6 - re-roll all 1s (i.e., 4d5 + 1), discard lowest\" , res4 , ), # marker=\"*\" ( \"2d6 + 6\" , res5 ), # marker=\"x\" ( \"4d4 + 2\" , res6 ), # marker=\"o\" ], ) for line , marker in zip ( ax . lines , \"Ds^*xo\" ): line . set_marker ( marker ) ax . legend () ax . set_title ( \"Comparing various take-three-of-4d6 methods\" , color = text_color )","title":"Modeling \u201cThe Probability of 4d6, Drop the Lowest, Reroll 1s\u201d"},{"location":"translations/#translating-one-example-from-markbrockettrobsonpython_dice","text":"Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 5 >>> from dyce import H >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: Source: plot_burning_arch.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot save_roll = H ( 20 ) burning_arch_damage = 10 @ H ( 6 ) + 10 pass_save = save_roll . ge ( 10 ) damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [( \"\" , damage_half_on_save )]) ax . set_title ( \"Attack with saving throw for half damage\" , color = text_color ) An alternative using the H.foreach class method : 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> H . foreach ( ... lambda outcome : ( ... burning_arch_damage // 2 ... if operator . __ge__ ( outcome , 10 ) ... else burning_arch_damage ... ), ... outcome = save_roll , ... ) == damage_half_on_save True","title":"Translating one example from markbrockettrobson/python_dice"},{"location":"translations/#more-translations-from-markbrockettrobsonpython_dice","text":"1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_h = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_h . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> max_h = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( max_h . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> min_h = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( min_h . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % }","title":"More translations from markbrockettrobson/python_dice"},{"location":"translations/#translations-from-lordsembordndice","text":"Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { ... , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { ... , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: Source: plot_great_weapon_fighting.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_burst , plot_line from dyce import H def do_it ( style : str ) -> None : import matplotlib.pyplot single_attack = 2 @ H ( 6 ) + 5 def gwf ( h : H , outcome ): return h if outcome in ( 1 , 2 ) else outcome great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 text_color = \"white\" if style == \"dark\" else \"black\" label_sa = \"Normal attack\" label_gwf = \"\u201cGreat Weapon Fighting\u201d\" ax_plot = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 0 )) ax_plot . tick_params ( axis = \"x\" , colors = text_color ) ax_plot . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax_plot , [( label_sa , single_attack ), ( label_gwf , great_weapon_fighting )]) ax_plot . lines [ 0 ] . set_color ( \"tab:green\" ) ax_plot . lines [ 1 ] . set_color ( \"tab:blue\" ) ax_plot . legend () ax_burst = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 1 )) plot_burst ( ax_burst , h_inner = great_weapon_fighting , h_outer = single_attack , title = f \" { label_sa } \\n vs. \\n { label_gwf } \" , inner_color = \"RdYlBu_r\" , outer_color = \"RdYlGn_r\" , text_color = text_color , ) Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = H . foreach ( crit , outcome = advantage ) Example 2 visualization: Source: plot_advantage.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot normal_hit = H ( 12 ) + 5 critical_hit = 3 @ H ( 12 ) + 5 advantage = ( 2 @ P ( 20 )) . h ( - 1 ) def crit ( outcome ): if outcome == 20 : return critical_hit elif outcome + 5 >= 14 : return normal_hit else : return 0 advantage_weighted = H . foreach ( crit , outcome = advantage ) ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [ ( \"Normal hit\" , normal_hit ), ( \"Critical hit\" , critical_hit ), ( \"Advantage-weighted\" , advantage_weighted ), ], ) ax . legend () ax . set_title ( \"Advantage-weighted attack with critical hits\" , color = text_color )","title":"Translations from LordSembor/DnDice"},{"location":"translations/#translation-of-the-accepted-answer-to-roll-and-keep-in-anydice","text":"Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 2 >>> from dyce import H , P >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: Source: plot_d10_explode.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_line ( ax , [ ( f \" { depth } rerolls\" , ( 10 @ P ( H ( 10 ) . explode ( max_depth = depth ))) . h ( slice ( - 3 , None )), ) for depth in range ( 5 , - 1 , - 1 ) ], ) for line in ax . lines : line . set_marker ( \"\" ) ax . legend () ax . set_title ( \"Taking the three highest of ten exploding d10s\" , color = text_color )","title":"Translation of the accepted answer to \u201cRoll and Keep in Anydice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-how-do-i-count-the-number-of-duplicates-in-anydice","text":"Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 11 12 >>> from dyce import P >>> from dyce.p import RollT >>> def dupes ( roll : RollT ): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... return dupes >>> res_15d6 = P . foreach ( dupes , roll = 15 @P ( 6 )) >>> res_8d10 = P . foreach ( dupes , roll = 8 @P ( 10 )) Visualization: Source: plot_dupes.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from anydyce.viz import plot_scatter from dyce import P from dyce.p import RollT def do_it ( style : str ) -> None : import matplotlib.pyplot def dupes ( roll : RollT ): dupes = 0 for i in range ( 1 , len ( roll )): if roll [ i ] == roll [ i - 1 ]: dupes += 1 return dupes res_15d6 = P . foreach ( dupes , roll = 15 @ P ( 6 )) res_8d10 = P . foreach ( dupes , roll = 8 @ P ( 10 )) matplotlib . pyplot . rcParams [ \"lines.markersize\" ] *= 2 ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) plot_scatter ( ax , [( \"15d6\" , res_15d6 ), ( \"8d10\" , res_8d10 )], alpha = 1.0 ) ax . legend () ax . set_title ( \"Chances of rolling $n$ duplicates\" , color = text_color )","title":"Translation of the accepted answer to \u201cHow do I count the number of duplicates in anydice?\u201d"},{"location":"translations/#translation-of-how-do-i-implement-this-specialized-roll-and-keep-mechanic-in-anydice","text":"Source: 1 2 3 4 5 6 7 8 9 function: N:n of SIZE:n keep K:n extras add { result: [helper NdSIZE SIZE K] } function: helper ROLL:s SIZE:n K:n { COUNT: [count SIZE in ROLL] if COUNT > K { result: K*SIZE - K + COUNT } result: {1..K}@ROLL } Translation: 1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H , P >>> def roll_and_keep ( p : P , k : int ): ... assert p . is_homogeneous ... max_d = max ( p [ - 1 ]) if p else 0 ... for roll , count in p . rolls_with_counts (): ... total = sum ( roll [ - k :]) + sum ( 1 for outcome in roll [: - k ] if outcome == max_d ) ... yield total , count >>> H ( roll_and_keep ( 6 @P ( 6 ), 3 )) H ({ 3 : 1 , 4 : 6 , 5 : 21 , 6 : 78 , 7 : 207 , ... , 17 : 5535 , 18 : 2500 , 19 : 375 , 20 : 30 , 21 : 1 }) Visualization: Source: plot_roll_and_keep.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # ====================================================================================== # Copyright and other protections apply. Please see the accompanying LICENSE file for # rights and restrictions governing use of this software. All rights not expressly # waived or licensed are reserved. If that file is missing or appears to be modified # from its original, then please contact the author before viewing or using this # software in any capacity. # ====================================================================================== from __future__ import annotations from typing import Iterator , Tuple from anydyce.viz import plot_line from dyce import H , P def do_it ( style : str ) -> None : import matplotlib.pyplot def roll_and_keep ( p : P , k : int ): assert p . is_homogeneous max_d = max ( p [ - 1 ]) if p else 0 for roll , count in p . rolls_with_counts (): total = sum ( roll [ - k :]) + sum ( 1 for outcome in roll [: - k ] if outcome == max_d ) yield total , count d , k = 6 , 3 ax = matplotlib . pyplot . axes () text_color = \"white\" if style == \"dark\" else \"black\" ax . tick_params ( axis = \"x\" , colors = text_color ) ax . tick_params ( axis = \"y\" , colors = text_color ) marker_start = 0 def _roll_and_keep_hs () -> Iterator [ Tuple [ str , H ]]: for n in range ( k + 1 , k + 9 ): p = n @ P ( d ) yield f \" { n } d { d } keep { k } add +1\" , H ( roll_and_keep ( p , k )) plot_line ( ax , tuple ( _roll_and_keep_hs ()), alpha = 0.75 ) for i in range ( marker_start , len ( ax . lines )): ax . lines [ i ] . set_marker ( \".\" ) marker_start = len ( ax . lines ) def _normal () -> Iterator [ Tuple [ str , H ]]: for n in range ( k + 1 , k + 9 ): p = n @ P ( d ) yield f \" { n } d { d } keep { k } \" , p . h ( slice ( - k , None )) plot_line ( ax , tuple ( _normal ()), alpha = 0.25 ) for i in range ( marker_start , len ( ax . lines )): ax . lines [ i ] . set_marker ( \"o\" ) ax . legend ( loc = \"upper left\" ) ax . set_title ( \"Roll-and-keep mechanic comparison\" , color = text_color )","title":"Translation of \u201cHow do I implement this specialized roll-and-keep mechanic in AnyDice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-modelling-opposed-dice-pools-with-a-swap","text":"Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 >>> from dyce.p import RollT >>> def brawl ( roll_a : RollT , roll_b : RollT ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... return a_successes - b_successes Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from dyce import P >>> res = P . foreach ( brawl , roll_a = 3 @P ( 6 ), roll_b = 3 @P ( 6 )) >>> print ( res . format ()) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> def brawl_w_optional_swap ( roll_a : RollT , roll_b : RollT ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... # Sort greatest-to-least after the swap ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... else : ... # Reverse to be greatest-to-least ... roll_a = roll_a [:: - 1 ] ... roll_b = roll_b [:: - 1 ] ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... return result Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> res = P . foreach ( brawl_w_optional_swap , roll_a = 3 @P ( 6 ), roll_b = 3 @P ( 6 )) >>> print ( res . format ()) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = P . foreach ( brawl_w_optional_swap , roll_a = 4 @P ( 6 ), roll_b = 4 @P ( 6 )) >>> print ( res . format ()) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Translation of the accepted answer to \u201cModelling opposed dice pools with a swap\u201d"}]}