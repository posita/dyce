{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to dyce dyce is a pure-Python library for exploring dice probabilities designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. dyce is an AnyDice replacement that leverages Pythonic syntax and operators for rolling dice and computing weighted outcomes. While Python is not as terse as a dedicated grammar, it is quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. dyce is fairly low level by design, prioritizing ergonomics and composability. While any AnyDice generously affords a very convenient platform for simple computations, its idiosyncrasies can lead to confusion and complicated workarounds. Like AnyDice, it avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. Unlike AnyDice, however, it is an open source library that can be run locally and modified as desired. Because it exposes Python primitives rather than defining a dedicated grammar and interpreter, one can easily integrate it with other Python tools and libraries. In an intentional departure from RFC 1925, \u00a7 2.2 , it provides minor computation optimizations (e.g., the H.lowest_terms method and various shorthands) and formatting conveniences (e.g., the H.data , H.data_xy , and H.format methods) for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter . dyce should be sufficient to replicate or replace AnyDice and most other dice probability modeling libraries. It strives to be fully documented and relies heavily on examples to develop understanding. If you find its functionality or documentation confusing or lacking in any way, please consider contributing an issue to start a discussion. Source code is available on GitHub . Examples dyce provides two key primitives: 1 >>> from dyce import H , P H objects represent histograms for modeling individual dice and outcomes. P objects represent pools (ordered sequences) of histograms. A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H(n) is shorthand for explicitly enumerating faces \\([{{1} .. {n}}]\\) , each with a frequency of 1: 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating faces are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P(n, ...) is shorthand for P(H(n), ...) . The above can be expressed more succinctly: 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case Sicherman dice ) can be compared to histograms: 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. One way to model outcomes from subtracting the least of two six-sided dice from the greatest is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms: 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of the pool\u2019s faces. This is done by providing one or more index arguments to the h method . Indexes can be integers, slices, or iterables thereof. Face indexes are ordered from least to greatest (i.e., 0 , 1 , \u2026, -2 , -1 ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than [\u2026] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Histograms provide rudimentary formatting for convenience: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 3 @P ( 6 )) . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( _ . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 3 @P ( 6 )) . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( _ . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 3 @P ( 6 )) . h ( - 1 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( _ . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> H ( 10 ) - 1 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> _ = P ( 4 , 6 , 8 , _ , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( _ . format ( width = 65 )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | 5 | 0.92 % | 6 | 2.03 % | # 7 | 3.76 % | # 8 | 5.57 % | ## 9 | 7.78 % | ### 10 | 8.99 % | #### 11 | 8.47 % | #### 12 | 8.64 % | #### 13 | 8.66 % | #### 14 | 6.64 % | ### 15 | 5.62 % | ## 16 | 5.16 % | ## 17 | 5.00 % | ## 18 | 5.00 % | ## 19 | 5.00 % | ## 20 | 5.00 % | ## 21 | 4.50 % | ## 22 | 2.01 % | # 23 | 0.73 % | 24 | 0.18 % | Note that pools are ordered and iterable: 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms in a pool: 1 2 >>> ( 2 @P ( 8 , 4 , 6 ))[ 1 : 3 ] ( H ( 4 ), H ( 6 )) If desired, one way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( \" {: >2} d6: {: >6.2%} \" . format ( n , all_even [ 1 ] / sum ( all_even . counts ()))) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( \" {: >2} d6-exploding: {: >6.2%} \" . format ( n , at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()))) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 % Visualization (e.g., with Matplotlib) H objects provide a data method and a data_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 >>> faces , probabilities = ( 2 @H ( 6 )) . data_xy ( relative = True ) >>> matplotlib . pyplot . bar ( ... [ str ( f ) for f in faces ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.plt provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ): 1 2 3 >>> from dyce.plt import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position: 1 2 3 4 5 6 7 8 >>> d20 = P ( 20 ) >>> fig , ax = plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), graph_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Modeling Risis Risus and its many community-developed alternative rules are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... print ( \" {} d6 vs {} d6: {} \" . format ( us , them , first_round . format ( width = 0 ))) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names = [] # type: List[str] ... rows = [] # type: List[Tuple[float, ...]] ... for us in range ( them , them + num_rows ): ... row_names . append ( \" {} d6 \u2026\" . format ( us )) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . data_xy ( relative = True )[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( \"\u2026 vs {} d6\" . format ( them )) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... \" {:.0%} \" . format ( rows [ y ][ x ]), ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib.pyplot.show presents: We can even model various starting configurations through to completion to get a better sense of the impact of any disparity (in this case, applying dynamic programming to avoid redundant computations): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 >>> def risus_combat_driver ( ... us : int , ... them : int , ... us_vs_them_func , # type: Callable[[int, int], H] ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( \"can't have negative numbers (us: {} , them: {} )\" . format ( us , them )) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # shouldn't happen unless combat(0, 0) is called from the start ... solved = {} # type: Dict[Tuple[int, int], H] ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in solved : return solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we're out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they're out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( h : H , f : int ) -> H : ... if f < 0 : return _resolve ( us - 1 , them ) ... elif f > 0 : return _resolve ( us , them - 1 ) ... else : return H ({}) # ignore (immediately reroll) all ties ... ... solved [( us , them )] = this_round . substitute ( _next_round ) ... return solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... print ( \" {} d6 vs {} d6: {} \" . format ( ... u , t , ... risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ), ... )) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } Using our risus_combat_driver from above, we can model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath rule for resolving ties ... h = h . substitute ( lambda h , f : int ( us < them ) - int ( us > them ) if f == 0 else f ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... print ( \" {} d6 vs {} d6: {} \" . format ( ... u , t , ... risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ), ... )) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional computation. This is for two reasons. First, dyce only provides mechanisms to approximate outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough, however. Second, with one narrow exception , dyce only provides a mechanism to substitute face values, not counts. Both of these limitations can be circumvented where probabilities can be computed and encoded as a histogram. In this case, we can observe that a single d6 has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes you can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue: 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem: \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{6}{10} = \\frac{3}{5} \\] As an aside, the Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 0 : 2 , 1 : 3 }) # 2/5 odd; 3/5 even >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , f : int ( us < them ) - int ( us > them ) if f == 0 else f ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... print ( \" {} d6 vs {} d6: {} \" . format ( ... u , t , ... risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ), ... )) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } License dyce is licensed under the MIT License . See the LICENSE file for details. Source code is available on GitHub . Installation Installation can be performed via pip (which will download and install the latest release ): 1 2 % pip install dycelib ... Alternately, you can download the sources (e.g., from GitHub ) and run setup.py : 1 2 3 4 5 % git clone https://github.com/posita/dyce ... % cd dyce % python setup.py install ... Requirements A modern version of Python is required: cPython (3.6+) PyPy (Python 3.6+ compatible) dyce has the following dependencies (which will be installed automatically): typing typing-extensions","title":"Introduction"},{"location":"#introduction-to-dyce","text":"dyce is a pure-Python library for exploring dice probabilities designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. dyce is an AnyDice replacement that leverages Pythonic syntax and operators for rolling dice and computing weighted outcomes. While Python is not as terse as a dedicated grammar, it is quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. dyce is fairly low level by design, prioritizing ergonomics and composability. While any AnyDice generously affords a very convenient platform for simple computations, its idiosyncrasies can lead to confusion and complicated workarounds. Like AnyDice, it avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. Unlike AnyDice, however, it is an open source library that can be run locally and modified as desired. Because it exposes Python primitives rather than defining a dedicated grammar and interpreter, one can easily integrate it with other Python tools and libraries. In an intentional departure from RFC 1925, \u00a7 2.2 , it provides minor computation optimizations (e.g., the H.lowest_terms method and various shorthands) and formatting conveniences (e.g., the H.data , H.data_xy , and H.format methods) for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter . dyce should be sufficient to replicate or replace AnyDice and most other dice probability modeling libraries. It strives to be fully documented and relies heavily on examples to develop understanding. If you find its functionality or documentation confusing or lacking in any way, please consider contributing an issue to start a discussion. Source code is available on GitHub .","title":"Introduction to dyce"},{"location":"#examples","text":"dyce provides two key primitives: 1 >>> from dyce import H , P H objects represent histograms for modeling individual dice and outcomes. P objects represent pools (ordered sequences) of histograms. A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H(n) is shorthand for explicitly enumerating faces \\([{{1} .. {n}}]\\) , each with a frequency of 1: 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating faces are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P(n, ...) is shorthand for P(H(n), ...) . The above can be expressed more succinctly: 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case Sicherman dice ) can be compared to histograms: 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. One way to model outcomes from subtracting the least of two six-sided dice from the greatest is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms: 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of the pool\u2019s faces. This is done by providing one or more index arguments to the h method . Indexes can be integers, slices, or iterables thereof. Face indexes are ordered from least to greatest (i.e., 0 , 1 , \u2026, -2 , -1 ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than [\u2026] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Histograms provide rudimentary formatting for convenience: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 3 @P ( 6 )) . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( _ . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 3 @P ( 6 )) . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( _ . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 3 @P ( 6 )) . h ( - 1 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( _ . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> H ( 10 ) - 1 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> _ = P ( 4 , 6 , 8 , _ , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( _ . format ( width = 65 )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | 5 | 0.92 % | 6 | 2.03 % | # 7 | 3.76 % | # 8 | 5.57 % | ## 9 | 7.78 % | ### 10 | 8.99 % | #### 11 | 8.47 % | #### 12 | 8.64 % | #### 13 | 8.66 % | #### 14 | 6.64 % | ### 15 | 5.62 % | ## 16 | 5.16 % | ## 17 | 5.00 % | ## 18 | 5.00 % | ## 19 | 5.00 % | ## 20 | 5.00 % | ## 21 | 4.50 % | ## 22 | 2.01 % | # 23 | 0.73 % | 24 | 0.18 % | Note that pools are ordered and iterable: 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms in a pool: 1 2 >>> ( 2 @P ( 8 , 4 , 6 ))[ 1 : 3 ] ( H ( 4 ), H ( 6 )) If desired, one way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( \" {: >2} d6: {: >6.2%} \" . format ( n , all_even [ 1 ] / sum ( all_even . counts ()))) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( \" {: >2} d6-exploding: {: >6.2%} \" . format ( n , at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()))) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 %","title":"Examples"},{"location":"#visualization-eg-with-matplotlib","text":"H objects provide a data method and a data_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 >>> faces , probabilities = ( 2 @H ( 6 )) . data_xy ( relative = True ) >>> matplotlib . pyplot . bar ( ... [ str ( f ) for f in faces ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.plt provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ): 1 2 3 >>> from dyce.plt import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position: 1 2 3 4 5 6 7 8 >>> d20 = P ( 20 ) >>> fig , ax = plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), graph_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Visualization (e.g., with Matplotlib)"},{"location":"#modeling-risis","text":"Risus and its many community-developed alternative rules are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... print ( \" {} d6 vs {} d6: {} \" . format ( us , them , first_round . format ( width = 0 ))) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names = [] # type: List[str] ... rows = [] # type: List[Tuple[float, ...]] ... for us in range ( them , them + num_rows ): ... row_names . append ( \" {} d6 \u2026\" . format ( us )) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . data_xy ( relative = True )[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( \"\u2026 vs {} d6\" . format ( them )) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... \" {:.0%} \" . format ( rows [ y ][ x ]), ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib.pyplot.show presents: We can even model various starting configurations through to completion to get a better sense of the impact of any disparity (in this case, applying dynamic programming to avoid redundant computations): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 >>> def risus_combat_driver ( ... us : int , ... them : int , ... us_vs_them_func , # type: Callable[[int, int], H] ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( \"can't have negative numbers (us: {} , them: {} )\" . format ( us , them )) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # shouldn't happen unless combat(0, 0) is called from the start ... solved = {} # type: Dict[Tuple[int, int], H] ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in solved : return solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we're out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they're out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( h : H , f : int ) -> H : ... if f < 0 : return _resolve ( us - 1 , them ) ... elif f > 0 : return _resolve ( us , them - 1 ) ... else : return H ({}) # ignore (immediately reroll) all ties ... ... solved [( us , them )] = this_round . substitute ( _next_round ) ... return solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... print ( \" {} d6 vs {} d6: {} \" . format ( ... u , t , ... risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ), ... )) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } Using our risus_combat_driver from above, we can model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath rule for resolving ties ... h = h . substitute ( lambda h , f : int ( us < them ) - int ( us > them ) if f == 0 else f ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... print ( \" {} d6 vs {} d6: {} \" . format ( ... u , t , ... risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ), ... )) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional computation. This is for two reasons. First, dyce only provides mechanisms to approximate outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough, however. Second, with one narrow exception , dyce only provides a mechanism to substitute face values, not counts. Both of these limitations can be circumvented where probabilities can be computed and encoded as a histogram. In this case, we can observe that a single d6 has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes you can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue: 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem: \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{6}{10} = \\frac{3}{5} \\] As an aside, the Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 0 : 2 , 1 : 3 }) # 2/5 odd; 3/5 even >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , f : int ( us < them ) - int ( us > them ) if f == 0 else f ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... print ( \" {} d6 vs {} d6: {} \" . format ( ... u , t , ... risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ), ... )) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % }","title":"Modeling Risis"},{"location":"#license","text":"dyce is licensed under the MIT License . See the LICENSE file for details. Source code is available on GitHub .","title":"License"},{"location":"#installation","text":"Installation can be performed via pip (which will download and install the latest release ): 1 2 % pip install dycelib ... Alternately, you can download the sources (e.g., from GitHub ) and run setup.py : 1 2 3 4 5 % git clone https://github.com/posita/dyce ... % cd dyce % python setup.py install ...","title":"Installation"},{"location":"#requirements","text":"A modern version of Python is required: cPython (3.6+) PyPy (Python 3.6+ compatible) dyce has the following dependencies (which will be installed automatically): typing typing-extensions","title":"Requirements"},{"location":"contrib/","text":"Contributing to dyce There are several ways you can contribute. Filing issues You can file new issues as you find them. Please avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful. Submission guidelines If you are willing and able, consider submitting a pull request (PR) with a fix. There are only a few guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file: 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub - [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Try to follow the source conventions as you observe them. (Note: I have purposely avoided aspects of PEP8 , in part because I have adopted conventions developed from my experiences with other languages, but mostly because I am growing older and more stubborn.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in ./tests and can be run with Tox or pytest . A helper script is provided for setting up an isolated development environment. For example: 1 2 3 [ PYTHON = /path/to/python ] ./helpers/venvsetup.sh tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] pytest [ PYTEST_ARGS... ] If you need me, mention me ( @posita ) in your comment, and describe specifically how I can help. If you want feedback on a work-in-progress (WIP), create a PR and prefix its title with something like, \u201c NEED FEEDBACK - \u201d. If your PR is still in progress, but you are not blocked on anything, prefix the title with something like, \u201c WIP - \u201d. Once you are ready for a merge, resolve any merge conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) Then prefix the PR\u2019s title to something like, \u201c READY FOR MERGE - \u201d. I will try to get to it as soon as I can.","title":"Contributing"},{"location":"contrib/#contributing-to-dyce","text":"There are several ways you can contribute.","title":"Contributing to dyce"},{"location":"contrib/#filing-issues","text":"You can file new issues as you find them. Please avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful.","title":"Filing issues"},{"location":"contrib/#submission-guidelines","text":"If you are willing and able, consider submitting a pull request (PR) with a fix. There are only a few guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file: 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub - [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Try to follow the source conventions as you observe them. (Note: I have purposely avoided aspects of PEP8 , in part because I have adopted conventions developed from my experiences with other languages, but mostly because I am growing older and more stubborn.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in ./tests and can be run with Tox or pytest . A helper script is provided for setting up an isolated development environment. For example: 1 2 3 [ PYTHON = /path/to/python ] ./helpers/venvsetup.sh tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] pytest [ PYTEST_ARGS... ] If you need me, mention me ( @posita ) in your comment, and describe specifically how I can help. If you want feedback on a work-in-progress (WIP), create a PR and prefix its title with something like, \u201c NEED FEEDBACK - \u201d. If your PR is still in progress, but you are not blocked on anything, prefix the title with something like, \u201c WIP - \u201d. Once you are ready for a merge, resolve any merge conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) Then prefix the PR\u2019s title to something like, \u201c READY FOR MERGE - \u201d. I will try to get to it as soon as I can.","title":"Submission guidelines"},{"location":"dyce/","text":"dyce package reference dyce provides two key primitives: H for histograms (outcomes or individual dice) P for collections of histograms (pools) H An immutable mapping for use as a histogram that supports arithmetic operations. This is useful for modeling individual dice and outcomes. The initializer takes a single parameter, items . In its most explicit form, items maps face values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ): 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of int s, counts of 1 are assumed: 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an int , it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative): 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps: 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up a face\u2019s count: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is an int , the operator applies to the faces: 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print ( _ . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand: 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct faces: 1 2 >>> len ( 2 @d6 ) 11 The counts method can be used to show the total number of combinations: 1 2 >>> sum (( 2 @d6 ) . counts ()) 36 Counts are generally accumulated without reduction. To reduce, call the lowest_terms method : 1 2 3 4 >>> d6 . accumulate ( d6 ) . accumulate ( d6 ) H ({ 1 : 3 , 2 : 3 , 3 : 3 , 4 : 3 , 5 : 3 , 6 : 3 }) >>> _ . lowest_terms () H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) Testing equivalence implicitly performs reductions of operands: 1 2 >>> d6 . accumulate ( d6 ) == d6 . accumulate ( d6 ) . accumulate ( d6 ) True Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ 0 : 6 , 1 : 30 }) >>> print ( _ . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ 0 : 21 , 1 : 15 }) >>> print ( _ . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6 . eq ( 2 ) # how often a 2 shows on a single six-sided die H ({ 0 : 5 , 1 : 1 }) >>> 4 @ ( _ ) # number of 2s that show on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> _ . ge ( 1 ) # how often that number is at least one H ({ 0 : 625 , 1 : 671 }) >>> print ( _ . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations: 1 2 3 4 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 >>> ( 2 @d6 ) . le ( 7 ) H ({ 0 : 15 , 1 : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False __init__ ( self , items ) special Initializer. Source code in dyce/h.py def __init__ ( self , items : SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init = None tmp : Counter [ int ] = counter () if isinstance ( items , int ): if items != 0 : self . _simple_init = items tmp . update ( range ( items , 0 , 1 if items < 0 else - 1 )) # count toward zero elif isinstance ( items , H . AbleT ): tmp . update ( items . h ()) elif isinstance ( items , ABCMapping ): tmp . update ( items ) else : # Items is either an Iterable[int] or an Iterable[Tuple[int, int]] (although # this technically supports Iterable[Union[int, Tuple[int, int]]]) for item in items : if isinstance ( item , tuple ): face , count = item tmp [ face ] += count else : tmp [ item ] += 1 # Sort and omit zero counts. We use an OrderedDict instead of a Counter to # support Python versions earlier than 3.7 which did not guarantee order # preservation for the latter. self . _h : Dict [ int , int ] = ordereddict ( { face : tmp [ face ] for face in sorted ( tmp ) if tmp [ face ]} ) accumulate ( self , other ) Accumulates counts: 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py def accumulate ( self , other : SourceT ) -> \"H\" : r \"\"\" Accumulates counts: ```python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , int ): other = ( other ,) elif isinstance ( other , ABCMapping ): other = other . items () return H ( chain ( self . items (), cast ( Iterable , other ))) counts ( self ) More descriptive synonym for the values method . Source code in dyce/h.py def counts ( self ) -> Iterator [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . values () data ( self , relative = False , fill_items = None ) Presentation helper function that returns an iterator for each face/frequency pair: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> list ( d6 . gt ( 3 ) . data ()) [( 0 , 3.0 ), ( 1 , 3.0 )] >>> list ( d6 . gt ( 3 ) . data ( relative = True )) [( 0 , 0.5 ), ( 1 , 0.5 )] If provided, fill_items supplies defaults for any missing faces: 1 2 3 4 >>> list ( d6 . gt ( 7 ) . data ()) [( 0 , 6.0 )] >>> list ( d6 . gt ( 7 ) . data ( fill_items = { 1 : 0 , 0 : 0 })) [( 0 , 6.0 ), ( 1 , 0.0 )] Source code in dyce/h.py def data ( self , relative : bool = False , fill_items : Optional [ Mapping [ int , int ]] = None , ) -> Iterator [ Tuple [ int , float ]]: r \"\"\" Presentation helper function that returns an iterator for each face/frequency pair: ```python >>> d6 = H(6) >>> list(d6.gt(3).data()) [(0, 3.0), (1, 3.0)] >>> list(d6.gt(3).data(relative=True)) [(0, 0.5), (1, 0.5)] ``` If provided, *fill_items* supplies defaults for any missing faces: ```python >>> list(d6.gt(7).data()) [(0, 6.0)] >>> list(d6.gt(7).data(fill_items={1: 0, 0: 0})) [(0, 6.0), (1, 0.0)] ``` \"\"\" if fill_items is None : fill_items = {} if relative : total = sum ( self . counts ()) or 1 else : total = 1 combined = dict ( chain ( fill_items . items (), self . items ())) return (( face , count / total ) for face , count in sorted ( combined . items ())) data_xy ( self , relative = False , fill_items = None ) Presentation helper function that returns an iterator for a \u201czipped\u201d arrangement of the output from the data method : 1 2 3 4 5 >>> d6 = H ( 6 ) >>> list ( d6 . data ()) [( 1 , 1.0 ), ( 2 , 1.0 ), ( 3 , 1.0 ), ( 4 , 1.0 ), ( 5 , 1.0 ), ( 6 , 1.0 )] >>> d6 . data_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 1.0 , 1.0 , 1.0 , 1.0 , 1.0 , 1.0 )) Source code in dyce/h.py def data_xy ( self , relative : bool = False , fill_items : Optional [ Mapping [ int , int ]] = None , ) -> Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function that returns an iterator for a \u201czipped\u201d arrangement of the output from the [``data`` method][dyce.h.H.data]: ```python >>> d6 = H(6) >>> list(d6.data()) [(1, 1.0), (2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0)] >>> d6.data_xy() ((1, 2, 3, 4, 5, 6), (1.0, 1.0, 1.0, 1.0, 1.0, 1.0)) ``` \"\"\" return cast ( Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]], tuple ( zip ( * self . data ( relative , fill_items ))), ) eq ( self , other ) Shorthand for self.map(operator.eq, other) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ 0 : 5 , 1 : 1 }) See the map method . Source code in dyce/h.py def eq ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.eq, other)``. ```python >>> H(6).eq(3) H({0: 5, 1: 1}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_eq , other ) even ( self ) Equivalent to self.umap(lambda f: int(f % 2 == 0)) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . even () H ({ 0 : 2 , 1 : 4 }) See the umap method . Source code in dyce/h.py def even ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda f: int(f % 2 == 0))``. ```python >>> H((-4, -2, 0, 1, 2, 3)).even() H({0: 2, 1: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_even ( f : int ) -> int : return ( f & 0b1 ) ^ 0b1 return self . umap ( is_even ) explode ( self , max_depth = 1 ) Shorthand for self.substitute(lambda h, f: h if f == max(h) else f, operator.add, max_depth) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py def explode ( self , max_depth : int = 1 , ) -> \"H\" : r \"\"\" Shorthand for ``self.substitute(lambda h, f: h if f == max(h) else f, operator.add, max_depth)``. ```python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , f : h if f == max ( h ) else f , op_add , max_depth , ) faces ( self ) More descriptive synonym for the keys method . Source code in dyce/h.py def faces ( self ) -> Iterator [ int ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . keys () format ( self , fill_items = None , width = 88 , scaled = False , tick = '#' , sep = ' \\n ' ) Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing faces. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( \" {:->65} \" . format ( \" 65 chars wide -->|\" )) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py def format ( self , fill_items : Optional [ Mapping [ int , int ]] = None , width : int = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing faces. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ```python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ```python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``True``, horizontal bars are scaled to *width*: ```python >>> h = (2@H(6)).ge(7) >>> print(\"{:->65}\".format(\" 65 chars wide -->|\")) ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" if width <= 0 : def parts (): yield \"avg: {:.2f} \" . format ( self . mean ()) for face , percentage in self . data ( relative = True , fill_items = fill_items ): yield \" {} : {:7.2%} \" . format ( face , percentage ) return \"{\" + \", \" . join ( parts ()) + \"}\" else : w = width - 15 def lines (): mu = self . mean () yield \"avg | {:7.2f} \" . format ( mu ) yield \"std | {:7.2f} \" . format ( self . stdev ( mu )) yield \"var | {:7.2f} \" . format ( self . variance ( mu )) total = sum ( self . counts ()) tick_scale = max ( self . counts ()) if scaled else total for face , count in self . data ( relative = False , fill_items = fill_items ): percentage = count / total ticks = int ( w * count / tick_scale ) yield \" {: 3} | {:7.2%} | {} \" . format ( face , percentage , tick * ticks ) return sep . join ( lines ()) ge ( self , other ) Shorthand for self.map(operator.ge, other) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ 0 : 2 , 1 : 4 }) See the map method . Source code in dyce/h.py def ge ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ge, other)``. ```python >>> H(6).ge(3) H({0: 2, 1: 4}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ge , other ) gt ( self , other ) Shorthand for self.map(operator.gt, other) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ 0 : 3 , 1 : 3 }) See the map method . Source code in dyce/h.py def gt ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.gt, other)``. ```python >>> H(6).gt(3) H({0: 3, 1: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_gt , other ) items ( self ) D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py def items ( self ): return self . _h . items () keys ( self ) D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py def keys ( self ): return self . _h . keys () le ( self , other ) Shorthand for self.map(operator.le, other) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ 0 : 3 , 1 : 3 }) See the map method . Source code in dyce/h.py def le ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.le, other)``. ```python >>> H(6).le(3) H({0: 3, 1: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_le , other ) lowest_terms ( self ) Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> H (( - 1 , - 1 , 0 , 0 , 1 , 1 )) H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> _ . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> _ . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py def lowest_terms ( self ) -> \"H\" : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ```python >>> H((-1, -1, 0, 0, 1, 1)) H({-1: 2, 0: 2, 1: 2}) >>> _.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ```python >>> H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) H({2: 2, 3: 4, 4: 4, 5: 2}) >>> _.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" counts_gcd = reduce ( gcd , self . counts (), 0 ) return H ({ k : v // counts_gcd for k , v in self . items ()}) lt ( self , other ) Shorthand for self.map(operator.lt, other) : 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ 0 : 4 , 1 : 2 }) See the map method . Source code in dyce/h.py def lt ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.lt, other)``: ```python >>> H(6).lt(3) H({0: 4, 1: 2}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_lt , other ) map ( self , oper , other ) Applies oper to each face of the histogram paired with other . Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . add , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> _ == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . mul , - 1 ) H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> _ == d6 * - 1 True 1 2 3 4 >>> d6 . map ( operator . gt , 3 ) H ({ 0 : 3 , 1 : 3 }) >>> _ == d6 . gt ( 3 ) True Source code in dyce/h.py def map ( self , oper : _BinaryOperatorT , other : OperandT ) -> \"H\" : r \"\"\" Applies *oper* to each face of the histogram paired with *other*. Shorthands exist for many arithmetic operators and comparators. ```python >>> import operator >>> d6 = H(6) >>> d6.map(operator.add, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> _ == d6 + d6 True ``` ```python >>> d6.map(operator.mul, -1) H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> _ == d6 * -1 True ``` ```python >>> d6.map(operator.gt, 3) H({0: 3, 1: 3}) >>> _ == d6.gt(3) True ``` \"\"\" if isinstance ( other , H . AbleT ): other = other . h () if isinstance ( other , int ): return H (( int ( oper ( face , other )), count ) for face , count in self . items ()) elif isinstance ( other , H ): return H ( ( int ( oper ( a , b )), self [ a ] * other [ b ]) for a , b in product ( self , other ) ) else : raise NotImplementedError mean ( self ) Returns the mean of the weighted faces (or 0.0 if there are no faces). Source code in dyce/h.py def mean ( self ) -> float : \"\"\" Returns the mean of the weighted faces (or 0.0 if there are no faces). \"\"\" numerator = denominator = 0 for face , count in self . items (): numerator += face * count denominator += count return numerator / ( denominator or 1 ) ne ( self , other ) Shorthand for self.map(operator.ne, other) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ 0 : 1 , 1 : 5 }) See the map method . Source code in dyce/h.py def ne ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ne, other)``. ```python >>> H(6).ne(3) H({0: 1, 1: 5}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ne , other ) odd ( self ) Equivalent to self.umap(lambda f: int(f % 2 != 0)) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . odd () H ({ 0 : 4 , 1 : 2 }) See the umap method . Source code in dyce/h.py def odd ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda f: int(f % 2 != 0))``. ```python >>> H((-4, -2, 0, 1, 2, 3)).odd() H({0: 4, 1: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_odd ( f : int ) -> int : return f & 0b1 return self . umap ( is_odd ) roll ( self ) Returns a (weighted) random face. Source code in dyce/h.py def roll ( self ) -> int : r \"\"\" Returns a (weighted) random face. \"\"\" val = randrange ( 0 , sum ( self . counts ())) total = 0 for face , count in self . items (): total += count if val < total : return face assert False , \"val ( {} ) \u2265 total ( {} )\" . format ( val , total ) stdev ( self , mu = None ) Shorthand for math.sqrt(self.variance(mu)) . Source code in dyce/h.py def stdev ( self , mu : Optional [ float ] = None ) -> float : \"\"\" Shorthand for ``math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu )) substitute ( self , expand , coalesce = None , max_depth = 1 ) Calls expand on each face, recursively up to max_depth times. If expand returns an int , it replaces the face. If it returns an H object , coalesce is called on the face and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the face with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the lowest_terms method .) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , face : int ) -> Union [ int , H ]: ... return h if face == 1 else face >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to the running sum). In nearly all cases, when a histogram is substituted for a face, it takes on the substituted face\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced face in relation to other faces. This becomes clearer when there is no overlap between the original histogram and the substitution: 1 2 3 4 5 6 7 8 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , f : - h if f == 4 else f ) >>> sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( c for f , c in orig . items () if f == 4 ) / sum ( orig . counts ()) 0.4 >>> sum ( c for f , c in sub . items () if f < 0 ) / sum ( sub . counts ()) 0.4 There is one important exception: If coalesce returns the empty histogram ( H({}) ), the corresponding face and its counts are omitted from the result without substitution or scaling. A trivial example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: 1 2 >>> H ( 6 ) . substitute ( lambda h , f : H ({}) if f == 6 else f ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> _ . substitute ( lambda h , f : H ({}) if f == 0 else f ) H ({ - 1 : 4553 , 1 : 8118 }) Because substitute accepts arbitrary functions, it is well suited for modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , face : int ) -> Union [ int , H ]: ... if face == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return face >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . add , max_depth = 6 ) >>> h_even = h . even () >>> print ( \" {:.3%} \" . format ( h_even . get ( 1 , 0 ) / sum ( h_even . counts ()))) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (potentially nudging us to an odd number slightly more often than not). We can also use this method to model expected damage from a single attack in d20-like roll playing games: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , face : int ) -> Union [ int , H ]: ... if face == 20 : ... return crit ... elif face >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 0 )) { avg : 2.15 , 0 : 65.00 % , 2 : 3.75 % , 3 : 3.83 % , 4 : 3.91 % , ... , 15 : 0.23 % , 16 : 0.16 % , 17 : 0.08 % } Source code in dyce/h.py def substitute ( self , expand : _ExpandT , coalesce : Optional [ _CoalesceT ] = None , max_depth : int = 1 , ) -> \"H\" : r \"\"\" Calls *expand* on each face, recursively up to *max_depth* times. If *expand* returns an ``int``, it replaces the face. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the face and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the face with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the [``lowest_terms`` method][dyce.h.H.lowest_terms].) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ```python >>> def reroll_one(h: H, face: int) -> Union[int, H]: ... return h if face == 1 else face >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to the running sum). In nearly all cases, when a histogram is substituted for a face, it takes on the substituted face\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced face in relation to other faces. This becomes clearer when there is no overlap between the original histogram and the substitution: ```python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, f: -h if f == 4 else f) >>> sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(c for f, c in orig.items() if f == 4) / sum(orig.counts()) 0.4 >>> sum(c for f, c in sub.items() if f < 0) / sum(sub.counts()) 0.4 ``` There is one important exception: If *coalesce* returns the empty histogram (``H({})``), the corresponding face and its counts are omitted from the result without substitution or scaling. A trivial example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: ```python >>> H(6).substitute(lambda h, f: H({}) if f == 6 else f) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> _.substitute(lambda h, f: H({}) if f == 0 else f) H({-1: 4553, 1: 8118}) ``` Because ``substitute`` accepts arbitrary functions, it is well suited for modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ```python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, face: int) -> Union[int, H]: ... if face == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return face >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.add, max_depth=6) >>> h_even = h.even() >>> print(\"{:.3%}\".format(h_even.get(1, 0) / sum(h_even.counts()))) 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (potentially nudging us to an odd number slightly more often than not). We can also use this method to model expected damage from a single attack in d20-like roll playing games: ```python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, face: int) -> Union[int, H]: ... if face == 20: ... return crit ... elif face >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=0)) {avg: 2.15, 0: 65.00%, 2: 3.75%, 3: 3.83%, 4: 3.91%, ..., 15: 0.23%, 16: 0.16%, 17: 0.08%} ``` \"\"\" if coalesce is None : coalesce = _coalesce_replace def _substitute ( h : H , depth : int = 0 , ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ int , int , int ]] = [] for face , count in h . items (): expanded = expand ( h , face ) if isinstance ( expanded , int ): items_for_reassembly . append (( expanded , count , 1 )) else : # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , face ) # Account for the impact of expansion on peers expanded_scalar = sum ( expanded . counts ()) if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) return H ( ( # Apply the total_scalar, but factor out this item's contribution ( f , c * total_scalar // s ) for f , c , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self ) umap ( self , oper ) Applies oper to each face of the histogram: 1 2 >>> H ( 6 ) . umap ( lambda f : f * - 1 ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda f : ( - f ) ** f ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py def umap ( self , oper : _UnaryOperatorT ) -> \"H\" : r \"\"\" Applies *oper* to each face of the histogram: ```python >>> H(6).umap(lambda f: f * -1) H(-6) ``` ```python >>> H(4).umap(lambda f: (-f) ** f) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = H (( oper ( face ), count ) for face , count in self . items ()) if self . _simple_init is not None : h_simple = H ( oper ( self . _simple_init )) if h_simple == h : return h_simple return h values ( self ) D.values() -> an object providing a view on D's values Source code in dyce/h.py def values ( self ): return self . _h . values () variance ( self , mu = None ) Returns the variance of the weighted faces. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py def variance ( self , mu : Optional [ float ] = None ) -> float : \"\"\" Returns the variance of the weighted faces. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator = denominator = 0 for face , count in self . items (): numerator += ( face - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 ) vs ( self , other ) Compares this histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self.within(0, 0, other) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> _ == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py def vs ( self , other : OperandT ) -> \"H\" : r \"\"\" Compares this histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``self.within(0, 0, other)``. ```python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> _ == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other ) within ( self , lo , hi , other = 0 ) Computes the difference between this histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 >>> ( 2 @H ( 6 )) . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( _ . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 >>> ( 3 @H ( 6 )) . within ( - 1 , 1 , 2 @H ( 8 )) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( _ . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py def within ( self , lo : int , hi : int , other : OperandT = 0 ) -> \"H\" : r \"\"\" Computes the difference between this histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ```python >>> (2@H(6)).within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(_.format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ```python >>> (3@H(6)).within(-1, 1, 2@H(8)) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(_.format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other ) P An immutable pool (ordered sequence) of zero or more H objects supporting group operations. Objects can be flattened to a single histogram, either explicitly via the h method , or by using binary arithmetic operations. Unary operators and the @ operator result in new P objects. If any of the initializer \u2019s args parameter is an int , it is passed to H \u2019s initializer . 1 2 3 4 5 >>> p_d6 = P ( 6 ) # shorthand for P(H(6)) >>> p_d6 P ( 6 ) >>> - p_d6 P ( - 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( _ . roll ()) in _ . h () True Arithmetic operators involving an int or another P object produce an H object : 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) Comparisons with H objects work as expected: 1 2 >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram: 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that containers are opinionated about histogram ordering: 1 2 >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True The h method also allows subsets of faces to be \u201ctaken\u201d (selected) by index from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> ( 3 @p_d6 ) . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( _ . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ### __init__ ( self , * args ) special Initializer. Source code in dyce/p.py def __init__ ( self , * args : Union [ int , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs (): for a in args : if isinstance ( a , int ): yield H ( a ) elif isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : # pylint: disable=protected-access yield h else : raise TypeError ( \"type {} incompatible initializer for {} \" . format ( type ( a ), type ( self ) ) ) hs = list ( h for h in _gen_hs () if h ) hs . sort ( key = lambda h : tuple ( h . items ())) self . _hs = tuple ( hs ) eq ( self , other ) Shorthand for self.h().eq(other) . See the h method and H.eq . Source code in dyce/p.py def eq ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().eq(other)``. See the [``h`` method][dyce.p.P.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other ) even ( self ) Shorthand for self.h().even() . See the h method and H.even . Source code in dyce/p.py def even ( self ) -> H : r \"\"\" Shorthand for ``self.h().even()``. See the [``h`` method][dyce.p.P.h] and [``H.even``][dyce.h.H.even]. \"\"\" return self . h () . even () explode ( self , max_depth = 1 ) Shorthand for self.h().explode(max_depth) . See the h method and H.explode . Source code in dyce/p.py def explode ( self , max_depth : int = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().explode(max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth ) ge ( self , other ) Shorthand for self.h().ge(other) . See the h method and H.ge . Source code in dyce/p.py def ge ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().ge(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other ) gt ( self , other ) Shorthand for self.h().gt(other) . See the h method and H.gt . Source code in dyce/p.py def gt ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().gt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other ) h ( self , * dice ) When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms: 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If the optional dice parameter is provided, h sums subsets of faces identified by dice . dice can include int s and slice s. All outcomes are counted. For each outcome, dice are ordered from least (index 0 ) to greatest (index -1 or len(self) ). Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 2 @P ( 6 )) . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( _ . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Slices and arbitrary iterables support more flexible face selections: 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = p_6d6 . h ( slice ( None , None , - 2 )) >>> every_other_d6 H ({ 3 : 1 , 4 : 21 , 5 : 86 , ... , 16 : 1106 , 17 : 395 , 18 : 31 }) >>> p_6d6 . h ( 5 , 3 , 1 ) == every_other_d6 True >>> p_6d6 . h ( * range ( 1 , 6 , 2 )) == every_other_d6 True >>> p_6d6 . h ( * ( i for i in range ( 0 , 6 ) if i % 2 == 1 )) == every_other_d6 True >>> p_6d6 . h ( * { 1 , 3 , 5 }) == every_other_d6 True Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> ( 10 @P ( 4 )) . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( _ . format ( width = 65 )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | ## 9 | 16.09 % | ######## 10 | 56.74 % | ############################ 11 | 16.09 % | ######## 12 | 4.96 % | ## 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | By taking all faces, we can confirm equivalence to our sum operation: 1 2 3 4 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> ( 2 @P ( d6 , d233445 )) . h ( slice ( None )) == d6 + d6 + d233445 + d233445 True Source code in dyce/p.py def h ( self , * dice : _GetItemT ) -> H : r \"\"\" When provided no arguments, ``h`` combines (or \u201cflattens\u201d) contained histograms: ```python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If the optional *dice* parameter is provided, ``h`` sums subsets of faces identified by *dice*. *dice* can include ``int``s and ``slice``s. All outcomes are counted. For each outcome, dice are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self)``). Taking the greatest of two six-sided dice can be modeled as: ```python >>> (2@P(6)).h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(_.format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Slices and arbitrary iterables support more flexible face selections: ```python >>> p_6d6 = 6@P(6) >>> every_other_d6 = p_6d6.h(slice(None, None, -2)) >>> every_other_d6 H({3: 1, 4: 21, 5: 86, ..., 16: 1106, 17: 395, 18: 31}) >>> p_6d6.h(5, 3, 1) == every_other_d6 True >>> p_6d6.h(*range(1, 6, 2)) == every_other_d6 True >>> p_6d6.h(*(i for i in range(0, 6) if i % 2 == 1)) == every_other_d6 True >>> p_6d6.h(*{1, 3, 5}) == every_other_d6 True ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ```python >>> (10@P(4)).h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(_.format(width=65)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |## 9 | 16.09% |######## 10 | 56.74% |############################ 11 | 16.09% |######## 12 | 4.96% |## 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` By taking all faces, we can confirm equivalence to our sum operation: ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> (2@P(d6, d233445)).h(slice(None)) == d6 + d6 + d233445 + d233445 True ``` \"\"\" if dice : return H ( _take_and_sum_faces ( self . rolls_with_counts (), dice )) else : if self . _hs : hs_sum = sum ( self . _hs ) else : hs_sum = H (()) return cast ( H , hs_sum ) le ( self , other ) Shorthand for self.h().le(other) . See the h method and H.le . Source code in dyce/p.py def le ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().le(other)``. See the [``h`` method][dyce.p.P.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other ) lt ( self , other ) Shorthand for self.h().lt(other) . See the h method and H.lt . Source code in dyce/p.py def lt ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().lt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other ) ne ( self , other ) Shorthand for self.h().ne(other) . See the h method and H.ne . Source code in dyce/p.py def ne ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().ne(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other ) odd ( self ) Shorthand for self.h().odd() . See the h method and H.odd . Source code in dyce/p.py def odd ( self ) -> H : r \"\"\" Shorthand for ``self.h().odd()``. See the [``h`` method][dyce.p.P.h] and [``H.odd``][dyce.h.H.odd]. \"\"\" return self . h () . odd () roll ( self ) Returns (weighted) random faces from contained histograms. Source code in dyce/p.py def roll ( self ) -> Tuple [ int , ... ]: r \"\"\" Returns (weighted) random faces from contained histograms. \"\"\" return tuple ( h . roll () for h in self . _hs ) rolls_with_counts ( self ) Returns an iterator that yields 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the faces for a distinct roll. The second is the count for that roll. Faces in each roll are ordered least to greatest. We can model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest faces are the same: 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } Note that, in the general case, rolls may appear more than once, and there are no guarantees about their order. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, (1, 2) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), faces are not repeated and are presented in order. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] By summing and counting all rolls, we can confirm equivalence to taking all faces: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> pool = 2 @P ( d6 , d233445 ) >>> H (( sum ( r ), c ) for r , c in pool . rolls_with_counts ()) == pool . h ( slice ( None )) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones. This is because, instead of merely computing the Cartesian product, we are able to leverage the multinomial coefficient : \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n@P(H(m)) . Enumerating combinations with replacements would yield all unique rolls: ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), (2, 2, \u2026, 2), \u2026, (m - 1, m, m), (m, m, m)) To determine the count for a particular roll (a, b, \u2026, n) , we compute the multinomial coefficient for that roll and multiply by the scalar H(m)[a] * H(m)[b] * \u2026 * H(m)[n] . (See this for an in-depth exploration of the topic.) This implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, while heterogeneous ones offer no such guarantees. As expected, this optimization allows mixed pools\u2019 performance to sit between purely homogeneous and purely heterogeneous ones: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 In [ 1 ]: from dyce import H , P In [ 2 ]: for i in range ( 2 , 11 , 2 ): ... : p = i @P ( 6 ) ... : print ( \"Pool len {} (homogeneous): {} \" . format ( len ( p ), p )) ... : % timeit p.h(slice(None)) ... : Pool len 2 ( homogeneous ): P ( 6 , 6 ) 105 \u00b5s \u00b1 1.97 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) Pool len 4 ( homogeneous ): P ( 6 , 6 , 6 , 6 ) 644 \u00b5s \u00b1 9.98 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 6 ( homogeneous ): P ( 6 , 6 , 6 , 6 , 6 , 6 ) 2.98 ms \u00b1 447 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 8 ( homogeneous ): P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 ) 9.16 ms \u00b1 667 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 10 ( homogeneous ): P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 ) 22.4 ms \u00b1 294 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 3 ]: for i in range ( 1 , 6 ): ... : hs = [ H ( 6 ) for _ in range ( i )] ... : hs . extend ( H ( 6 ) - j for j in range ( i )) ... : p = P ( * hs ) ... : print ( \"Pool len {} (mixed): {} \" . format ( len ( p ), p )) ... : % timeit p.h(slice(None)) ... : Pool len 2 ( mixed ): P ( 6 , H ({ 1 : 1 , ... , 6 : 1 })) 158 \u00b5s \u00b1 688 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) Pool len 4 ( mixed ): P ( H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 1.12 ms \u00b1 16.9 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 6 ( mixed ): P ( H ({ - 1 : 1 , ... , 4 : 1 }), ... , 6 , 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 11.6 ms \u00b1 714 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 8 ( mixed ): P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , 6 , 6 , 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 152 ms \u00b1 8.65 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Pool len 10 ( mixed ): P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , 6 , 6 , 6 , 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 1.73 s \u00b1 96.8 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 4 ]: for i in range ( 2 , 10 ): # larger takes too long on my laptop ... : p = P ( * ( H ( 6 ) - j for j in range ( i ))) ... : print ( \"Pool len {} (heterogeneous): {} \" . format ( len ( p ), p )) ... : % timeit p.h(slice(None)) ... : Pool len 2 ( heterogeneous ): P ( H ({ 0 : 1 , ... , 5 : 1 }), H ({ 1 : 1 , ... , 6 : 1 })) 238 \u00b5s \u00b1 9.76 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 3 ( heterogeneous ): P ( H ({ - 1 : 1 , ... , 4 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 685 \u00b5s \u00b1 18.2 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 4 ( heterogeneous ): P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 3.28 ms \u00b1 14.2 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 5 ( heterogeneous ): P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 19.3 ms \u00b1 41.2 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 6 ( heterogeneous ): P ( H ({ - 4 : 1 , ... , 1 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 114 ms \u00b1 749 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Pool len 7 ( heterogeneous ): P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 725 ms \u00b1 7.67 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Pool len 8 ( heterogeneous ): P ( H ({ - 6 : 1 , ... , - 1 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 4.58 s \u00b1 38.7 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Pool len 9 ( heterogeneous ): P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 31 s \u00b1 969 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def rolls_with_counts ( self ) -> Iterator [ Tuple [ Tuple [ int , ... ], int ]]: r \"\"\" Returns an iterator that yields 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the faces for a distinct roll. The second is the count for that roll. Faces in each roll are ordered least to greatest. We can model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest faces are the same: ```python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` Note that, in the general case, rolls may appear more than once, and there are no guarantees about their order. ```python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, `(1, 2)` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), faces are not repeated and are presented in order. (See the note on implementation below.) ```python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` By summing and counting all rolls, we can confirm equivalence to taking all faces: ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> pool = 2@P(d6, d233445) >>> H((sum(r), c) for r, c in pool.rolls_with_counts()) == pool.h(slice(None)) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones. This is because, instead of merely computing the Cartesian product, we are able to leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets): $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls: ``((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), (2, 2, \u2026, 2), \u2026, (m - 1, m, m), (m, m, m))`` To determine the count for a particular roll ``(a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) This implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, while heterogeneous ones offer no such guarantees. As expected, this optimization allows mixed pools\u2019 performance to sit between purely homogeneous and purely heterogeneous ones: ```ipython In [1]: from dyce import H, P In [2]: for i in range(2, 11, 2): ...: p = i@P(6) ...: print(\"Pool len {} (homogeneous): {}\".format(len(p), p)) ...: %timeit p.h(slice(None)) ...: Pool len 2 (homogeneous): P(6, 6) 105 \u00b5s \u00b1 1.97 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each) Pool len 4 (homogeneous): P(6, 6, 6, 6) 644 \u00b5s \u00b1 9.98 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 6 (homogeneous): P(6, 6, 6, 6, 6, 6) 2.98 ms \u00b1 447 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 8 (homogeneous): P(6, 6, 6, 6, 6, 6, 6, 6) 9.16 ms \u00b1 667 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 10 (homogeneous): P(6, 6, 6, 6, 6, 6, 6, 6, 6, 6) 22.4 ms \u00b1 294 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for i in range(1, 6): ...: hs = [H(6) for _ in range(i)] ...: hs.extend(H(6) - j for j in range(i)) ...: p = P(*hs) ...: print(\"Pool len {} (mixed): {}\".format(len(p), p)) ...: %timeit p.h(slice(None)) ...: Pool len 2 (mixed): P(6, H({1: 1, ..., 6: 1})) 158 \u00b5s \u00b1 688 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each) Pool len 4 (mixed): P(H({0: 1, ..., 5: 1}), 6, 6, H({1: 1, ..., 6: 1})) 1.12 ms \u00b1 16.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 6 (mixed): P(H({-1: 1, ..., 4: 1}), ..., 6, 6, 6, H({1: 1, ..., 6: 1})) 11.6 ms \u00b1 714 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 8 (mixed): P(H({-2: 1, ..., 3: 1}), ..., 6, 6, 6, 6, H({1: 1, ..., 6: 1})) 152 ms \u00b1 8.65 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) Pool len 10 (mixed): P(H({-3: 1, ..., 2: 1}), ..., 6, 6, 6, 6, 6, H({1: 1, ..., 6: 1})) 1.73 s \u00b1 96.8 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for i in range(2, 10): # larger takes too long on my laptop ...: p = P(*(H(6) - j for j in range(i))) ...: print(\"Pool len {} (heterogeneous): {}\".format(len(p), p)) ...: %timeit p.h(slice(None)) ...: Pool len 2 (heterogeneous): P(H({0: 1, ..., 5: 1}), H({1: 1, ..., 6: 1})) 238 \u00b5s \u00b1 9.76 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 3 (heterogeneous): P(H({-1: 1, ..., 4: 1}), ..., H({1: 1, ..., 6: 1})) 685 \u00b5s \u00b1 18.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 4 (heterogeneous): P(H({-2: 1, ..., 3: 1}), ..., H({1: 1, ..., 6: 1})) 3.28 ms \u00b1 14.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 5 (heterogeneous): P(H({-3: 1, ..., 2: 1}), ..., H({1: 1, ..., 6: 1})) 19.3 ms \u00b1 41.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 6 (heterogeneous): P(H({-4: 1, ..., 1: 1}), ..., H({1: 1, ..., 6: 1})) 114 ms \u00b1 749 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) Pool len 7 (heterogeneous): P(H({-5: 1, ..., 0: 1}), ..., H({1: 1, ..., 6: 1})) 725 ms \u00b1 7.67 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Pool len 8 (heterogeneous): P(H({-6: 1, ..., -1: 1}), ..., H({1: 1, ..., 6: 1})) 4.58 s \u00b1 38.7 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Pool len 9 (heterogeneous): P(H({-7: 1, ..., -2: 1}), ..., H({1: 1, ..., 6: 1})) 31 s \u00b1 969 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self . _hs )) if len ( groups ) == 1 : # Optimization to use _rolls_with_counts_for_n_homogeneous_histograms directly if # there's only one group; roughly 15% time savings based on cursory # performance analysis h , n = groups [ 0 ] return _rolls_with_counts_for_n_homogeneous_histograms ( h , n ) else : return _rolls_with_counts_for_heterogeneous_histograms ( groups ) substitute ( self , expand , coalesce = None , max_depth = 1 ) Shorthand for self.h().substitute(expand, coalesce, max_depth) . See the h method and H.substitute . Source code in dyce/p.py def substitute ( self , expand : _ExpandT , coalesce : Optional [ _CoalesceT ] = None , max_depth : int = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth ) within ( self , lo , hi , other = 0 ) Shorthand for self.h().within(lo, hi, other) . See the h method and H.within . Source code in dyce/p.py def within ( self , lo : int , hi : int , other : OperandT = 0 ) -> H : r \"\"\" Shorthand for ``self.h().within(lo, hi, other)``. See the [``h`` method][dyce.p.P.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"<tt>dyce</tt>"},{"location":"dyce/#dyce-package-reference","text":"dyce provides two key primitives: H for histograms (outcomes or individual dice) P for collections of histograms (pools)","title":"dyce package reference"},{"location":"dyce/#dyce.h.H","text":"An immutable mapping for use as a histogram that supports arithmetic operations. This is useful for modeling individual dice and outcomes. The initializer takes a single parameter, items . In its most explicit form, items maps face values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ): 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of int s, counts of 1 are assumed: 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an int , it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative): 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps: 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up a face\u2019s count: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is an int , the operator applies to the faces: 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print ( _ . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand: 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct faces: 1 2 >>> len ( 2 @d6 ) 11 The counts method can be used to show the total number of combinations: 1 2 >>> sum (( 2 @d6 ) . counts ()) 36 Counts are generally accumulated without reduction. To reduce, call the lowest_terms method : 1 2 3 4 >>> d6 . accumulate ( d6 ) . accumulate ( d6 ) H ({ 1 : 3 , 2 : 3 , 3 : 3 , 4 : 3 , 5 : 3 , 6 : 3 }) >>> _ . lowest_terms () H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) Testing equivalence implicitly performs reductions of operands: 1 2 >>> d6 . accumulate ( d6 ) == d6 . accumulate ( d6 ) . accumulate ( d6 ) True Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ 0 : 6 , 1 : 30 }) >>> print ( _ . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ 0 : 21 , 1 : 15 }) >>> print ( _ . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6 . eq ( 2 ) # how often a 2 shows on a single six-sided die H ({ 0 : 5 , 1 : 1 }) >>> 4 @ ( _ ) # number of 2s that show on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> _ . ge ( 1 ) # how often that number is at least one H ({ 0 : 625 , 1 : 671 }) >>> print ( _ . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations: 1 2 3 4 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 >>> ( 2 @d6 ) . le ( 7 ) H ({ 0 : 15 , 1 : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False","title":"H"},{"location":"dyce/#dyce.h.H.__init__","text":"Initializer. Source code in dyce/h.py def __init__ ( self , items : SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init = None tmp : Counter [ int ] = counter () if isinstance ( items , int ): if items != 0 : self . _simple_init = items tmp . update ( range ( items , 0 , 1 if items < 0 else - 1 )) # count toward zero elif isinstance ( items , H . AbleT ): tmp . update ( items . h ()) elif isinstance ( items , ABCMapping ): tmp . update ( items ) else : # Items is either an Iterable[int] or an Iterable[Tuple[int, int]] (although # this technically supports Iterable[Union[int, Tuple[int, int]]]) for item in items : if isinstance ( item , tuple ): face , count = item tmp [ face ] += count else : tmp [ item ] += 1 # Sort and omit zero counts. We use an OrderedDict instead of a Counter to # support Python versions earlier than 3.7 which did not guarantee order # preservation for the latter. self . _h : Dict [ int , int ] = ordereddict ( { face : tmp [ face ] for face in sorted ( tmp ) if tmp [ face ]} )","title":"__init__()"},{"location":"dyce/#dyce.h.H.accumulate","text":"Accumulates counts: 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py def accumulate ( self , other : SourceT ) -> \"H\" : r \"\"\" Accumulates counts: ```python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , int ): other = ( other ,) elif isinstance ( other , ABCMapping ): other = other . items () return H ( chain ( self . items (), cast ( Iterable , other )))","title":"accumulate()"},{"location":"dyce/#dyce.h.H.counts","text":"More descriptive synonym for the values method . Source code in dyce/h.py def counts ( self ) -> Iterator [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . values ()","title":"counts()"},{"location":"dyce/#dyce.h.H.data","text":"Presentation helper function that returns an iterator for each face/frequency pair: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> list ( d6 . gt ( 3 ) . data ()) [( 0 , 3.0 ), ( 1 , 3.0 )] >>> list ( d6 . gt ( 3 ) . data ( relative = True )) [( 0 , 0.5 ), ( 1 , 0.5 )] If provided, fill_items supplies defaults for any missing faces: 1 2 3 4 >>> list ( d6 . gt ( 7 ) . data ()) [( 0 , 6.0 )] >>> list ( d6 . gt ( 7 ) . data ( fill_items = { 1 : 0 , 0 : 0 })) [( 0 , 6.0 ), ( 1 , 0.0 )] Source code in dyce/h.py def data ( self , relative : bool = False , fill_items : Optional [ Mapping [ int , int ]] = None , ) -> Iterator [ Tuple [ int , float ]]: r \"\"\" Presentation helper function that returns an iterator for each face/frequency pair: ```python >>> d6 = H(6) >>> list(d6.gt(3).data()) [(0, 3.0), (1, 3.0)] >>> list(d6.gt(3).data(relative=True)) [(0, 0.5), (1, 0.5)] ``` If provided, *fill_items* supplies defaults for any missing faces: ```python >>> list(d6.gt(7).data()) [(0, 6.0)] >>> list(d6.gt(7).data(fill_items={1: 0, 0: 0})) [(0, 6.0), (1, 0.0)] ``` \"\"\" if fill_items is None : fill_items = {} if relative : total = sum ( self . counts ()) or 1 else : total = 1 combined = dict ( chain ( fill_items . items (), self . items ())) return (( face , count / total ) for face , count in sorted ( combined . items ()))","title":"data()"},{"location":"dyce/#dyce.h.H.data_xy","text":"Presentation helper function that returns an iterator for a \u201czipped\u201d arrangement of the output from the data method : 1 2 3 4 5 >>> d6 = H ( 6 ) >>> list ( d6 . data ()) [( 1 , 1.0 ), ( 2 , 1.0 ), ( 3 , 1.0 ), ( 4 , 1.0 ), ( 5 , 1.0 ), ( 6 , 1.0 )] >>> d6 . data_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 1.0 , 1.0 , 1.0 , 1.0 , 1.0 , 1.0 )) Source code in dyce/h.py def data_xy ( self , relative : bool = False , fill_items : Optional [ Mapping [ int , int ]] = None , ) -> Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function that returns an iterator for a \u201czipped\u201d arrangement of the output from the [``data`` method][dyce.h.H.data]: ```python >>> d6 = H(6) >>> list(d6.data()) [(1, 1.0), (2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0)] >>> d6.data_xy() ((1, 2, 3, 4, 5, 6), (1.0, 1.0, 1.0, 1.0, 1.0, 1.0)) ``` \"\"\" return cast ( Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]], tuple ( zip ( * self . data ( relative , fill_items ))), )","title":"data_xy()"},{"location":"dyce/#dyce.h.H.eq","text":"Shorthand for self.map(operator.eq, other) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ 0 : 5 , 1 : 1 }) See the map method . Source code in dyce/h.py def eq ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.eq, other)``. ```python >>> H(6).eq(3) H({0: 5, 1: 1}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_eq , other )","title":"eq()"},{"location":"dyce/#dyce.h.H.even","text":"Equivalent to self.umap(lambda f: int(f % 2 == 0)) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . even () H ({ 0 : 2 , 1 : 4 }) See the umap method . Source code in dyce/h.py def even ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda f: int(f % 2 == 0))``. ```python >>> H((-4, -2, 0, 1, 2, 3)).even() H({0: 2, 1: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_even ( f : int ) -> int : return ( f & 0b1 ) ^ 0b1 return self . umap ( is_even )","title":"even()"},{"location":"dyce/#dyce.h.H.explode","text":"Shorthand for self.substitute(lambda h, f: h if f == max(h) else f, operator.add, max_depth) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py def explode ( self , max_depth : int = 1 , ) -> \"H\" : r \"\"\" Shorthand for ``self.substitute(lambda h, f: h if f == max(h) else f, operator.add, max_depth)``. ```python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , f : h if f == max ( h ) else f , op_add , max_depth , )","title":"explode()"},{"location":"dyce/#dyce.h.H.faces","text":"More descriptive synonym for the keys method . Source code in dyce/h.py def faces ( self ) -> Iterator [ int ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . keys ()","title":"faces()"},{"location":"dyce/#dyce.h.H.format","text":"Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing faces. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( \" {:->65} \" . format ( \" 65 chars wide -->|\" )) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py def format ( self , fill_items : Optional [ Mapping [ int , int ]] = None , width : int = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing faces. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ```python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ```python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``True``, horizontal bars are scaled to *width*: ```python >>> h = (2@H(6)).ge(7) >>> print(\"{:->65}\".format(\" 65 chars wide -->|\")) ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" if width <= 0 : def parts (): yield \"avg: {:.2f} \" . format ( self . mean ()) for face , percentage in self . data ( relative = True , fill_items = fill_items ): yield \" {} : {:7.2%} \" . format ( face , percentage ) return \"{\" + \", \" . join ( parts ()) + \"}\" else : w = width - 15 def lines (): mu = self . mean () yield \"avg | {:7.2f} \" . format ( mu ) yield \"std | {:7.2f} \" . format ( self . stdev ( mu )) yield \"var | {:7.2f} \" . format ( self . variance ( mu )) total = sum ( self . counts ()) tick_scale = max ( self . counts ()) if scaled else total for face , count in self . data ( relative = False , fill_items = fill_items ): percentage = count / total ticks = int ( w * count / tick_scale ) yield \" {: 3} | {:7.2%} | {} \" . format ( face , percentage , tick * ticks ) return sep . join ( lines ())","title":"format()"},{"location":"dyce/#dyce.h.H.ge","text":"Shorthand for self.map(operator.ge, other) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ 0 : 2 , 1 : 4 }) See the map method . Source code in dyce/h.py def ge ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ge, other)``. ```python >>> H(6).ge(3) H({0: 2, 1: 4}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ge , other )","title":"ge()"},{"location":"dyce/#dyce.h.H.gt","text":"Shorthand for self.map(operator.gt, other) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ 0 : 3 , 1 : 3 }) See the map method . Source code in dyce/h.py def gt ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.gt, other)``. ```python >>> H(6).gt(3) H({0: 3, 1: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_gt , other )","title":"gt()"},{"location":"dyce/#dyce.h.H.items","text":"D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py def items ( self ): return self . _h . items ()","title":"items()"},{"location":"dyce/#dyce.h.H.keys","text":"D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py def keys ( self ): return self . _h . keys ()","title":"keys()"},{"location":"dyce/#dyce.h.H.le","text":"Shorthand for self.map(operator.le, other) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ 0 : 3 , 1 : 3 }) See the map method . Source code in dyce/h.py def le ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.le, other)``. ```python >>> H(6).le(3) H({0: 3, 1: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_le , other )","title":"le()"},{"location":"dyce/#dyce.h.H.lowest_terms","text":"Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> H (( - 1 , - 1 , 0 , 0 , 1 , 1 )) H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> _ . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> _ . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py def lowest_terms ( self ) -> \"H\" : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ```python >>> H((-1, -1, 0, 0, 1, 1)) H({-1: 2, 0: 2, 1: 2}) >>> _.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ```python >>> H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) H({2: 2, 3: 4, 4: 4, 5: 2}) >>> _.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" counts_gcd = reduce ( gcd , self . counts (), 0 ) return H ({ k : v // counts_gcd for k , v in self . items ()})","title":"lowest_terms()"},{"location":"dyce/#dyce.h.H.lt","text":"Shorthand for self.map(operator.lt, other) : 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ 0 : 4 , 1 : 2 }) See the map method . Source code in dyce/h.py def lt ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.lt, other)``: ```python >>> H(6).lt(3) H({0: 4, 1: 2}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_lt , other )","title":"lt()"},{"location":"dyce/#dyce.h.H.map","text":"Applies oper to each face of the histogram paired with other . Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . add , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> _ == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . mul , - 1 ) H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> _ == d6 * - 1 True 1 2 3 4 >>> d6 . map ( operator . gt , 3 ) H ({ 0 : 3 , 1 : 3 }) >>> _ == d6 . gt ( 3 ) True Source code in dyce/h.py def map ( self , oper : _BinaryOperatorT , other : OperandT ) -> \"H\" : r \"\"\" Applies *oper* to each face of the histogram paired with *other*. Shorthands exist for many arithmetic operators and comparators. ```python >>> import operator >>> d6 = H(6) >>> d6.map(operator.add, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> _ == d6 + d6 True ``` ```python >>> d6.map(operator.mul, -1) H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> _ == d6 * -1 True ``` ```python >>> d6.map(operator.gt, 3) H({0: 3, 1: 3}) >>> _ == d6.gt(3) True ``` \"\"\" if isinstance ( other , H . AbleT ): other = other . h () if isinstance ( other , int ): return H (( int ( oper ( face , other )), count ) for face , count in self . items ()) elif isinstance ( other , H ): return H ( ( int ( oper ( a , b )), self [ a ] * other [ b ]) for a , b in product ( self , other ) ) else : raise NotImplementedError","title":"map()"},{"location":"dyce/#dyce.h.H.mean","text":"Returns the mean of the weighted faces (or 0.0 if there are no faces). Source code in dyce/h.py def mean ( self ) -> float : \"\"\" Returns the mean of the weighted faces (or 0.0 if there are no faces). \"\"\" numerator = denominator = 0 for face , count in self . items (): numerator += face * count denominator += count return numerator / ( denominator or 1 )","title":"mean()"},{"location":"dyce/#dyce.h.H.ne","text":"Shorthand for self.map(operator.ne, other) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ 0 : 1 , 1 : 5 }) See the map method . Source code in dyce/h.py def ne ( self , other : OperandT , ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ne, other)``. ```python >>> H(6).ne(3) H({0: 1, 1: 5}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ne , other )","title":"ne()"},{"location":"dyce/#dyce.h.H.odd","text":"Equivalent to self.umap(lambda f: int(f % 2 != 0)) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . odd () H ({ 0 : 4 , 1 : 2 }) See the umap method . Source code in dyce/h.py def odd ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda f: int(f % 2 != 0))``. ```python >>> H((-4, -2, 0, 1, 2, 3)).odd() H({0: 4, 1: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_odd ( f : int ) -> int : return f & 0b1 return self . umap ( is_odd )","title":"odd()"},{"location":"dyce/#dyce.h.H.roll","text":"Returns a (weighted) random face. Source code in dyce/h.py def roll ( self ) -> int : r \"\"\" Returns a (weighted) random face. \"\"\" val = randrange ( 0 , sum ( self . counts ())) total = 0 for face , count in self . items (): total += count if val < total : return face assert False , \"val ( {} ) \u2265 total ( {} )\" . format ( val , total )","title":"roll()"},{"location":"dyce/#dyce.h.H.stdev","text":"Shorthand for math.sqrt(self.variance(mu)) . Source code in dyce/h.py def stdev ( self , mu : Optional [ float ] = None ) -> float : \"\"\" Shorthand for ``math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu ))","title":"stdev()"},{"location":"dyce/#dyce.h.H.substitute","text":"Calls expand on each face, recursively up to max_depth times. If expand returns an int , it replaces the face. If it returns an H object , coalesce is called on the face and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the face with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the lowest_terms method .) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , face : int ) -> Union [ int , H ]: ... return h if face == 1 else face >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to the running sum). In nearly all cases, when a histogram is substituted for a face, it takes on the substituted face\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced face in relation to other faces. This becomes clearer when there is no overlap between the original histogram and the substitution: 1 2 3 4 5 6 7 8 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , f : - h if f == 4 else f ) >>> sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( c for f , c in orig . items () if f == 4 ) / sum ( orig . counts ()) 0.4 >>> sum ( c for f , c in sub . items () if f < 0 ) / sum ( sub . counts ()) 0.4 There is one important exception: If coalesce returns the empty histogram ( H({}) ), the corresponding face and its counts are omitted from the result without substitution or scaling. A trivial example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: 1 2 >>> H ( 6 ) . substitute ( lambda h , f : H ({}) if f == 6 else f ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> _ . substitute ( lambda h , f : H ({}) if f == 0 else f ) H ({ - 1 : 4553 , 1 : 8118 }) Because substitute accepts arbitrary functions, it is well suited for modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , face : int ) -> Union [ int , H ]: ... if face == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return face >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . add , max_depth = 6 ) >>> h_even = h . even () >>> print ( \" {:.3%} \" . format ( h_even . get ( 1 , 0 ) / sum ( h_even . counts ()))) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (potentially nudging us to an odd number slightly more often than not). We can also use this method to model expected damage from a single attack in d20-like roll playing games: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , face : int ) -> Union [ int , H ]: ... if face == 20 : ... return crit ... elif face >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 0 )) { avg : 2.15 , 0 : 65.00 % , 2 : 3.75 % , 3 : 3.83 % , 4 : 3.91 % , ... , 15 : 0.23 % , 16 : 0.16 % , 17 : 0.08 % } Source code in dyce/h.py def substitute ( self , expand : _ExpandT , coalesce : Optional [ _CoalesceT ] = None , max_depth : int = 1 , ) -> \"H\" : r \"\"\" Calls *expand* on each face, recursively up to *max_depth* times. If *expand* returns an ``int``, it replaces the face. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the face and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the face with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the [``lowest_terms`` method][dyce.h.H.lowest_terms].) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ```python >>> def reroll_one(h: H, face: int) -> Union[int, H]: ... return h if face == 1 else face >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to the running sum). In nearly all cases, when a histogram is substituted for a face, it takes on the substituted face\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced face in relation to other faces. This becomes clearer when there is no overlap between the original histogram and the substitution: ```python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, f: -h if f == 4 else f) >>> sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(c for f, c in orig.items() if f == 4) / sum(orig.counts()) 0.4 >>> sum(c for f, c in sub.items() if f < 0) / sum(sub.counts()) 0.4 ``` There is one important exception: If *coalesce* returns the empty histogram (``H({})``), the corresponding face and its counts are omitted from the result without substitution or scaling. A trivial example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: ```python >>> H(6).substitute(lambda h, f: H({}) if f == 6 else f) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> _.substitute(lambda h, f: H({}) if f == 0 else f) H({-1: 4553, 1: 8118}) ``` Because ``substitute`` accepts arbitrary functions, it is well suited for modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ```python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, face: int) -> Union[int, H]: ... if face == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return face >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.add, max_depth=6) >>> h_even = h.even() >>> print(\"{:.3%}\".format(h_even.get(1, 0) / sum(h_even.counts()))) 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (potentially nudging us to an odd number slightly more often than not). We can also use this method to model expected damage from a single attack in d20-like roll playing games: ```python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, face: int) -> Union[int, H]: ... if face == 20: ... return crit ... elif face >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=0)) {avg: 2.15, 0: 65.00%, 2: 3.75%, 3: 3.83%, 4: 3.91%, ..., 15: 0.23%, 16: 0.16%, 17: 0.08%} ``` \"\"\" if coalesce is None : coalesce = _coalesce_replace def _substitute ( h : H , depth : int = 0 , ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ int , int , int ]] = [] for face , count in h . items (): expanded = expand ( h , face ) if isinstance ( expanded , int ): items_for_reassembly . append (( expanded , count , 1 )) else : # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , face ) # Account for the impact of expansion on peers expanded_scalar = sum ( expanded . counts ()) if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) return H ( ( # Apply the total_scalar, but factor out this item's contribution ( f , c * total_scalar // s ) for f , c , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self )","title":"substitute()"},{"location":"dyce/#dyce.h.H.umap","text":"Applies oper to each face of the histogram: 1 2 >>> H ( 6 ) . umap ( lambda f : f * - 1 ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda f : ( - f ) ** f ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py def umap ( self , oper : _UnaryOperatorT ) -> \"H\" : r \"\"\" Applies *oper* to each face of the histogram: ```python >>> H(6).umap(lambda f: f * -1) H(-6) ``` ```python >>> H(4).umap(lambda f: (-f) ** f) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = H (( oper ( face ), count ) for face , count in self . items ()) if self . _simple_init is not None : h_simple = H ( oper ( self . _simple_init )) if h_simple == h : return h_simple return h","title":"umap()"},{"location":"dyce/#dyce.h.H.values","text":"D.values() -> an object providing a view on D's values Source code in dyce/h.py def values ( self ): return self . _h . values ()","title":"values()"},{"location":"dyce/#dyce.h.H.variance","text":"Returns the variance of the weighted faces. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py def variance ( self , mu : Optional [ float ] = None ) -> float : \"\"\" Returns the variance of the weighted faces. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator = denominator = 0 for face , count in self . items (): numerator += ( face - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 )","title":"variance()"},{"location":"dyce/#dyce.h.H.vs","text":"Compares this histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self.within(0, 0, other) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> _ == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py def vs ( self , other : OperandT ) -> \"H\" : r \"\"\" Compares this histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``self.within(0, 0, other)``. ```python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> _ == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other )","title":"vs()"},{"location":"dyce/#dyce.h.H.within","text":"Computes the difference between this histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 >>> ( 2 @H ( 6 )) . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( _ . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 >>> ( 3 @H ( 6 )) . within ( - 1 , 1 , 2 @H ( 8 )) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( _ . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py def within ( self , lo : int , hi : int , other : OperandT = 0 ) -> \"H\" : r \"\"\" Computes the difference between this histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ```python >>> (2@H(6)).within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(_.format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ```python >>> (3@H(6)).within(-1, 1, 2@H(8)) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(_.format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other )","title":"within()"},{"location":"dyce/#dyce.p.P","text":"An immutable pool (ordered sequence) of zero or more H objects supporting group operations. Objects can be flattened to a single histogram, either explicitly via the h method , or by using binary arithmetic operations. Unary operators and the @ operator result in new P objects. If any of the initializer \u2019s args parameter is an int , it is passed to H \u2019s initializer . 1 2 3 4 5 >>> p_d6 = P ( 6 ) # shorthand for P(H(6)) >>> p_d6 P ( 6 ) >>> - p_d6 P ( - 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( _ . roll ()) in _ . h () True Arithmetic operators involving an int or another P object produce an H object : 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) Comparisons with H objects work as expected: 1 2 >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram: 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that containers are opinionated about histogram ordering: 1 2 >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True The h method also allows subsets of faces to be \u201ctaken\u201d (selected) by index from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> ( 3 @p_d6 ) . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( _ . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ###","title":"P"},{"location":"dyce/#dyce.p.P.__init__","text":"Initializer. Source code in dyce/p.py def __init__ ( self , * args : Union [ int , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs (): for a in args : if isinstance ( a , int ): yield H ( a ) elif isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : # pylint: disable=protected-access yield h else : raise TypeError ( \"type {} incompatible initializer for {} \" . format ( type ( a ), type ( self ) ) ) hs = list ( h for h in _gen_hs () if h ) hs . sort ( key = lambda h : tuple ( h . items ())) self . _hs = tuple ( hs )","title":"__init__()"},{"location":"dyce/#dyce.p.P.eq","text":"Shorthand for self.h().eq(other) . See the h method and H.eq . Source code in dyce/p.py def eq ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().eq(other)``. See the [``h`` method][dyce.p.P.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other )","title":"eq()"},{"location":"dyce/#dyce.p.P.even","text":"Shorthand for self.h().even() . See the h method and H.even . Source code in dyce/p.py def even ( self ) -> H : r \"\"\" Shorthand for ``self.h().even()``. See the [``h`` method][dyce.p.P.h] and [``H.even``][dyce.h.H.even]. \"\"\" return self . h () . even ()","title":"even()"},{"location":"dyce/#dyce.p.P.explode","text":"Shorthand for self.h().explode(max_depth) . See the h method and H.explode . Source code in dyce/p.py def explode ( self , max_depth : int = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().explode(max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth )","title":"explode()"},{"location":"dyce/#dyce.p.P.ge","text":"Shorthand for self.h().ge(other) . See the h method and H.ge . Source code in dyce/p.py def ge ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().ge(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other )","title":"ge()"},{"location":"dyce/#dyce.p.P.gt","text":"Shorthand for self.h().gt(other) . See the h method and H.gt . Source code in dyce/p.py def gt ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().gt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other )","title":"gt()"},{"location":"dyce/#dyce.p.P.h","text":"When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms: 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If the optional dice parameter is provided, h sums subsets of faces identified by dice . dice can include int s and slice s. All outcomes are counted. For each outcome, dice are ordered from least (index 0 ) to greatest (index -1 or len(self) ). Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 >>> ( 2 @P ( 6 )) . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( _ . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Slices and arbitrary iterables support more flexible face selections: 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = p_6d6 . h ( slice ( None , None , - 2 )) >>> every_other_d6 H ({ 3 : 1 , 4 : 21 , 5 : 86 , ... , 16 : 1106 , 17 : 395 , 18 : 31 }) >>> p_6d6 . h ( 5 , 3 , 1 ) == every_other_d6 True >>> p_6d6 . h ( * range ( 1 , 6 , 2 )) == every_other_d6 True >>> p_6d6 . h ( * ( i for i in range ( 0 , 6 ) if i % 2 == 1 )) == every_other_d6 True >>> p_6d6 . h ( * { 1 , 3 , 5 }) == every_other_d6 True Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> ( 10 @P ( 4 )) . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( _ . format ( width = 65 )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | ## 9 | 16.09 % | ######## 10 | 56.74 % | ############################ 11 | 16.09 % | ######## 12 | 4.96 % | ## 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | By taking all faces, we can confirm equivalence to our sum operation: 1 2 3 4 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> ( 2 @P ( d6 , d233445 )) . h ( slice ( None )) == d6 + d6 + d233445 + d233445 True Source code in dyce/p.py def h ( self , * dice : _GetItemT ) -> H : r \"\"\" When provided no arguments, ``h`` combines (or \u201cflattens\u201d) contained histograms: ```python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If the optional *dice* parameter is provided, ``h`` sums subsets of faces identified by *dice*. *dice* can include ``int``s and ``slice``s. All outcomes are counted. For each outcome, dice are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self)``). Taking the greatest of two six-sided dice can be modeled as: ```python >>> (2@P(6)).h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(_.format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Slices and arbitrary iterables support more flexible face selections: ```python >>> p_6d6 = 6@P(6) >>> every_other_d6 = p_6d6.h(slice(None, None, -2)) >>> every_other_d6 H({3: 1, 4: 21, 5: 86, ..., 16: 1106, 17: 395, 18: 31}) >>> p_6d6.h(5, 3, 1) == every_other_d6 True >>> p_6d6.h(*range(1, 6, 2)) == every_other_d6 True >>> p_6d6.h(*(i for i in range(0, 6) if i % 2 == 1)) == every_other_d6 True >>> p_6d6.h(*{1, 3, 5}) == every_other_d6 True ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ```python >>> (10@P(4)).h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(_.format(width=65)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |## 9 | 16.09% |######## 10 | 56.74% |############################ 11 | 16.09% |######## 12 | 4.96% |## 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` By taking all faces, we can confirm equivalence to our sum operation: ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> (2@P(d6, d233445)).h(slice(None)) == d6 + d6 + d233445 + d233445 True ``` \"\"\" if dice : return H ( _take_and_sum_faces ( self . rolls_with_counts (), dice )) else : if self . _hs : hs_sum = sum ( self . _hs ) else : hs_sum = H (()) return cast ( H , hs_sum )","title":"h()"},{"location":"dyce/#dyce.p.P.le","text":"Shorthand for self.h().le(other) . See the h method and H.le . Source code in dyce/p.py def le ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().le(other)``. See the [``h`` method][dyce.p.P.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other )","title":"le()"},{"location":"dyce/#dyce.p.P.lt","text":"Shorthand for self.h().lt(other) . See the h method and H.lt . Source code in dyce/p.py def lt ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().lt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other )","title":"lt()"},{"location":"dyce/#dyce.p.P.ne","text":"Shorthand for self.h().ne(other) . See the h method and H.ne . Source code in dyce/p.py def ne ( self , other : OperandT , ) -> H : r \"\"\" Shorthand for ``self.h().ne(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other )","title":"ne()"},{"location":"dyce/#dyce.p.P.odd","text":"Shorthand for self.h().odd() . See the h method and H.odd . Source code in dyce/p.py def odd ( self ) -> H : r \"\"\" Shorthand for ``self.h().odd()``. See the [``h`` method][dyce.p.P.h] and [``H.odd``][dyce.h.H.odd]. \"\"\" return self . h () . odd ()","title":"odd()"},{"location":"dyce/#dyce.p.P.roll","text":"Returns (weighted) random faces from contained histograms. Source code in dyce/p.py def roll ( self ) -> Tuple [ int , ... ]: r \"\"\" Returns (weighted) random faces from contained histograms. \"\"\" return tuple ( h . roll () for h in self . _hs )","title":"roll()"},{"location":"dyce/#dyce.p.P.rolls_with_counts","text":"Returns an iterator that yields 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the faces for a distinct roll. The second is the count for that roll. Faces in each roll are ordered least to greatest. We can model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest faces are the same: 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } Note that, in the general case, rolls may appear more than once, and there are no guarantees about their order. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, (1, 2) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), faces are not repeated and are presented in order. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] By summing and counting all rolls, we can confirm equivalence to taking all faces: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> pool = 2 @P ( d6 , d233445 ) >>> H (( sum ( r ), c ) for r , c in pool . rolls_with_counts ()) == pool . h ( slice ( None )) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones. This is because, instead of merely computing the Cartesian product, we are able to leverage the multinomial coefficient : \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n@P(H(m)) . Enumerating combinations with replacements would yield all unique rolls: ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), (2, 2, \u2026, 2), \u2026, (m - 1, m, m), (m, m, m)) To determine the count for a particular roll (a, b, \u2026, n) , we compute the multinomial coefficient for that roll and multiply by the scalar H(m)[a] * H(m)[b] * \u2026 * H(m)[n] . (See this for an in-depth exploration of the topic.) This implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, while heterogeneous ones offer no such guarantees. As expected, this optimization allows mixed pools\u2019 performance to sit between purely homogeneous and purely heterogeneous ones: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 In [ 1 ]: from dyce import H , P In [ 2 ]: for i in range ( 2 , 11 , 2 ): ... : p = i @P ( 6 ) ... : print ( \"Pool len {} (homogeneous): {} \" . format ( len ( p ), p )) ... : % timeit p.h(slice(None)) ... : Pool len 2 ( homogeneous ): P ( 6 , 6 ) 105 \u00b5s \u00b1 1.97 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) Pool len 4 ( homogeneous ): P ( 6 , 6 , 6 , 6 ) 644 \u00b5s \u00b1 9.98 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 6 ( homogeneous ): P ( 6 , 6 , 6 , 6 , 6 , 6 ) 2.98 ms \u00b1 447 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 8 ( homogeneous ): P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 ) 9.16 ms \u00b1 667 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 10 ( homogeneous ): P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 ) 22.4 ms \u00b1 294 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 3 ]: for i in range ( 1 , 6 ): ... : hs = [ H ( 6 ) for _ in range ( i )] ... : hs . extend ( H ( 6 ) - j for j in range ( i )) ... : p = P ( * hs ) ... : print ( \"Pool len {} (mixed): {} \" . format ( len ( p ), p )) ... : % timeit p.h(slice(None)) ... : Pool len 2 ( mixed ): P ( 6 , H ({ 1 : 1 , ... , 6 : 1 })) 158 \u00b5s \u00b1 688 ns per loop ( mean \u00b1 std . dev . of 7 runs , 10000 loops each ) Pool len 4 ( mixed ): P ( H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 1.12 ms \u00b1 16.9 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 6 ( mixed ): P ( H ({ - 1 : 1 , ... , 4 : 1 }), ... , 6 , 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 11.6 ms \u00b1 714 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 8 ( mixed ): P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , 6 , 6 , 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 152 ms \u00b1 8.65 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Pool len 10 ( mixed ): P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , 6 , 6 , 6 , 6 , 6 , H ({ 1 : 1 , ... , 6 : 1 })) 1.73 s \u00b1 96.8 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 4 ]: for i in range ( 2 , 10 ): # larger takes too long on my laptop ... : p = P ( * ( H ( 6 ) - j for j in range ( i ))) ... : print ( \"Pool len {} (heterogeneous): {} \" . format ( len ( p ), p )) ... : % timeit p.h(slice(None)) ... : Pool len 2 ( heterogeneous ): P ( H ({ 0 : 1 , ... , 5 : 1 }), H ({ 1 : 1 , ... , 6 : 1 })) 238 \u00b5s \u00b1 9.76 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 3 ( heterogeneous ): P ( H ({ - 1 : 1 , ... , 4 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 685 \u00b5s \u00b1 18.2 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) Pool len 4 ( heterogeneous ): P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 3.28 ms \u00b1 14.2 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 5 ( heterogeneous ): P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 19.3 ms \u00b1 41.2 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) Pool len 6 ( heterogeneous ): P ( H ({ - 4 : 1 , ... , 1 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 114 ms \u00b1 749 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Pool len 7 ( heterogeneous ): P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 725 ms \u00b1 7.67 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Pool len 8 ( heterogeneous ): P ( H ({ - 6 : 1 , ... , - 1 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 4.58 s \u00b1 38.7 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Pool len 9 ( heterogeneous ): P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 1 : 1 , ... , 6 : 1 })) 31 s \u00b1 969 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def rolls_with_counts ( self ) -> Iterator [ Tuple [ Tuple [ int , ... ], int ]]: r \"\"\" Returns an iterator that yields 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the faces for a distinct roll. The second is the count for that roll. Faces in each roll are ordered least to greatest. We can model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest faces are the same: ```python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` Note that, in the general case, rolls may appear more than once, and there are no guarantees about their order. ```python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, `(1, 2)` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), faces are not repeated and are presented in order. (See the note on implementation below.) ```python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` By summing and counting all rolls, we can confirm equivalence to taking all faces: ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> pool = 2@P(d6, d233445) >>> H((sum(r), c) for r, c in pool.rolls_with_counts()) == pool.h(slice(None)) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones. This is because, instead of merely computing the Cartesian product, we are able to leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets): $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls: ``((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), (2, 2, \u2026, 2), \u2026, (m - 1, m, m), (m, m, m))`` To determine the count for a particular roll ``(a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) This implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, while heterogeneous ones offer no such guarantees. As expected, this optimization allows mixed pools\u2019 performance to sit between purely homogeneous and purely heterogeneous ones: ```ipython In [1]: from dyce import H, P In [2]: for i in range(2, 11, 2): ...: p = i@P(6) ...: print(\"Pool len {} (homogeneous): {}\".format(len(p), p)) ...: %timeit p.h(slice(None)) ...: Pool len 2 (homogeneous): P(6, 6) 105 \u00b5s \u00b1 1.97 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each) Pool len 4 (homogeneous): P(6, 6, 6, 6) 644 \u00b5s \u00b1 9.98 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 6 (homogeneous): P(6, 6, 6, 6, 6, 6) 2.98 ms \u00b1 447 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 8 (homogeneous): P(6, 6, 6, 6, 6, 6, 6, 6) 9.16 ms \u00b1 667 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 10 (homogeneous): P(6, 6, 6, 6, 6, 6, 6, 6, 6, 6) 22.4 ms \u00b1 294 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for i in range(1, 6): ...: hs = [H(6) for _ in range(i)] ...: hs.extend(H(6) - j for j in range(i)) ...: p = P(*hs) ...: print(\"Pool len {} (mixed): {}\".format(len(p), p)) ...: %timeit p.h(slice(None)) ...: Pool len 2 (mixed): P(6, H({1: 1, ..., 6: 1})) 158 \u00b5s \u00b1 688 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each) Pool len 4 (mixed): P(H({0: 1, ..., 5: 1}), 6, 6, H({1: 1, ..., 6: 1})) 1.12 ms \u00b1 16.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 6 (mixed): P(H({-1: 1, ..., 4: 1}), ..., 6, 6, 6, H({1: 1, ..., 6: 1})) 11.6 ms \u00b1 714 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 8 (mixed): P(H({-2: 1, ..., 3: 1}), ..., 6, 6, 6, 6, H({1: 1, ..., 6: 1})) 152 ms \u00b1 8.65 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) Pool len 10 (mixed): P(H({-3: 1, ..., 2: 1}), ..., 6, 6, 6, 6, 6, H({1: 1, ..., 6: 1})) 1.73 s \u00b1 96.8 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for i in range(2, 10): # larger takes too long on my laptop ...: p = P(*(H(6) - j for j in range(i))) ...: print(\"Pool len {} (heterogeneous): {}\".format(len(p), p)) ...: %timeit p.h(slice(None)) ...: Pool len 2 (heterogeneous): P(H({0: 1, ..., 5: 1}), H({1: 1, ..., 6: 1})) 238 \u00b5s \u00b1 9.76 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 3 (heterogeneous): P(H({-1: 1, ..., 4: 1}), ..., H({1: 1, ..., 6: 1})) 685 \u00b5s \u00b1 18.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) Pool len 4 (heterogeneous): P(H({-2: 1, ..., 3: 1}), ..., H({1: 1, ..., 6: 1})) 3.28 ms \u00b1 14.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 5 (heterogeneous): P(H({-3: 1, ..., 2: 1}), ..., H({1: 1, ..., 6: 1})) 19.3 ms \u00b1 41.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) Pool len 6 (heterogeneous): P(H({-4: 1, ..., 1: 1}), ..., H({1: 1, ..., 6: 1})) 114 ms \u00b1 749 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) Pool len 7 (heterogeneous): P(H({-5: 1, ..., 0: 1}), ..., H({1: 1, ..., 6: 1})) 725 ms \u00b1 7.67 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Pool len 8 (heterogeneous): P(H({-6: 1, ..., -1: 1}), ..., H({1: 1, ..., 6: 1})) 4.58 s \u00b1 38.7 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Pool len 9 (heterogeneous): P(H({-7: 1, ..., -2: 1}), ..., H({1: 1, ..., 6: 1})) 31 s \u00b1 969 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self . _hs )) if len ( groups ) == 1 : # Optimization to use _rolls_with_counts_for_n_homogeneous_histograms directly if # there's only one group; roughly 15% time savings based on cursory # performance analysis h , n = groups [ 0 ] return _rolls_with_counts_for_n_homogeneous_histograms ( h , n ) else : return _rolls_with_counts_for_heterogeneous_histograms ( groups )","title":"rolls_with_counts()"},{"location":"dyce/#dyce.p.P.substitute","text":"Shorthand for self.h().substitute(expand, coalesce, max_depth) . See the h method and H.substitute . Source code in dyce/p.py def substitute ( self , expand : _ExpandT , coalesce : Optional [ _CoalesceT ] = None , max_depth : int = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth )","title":"substitute()"},{"location":"dyce/#dyce.p.P.within","text":"Shorthand for self.h().within(lo, hi, other) . See the h method and H.within . Source code in dyce/p.py def within ( self , lo : int , hi : int , other : OperandT = 0 ) -> H : r \"\"\" Shorthand for ``self.h().within(lo, hi, other)``. See the [``h`` method][dyce.p.P.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"within()"},{"location":"dyce.plt/","text":"dyce.plt package reference Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Suggestions and contributions are welcome. display_burst ( ax , h_inner , outer = None , desc = None , graph_color = 'RdYlGn_r' , text_color = 'black' , alpha = 0.5 ) Source code in dyce/plt.py def display_burst ( ax : AxesT , h_inner : H , outer : Optional [ Iterable [ LabelT ]] = None , desc : Optional [ str ] = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : assert matplotlib if outer is None : outer = ( ( \" {:.2%} \" . format ( v ) if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . data ( relative = True ) ) outer_labels , outer_values = list ( zip ( * outer )) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.2 , labeldistance = 1.2 , startangle = 90 , colors = graph_colors ( graph_color , outer_values , alpha ), wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 1 , labeldistance = 0.8 , startangle = 90 , colors = graph_colors ( graph_color , h_inner , alpha ), textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.4 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" ) labels_cumulative ( h ) Source code in dyce/plt.py def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: le_total , ge_total = 0.0 , 1.0 for face , percentage in h . data ( relative = True ): le_total += percentage if percentage >= _HIDE_LIM : label = \" {} {:.2%} ; \u2265 {:.2%} ; \u2264 {:.2%} \" . format ( face , percentage , le_total , ge_total ) else : label = \"\" ge_total -= percentage yield ( label , percentage ) plot_burst ( h_inner , outer = None , desc = None , graph_color = 'RdYlGn_r' , text_color = 'black' , alpha = 0.5 ) Source code in dyce/plt.py def plot_burst ( h_inner : H , outer : Optional [ Iterable [ LabelT ]] = None , desc : Optional [ str ] = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ FigureT , AxesT ]: assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , graph_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"<tt>dyce.plt</tt>"},{"location":"dyce.plt/#dyceplt-package-reference","text":"Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Suggestions and contributions are welcome.","title":"dyce.plt package reference"},{"location":"dyce.plt/#dyce.plt.display_burst","text":"Source code in dyce/plt.py def display_burst ( ax : AxesT , h_inner : H , outer : Optional [ Iterable [ LabelT ]] = None , desc : Optional [ str ] = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : assert matplotlib if outer is None : outer = ( ( \" {:.2%} \" . format ( v ) if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . data ( relative = True ) ) outer_labels , outer_values = list ( zip ( * outer )) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.2 , labeldistance = 1.2 , startangle = 90 , colors = graph_colors ( graph_color , outer_values , alpha ), wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 1 , labeldistance = 0.8 , startangle = 90 , colors = graph_colors ( graph_color , h_inner , alpha ), textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.4 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" )","title":"display_burst()"},{"location":"dyce.plt/#dyce.plt.labels_cumulative","text":"Source code in dyce/plt.py def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: le_total , ge_total = 0.0 , 1.0 for face , percentage in h . data ( relative = True ): le_total += percentage if percentage >= _HIDE_LIM : label = \" {} {:.2%} ; \u2265 {:.2%} ; \u2264 {:.2%} \" . format ( face , percentage , le_total , ge_total ) else : label = \"\" ge_total -= percentage yield ( label , percentage )","title":"labels_cumulative()"},{"location":"dyce.plt/#dyce.plt.plot_burst","text":"Source code in dyce/plt.py def plot_burst ( h_inner : H , outer : Optional [ Iterable [ LabelT ]] = None , desc : Optional [ str ] = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ FigureT , AxesT ]: assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , graph_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"plot_burst()"},{"location":"license/","text":"License & credits The MIT License (MIT) Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contributors The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub - @posita By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"License"},{"location":"license/#license-credits","text":"","title":"License &amp; credits"},{"location":"license/#the-mit-license-mit","text":"Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"license/#contributors","text":"The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub - @posita By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"Contributors"}]}