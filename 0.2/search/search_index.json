{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Copyright and other protections apply. Please see the accompanying LICENSE file for rights and restrictions governing use of this software. All rights not expressly waived or licensed are reserved. If that file is missing or appears to be modified from its original, then please contact the author before viewing or using this software in any capacity. dyce \u2013 simple Python tools for exploring dice probabilities and outcomes dyce is a pure-Python library for computing discrete probability distributions. It is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. If you find it lacking in any way, please consider contributing an issue to start a discussion. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Source code is available on GitHub . A taste dyce provides two key primitives. H objects represent histograms for modeling discrete outcomes, like individual dice. P objects objects represent pools (ordered sequences) of histograms. Both support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ( width = 65 )) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . style . use ( \"dark_background\" ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( 0 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Lowest\" , ... ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( - 1 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Highest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Taking the lowest or highest die of 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP See the tutorial and the API guide for a much more thorough treatment, including detailed examples. Design philosophy dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. Because it exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. It can be installed and run anywhere, and modified as desired. On its own, it is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter . In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods). Comparison to alternatives The following is a best-effort\u00b9 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen AnyDice Flick python_dice Robson et al. d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clemens et al. dice-notation Garrido dyce Eyk Actively maintained and documented \u2705 \u26a0\u00b2 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c \u274c Arbitrary expressions \u2705 \u26a0\u00b3 \u2705 \u2705 \u2705 \u26a0\u2074 \u274c \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u274c \u26a0\u2075 \u26a0\u2075 \u2705 \u26a0\u2075 \u26a0\u2075 \u26a0\u2075 Open source \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Permissive licensing \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Notes \u00b9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if there are discrepancies. \u00b2 Actively maintained, but sparsely documented. The author has expressed a desire to release a more polished version. \u00b3 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u2074 Limited arithmetic operations are available. The library also provides game-specific functions. \u2075 Results only. Input is limited to specialized grammar. License dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub . Installation Installation can be performed via PyPI : 1 2 % pip install dycelib ... Alternately, you can download the source and run setup.py : 1 2 3 4 5 % git clone https://github.com/posita/dyce ... % cd dyce % python setup.py install # --editable '.[dev]' ... Requirements dyce requires a relatively modern version of Python: cPython (3.7+) PyPy (Python 3.7+ compatible) It has the following dependencies: typing-extensions","title":"Introduction"},{"location":"#dyce-simple-python-tools-for-exploring-dice-probabilities-and-outcomes","text":"dyce is a pure-Python library for computing discrete probability distributions. It is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. If you find it lacking in any way, please consider contributing an issue to start a discussion. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Source code is available on GitHub .","title":"dyce \u2013 simple Python tools for exploring dice probabilities and outcomes"},{"location":"#a-taste","text":"dyce provides two key primitives. H objects represent histograms for modeling discrete outcomes, like individual dice. P objects objects represent pools (ordered sequences) of histograms. Both support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ( width = 65 )) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . style . use ( \"dark_background\" ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( 0 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Lowest\" , ... ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( - 1 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Highest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Taking the lowest or highest die of 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP See the tutorial and the API guide for a much more thorough treatment, including detailed examples.","title":"A taste"},{"location":"#design-philosophy","text":"dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. Because it exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. It can be installed and run anywhere, and modified as desired. On its own, it is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter . In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods).","title":"Design philosophy"},{"location":"#comparison-to-alternatives","text":"The following is a best-effort\u00b9 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen AnyDice Flick python_dice Robson et al. d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clemens et al. dice-notation Garrido dyce Eyk Actively maintained and documented \u2705 \u26a0\u00b2 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c \u274c Arbitrary expressions \u2705 \u26a0\u00b3 \u2705 \u2705 \u2705 \u26a0\u2074 \u274c \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u274c \u26a0\u2075 \u26a0\u2075 \u2705 \u26a0\u2075 \u26a0\u2075 \u26a0\u2075 Open source \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Permissive licensing \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Notes \u00b9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if there are discrepancies. \u00b2 Actively maintained, but sparsely documented. The author has expressed a desire to release a more polished version. \u00b3 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u2074 Limited arithmetic operations are available. The library also provides game-specific functions. \u2075 Results only. Input is limited to specialized grammar.","title":"Comparison to alternatives"},{"location":"#license","text":"dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub .","title":"License"},{"location":"#installation","text":"Installation can be performed via PyPI : 1 2 % pip install dycelib ... Alternately, you can download the source and run setup.py : 1 2 3 4 5 % git clone https://github.com/posita/dyce ... % cd dyce % python setup.py install # --editable '.[dev]' ...","title":"Installation"},{"location":"#requirements","text":"dyce requires a relatively modern version of Python: cPython (3.7+) PyPy (Python 3.7+ compatible) It has the following dependencies: typing-extensions","title":"Requirements"},{"location":"contrib/","text":"Contributing to dyce There are several ways you can contribute. Filing issues You can file new issues as you find them. Please avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful. Submission guidelines If you are willing and able, consider submitting a pull request (PR) with a fix. There are only a few guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file: 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub - [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Try to follow the source conventions as you observe them. (Note: I have purposely avoided aspects of PEP8 , in part because I have adopted conventions developed from my experiences with other languages, but mostly because I am growing older and more stubborn.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in ./tests and can be run with Tox or pytest . A helper script is provided for setting up an isolated development environment. For example: 1 2 3 [ PYTHON = /path/to/python ] ./helpers/venvsetup.sh tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] pytest [ PYTEST_ARGS... ] If you need me, mention me ( @posita ) in your comment, and describe specifically how I can help. If you want feedback on a work-in-progress (WIP), create a PR and prefix its title with something like, \u201c NEED FEEDBACK - \u201d. If your PR is still in progress, but you are not blocked on anything, prefix the title with something like, \u201c WIP - \u201d. Once you are ready for a merge, resolve any merge conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) Then prefix the PR\u2019s title to something like, \u201c READY FOR MERGE - \u201d. I will try to get to it as soon as I can.","title":"Contributing"},{"location":"contrib/#contributing-to-dyce","text":"There are several ways you can contribute.","title":"Contributing to dyce"},{"location":"contrib/#filing-issues","text":"You can file new issues as you find them. Please avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful.","title":"Filing issues"},{"location":"contrib/#submission-guidelines","text":"If you are willing and able, consider submitting a pull request (PR) with a fix. There are only a few guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file: 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub - [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Try to follow the source conventions as you observe them. (Note: I have purposely avoided aspects of PEP8 , in part because I have adopted conventions developed from my experiences with other languages, but mostly because I am growing older and more stubborn.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in ./tests and can be run with Tox or pytest . A helper script is provided for setting up an isolated development environment. For example: 1 2 3 [ PYTHON = /path/to/python ] ./helpers/venvsetup.sh tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] pytest [ PYTEST_ARGS... ] If you need me, mention me ( @posita ) in your comment, and describe specifically how I can help. If you want feedback on a work-in-progress (WIP), create a PR and prefix its title with something like, \u201c NEED FEEDBACK - \u201d. If your PR is still in progress, but you are not blocked on anything, prefix the title with something like, \u201c WIP - \u201d. Once you are ready for a merge, resolve any merge conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) Then prefix the PR\u2019s title to something like, \u201c READY FOR MERGE - \u201d. I will try to get to it as soon as I can.","title":"Submission guidelines"},{"location":"dyce/","text":"dyce package reference dyce special dyce provides two core primitives: H for histograms (outcomes or individual dice) P for collections of histograms (pools) H An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, it is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derives, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ): 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed: 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative): 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps: 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes: 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand: 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes: 1 2 >>> len ( 2 @d6 ) 11 The counts method can be used to compute the total number of combinations and each outcome\u2019s probability: 1 2 3 4 5 >>> from fractions import Fraction >>> total = sum (( 2 @d6 ) . counts ()) ; total 36 >>> [( outcome , Fraction ( count , total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ); d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [\u2026] : 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method : 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands: 1 2 >>> d6 . accumulate ( d6 ) == d6 . accumulate ( d6 ) . accumulate ( d6 ) True __hash__ ( self ) -> int special Return hash(self). Source code in dyce/h.py def __hash__ ( self ) -> int : return hash ( tuple ( self . _lowest_terms ())) __init__ ( self , items : _SourceT ) -> None special Initializer. Source code in dyce/h.py def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init = None tmp : Counter [ _OutcomeT ] = counter () if isinstance ( items , ( int , Integral )): if items != 0 : self . _simple_init = items outcome_type = type ( items ) count_1 = type ( items )( 1 ) outcome_range = range ( items , 0 , 1 if items < 0 else - 1 # count toward zero ) tmp . update ({ outcome_type ( i ): count_1 for i in outcome_range }) elif isinstance ( items , HAbleT ): tmp . update ( items . h ()) elif isinstance ( items , ABCMapping ): tmp . update ( items ) elif isinstance ( items , ABCIterable ): # Items is either an Iterable[_OutcomeT] or an Iterable[Tuple[_OutcomeT, # _CountT]] (although this technically supports Iterable[Union[_OutcomeT, # Tuple[_OutcomeT, _CountT]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += count else : tmp [ item ] += 1 else : raise ValueError ( \"unrecognized initializer {} \" . format ( type ( items ))) # Sort and omit zero counts. We use an OrderedDict instead of a Counter to # support Python versions earlier than 3.7 which did not guarantee order # preservation for the latter. self . _h : _MappingT = ordereddict ( { outcome : tmp [ outcome ] for outcome in sorted ( tmp ) if tmp [ outcome ]} ) accumulate ( self , other : _SourceT ) -> 'H' Accumulates counts: 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py def accumulate ( self , other : _SourceT ) -> \"H\" : r \"\"\" Accumulates counts: ```python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , ABCMapping ): other = other . items () elif not isinstance ( other , ABCIterable ): other = cast ( Iterable [ _OutcomeT ], ( other ,)) return H ( chain ( self . items (), cast ( Iterable , other ))) counts ( self ) -> Iterator [ _CountT ] More descriptive synonym for the values method . Source code in dyce/h.py def counts ( self ) -> Iterator [ _CountT ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . values () data ( self , relative : bool = True , fill_items : _MappingT = None ) -> Iterator [ Tuple [ _OutcomeT , float ]] Synonym for distribution . The relative parameter is ignored. Deprecated This alias is deprecated and will be removed in a future version. Source code in dyce/h.py def data ( self , relative : bool = True , # pylint: disable=unused-argument fill_items : _MappingT = None , ) -> Iterator [ Tuple [ _OutcomeT , float ]]: r \"\"\" Synonym for [``distribution``][dyce.h.H.distribution]. The *relative* parameter is ignored. !!! warning \"Deprecated\" This alias is deprecated and will be removed in a future version. \"\"\" warnings . warn ( \"H.data is deprecated; use H.distribution\" , DeprecationWarning , ) return self . distribution ( fill_items ) data_xy ( self , fill_items : _MappingT = None ) -> Tuple [ Tuple [ _OutcomeT , ... ], Tuple [ float , ... ]] Synonym for distribution_xy . Deprecated This alias is deprecated and will be removed in a future version. Source code in dyce/h.py def data_xy ( self , fill_items : _MappingT = None , ) -> Tuple [ Tuple [ _OutcomeT , ... ], Tuple [ float , ... ]]: r \"\"\" Synonym for [``distribution_xy``][dyce.h.H.distribution_xy]. !!! warning \"Deprecated\" This alias is deprecated and will be removed in a future version. \"\"\" warnings . warn ( \"H.data_xy is deprecated; use H.distribution_xy\" , DeprecationWarning , ) return self . distribution_xy ( fill_items ) distribution ( self , fill_items : _MappingT = None ) -> Iterator [ Tuple [ _OutcomeT , float ]] Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: 1 2 >>> list ( H ( 6 ) . gt ( 3 ) . distribution ()) [( False , 0.5 ), ( True , 0.5 )] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes: 1 2 3 4 >>> list ( H ( 6 ) . gt ( 7 ) . distribution ()) [( False , 1.0 )] >>> list ( H ( 6 ) . gt ( 7 ) . distribution ( fill_items = { True : 0 , False : 0 })) [( False , 1.0 ), ( True , 0.0 )] Source code in dyce/h.py def distribution ( self , fill_items : _MappingT = None , ) -> Iterator [ Tuple [ _OutcomeT , float ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: ```python >>> list(H(6).gt(3).distribution()) [(False, 0.5), (True, 0.5)] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes: ```python >>> list(H(6).gt(7).distribution()) [(False, 1.0)] >>> list(H(6).gt(7).distribution(fill_items={True: 0, False: 0})) [(False, 1.0), (True, 0.0)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return (( outcome , count / total ) for outcome , count in sorted ( combined . items ())) distribution_xy ( self , fill_items : _MappingT = None ) -> Tuple [ Tuple [ _OutcomeT , ... ], Tuple [ float , ... ]] Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method : 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , 0.16666666 ), ( 2 , 0.16666666 ), ( 3 , 0.16666666 ), ( 4 , 0.16666666 ), ( 5 , 0.16666666 ), ( 6 , 0.16666666 )] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py def distribution_xy ( self , fill_items : _MappingT = None , ) -> Tuple [ Tuple [ _OutcomeT , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution]: ```python >>> list(H(6).distribution()) [(1, 0.16666666), (2, 0.16666666), (3, 0.16666666), (4, 0.16666666), (5, 0.16666666), (6, 0.16666666)] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" return cast ( Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]], tuple ( zip ( * self . distribution ( fill_items ))), ) eq ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.eq, other) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map method . Source code in dyce/h.py def eq ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.eq, other)``. ```python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_eq , other ) even ( self ) -> 'H' Equivalent to self.umap(lambda outcome: outcome % 2 == 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py def even ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 == 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_even ( outcome : _OutcomeT ) -> bool : if isinstance ( outcome , ( int , Integral )): return outcome % 2 == 0 else : raise TypeError ( \"not supported for outcomes of type {} \" . format ( type ( outcome ) . __name__ ) ) return self . umap ( is_even ) explode ( self , max_depth : int = 1 ) -> 'H' Shorthand for self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py def explode ( self , max_depth : int = 1 ) -> \"H\" : r \"\"\" Shorthand for ``self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth)``. ```python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , op_add , max_depth , ) faces ( self ) -> Iterator [ _OutcomeT ] Synonym for outcomes . Deprecated This alias is deprecated and will be removed in a future version. Source code in dyce/h.py def faces ( self ) -> Iterator [ _OutcomeT ]: r \"\"\" Synonym for [``outcomes``][dyce.h.H.outcomes]. !!! warning \"Deprecated\" This alias is deprecated and will be removed in a future version. \"\"\" warnings . warn ( \"H.faces is deprecated; use H.outcomes\" , DeprecationWarning , ) return self . outcomes () format ( self , fill_items : _MappingT = None , width : int = 88 , scaled : bool = False , tick : str = '#' , sep : str = ' \\n ' ) -> str Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( \" {:->65} \" . format ( \" 65 chars wide -->|\" )) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py def format ( self , fill_items : _MappingT = None , width : int = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ```python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ```python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``True``, horizontal bars are scaled to *width*: ```python >>> h = (2@H(6)).ge(7) >>> print(\"{:->65}\".format(\" 65 chars wide -->|\")) ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu = float ( self . mean ()) except TypeError : mu = self . mean () if width <= 0 : def parts (): yield f \"avg: { mu : .2f } \" for outcome , probability in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( parts ()) + \"}\" else : w = width - 15 def lines (): yield f \"avg | { mu : 7.2f } \" try : std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except TypeError : pass outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( lines ()) ge ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.ge, other) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map method . Source code in dyce/h.py def ge ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ge, other)``. ```python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ge , other ) gt ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.gt, other) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def gt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.gt, other)``. ```python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_gt , other ) items ( self ) D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py def items ( self ): return self . _h . items () keys ( self ) D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py def keys ( self ): return self . _h . keys () le ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.le, other) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def le ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.le, other)``. ```python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_le , other ) lowest_terms ( self ) -> 'H' Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )); df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d233445 = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d233445 H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d233445 . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py def lowest_terms ( self ) -> \"H\" : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ```python >>> df = H((-1, -1, 0, 0, 1, 1)); df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ```python >>> d233445 = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d233445 H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d233445.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return H ( self . _lowest_terms ()) lt ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.lt, other) : 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map method . Source code in dyce/h.py def lt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.lt, other)``: ```python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_lt , other ) map ( self , oper : _BinaryOperatorT , other : _OperandT ) -> 'H' Applies oper to each outcome of the histogram paired with other . Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . add , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . add , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . mul , - 1 ) H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 . map ( operator . mul , - 1 ) == d6 * - 1 True 1 2 3 4 >>> d6 . map ( operator . gt , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . gt , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py def map ( self , oper : _BinaryOperatorT , other : _OperandT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram paired with *other*. Shorthands exist for many arithmetic operators and comparators. ```python >>> import operator >>> d6 = H(6) >>> d6.map(operator.add, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.add, d6) == d6 + d6 True ``` ```python >>> d6.map(operator.mul, -1) H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> d6.map(operator.mul, -1) == d6 * -1 True ``` ```python >>> d6.map(operator.gt, 3) H({False: 3, True: 3}) >>> d6.map(operator.gt, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( other , HAbleT ): other = other . h () if isinstance ( other , ( int , float , Number )): return H (( oper ( outcome , other ), count ) for outcome , count in self . items ()) elif isinstance ( other , H ): return H (( oper ( s , o ), self [ s ] * other [ o ]) for s , o in product ( self , other )) else : raise NotImplementedError mean ( self ) -> float Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py def mean ( self ) -> float : \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 ) ne ( self , other : _OperandT ) -> 'H' Shorthand for self.map(operator.ne, other) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map method . Source code in dyce/h.py def ne ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ne, other)``. ```python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ne , other ) odd ( self ) -> 'H' Equivalent to self.umap(lambda outcome: outcome % 2 != 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py def odd ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 != 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_odd ( outcome : _OutcomeT ) -> bool : if isinstance ( outcome , ( int , Integral )): return outcome % 2 != 0 else : raise TypeError ( \"not supported for outcomes of type {} \" . format ( type ( outcome ) . __name__ ) ) return self . umap ( is_odd ) outcomes ( self ) -> Iterator [ _OutcomeT ] More descriptive synonym for the keys method . Source code in dyce/h.py def outcomes ( self ) -> Iterator [ _OutcomeT ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . keys () roll ( self ) -> _OutcomeT Returns a (weighted) random outcome. Source code in dyce/h.py def roll ( self ) -> _OutcomeT : r \"\"\" Returns a (weighted) random outcome. \"\"\" val = randrange ( 0 , sum ( self . counts ())) total = 0 for outcome , count in self . items (): total += count if val < total : return outcome assert False , f \"val ( { val } ) \u2265 total ( { total } )\" stdev ( self , mu : float = None ) -> float Shorthand for math.sqrt(self.variance(mu)) . Source code in dyce/h.py def stdev ( self , mu : float = None ) -> float : \"\"\" Shorthand for ``math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu )) substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = None , max_depth : int = 1 ) -> 'H' Calls expand on each outcome, recursively up to max_depth times. If expand returns a number, it replaces the outcome. If it returns an H object , coalesce is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the lowest_terms method .) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: 1 2 3 4 5 6 7 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , outcome : - h if outcome == 4 else outcome ) ; sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( count for outcome , count in orig . items () if outcome == 4 ) / sum ( orig . counts ()) 0.4 >>> sum ( count for outcome , count in sub . items () if outcome < 0 ) / sum ( sub . counts ()) 0.4 An important exception If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: 1 2 >>> H ( 6 ) . substitute ( lambda h , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda h , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . add , max_depth = 6 ) >>> h_even = h . even () >>> print ( \" {:.3%} \" . format ( h_even [ 1 ] / sum ( h_even . counts ()))) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | Source code in dyce/h.py def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = None , max_depth : int = 1 , ) -> \"H\" : r \"\"\" Calls *expand* on each outcome, recursively up to *max_depth* times. If *expand* returns a number, it replaces the outcome. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the [``lowest_terms`` method][dyce.h.H.lowest_terms].) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ```python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: ```python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, outcome: -h if outcome == 4 else outcome) ; sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(count for outcome, count in orig.items() if outcome == 4) / sum(orig.counts()) 0.4 >>> sum(count for outcome, count in sub.items() if outcome < 0) / sum(sub.counts()) 0.4 ``` !!! tip \"An important exception\" If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: ```python >>> H(6).substitute(lambda h, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda h, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ```python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.add, max_depth=6) >>> h_even = h.even() >>> print(\"{:.3%}\".format(h_even[1] / sum(h_even.counts()))) 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: ```python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=65, scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` \"\"\" if coalesce is None : coalesce = _coalesce_replace def _substitute ( h : H , depth : int = 0 ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ _OutcomeT , _CountT , _CountT ]] = [] for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , outcome ) # Account for the impact of expansion on peers expanded_scalar = sum ( expanded . counts ()) if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) else : items_for_reassembly . append (( expanded , count , 1 )) return H ( ( # Apply the total_scalar, but factor out this item's contribution ( outcome , count * total_scalar // s ) for outcome , count , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self ) umap ( self , oper : _UnaryOperatorT ) -> 'H' Applies oper to each outcome of the histogram: 1 2 >>> H ( 6 ) . umap ( lambda outcome : outcome * - 1 ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py def umap ( self , oper : _UnaryOperatorT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram: ```python >>> H(6).umap(lambda outcome: outcome * -1) H(-6) ``` ```python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = H (( oper ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : h_simple = H ( type ( self . _simple_init )( oper ( self . _simple_init ))) if h_simple == h : return h_simple return h values ( self ) D.values() -> an object providing a view on D's values Source code in dyce/h.py def values ( self ): return self . _h . values () variance ( self , mu : float = None ) -> float Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py def variance ( self , mu : float = None ) -> float : \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 ) vs ( self , other : _OperandT ) -> 'H' Compares this histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self.within(0, 0, other) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py def vs ( self , other : _OperandT ) -> \"H\" : r \"\"\" Compares this histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``self.within(0, 0, other)``. ```python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other ) within ( self , lo : _OutcomeT , hi : _OutcomeT , other : _OperandT = 0 ) -> 'H' Computes the difference between this histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py def within ( self , lo : _OutcomeT , hi : _OutcomeT , other : _OperandT = 0 ) -> \"H\" : r \"\"\" Computes the difference between this histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ```python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other ) P An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). This class implements the HAbleT protocol and derives from the HAbleBinOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using binary arithmetic operations. Note that this class also provides its own @ and unary operator implementations that result in new P objects, not flattened histograms. 1 2 3 4 5 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) >>> - p_d6 P ( - 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True Arithmetic operators involving a number or another P object produce an H object : 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) Comparisons with H objects work as expected: 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram: 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering: 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HAbleT protocol , the P.h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ### __init__ ( self , * args : Union [ int , 'P' , H ]) -> None special Initializer. Source code in dyce/p.py def __init__ ( self , * args : Union [ int , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs (): for a in args : if isinstance ( a , ( int , Integral )): yield H ( a ) elif isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : # pylint: disable=protected-access yield h else : raise TypeError ( \"type {} incompatible initializer for {} \" . format ( type ( a ), type ( self ) ) ) hs = list ( h for h in _gen_hs () if h ) hs . sort ( key = lambda h : tuple ( h . items ())) self . _hs = tuple ( hs ) self . _homogeneous = len ( set ( self . _hs )) <= 1 appearances_in_rolls ( self , outcome : _OutcomeT ) -> H Experimental This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being almost twice (about \\(\\frac{7}{4}\\) ) as efficient as the boolean accumulation technique for larger sets: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 In [ 3 ]: % timeit 3 @d4_eq3 + 2 @d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 4 ]: % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 402 \u00b5s \u00b1 5.59 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 5 ]: % timeit 9 @d4_eq3 + 6 @d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 6 ]: % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 597 \u00b5s \u00b1 9.46 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 7 ]: % timeit 90 @d4_eq3 + 60 @d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 8 ]: % timeit P ( 90 @P ( 4 ), 60 @P ( 6 )) . appearances_in_rolls ( 3 ) 7.5 ms \u00b1 84.6 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) In [ 9 ]: % timeit 900 @d4_eq3 + 600 @d6_eq3 3.34 s \u00b1 19.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 10 ]: % timeit P ( 900 @P ( 4 ), 600 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.93 s \u00b1 14.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def appearances_in_rolls ( self , outcome : _OutcomeT ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ```python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ```python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being almost twice (about $\\frac{7}{4}$) as efficient as the boolean accumulation technique for larger sets: ```python In [3]: %timeit 3@d4_eq3 + 2@d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [4]: %timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3) 402 \u00b5s \u00b1 5.59 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [5]: %timeit 9@d4_eq3 + 6@d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [6]: %timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3) 597 \u00b5s \u00b1 9.46 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [7]: %timeit 90@d4_eq3 + 60@d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [8]: %timeit P(90@P(4), 60@P(6)).appearances_in_rolls(3) 7.5 ms \u00b1 84.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) In [9]: %timeit 900@d4_eq3 + 600@d6_eq3 3.34 s \u00b1 19.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [10]: %timeit P(900@P(4), 600@P(6)).appearances_in_rolls(3) 1.93 s \u00b1 14.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" group_counters : List [ Counter [ _OutcomeT ]] = [] for h , hs in groupby ( self . _hs ): group_counter : Counter [ _OutcomeT ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = _count_of_exactly_k_of_outcome_in_n_of_h ( h , outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_w_start ( ( H ( group_counter ) for group_counter in group_counters ), start = H ({}) ) eq ( self , other : _OperandT ) -> H Shorthand for self.h().eq(other) . See the h method and H.eq . Source code in dyce/p.py def eq ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().eq(other)``. See the [``h`` method][dyce.p.P.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other ) even ( self ) -> H Shorthand for self.h().even() . See the h method and H.even . Source code in dyce/p.py def even ( self ) -> H : r \"\"\" Shorthand for ``self.h().even()``. See the [``h`` method][dyce.p.P.h] and [``H.even``][dyce.h.H.even]. \"\"\" return self . h () . even () explode ( self , max_depth : int = 1 ) -> H Shorthand for self.h().explode(max_depth) . See the h method and H.explode . Source code in dyce/p.py def explode ( self , max_depth : int = 1 ) -> H : r \"\"\" Shorthand for ``self.h().explode(max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth ) ge ( self , other : _OperandT ) -> H Shorthand for self.h().ge(other) . See the h method and H.ge . Source code in dyce/p.py def ge ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ge(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other ) gt ( self , other : _OperandT ) -> H Shorthand for self.h().gt(other) . See the h method and H.gt . Source code in dyce/p.py def gt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().gt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other ) h ( self , * which : _GetItemT ) -> H Roughly equivalent to H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) ) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HAbleT protocol : 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( width = 65 , scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d233445 ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d233445 + d233445 True Source code in dyce/p.py def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) )`` with some short-circuit optimizations. When provided no arguments, ``h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HAbleT`` protocol][dyce.h.HAbleT]: ```python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ```python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ```python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(width=65, scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d233445) >>> p.h(slice(None)) == p.h() == d6 + d6 + d233445 + d233445 True ``` \"\"\" if which : n = len ( self . _hs ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * i // n else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_w_start ( self . _hs , start = H ({})) le ( self , other : _OperandT ) -> H Shorthand for self.h().le(other) . See the h method and H.le . Source code in dyce/p.py def le ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().le(other)``. See the [``h`` method][dyce.p.P.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other ) lt ( self , other : _OperandT ) -> H Shorthand for self.h().lt(other) . See the h method and H.lt . Source code in dyce/p.py def lt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().lt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other ) ne ( self , other : _OperandT ) -> H Shorthand for self.h().ne(other) . See the h method and H.ne . Source code in dyce/p.py def ne ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ne(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other ) odd ( self ) -> H Shorthand for self.h().odd() . See the h method and H.odd . Source code in dyce/p.py def odd ( self ) -> H : r \"\"\" Shorthand for ``self.h().odd()``. See the [``h`` method][dyce.p.P.h] and [``H.odd``][dyce.h.H.odd]. \"\"\" return self . h () . odd () roll ( self ) -> _RollT Returns (weighted) random outcomes from contained histograms. Source code in dyce/p.py def roll ( self ) -> _RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. \"\"\" return tuple ( h . roll () for h in self . _hs ) rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ] Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, (1, 2) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d233445 ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d233445 + d233445 True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable: 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted: 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) : \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n@P(H(m)) . Enumerating combinations with replacements would yield all unique rolls: ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m)) To determine the count for a particular roll (a, b, \u2026, n) , we compute the multinomial coefficient for that roll and multiply by the scalar H(m)[a] * H(m)[b] * \u2026 * H(m)[n] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 In [ 1 ]: from dyce import H , P In [ 2 ]: for n in ( 6 , 8 ): ... : p = n @P ( 6 ) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 1.35 ms \u00b1 23.4 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 3.15 ms \u00b1 516 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.37 ms \u00b1 182 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 10.5 ms \u00b1 1.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.58 ms \u00b1 25.3 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 9.81 ms \u00b1 171 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 14.7 ms \u00b1 430 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 20.4 ms \u00b1 328 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 3 ]: for n in ( 3 , 4 ): ... : p = P ( n @P ( 6 ), * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 2 )): 16.1 ms \u00b1 1.09 ms per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 3 )): 39 ms \u00b1 602 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 4 )): 40.3 ms \u00b1 3.49 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 5 )): 46.2 ms \u00b1 7.43 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 538 ms \u00b1 9.46 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 534 ms \u00b1 30.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 536 ms \u00b1 13.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 604 ms \u00b1 52.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 4 ]: for n in ( 6 , 8 ): ... : p = P ( * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 2 )): 145 ms \u00b1 4.59 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 3 )): 147 ms \u00b1 3.6 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 158 ms \u00b1 1.38 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 147 ms \u00b1 691 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 6.09 s \u00b1 14.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 6.11 s \u00b1 36.9 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 6 )): 6.25 s \u00b1 47.5 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 7 )): 6.31 s \u00b1 42.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed for more flexible selections: ```python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: ```python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ```python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, `(1, 2)` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ```python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity: ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d233445) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d233445 + d233445 True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: ```python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable: ```python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted: ```python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ```python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$: $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls: ``((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``(a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ```ipython In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" n = len ( self . _hs ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self . _hs )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( _getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = None , max_depth : int = 1 ) -> H Shorthand for self.h().substitute(expand, coalesce, max_depth) . See the h method and H.substitute . Source code in dyce/p.py def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = None , max_depth : int = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth ) within ( self , lo : _OutcomeT , hi : _OutcomeT , other : _OperandT = 0 ) -> H Shorthand for self.h().within(lo, hi, other) . See the h method and H.within . Source code in dyce/p.py def within ( self , lo : _OutcomeT , hi : _OutcomeT , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``self.h().within(lo, hi, other)``. See the [``h`` method][dyce.p.P.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other ) HAbleT A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users. h ( self ) -> H Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ... HAbleBinOpsMixin A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HAbleT protocol . The P class derives from this class. __add__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.add(self.h(), other) . Source code in dyce/h.py def __add__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.add(self.h(), other)``. \"\"\" return op_add ( self . h (), other ) __and__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.and_(self.h(), other) . Source code in dyce/h.py def __and__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.and_(self.h(), other)``. \"\"\" return op_and ( self . h (), other ) __floordiv__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.floordiv(self.h(), other) . Source code in dyce/h.py def __floordiv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.floordiv(self.h(), other)``. \"\"\" return op_floordiv ( self . h (), other ) __mod__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.mod(self.h(), other) . Source code in dyce/h.py def __mod__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mod(self.h(), other)``. \"\"\" return op_mod ( self . h (), other ) __mul__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.mul(self.h(), other) . Source code in dyce/h.py def __mul__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mul(self.h(), other)``. \"\"\" return op_mul ( self . h (), other ) __or__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.or_(self.h(), other) . Source code in dyce/h.py def __or__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.or_(self.h(), other)``. \"\"\" return op_or ( self . h (), other ) __pow__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.pow(self.h(), other) . Source code in dyce/h.py def __pow__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.pow(self.h(), other)``. \"\"\" return op_pow ( self . h (), other ) __radd__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.add(other, self.h()) . Source code in dyce/h.py def __radd__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.add(other, self.h())``. \"\"\" return op_add ( other , self . h ()) __rand__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.and_(other, self.h()) . Source code in dyce/h.py def __rand__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.and_(other, self.h())``. \"\"\" return op_and ( other , self . h ()) __rfloordiv__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.floordiv(other, self.h()) . Source code in dyce/h.py def __rfloordiv__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.floordiv(other, self.h())``. \"\"\" return op_floordiv ( other , self . h ()) __rmod__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.mod(other, self.h()) . Source code in dyce/h.py def __rmod__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.mod(other, self.h())``. \"\"\" return op_mod ( other , self . h ()) __rmul__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.mul(other, self.h()) . Source code in dyce/h.py def __rmul__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.mul(other, self.h())``. \"\"\" return op_mul ( other , self . h ()) __ror__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.or_(other, self.h()) . Source code in dyce/h.py def __ror__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.or_(other, self.h())``. \"\"\" return op_or ( other , self . h ()) __rpow__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.pow(other, self.h()) . Source code in dyce/h.py def __rpow__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.pow(other, self.h())``. \"\"\" return op_pow ( other , self . h ()) __rsub__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.sub(other, self.h()) . Source code in dyce/h.py def __rsub__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.sub(other, self.h())``. \"\"\" return op_sub ( other , self . h ()) __rtruediv__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.truediv(other, self.h()) . Source code in dyce/h.py def __rtruediv__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.truediv(other, self.h())``. \"\"\" return op_truediv ( other , self . h ()) __rxor__ ( self : HAbleT , other : _OutcomeT ) -> H special Shorthand for operator.xor(other, self.h()) . Source code in dyce/h.py def __rxor__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.xor(other, self.h())``. \"\"\" return op_xor ( other , self . h ()) __sub__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.sub(self.h(), other) . Source code in dyce/h.py def __sub__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.sub(self.h(), other)``. \"\"\" return op_sub ( self . h (), other ) __truediv__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.truediv(self.h(), other) . Source code in dyce/h.py def __truediv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.truediv(self.h(), other)``. \"\"\" return op_truediv ( self . h (), other ) __xor__ ( self : HAbleT , other : _OperandT ) -> H special Shorthand for operator.xor(self.h(), other) . Source code in dyce/h.py def __xor__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.xor(self.h(), other)``. \"\"\" return op_xor ( self . h (), other )","title":"<tt>dyce</tt>"},{"location":"dyce/#dyce-package-reference","text":"","title":"dyce package reference"},{"location":"dyce/#dyce","text":"dyce provides two core primitives: H for histograms (outcomes or individual dice) P for collections of histograms (pools)","title":"dyce"},{"location":"dyce/#dyce.h.H","text":"An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, it is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derives, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ): 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed: 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative): 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps: 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes: 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand: 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes: 1 2 >>> len ( 2 @d6 ) 11 The counts method can be used to compute the total number of combinations and each outcome\u2019s probability: 1 2 3 4 5 >>> from fractions import Fraction >>> total = sum (( 2 @d6 ) . counts ()) ; total 36 >>> [( outcome , Fraction ( count , total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ); d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [\u2026] : 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method : 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands: 1 2 >>> d6 . accumulate ( d6 ) == d6 . accumulate ( d6 ) . accumulate ( d6 ) True","title":"H"},{"location":"dyce/#dyce.h.H.__hash__","text":"Return hash(self). Source code in dyce/h.py def __hash__ ( self ) -> int : return hash ( tuple ( self . _lowest_terms ()))","title":"__hash__()"},{"location":"dyce/#dyce.h.H.__init__","text":"Initializer. Source code in dyce/h.py def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init = None tmp : Counter [ _OutcomeT ] = counter () if isinstance ( items , ( int , Integral )): if items != 0 : self . _simple_init = items outcome_type = type ( items ) count_1 = type ( items )( 1 ) outcome_range = range ( items , 0 , 1 if items < 0 else - 1 # count toward zero ) tmp . update ({ outcome_type ( i ): count_1 for i in outcome_range }) elif isinstance ( items , HAbleT ): tmp . update ( items . h ()) elif isinstance ( items , ABCMapping ): tmp . update ( items ) elif isinstance ( items , ABCIterable ): # Items is either an Iterable[_OutcomeT] or an Iterable[Tuple[_OutcomeT, # _CountT]] (although this technically supports Iterable[Union[_OutcomeT, # Tuple[_OutcomeT, _CountT]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += count else : tmp [ item ] += 1 else : raise ValueError ( \"unrecognized initializer {} \" . format ( type ( items ))) # Sort and omit zero counts. We use an OrderedDict instead of a Counter to # support Python versions earlier than 3.7 which did not guarantee order # preservation for the latter. self . _h : _MappingT = ordereddict ( { outcome : tmp [ outcome ] for outcome in sorted ( tmp ) if tmp [ outcome ]} )","title":"__init__()"},{"location":"dyce/#dyce.h.H.accumulate","text":"Accumulates counts: 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py def accumulate ( self , other : _SourceT ) -> \"H\" : r \"\"\" Accumulates counts: ```python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , ABCMapping ): other = other . items () elif not isinstance ( other , ABCIterable ): other = cast ( Iterable [ _OutcomeT ], ( other ,)) return H ( chain ( self . items (), cast ( Iterable , other )))","title":"accumulate()"},{"location":"dyce/#dyce.h.H.counts","text":"More descriptive synonym for the values method . Source code in dyce/h.py def counts ( self ) -> Iterator [ _CountT ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . values ()","title":"counts()"},{"location":"dyce/#dyce.h.H.data","text":"Synonym for distribution . The relative parameter is ignored. Deprecated This alias is deprecated and will be removed in a future version. Source code in dyce/h.py def data ( self , relative : bool = True , # pylint: disable=unused-argument fill_items : _MappingT = None , ) -> Iterator [ Tuple [ _OutcomeT , float ]]: r \"\"\" Synonym for [``distribution``][dyce.h.H.distribution]. The *relative* parameter is ignored. !!! warning \"Deprecated\" This alias is deprecated and will be removed in a future version. \"\"\" warnings . warn ( \"H.data is deprecated; use H.distribution\" , DeprecationWarning , ) return self . distribution ( fill_items )","title":"data()"},{"location":"dyce/#dyce.h.H.data_xy","text":"Synonym for distribution_xy . Deprecated This alias is deprecated and will be removed in a future version. Source code in dyce/h.py def data_xy ( self , fill_items : _MappingT = None , ) -> Tuple [ Tuple [ _OutcomeT , ... ], Tuple [ float , ... ]]: r \"\"\" Synonym for [``distribution_xy``][dyce.h.H.distribution_xy]. !!! warning \"Deprecated\" This alias is deprecated and will be removed in a future version. \"\"\" warnings . warn ( \"H.data_xy is deprecated; use H.distribution_xy\" , DeprecationWarning , ) return self . distribution_xy ( fill_items )","title":"data_xy()"},{"location":"dyce/#dyce.h.H.distribution","text":"Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: 1 2 >>> list ( H ( 6 ) . gt ( 3 ) . distribution ()) [( False , 0.5 ), ( True , 0.5 )] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes: 1 2 3 4 >>> list ( H ( 6 ) . gt ( 7 ) . distribution ()) [( False , 1.0 )] >>> list ( H ( 6 ) . gt ( 7 ) . distribution ( fill_items = { True : 0 , False : 0 })) [( False , 1.0 ), ( True , 0.0 )] Source code in dyce/h.py def distribution ( self , fill_items : _MappingT = None , ) -> Iterator [ Tuple [ _OutcomeT , float ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair: ```python >>> list(H(6).gt(3).distribution()) [(False, 0.5), (True, 0.5)] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes: ```python >>> list(H(6).gt(7).distribution()) [(False, 1.0)] >>> list(H(6).gt(7).distribution(fill_items={True: 0, False: 0})) [(False, 1.0), (True, 0.0)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return (( outcome , count / total ) for outcome , count in sorted ( combined . items ()))","title":"distribution()"},{"location":"dyce/#dyce.h.H.distribution_xy","text":"Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method : 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , 0.16666666 ), ( 2 , 0.16666666 ), ( 3 , 0.16666666 ), ( 4 , 0.16666666 ), ( 5 , 0.16666666 ), ( 6 , 0.16666666 )] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py def distribution_xy ( self , fill_items : _MappingT = None , ) -> Tuple [ Tuple [ _OutcomeT , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution]: ```python >>> list(H(6).distribution()) [(1, 0.16666666), (2, 0.16666666), (3, 0.16666666), (4, 0.16666666), (5, 0.16666666), (6, 0.16666666)] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" return cast ( Tuple [ Tuple [ int , ... ], Tuple [ float , ... ]], tuple ( zip ( * self . distribution ( fill_items ))), )","title":"distribution_xy()"},{"location":"dyce/#dyce.h.H.eq","text":"Shorthand for self.map(operator.eq, other) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map method . Source code in dyce/h.py def eq ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.eq, other)``. ```python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_eq , other )","title":"eq()"},{"location":"dyce/#dyce.h.H.even","text":"Equivalent to self.umap(lambda outcome: outcome % 2 == 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py def even ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 == 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_even ( outcome : _OutcomeT ) -> bool : if isinstance ( outcome , ( int , Integral )): return outcome % 2 == 0 else : raise TypeError ( \"not supported for outcomes of type {} \" . format ( type ( outcome ) . __name__ ) ) return self . umap ( is_even )","title":"even()"},{"location":"dyce/#dyce.h.H.explode","text":"Shorthand for self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py def explode ( self , max_depth : int = 1 ) -> \"H\" : r \"\"\" Shorthand for ``self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.add, max_depth)``. ```python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , op_add , max_depth , )","title":"explode()"},{"location":"dyce/#dyce.h.H.faces","text":"Synonym for outcomes . Deprecated This alias is deprecated and will be removed in a future version. Source code in dyce/h.py def faces ( self ) -> Iterator [ _OutcomeT ]: r \"\"\" Synonym for [``outcomes``][dyce.h.H.outcomes]. !!! warning \"Deprecated\" This alias is deprecated and will be removed in a future version. \"\"\" warnings . warn ( \"H.faces is deprecated; use H.outcomes\" , DeprecationWarning , ) return self . outcomes ()","title":"faces()"},{"location":"dyce/#dyce.h.H.format","text":"Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( \" {:->65} \" . format ( \" 65 chars wide -->|\" )) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py def format ( self , fill_items : _MappingT = None , width : int = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ```python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ```python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``True``, horizontal bars are scaled to *width*: ```python >>> h = (2@H(6)).ge(7) >>> print(\"{:->65}\".format(\" 65 chars wide -->|\")) ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu = float ( self . mean ()) except TypeError : mu = self . mean () if width <= 0 : def parts (): yield f \"avg: { mu : .2f } \" for outcome , probability in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( parts ()) + \"}\" else : w = width - 15 def lines (): yield f \"avg | { mu : 7.2f } \" try : std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except TypeError : pass outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( lines ())","title":"format()"},{"location":"dyce/#dyce.h.H.ge","text":"Shorthand for self.map(operator.ge, other) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map method . Source code in dyce/h.py def ge ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ge, other)``. ```python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ge , other )","title":"ge()"},{"location":"dyce/#dyce.h.H.gt","text":"Shorthand for self.map(operator.gt, other) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def gt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.gt, other)``. ```python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_gt , other )","title":"gt()"},{"location":"dyce/#dyce.h.H.items","text":"D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py def items ( self ): return self . _h . items ()","title":"items()"},{"location":"dyce/#dyce.h.H.keys","text":"D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py def keys ( self ): return self . _h . keys ()","title":"keys()"},{"location":"dyce/#dyce.h.H.le","text":"Shorthand for self.map(operator.le, other) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map method . Source code in dyce/h.py def le ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.le, other)``. ```python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_le , other )","title":"le()"},{"location":"dyce/#dyce.h.H.lowest_terms","text":"Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )); df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d233445 = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d233445 H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d233445 . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py def lowest_terms ( self ) -> \"H\" : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ```python >>> df = H((-1, -1, 0, 0, 1, 1)); df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ```python >>> d233445 = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d233445 H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d233445.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return H ( self . _lowest_terms ())","title":"lowest_terms()"},{"location":"dyce/#dyce.h.H.lt","text":"Shorthand for self.map(operator.lt, other) : 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map method . Source code in dyce/h.py def lt ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.lt, other)``: ```python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_lt , other )","title":"lt()"},{"location":"dyce/#dyce.h.H.map","text":"Applies oper to each outcome of the histogram paired with other . Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . add , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . add , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . mul , - 1 ) H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 . map ( operator . mul , - 1 ) == d6 * - 1 True 1 2 3 4 >>> d6 . map ( operator . gt , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . gt , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py def map ( self , oper : _BinaryOperatorT , other : _OperandT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram paired with *other*. Shorthands exist for many arithmetic operators and comparators. ```python >>> import operator >>> d6 = H(6) >>> d6.map(operator.add, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.add, d6) == d6 + d6 True ``` ```python >>> d6.map(operator.mul, -1) H({-6: 1, -5: 1, -4: 1, -3: 1, -2: 1, -1: 1}) >>> d6.map(operator.mul, -1) == d6 * -1 True ``` ```python >>> d6.map(operator.gt, 3) H({False: 3, True: 3}) >>> d6.map(operator.gt, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( other , HAbleT ): other = other . h () if isinstance ( other , ( int , float , Number )): return H (( oper ( outcome , other ), count ) for outcome , count in self . items ()) elif isinstance ( other , H ): return H (( oper ( s , o ), self [ s ] * other [ o ]) for s , o in product ( self , other )) else : raise NotImplementedError","title":"map()"},{"location":"dyce/#dyce.h.H.mean","text":"Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py def mean ( self ) -> float : \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 )","title":"mean()"},{"location":"dyce/#dyce.h.H.ne","text":"Shorthand for self.map(operator.ne, other) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map method . Source code in dyce/h.py def ne ( self , other : _OperandT ) -> \"H\" : r \"\"\" Shorthand for ``self.map(operator.ne, other)``. ```python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map`` method][dyce.h.H.map]. \"\"\" return self . map ( op_ne , other )","title":"ne()"},{"location":"dyce/#dyce.h.H.odd","text":"Equivalent to self.umap(lambda outcome: outcome % 2 != 0) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py def odd ( self ) -> \"H\" : r \"\"\" Equivalent to ``self.umap(lambda outcome: outcome % 2 != 0)``. ```python >>> H((-4, -2, 0, 1, 2, 3)).odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" def is_odd ( outcome : _OutcomeT ) -> bool : if isinstance ( outcome , ( int , Integral )): return outcome % 2 != 0 else : raise TypeError ( \"not supported for outcomes of type {} \" . format ( type ( outcome ) . __name__ ) ) return self . umap ( is_odd )","title":"odd()"},{"location":"dyce/#dyce.h.H.outcomes","text":"More descriptive synonym for the keys method . Source code in dyce/h.py def outcomes ( self ) -> Iterator [ _OutcomeT ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" return self . keys ()","title":"outcomes()"},{"location":"dyce/#dyce.h.H.roll","text":"Returns a (weighted) random outcome. Source code in dyce/h.py def roll ( self ) -> _OutcomeT : r \"\"\" Returns a (weighted) random outcome. \"\"\" val = randrange ( 0 , sum ( self . counts ())) total = 0 for outcome , count in self . items (): total += count if val < total : return outcome assert False , f \"val ( { val } ) \u2265 total ( { total } )\"","title":"roll()"},{"location":"dyce/#dyce.h.H.stdev","text":"Shorthand for math.sqrt(self.variance(mu)) . Source code in dyce/h.py def stdev ( self , mu : float = None ) -> float : \"\"\" Shorthand for ``math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu ))","title":"stdev()"},{"location":"dyce/#dyce.h.H.substitute","text":"Calls expand on each outcome, recursively up to max_depth times. If expand returns a number, it replaces the outcome. If it returns an H object , coalesce is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the lowest_terms method .) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: 1 2 3 4 5 6 7 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , outcome : - h if outcome == 4 else outcome ) ; sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( count for outcome , count in orig . items () if outcome == 4 ) / sum ( orig . counts ()) 0.4 >>> sum ( count for outcome , count in sub . items () if outcome < 0 ) / sum ( sub . counts ()) 0.4 An important exception If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: 1 2 >>> H ( 6 ) . substitute ( lambda h , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda h , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . add , max_depth = 6 ) >>> h_even = h . even () >>> print ( \" {:.3%} \" . format ( h_even [ 1 ] / sum ( h_even . counts ()))) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | Source code in dyce/h.py def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = None , max_depth : int = 1 , ) -> \"H\" : r \"\"\" Calls *expand* on each outcome, recursively up to *max_depth* times. If *expand* returns a number, it replaces the outcome. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. (See the [``lowest_terms`` method][dyce.h.H.lowest_terms].) This can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ```python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution: ```python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, outcome: -h if outcome == 4 else outcome) ; sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(count for outcome, count in orig.items() if outcome == 4) / sum(orig.counts()) 0.4 >>> sum(count for outcome, count in sub.items() if outcome < 0) / sum(sub.counts()) 0.4 ``` !!! tip \"An important exception\" If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up: ```python >>> H(6).substitute(lambda h, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest: ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda h, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ```python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.add, max_depth=6) >>> h_even = h.even() >>> print(\"{:.3%}\".format(h_even[1] / sum(h_even.counts()))) 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games: ```python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=65, scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` \"\"\" if coalesce is None : coalesce = _coalesce_replace def _substitute ( h : H , depth : int = 0 ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ _OutcomeT , _CountT , _CountT ]] = [] for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , outcome ) # Account for the impact of expansion on peers expanded_scalar = sum ( expanded . counts ()) if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) else : items_for_reassembly . append (( expanded , count , 1 )) return H ( ( # Apply the total_scalar, but factor out this item's contribution ( outcome , count * total_scalar // s ) for outcome , count , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self )","title":"substitute()"},{"location":"dyce/#dyce.h.H.umap","text":"Applies oper to each outcome of the histogram: 1 2 >>> H ( 6 ) . umap ( lambda outcome : outcome * - 1 ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py def umap ( self , oper : _UnaryOperatorT ) -> \"H\" : r \"\"\" Applies *oper* to each outcome of the histogram: ```python >>> H(6).umap(lambda outcome: outcome * -1) H(-6) ``` ```python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = H (( oper ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : h_simple = H ( type ( self . _simple_init )( oper ( self . _simple_init ))) if h_simple == h : return h_simple return h","title":"umap()"},{"location":"dyce/#dyce.h.H.values","text":"D.values() -> an object providing a view on D's values Source code in dyce/h.py def values ( self ): return self . _h . values ()","title":"values()"},{"location":"dyce/#dyce.h.H.variance","text":"Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py def variance ( self , mu : float = None ) -> float : \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 )","title":"variance()"},{"location":"dyce/#dyce.h.H.vs","text":"Compares this histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self.within(0, 0, other) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py def vs ( self , other : _OperandT ) -> \"H\" : r \"\"\" Compares this histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``self.within(0, 0, other)``. ```python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other )","title":"vs()"},{"location":"dyce/#dyce.h.H.within","text":"Computes the difference between this histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py def within ( self , lo : _OutcomeT , hi : _OutcomeT , other : _OperandT = 0 ) -> \"H\" : r \"\"\" Computes the difference between this histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ```python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ```python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other )","title":"within()"},{"location":"dyce/#dyce.p.P","text":"An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). This class implements the HAbleT protocol and derives from the HAbleBinOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using binary arithmetic operations. Note that this class also provides its own @ and unary operator implementations that result in new P objects, not flattened histograms. 1 2 3 4 5 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) >>> - p_d6 P ( - 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True Arithmetic operators involving a number or another P object produce an H object : 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) Comparisons with H objects work as expected: 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram: 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering: 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HAbleT protocol , the P.h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ###","title":"P"},{"location":"dyce/#dyce.p.P.__init__","text":"Initializer. Source code in dyce/p.py def __init__ ( self , * args : Union [ int , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs (): for a in args : if isinstance ( a , ( int , Integral )): yield H ( a ) elif isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : # pylint: disable=protected-access yield h else : raise TypeError ( \"type {} incompatible initializer for {} \" . format ( type ( a ), type ( self ) ) ) hs = list ( h for h in _gen_hs () if h ) hs . sort ( key = lambda h : tuple ( h . items ())) self . _hs = tuple ( hs ) self . _homogeneous = len ( set ( self . _hs )) <= 1","title":"__init__()"},{"location":"dyce/#dyce.p.P.appearances_in_rolls","text":"Experimental This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being almost twice (about \\(\\frac{7}{4}\\) ) as efficient as the boolean accumulation technique for larger sets: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 In [ 3 ]: % timeit 3 @d4_eq3 + 2 @d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 4 ]: % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 402 \u00b5s \u00b1 5.59 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 5 ]: % timeit 9 @d4_eq3 + 6 @d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 6 ]: % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 597 \u00b5s \u00b1 9.46 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 7 ]: % timeit 90 @d4_eq3 + 60 @d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 8 ]: % timeit P ( 90 @P ( 4 ), 60 @P ( 6 )) . appearances_in_rolls ( 3 ) 7.5 ms \u00b1 84.6 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) In [ 9 ]: % timeit 900 @d4_eq3 + 600 @d6_eq3 3.34 s \u00b1 19.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 10 ]: % timeit P ( 900 @P ( 4 ), 600 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.93 s \u00b1 14.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def appearances_in_rolls ( self , outcome : _OutcomeT ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ```python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ```python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ```python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being almost twice (about $\\frac{7}{4}$) as efficient as the boolean accumulation technique for larger sets: ```python In [3]: %timeit 3@d4_eq3 + 2@d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [4]: %timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3) 402 \u00b5s \u00b1 5.59 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [5]: %timeit 9@d4_eq3 + 6@d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [6]: %timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3) 597 \u00b5s \u00b1 9.46 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [7]: %timeit 90@d4_eq3 + 60@d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [8]: %timeit P(90@P(4), 60@P(6)).appearances_in_rolls(3) 7.5 ms \u00b1 84.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) In [9]: %timeit 900@d4_eq3 + 600@d6_eq3 3.34 s \u00b1 19.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [10]: %timeit P(900@P(4), 600@P(6)).appearances_in_rolls(3) 1.93 s \u00b1 14.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" group_counters : List [ Counter [ _OutcomeT ]] = [] for h , hs in groupby ( self . _hs ): group_counter : Counter [ _OutcomeT ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = _count_of_exactly_k_of_outcome_in_n_of_h ( h , outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_w_start ( ( H ( group_counter ) for group_counter in group_counters ), start = H ({}) )","title":"appearances_in_rolls()"},{"location":"dyce/#dyce.p.P.eq","text":"Shorthand for self.h().eq(other) . See the h method and H.eq . Source code in dyce/p.py def eq ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().eq(other)``. See the [``h`` method][dyce.p.P.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other )","title":"eq()"},{"location":"dyce/#dyce.p.P.even","text":"Shorthand for self.h().even() . See the h method and H.even . Source code in dyce/p.py def even ( self ) -> H : r \"\"\" Shorthand for ``self.h().even()``. See the [``h`` method][dyce.p.P.h] and [``H.even``][dyce.h.H.even]. \"\"\" return self . h () . even ()","title":"even()"},{"location":"dyce/#dyce.p.P.explode","text":"Shorthand for self.h().explode(max_depth) . See the h method and H.explode . Source code in dyce/p.py def explode ( self , max_depth : int = 1 ) -> H : r \"\"\" Shorthand for ``self.h().explode(max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth )","title":"explode()"},{"location":"dyce/#dyce.p.P.ge","text":"Shorthand for self.h().ge(other) . See the h method and H.ge . Source code in dyce/p.py def ge ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ge(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other )","title":"ge()"},{"location":"dyce/#dyce.p.P.gt","text":"Shorthand for self.h().gt(other) . See the h method and H.gt . Source code in dyce/p.py def gt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().gt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other )","title":"gt()"},{"location":"dyce/#dyce.p.P.h","text":"Roughly equivalent to H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) ) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HAbleT protocol : 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( width = 65 , scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d233445 ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d233445 + d233445 True Source code in dyce/p.py def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``H( (sum(roll), count) for roll, count in self.rolls_with_counts(*which) )`` with some short-circuit optimizations. When provided no arguments, ``h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HAbleT`` protocol][dyce.h.HAbleT]: ```python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ```python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ```python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(width=65, scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d233445) >>> p.h(slice(None)) == p.h() == d6 + d6 + d233445 + d233445 True ``` \"\"\" if which : n = len ( self . _hs ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * i // n else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_w_start ( self . _hs , start = H ({}))","title":"h()"},{"location":"dyce/#dyce.p.P.le","text":"Shorthand for self.h().le(other) . See the h method and H.le . Source code in dyce/p.py def le ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().le(other)``. See the [``h`` method][dyce.p.P.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other )","title":"le()"},{"location":"dyce/#dyce.p.P.lt","text":"Shorthand for self.h().lt(other) . See the h method and H.lt . Source code in dyce/p.py def lt ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().lt(other)``. See the [``h`` method][dyce.p.P.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other )","title":"lt()"},{"location":"dyce/#dyce.p.P.ne","text":"Shorthand for self.h().ne(other) . See the h method and H.ne . Source code in dyce/p.py def ne ( self , other : _OperandT ) -> H : r \"\"\" Shorthand for ``self.h().ne(other)``. See the [``h`` method][dyce.p.P.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other )","title":"ne()"},{"location":"dyce/#dyce.p.P.odd","text":"Shorthand for self.h().odd() . See the h method and H.odd . Source code in dyce/p.py def odd ( self ) -> H : r \"\"\" Shorthand for ``self.h().odd()``. See the [``h`` method][dyce.p.P.h] and [``H.odd``][dyce.h.H.odd]. \"\"\" return self . h () . odd ()","title":"odd()"},{"location":"dyce/#dyce.p.P.roll","text":"Returns (weighted) random outcomes from contained histograms. Source code in dyce/p.py def roll ( self ) -> _RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. \"\"\" return tuple ( h . roll () for h in self . _hs )","title":"roll()"},{"location":"dyce/#dyce.p.P.rolls_with_counts","text":"Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index -1 or len(self) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, (1, 2) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity: 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d233445 = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d233445 ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d233445 + d233445 True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable: 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted: 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) : \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n@P(H(m)) . Enumerating combinations with replacements would yield all unique rolls: ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m)) To determine the count for a particular roll (a, b, \u2026, n) , we compute the multinomial coefficient for that roll and multiply by the scalar H(m)[a] * H(m)[b] * \u2026 * H(m)[n] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 In [ 1 ]: from dyce import H , P In [ 2 ]: for n in ( 6 , 8 ): ... : p = n @P ( 6 ) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 2 )): 1.35 ms \u00b1 23.4 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 3 )): 3.15 ms \u00b1 516 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.37 ms \u00b1 182 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 10.5 ms \u00b1 1.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 5.58 ms \u00b1 25.3 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 9.81 ms \u00b1 171 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 14.7 ms \u00b1 430 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( 6 , 6 , 6 , 6 , 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 20.4 ms \u00b1 328 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 3 ]: for n in ( 3 , 4 ): ... : p = P ( n @P ( 6 ), * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 2 )): 16.1 ms \u00b1 1.09 ms per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 3 )): 39 ms \u00b1 602 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 4 )): 40.3 ms \u00b1 3.49 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 2 : 1 , ... , 3 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 )) . h ( slice ( 5 )): 46.2 ms \u00b1 7.43 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 4 )): 538 ms \u00b1 9.46 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 5 )): 534 ms \u00b1 30.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 6 )): 536 ms \u00b1 13.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 3 : 1 , ... , 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }), 6 , 6 , 6 , 6 )) . h ( slice ( 7 )): 604 ms \u00b1 52.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 4 ]: for n in ( 6 , 8 ): ... : p = P ( * [ H ( 6 ) - m for m in range ( n , 0 , - 1 )]) ... : for i in range ( len ( p ) - 4 , len ( p )): ... : print ( f \"( { p } ).h(slice( { i } )):\" ) ... : % timeit p.h(slice(i)) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 2 )): 145 ms \u00b1 4.59 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 3 )): 147 ms \u00b1 3.6 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 158 ms \u00b1 1.38 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 5 : 1 , ... , 0 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 147 ms \u00b1 691 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 4 )): 6.09 s \u00b1 14.4 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 5 )): 6.11 s \u00b1 36.9 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 6 )): 6.25 s \u00b1 47.5 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) ( P ( H ({ - 7 : 1 , ... , - 2 : 1 }), ... , H ({ 0 : 1 , ... , 5 : 1 }))) . h ( slice ( 7 )): 6.31 s \u00b1 42.2 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``0``) to greatest (index ``-1`` or ``len(self) - 1``). Identifiers can be ``int``s or ``slice``s, and can be mixed for more flexible selections: ```python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same: ```python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ```python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, `(1, 2)` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ```python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity: ```python >>> d6 = H(6) >>> d233445 = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d233445) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d233445 + d233445 True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy: ```python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable: ```python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted: ```python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ```python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$: $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls: ``((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``(a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ```ipython In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" n = len ( self . _hs ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self . _hs )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( _getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count","title":"rolls_with_counts()"},{"location":"dyce/#dyce.p.P.substitute","text":"Shorthand for self.h().substitute(expand, coalesce, max_depth) . See the h method and H.substitute . Source code in dyce/p.py def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = None , max_depth : int = 1 , ) -> H : r \"\"\" Shorthand for ``self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.p.P.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth )","title":"substitute()"},{"location":"dyce/#dyce.p.P.within","text":"Shorthand for self.h().within(lo, hi, other) . See the h method and H.within . Source code in dyce/p.py def within ( self , lo : _OutcomeT , hi : _OutcomeT , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``self.h().within(lo, hi, other)``. See the [``h`` method][dyce.p.P.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"within()"},{"location":"dyce/#dyce.h.HAbleT","text":"A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users.","title":"HAbleT"},{"location":"dyce/#dyce.h.HAbleT.h","text":"Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ...","title":"h()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin","text":"A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HAbleT protocol . The P class derives from this class.","title":"HAbleBinOpsMixin"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__add__","text":"Shorthand for operator.add(self.h(), other) . Source code in dyce/h.py def __add__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.add(self.h(), other)``. \"\"\" return op_add ( self . h (), other )","title":"__add__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__and__","text":"Shorthand for operator.and_(self.h(), other) . Source code in dyce/h.py def __and__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.and_(self.h(), other)``. \"\"\" return op_and ( self . h (), other )","title":"__and__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__floordiv__","text":"Shorthand for operator.floordiv(self.h(), other) . Source code in dyce/h.py def __floordiv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.floordiv(self.h(), other)``. \"\"\" return op_floordiv ( self . h (), other )","title":"__floordiv__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__mod__","text":"Shorthand for operator.mod(self.h(), other) . Source code in dyce/h.py def __mod__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mod(self.h(), other)``. \"\"\" return op_mod ( self . h (), other )","title":"__mod__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__mul__","text":"Shorthand for operator.mul(self.h(), other) . Source code in dyce/h.py def __mul__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.mul(self.h(), other)``. \"\"\" return op_mul ( self . h (), other )","title":"__mul__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__or__","text":"Shorthand for operator.or_(self.h(), other) . Source code in dyce/h.py def __or__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.or_(self.h(), other)``. \"\"\" return op_or ( self . h (), other )","title":"__or__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__pow__","text":"Shorthand for operator.pow(self.h(), other) . Source code in dyce/h.py def __pow__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.pow(self.h(), other)``. \"\"\" return op_pow ( self . h (), other )","title":"__pow__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__radd__","text":"Shorthand for operator.add(other, self.h()) . Source code in dyce/h.py def __radd__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.add(other, self.h())``. \"\"\" return op_add ( other , self . h ())","title":"__radd__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rand__","text":"Shorthand for operator.and_(other, self.h()) . Source code in dyce/h.py def __rand__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.and_(other, self.h())``. \"\"\" return op_and ( other , self . h ())","title":"__rand__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rfloordiv__","text":"Shorthand for operator.floordiv(other, self.h()) . Source code in dyce/h.py def __rfloordiv__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.floordiv(other, self.h())``. \"\"\" return op_floordiv ( other , self . h ())","title":"__rfloordiv__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rmod__","text":"Shorthand for operator.mod(other, self.h()) . Source code in dyce/h.py def __rmod__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.mod(other, self.h())``. \"\"\" return op_mod ( other , self . h ())","title":"__rmod__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rmul__","text":"Shorthand for operator.mul(other, self.h()) . Source code in dyce/h.py def __rmul__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.mul(other, self.h())``. \"\"\" return op_mul ( other , self . h ())","title":"__rmul__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__ror__","text":"Shorthand for operator.or_(other, self.h()) . Source code in dyce/h.py def __ror__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.or_(other, self.h())``. \"\"\" return op_or ( other , self . h ())","title":"__ror__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rpow__","text":"Shorthand for operator.pow(other, self.h()) . Source code in dyce/h.py def __rpow__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.pow(other, self.h())``. \"\"\" return op_pow ( other , self . h ())","title":"__rpow__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rsub__","text":"Shorthand for operator.sub(other, self.h()) . Source code in dyce/h.py def __rsub__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.sub(other, self.h())``. \"\"\" return op_sub ( other , self . h ())","title":"__rsub__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rtruediv__","text":"Shorthand for operator.truediv(other, self.h()) . Source code in dyce/h.py def __rtruediv__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.truediv(other, self.h())``. \"\"\" return op_truediv ( other , self . h ())","title":"__rtruediv__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__rxor__","text":"Shorthand for operator.xor(other, self.h()) . Source code in dyce/h.py def __rxor__ ( self : HAbleT , other : _OutcomeT ) -> H : r \"\"\" Shorthand for ``operator.xor(other, self.h())``. \"\"\" return op_xor ( other , self . h ())","title":"__rxor__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__sub__","text":"Shorthand for operator.sub(self.h(), other) . Source code in dyce/h.py def __sub__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.sub(self.h(), other)``. \"\"\" return op_sub ( self . h (), other )","title":"__sub__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__truediv__","text":"Shorthand for operator.truediv(self.h(), other) . Source code in dyce/h.py def __truediv__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.truediv(self.h(), other)``. \"\"\" return op_truediv ( self . h (), other )","title":"__truediv__()"},{"location":"dyce/#dyce.h.HAbleBinOpsMixin.__xor__","text":"Shorthand for operator.xor(self.h(), other) . Source code in dyce/h.py def __xor__ ( self : HAbleT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``operator.xor(self.h(), other)``. \"\"\" return op_xor ( self . h (), other )","title":"__xor__()"},{"location":"dyce.plt/","text":"dyce.plt package reference Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Suggestions and contributions are welcome. plt display_burst ( ax : AxesT , h_inner : H , outer : Iterable [ LabelT ] = None , desc : str = None , graph_color : str = 'RdYlGn_r' , text_color : str = 'black' , alpha : float = 0.5 ) -> None Source code in dyce/plt.py def display_burst ( ax : AxesT , h_inner : H , outer : Iterable [ LabelT ] = None , desc : str = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : assert matplotlib if outer is None : outer = ( ( \" {:.2%} \" . format ( v ) if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . distribution () ) outer_labels , outer_values = list ( zip ( * outer )) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.2 , labeldistance = 1.2 , startangle = 90 , colors = graph_colors ( graph_color , outer_values , alpha ), wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 1 , labeldistance = 0.8 , startangle = 90 , colors = graph_colors ( graph_color , h_inner , alpha ), textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.4 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" ) labels_cumulative ( h : H ) -> Iterator [ LabelT ] Source code in dyce/plt.py def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: le_total , ge_total = 0.0 , 1.0 for outcome , probability in h . distribution (): le_total += probability if probability >= _HIDE_LIM : label = \" {} {:.2%} ; \u2265 {:.2%} ; \u2264 {:.2%} \" . format ( outcome , probability , le_total , ge_total ) else : label = \"\" ge_total -= probability yield ( label , probability ) plot_burst ( h_inner : H , outer : Iterable [ LabelT ] = None , desc : str = None , graph_color : str = 'RdYlGn_r' , text_color : str = 'black' , alpha : float = 0.5 ) -> Tuple [ FigureT , AxesT ] Source code in dyce/plt.py def plot_burst ( h_inner : H , outer : Iterable [ LabelT ] = None , desc : str = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ FigureT , AxesT ]: assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , graph_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"<tt>dyce.plt</tt>"},{"location":"dyce.plt/#dyceplt-package-reference","text":"Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Suggestions and contributions are welcome.","title":"dyce.plt package reference"},{"location":"dyce.plt/#dyce.plt","text":"","title":"plt"},{"location":"dyce.plt/#dyce.plt.display_burst","text":"Source code in dyce/plt.py def display_burst ( ax : AxesT , h_inner : H , outer : Iterable [ LabelT ] = None , desc : str = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : assert matplotlib if outer is None : outer = ( ( \" {:.2%} \" . format ( v ) if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . distribution () ) outer_labels , outer_values = list ( zip ( * outer )) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.2 , labeldistance = 1.2 , startangle = 90 , colors = graph_colors ( graph_color , outer_values , alpha ), wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 1 , labeldistance = 0.8 , startangle = 90 , colors = graph_colors ( graph_color , h_inner , alpha ), textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.4 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" )","title":"display_burst()"},{"location":"dyce.plt/#dyce.plt.labels_cumulative","text":"Source code in dyce/plt.py def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: le_total , ge_total = 0.0 , 1.0 for outcome , probability in h . distribution (): le_total += probability if probability >= _HIDE_LIM : label = \" {} {:.2%} ; \u2265 {:.2%} ; \u2264 {:.2%} \" . format ( outcome , probability , le_total , ge_total ) else : label = \"\" ge_total -= probability yield ( label , probability )","title":"labels_cumulative()"},{"location":"dyce.plt/#dyce.plt.plot_burst","text":"Source code in dyce/plt.py def plot_burst ( h_inner : H , outer : Iterable [ LabelT ] = None , desc : str = None , graph_color : str = DEFAULT_GRAPH_COLOR , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ FigureT , AxesT ]: assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , graph_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"plot_burst()"},{"location":"license/","text":"License & credits The MIT License (MIT) Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contributors The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub - @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"License"},{"location":"license/#license-credits","text":"","title":"License &amp; credits"},{"location":"license/#the-mit-license-mit","text":"Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"license/#contributors","text":"The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub - @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"Contributors"},{"location":"translations/","text":"The following examples and translations are intended to showcase dyce \u2019s flexibility. If you have exposure to another tool , they may also help with transition. Modeling \u201c The Probability of 4d6, Drop the Lowest, Reroll 1s \u201d 1 2 3 4 5 6 7 8 >>> from dyce import H , P >>> p_4d6 = 4 @P ( 6 ) >>> res1 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : H ( 6 ) if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res2 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H ( range ( 2 , 7 ))) >>> res3 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res1 . distribution_xy (), ... marker = \".\" , ... label = \"Discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res2 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll first 1; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res3 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll all 1s; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Comparing various take-three-of-4d6 methods\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translating one example from markbrockettrobson/python_dice Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: 1 2 3 4 5 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = damage_half_on_save . distribution_xy () >>> matplotlib . pyplot . plot ( outcomes , probabilities , marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Expected outcomes for attack with saving throw for half damage\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP An alternative using the H.substitute method : 1 2 3 4 5 6 >>> save_roll . substitute ( ... lambda h , outcome : ... burning_arch_damage // 2 if outcome >= 10 ... else burning_arch_damage ... ) == damage_half_on_save True More translations from markbrockettrobson/python_dice 1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_ = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_ . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> _ = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( _ . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> _ = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( _ . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % } Translations from LordSembor/DnDice Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { avg : 12.00 , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { avg : 13.33 , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * single_attack . distribution_xy (), ... marker = \".\" , ... label = \"Normal attack\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * great_weapon_fighting . distribution_xy (), ... marker = \".\" , ... label = \"\u201cGreat Weapon Fighting\u201d\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Comparing a normal attack to an enhanced one\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( _ : H , outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = advantage . substitute ( crit ) Example 2 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * normal_hit . distribution_xy (), ... marker = \".\" , ... label = \"Normal hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * critical_hit . distribution_xy (), ... marker = \".\" , ... label = \"Critical hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * advantage_weighted . distribution_xy (), ... marker = \".\" , ... label = \"Advantage-weighted\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling an advantage-weighted attack with critical hits\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c Roll and Keep in Anydice? \u201d Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: 1 2 3 4 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( * res . distribution_xy (), marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling taking the three highest of ten exploding d10s\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c How do I count the number of duplicates in anydice? \u201d Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 >>> def dupes ( p : P ): ... for roll , count in p . rolls_with_counts (): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... # Outcomes are ordered, so we only have to look at one neighbor ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... yield dupes , count >>> res = H ( dupes ( 8 @P ( 10 ))) . lowest_terms () Visualization: 1 2 3 4 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( * res . distribution_xy ()) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Chances of rolling $n$ duplicates in 8d10\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c Modelling [sic] opposed dice pools with a swap \u201d: Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> from itertools import product >>> def brawl ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... yield a_successes - b_successes , count_a * count_b >>> res = H ( brawl ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> def brawl_w_optional_swap ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... yield result , count_a * count_b >>> res = H ( brawl_w_optional_swap ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = H ( brawl_w_optional_swap ( 4 @P ( 6 ), 4 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Applications & translations"},{"location":"translations/#modeling-the-probability-of-4d6-drop-the-lowest-reroll-1s","text":"1 2 3 4 5 6 7 8 >>> from dyce import H , P >>> p_4d6 = 4 @P ( 6 ) >>> res1 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : H ( 6 ) if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res2 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H ( range ( 2 , 7 ))) >>> res3 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res1 . distribution_xy (), ... marker = \".\" , ... label = \"Discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res2 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll first 1; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res3 . distribution_xy (), ... marker = \".\" , ... label = \"Re-roll all 1s; discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Comparing various take-three-of-4d6 methods\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Modeling \u201cThe Probability of 4d6, Drop the Lowest, Reroll 1s\u201d"},{"location":"translations/#translating-one-example-from-markbrockettrobsonpython_dice","text":"Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: 1 2 3 4 5 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = damage_half_on_save . distribution_xy () >>> matplotlib . pyplot . plot ( outcomes , probabilities , marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Expected outcomes for attack with saving throw for half damage\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP An alternative using the H.substitute method : 1 2 3 4 5 6 >>> save_roll . substitute ( ... lambda h , outcome : ... burning_arch_damage // 2 if outcome >= 10 ... else burning_arch_damage ... ) == damage_half_on_save True","title":"Translating one example from markbrockettrobson/python_dice"},{"location":"translations/#more-translations-from-markbrockettrobsonpython_dice","text":"1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_ = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_ . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> _ = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( _ . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> _ = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( _ . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % }","title":"More translations from markbrockettrobson/python_dice"},{"location":"translations/#translations-from-lordsembordndice","text":"Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { avg : 12.00 , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { avg : 13.33 , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * single_attack . distribution_xy (), ... marker = \".\" , ... label = \"Normal attack\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * great_weapon_fighting . distribution_xy (), ... marker = \".\" , ... label = \"\u201cGreat Weapon Fighting\u201d\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Comparing a normal attack to an enhanced one\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( _ : H , outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = advantage . substitute ( crit ) Example 2 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * normal_hit . distribution_xy (), ... marker = \".\" , ... label = \"Normal hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * critical_hit . distribution_xy (), ... marker = \".\" , ... label = \"Critical hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * advantage_weighted . distribution_xy (), ... marker = \".\" , ... label = \"Advantage-weighted\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling an advantage-weighted attack with critical hits\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translations from LordSembor/DnDice"},{"location":"translations/#translation-of-the-accepted-answer-to-roll-and-keep-in-anydice","text":"Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: 1 2 3 4 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( * res . distribution_xy (), marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Modeling taking the three highest of ten exploding d10s\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translation of the accepted answer to \u201cRoll and Keep in Anydice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-how-do-i-count-the-number-of-duplicates-in-anydice","text":"Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 >>> def dupes ( p : P ): ... for roll , count in p . rolls_with_counts (): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... # Outcomes are ordered, so we only have to look at one neighbor ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... yield dupes , count >>> res = H ( dupes ( 8 @P ( 10 ))) . lowest_terms () Visualization: 1 2 3 4 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( * res . distribution_xy ()) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Chances of rolling $n$ duplicates in 8d10\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translation of the accepted answer to \u201cHow do I count the number of duplicates in anydice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-modelling-sic-opposed-dice-pools-with-a-swap","text":"Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> from itertools import product >>> def brawl ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... yield a_successes - b_successes , count_a * count_b >>> res = H ( brawl ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> def brawl_w_optional_swap ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... yield result , count_a * count_b >>> res = H ( brawl_w_optional_swap ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = H ( brawl_w_optional_swap ( 4 @P ( 6 ), 4 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Translation of the accepted answer to \u201cModelling [sic] opposed dice pools with a swap\u201d:"},{"location":"tutorial/","text":"Basic examples dyce provides two key primitives: 1 >>> from dyce import H , P H objects represent histograms for modeling discrete outcomes. They encode discrete probability distributions as integer counts without any denominator. P objects represent pools (ordered sequences) of histograms. A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H(n) is shorthand for explicitly enumerating outcomes \\([{{1} .. {n}}]\\) , each with a frequency of 1: 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P(n, ...) is shorthand for P(H(n), ...) . The above can be expressed more succinctly: 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case Sicherman dice ) can be compared to histograms: 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. One way to model the outcomes of subtracting the least of two six-sided dice from the greatest is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms: 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest (i.e., 0 , 1 , \u2026, -2 , -1 ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [\u2026] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Histograms provide rudimentary formatting for convenience: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable: 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool: 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 2 ] P ( 4 , 6 , 8 ) A brute-force way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( \" {: >2} d6: {: >6.2%} \" . format ( n , all_even [ 1 ] / sum ( all_even . counts ()))) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( \" {: >2} d6-exploding: {: >6.2%} \" . format ( n , at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()))) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 % Visualization H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 >>> outcomes , probabilities = ( 2 @H ( 6 )) . distribution_xy () >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Distribution for 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.plt provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ): 1 2 3 >>> from dyce.plt import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position: 1 2 3 4 5 6 7 8 >>> d20 = H ( 20 ) >>> fig , ax = plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), graph_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Advanced exercise \u2013 modeling Risis Risus and its many community-developed alternative rules are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from typing import List , Tuple >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names : List [ str ] = [] ... rows : List [ Tuple [ float , ... ]] = [] ... for us in range ( them , them + num_rows ): ... row_names . append ( \" {} d6 \u2026\" . format ( us )) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . distribution_xy ()[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( \"\u2026 vs {} d6\" . format ( them )) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... \" {:.0%} \" . format ( rows [ y ][ x ]), ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib.pyplot.show presents: We can even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> from typing import Callable , Dict , Tuple >>> def risus_combat_driver ( ... us : int , ... them : int , ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( \"cannot have negative numbers (us: {} , them: {} )\" . format ( us , them )) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... already_solved : Dict [ Tuple [ int , int ], H ] = {} ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in already_solved : return already_solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( _ : H , outcome ) -> H : ... if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die ... else : return H ({}) # ignore (immediately reroll) all ties ... ... already_solved [( us , them )] = this_round . substitute ( _next_round ) ... return already_solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } Using our risus_combat_driver from above, we can model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath rule for resolving ties ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional computation. This is for two reasons. First, dyce only provides mechanisms to approximate outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough. Second, with one narrow exception , dyce only provides a mechanism to substitute outcomes, not counts. Both of these limitations can be circumvented where distributions can be computed and encoded as histograms. For this mechanic, we can observe that a single six-sided die ( 1d6 ) has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes you can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue: 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem: \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{6}{10} = \\frac{3}{5} \\] Well, butter my butt and call me a biscuit! Math really is fun! \ud83e\uddc8 \ud83e\udd20 \ud83e\uddee As an aside, the Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 1 : 3 , 0 : 2 }) # 3 dubyas, 2 doughnuts >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } Further exploration Consider exploring the applications and translations for more examples, or jump right into the API .","title":"Tutorial"},{"location":"tutorial/#basic-examples","text":"dyce provides two key primitives: 1 >>> from dyce import H , P H objects represent histograms for modeling discrete outcomes. They encode discrete probability distributions as integer counts without any denominator. P objects represent pools (ordered sequences) of histograms. A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H(n) is shorthand for explicitly enumerating outcomes \\([{{1} .. {n}}]\\) , each with a frequency of 1: 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P(n, ...) is shorthand for P(H(n), ...) . The above can be expressed more succinctly: 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case Sicherman dice ) can be compared to histograms: 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. One way to model the outcomes of subtracting the least of two six-sided dice from the greatest is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms: 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest (i.e., 0 , 1 , \u2026, -2 , -1 ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [\u2026] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Histograms provide rudimentary formatting for convenience: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable: 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool: 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 2 ] P ( 4 , 6 , 8 ) A brute-force way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( \" {: >2} d6: {: >6.2%} \" . format ( n , all_even [ 1 ] / sum ( all_even . counts ()))) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( \" {: >2} d6-exploding: {: >6.2%} \" . format ( n , at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()))) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 %","title":"Basic examples"},{"location":"tutorial/#visualization","text":"H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib : 1 2 3 4 5 6 7 8 >>> outcomes , probabilities = ( 2 @H ( 6 )) . distribution_xy () >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Distribution for 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.plt provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ): 1 2 3 >>> from dyce.plt import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position: 1 2 3 4 5 6 7 8 >>> d20 = H ( 20 ) >>> fig , ax = plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), graph_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Visualization"},{"location":"tutorial/#advanced-exercise-modeling-risis","text":"Risus and its many community-developed alternative rules are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from typing import List , Tuple >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names : List [ str ] = [] ... rows : List [ Tuple [ float , ... ]] = [] ... for us in range ( them , them + num_rows ): ... row_names . append ( \" {} d6 \u2026\" . format ( us )) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . distribution_xy ()[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( \"\u2026 vs {} d6\" . format ( them )) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... \" {:.0%} \" . format ( rows [ y ][ x ]), ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib.pyplot.show presents: We can even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> from typing import Callable , Dict , Tuple >>> def risus_combat_driver ( ... us : int , ... them : int , ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( \"cannot have negative numbers (us: {} , them: {} )\" . format ( us , them )) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... already_solved : Dict [ Tuple [ int , int ], H ] = {} ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in already_solved : return already_solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( _ : H , outcome ) -> H : ... if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die ... else : return H ({}) # ignore (immediately reroll) all ties ... ... already_solved [( us , them )] = this_round . substitute ( _next_round ) ... return already_solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } Using our risus_combat_driver from above, we can model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath rule for resolving ties ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional computation. This is for two reasons. First, dyce only provides mechanisms to approximate outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough. Second, with one narrow exception , dyce only provides a mechanism to substitute outcomes, not counts. Both of these limitations can be circumvented where distributions can be computed and encoded as histograms. For this mechanic, we can observe that a single six-sided die ( 1d6 ) has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes you can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue: 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem: \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{6}{10} = \\frac{3}{5} \\] Well, butter my butt and call me a biscuit! Math really is fun! \ud83e\uddc8 \ud83e\udd20 \ud83e\uddee As an aside, the Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 1 : 3 , 0 : 2 }) # 3 dubyas, 2 doughnuts >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % }","title":"Advanced exercise \u2013 modeling Risis"},{"location":"tutorial/#further-exploration","text":"Consider exploring the applications and translations for more examples, or jump right into the API .","title":"Further exploration"}]}