{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Copyright and other protections apply. Please see the accompanying LICENSE file for rights and restrictions governing use of this software. All rights not expressly waived or licensed are reserved. If that file is missing or appears to be modified from its original, then please contact the author before viewing or using this software in any capacity. Now you\u2019re playing with \u2026 dyce \u2013 simple Python tools for exploring dice outcomes and other finite discrete probabilities \ud83d\udca5 Now 100% Bear-ified\u2122 ! \ud83d\udc4c\ud83c\udffe\ud83d\udc3b ( Details below.) dyce is a pure-Python library for modeling arbitrarily complex dice mechanics. It strives for compact expression and efficient computation , especially for the most common cases. Its primary applications are: Computing finite discrete probability distributions for: Game designers who want to understand or experiment with various dice mechanics and interactions; and Design tool developers . Generating transparent, weighted random rolls for: Game environment developers who want flexible dice mechanic resolution in, e.g., virtual tabletops (VTTs), chat servers, etc. Beyond those audiences, dyce may be useful to anyone interested in exploring finite discrete probabilities but not in developing all the low-level math bits from scratch. dyce is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. If you\u2019re looking at something on which to build your own grammar or interface, dyce can serve you well. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Non-experimental features should be considered stable (but an unquenchable thirst to increase performance remains). See the release notes for a summary of version-to-version changes. Source code is available on GitHub . If you find it lacking in any way, please don\u2019t hesitate to bring it to my attention . Customers This could be you ! \ud83d\udc4b Do you have a project that uses dyce ? Let me know , and I\u2019ll promote it here! And don\u2019t forget to do your part in perpetuating gratuitous badge-ification! 1 2 3 4 <!-- Markdown --> As of version 1.1, HighRollin is [ ![dyce-powered ]( https://raw.githubusercontent.com/posita/dyce/master/docs/dyce-powered.svg )][dyce-powered]! [ dyce-powered ]: https://posita.github.io/dyce/ \"dyce-powered!\" 1 2 3 4 5 6 7 8 9 .. reStructuredText - see https://docutils.sourceforge.io/docs/ref/rst/directives.html#image As of version 1.1, HighRollin is |dyce-powered|! .. |dyce-powered| image :: https://raw.githubusercontent.com/posita/dyce/master/docs/dyce-powered.svg :align: top :target: https://posita.github.io/dyce/ :alt: dyce-powered 1 2 3 4 5 <!-- HTML --> As of version 1.1, HighRollin is < a href = \"https://posita.github.io/dyce/\" >< img src = \"https://raw.githubusercontent.com/posita/dyce/master/docs/dyce-powered.svg\" alt = \"dyce-powered\" style = \"vertical-align: middle;\" ></ a > ! Donors When one worries that the flickering light of humanity may be snuffed out at any moment, when one\u2019s heart breaks at the perverse celebration of judgment, vengeance, and death and the demonizing of empathy, compassion, and love, sometimes all that is needed is the kindness of a single stranger to reinvigorate one\u2019s faith that\u2014while all may not be right in the world\u2014there is hope for us human beings. David Eyk not only inspires others to explore creative writing , but has graciously ceded his PyPI project dedicated to his own prior work under a similar name . As such, dyce is now available as dycelib dyce ! Thanks to his generosity, \u2014 millions dozens of future dyce users will be spared from typing superfluous characters. On behalf of myself, those souls, and our keyboards, we salute you, Mr. Eyk. \ud83d\ude47\u200d\u2642\ufe0f A taste dyce provides several core primitives. H objects represent histograms for modeling finite discrete outcomes, like individual dice. P objects represent pools (ordered sequences) of histograms. R objects (covered elsewhere ) represent nodes in arbitrary roller trees useful for translating from proprietary grammars and generating weighted random rolls that \u201cshow their work\u201d without the overhead of enumeration. All support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ( width = 65 )) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( 0 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v - 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Lowest\" , ... ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( - 1 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v + 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Highest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Taking the lowest or highest die of 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP H objects and P objects can generate random rolls. 1 2 3 >>> d6 = H ( 6 ) >>> d6 . roll () # doctest: +SKIP 4 1 2 3 4 >>> d10 = H ( 10 ) - 1 >>> p_6d10 = 6 @P ( d10 ) >>> p_6d10 . roll () # doctest: +SKIP ( 0 , 1 , 2 , 3 , 5 , 7 ) See the tutorials on counting and rolling , as well as the API guide for much more thorough treatments, including detailed examples. Design philosophy dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. That\u2019s a highfalutin way of saying it doesn\u2019t guess. It knows , even if knowing is harder or more limiting. Which, if we possess a modicum of humility, it often is. Quote \u201cIt\u2019s frightening to think that you might not know something, but more frightening to think that, by and large, the world is run by people who have faith that they know exactly what is going on.\u201d \u2014Amos Tversky Because dyce exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. 1 It can be installed and run anywhere 2 , and modified as desired. On its own, dyce is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter or embedded in a special-purpose application. In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods). Comparison to alternatives The following is a best-effort 3 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen python-dice Robson et al. AnyDice Flick d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clements et al. dice-notation Garrido Latest release 2021 N/A 2021 Unknown 2021 2016 2021 2021 Actively maintained and documented \u2705 \u26a0\ufe0f 4 \u2705 \u2705 \u2705 \u274c \u2705 \u274c Suitable as a dependency in other projects \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u2705 \u26a0\ufe0f 5 \u2705 \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Arbitrary expressions \u2705 \u26a0\ufe0f 6 \u2705 \u2705 \u2705 \u26a0\ufe0f 7 \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u26a0\ufe0f 8 \u274c \u26a0\ufe0f 8 \u2705 \u26a0\ufe0f 8 \u26a0\ufe0f 8 Open source (can inspect) \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 Permissive licensing (can use and extend) \u2705 \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705 License dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub . Installation Installation can be performed via PyPI . 1 2 % pip install dyce ... Alternately, you can download the source and install manually. 1 2 3 4 5 % git clone https://github.com/posita/dyce.git ... % cd dyce % python -m pip install . # -or- python -c 'from setuptools import setup ; setup()' install . ... Requirements dyce requires a relatively modern version of Python: CPython (3.7+) PyPy (CPython 3.7+ compatible) It has the following runtime dependencies: numerary dyce will opportunistically use the following, if available at runtime: beartype for yummy runtime type-checking goodness (0.8+) matplotlib for visualizing histograms and pools numpy to supply dyce with an alternate random number generator implementation dyce leverages numerary for its opportunistic use of beartype . If you use beartype for type checking your code that interacts with dyce , but don\u2019t want dyce or numerary to use it internally (e.g., for performance reasons), disable it with numerary \u2019s NUMERARY_BEARTYPE environment variable . See the hacking quick-start for additional development and testing dependencies. You won\u2019t find any lexers, parsers, or tokenizers in dyce \u2019s core, other than straight-up Python. That being said, you can always \u201croll\u201d your own (see what we did there?) and lean on dyce underneath. It doesn\u2019t mind. It actually kind of likes it . \u21a9 Okay, maybe not literally anywhere, but you\u2019d be surprised . Void where prohibited. Certain restrictions apply. Do not taunt Happy Fun Ball . \u21a9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if you observe discrepancies. \u21a9 Actively maintained, but sparsely documented. The author has expressed a desire to release a more polished version. \u21a9 Source can be downloaded and incorporated directly, but there is no packaging, versioning, or dependency tracking. \u21a9 \u21a9 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u21a9 Limited arithmetic operations are available. The library also provides game-specific functions. \u21a9 Results only. Input is limited to specialized grammar. \u21a9 \u21a9 \u21a9 \u21a9","title":"Introduction"},{"location":"#dyce-simple-python-tools-for-exploring-dice-outcomes-and-other-finite-discrete-probabilities","text":"\ud83d\udca5 Now 100% Bear-ified\u2122 ! \ud83d\udc4c\ud83c\udffe\ud83d\udc3b ( Details below.) dyce is a pure-Python library for modeling arbitrarily complex dice mechanics. It strives for compact expression and efficient computation , especially for the most common cases. Its primary applications are: Computing finite discrete probability distributions for: Game designers who want to understand or experiment with various dice mechanics and interactions; and Design tool developers . Generating transparent, weighted random rolls for: Game environment developers who want flexible dice mechanic resolution in, e.g., virtual tabletops (VTTs), chat servers, etc. Beyond those audiences, dyce may be useful to anyone interested in exploring finite discrete probabilities but not in developing all the low-level math bits from scratch. dyce is designed to be immediately and broadly useful with minimal additional investment beyond basic knowledge of Python. While not as compact as a dedicated grammar, dyce \u2019s Python-based primitives are quite sufficient, and often more expressive. Those familiar with various game notations should be able to adapt quickly. If you\u2019re looking at something on which to build your own grammar or interface, dyce can serve you well. dyce should be able to replicate or replace most other dice probability modeling tools. It strives to be fully documented and relies heavily on examples to develop understanding. dyce is licensed under the MIT License . See the accompanying LICENSE file for details. Non-experimental features should be considered stable (but an unquenchable thirst to increase performance remains). See the release notes for a summary of version-to-version changes. Source code is available on GitHub . If you find it lacking in any way, please don\u2019t hesitate to bring it to my attention .","title":"dyce \u2013 simple Python tools for exploring dice outcomes and other finite discrete probabilities"},{"location":"#customers","text":"This could be you ! \ud83d\udc4b Do you have a project that uses dyce ? Let me know , and I\u2019ll promote it here! And don\u2019t forget to do your part in perpetuating gratuitous badge-ification! 1 2 3 4 <!-- Markdown --> As of version 1.1, HighRollin is [ ![dyce-powered ]( https://raw.githubusercontent.com/posita/dyce/master/docs/dyce-powered.svg )][dyce-powered]! [ dyce-powered ]: https://posita.github.io/dyce/ \"dyce-powered!\" 1 2 3 4 5 6 7 8 9 .. reStructuredText - see https://docutils.sourceforge.io/docs/ref/rst/directives.html#image As of version 1.1, HighRollin is |dyce-powered|! .. |dyce-powered| image :: https://raw.githubusercontent.com/posita/dyce/master/docs/dyce-powered.svg :align: top :target: https://posita.github.io/dyce/ :alt: dyce-powered 1 2 3 4 5 <!-- HTML --> As of version 1.1, HighRollin is < a href = \"https://posita.github.io/dyce/\" >< img src = \"https://raw.githubusercontent.com/posita/dyce/master/docs/dyce-powered.svg\" alt = \"dyce-powered\" style = \"vertical-align: middle;\" ></ a > !","title":"Customers"},{"location":"#donors","text":"When one worries that the flickering light of humanity may be snuffed out at any moment, when one\u2019s heart breaks at the perverse celebration of judgment, vengeance, and death and the demonizing of empathy, compassion, and love, sometimes all that is needed is the kindness of a single stranger to reinvigorate one\u2019s faith that\u2014while all may not be right in the world\u2014there is hope for us human beings. David Eyk not only inspires others to explore creative writing , but has graciously ceded his PyPI project dedicated to his own prior work under a similar name . As such, dyce is now available as dycelib dyce ! Thanks to his generosity, \u2014 millions dozens of future dyce users will be spared from typing superfluous characters. On behalf of myself, those souls, and our keyboards, we salute you, Mr. Eyk. \ud83d\ude47\u200d\u2642\ufe0f","title":"Donors"},{"location":"#a-taste","text":"dyce provides several core primitives. H objects represent histograms for modeling finite discrete outcomes, like individual dice. P objects represent pools (ordered sequences) of histograms. R objects (covered elsewhere ) represent nodes in arbitrary roller trees useful for translating from proprietary grammars and generating weighted random rolls that \u201cshow their work\u201d without the overhead of enumeration. All support a variety of operations. 1 2 3 4 5 6 7 8 >>> from dyce import H >>> d6 = H ( 6 ) # a standard six-sided die >>> 2 @d6 * 3 - 4 # 2d6 \u00d7 3 - 4 H ({ 2 : 1 , 5 : 2 , 8 : 3 , 11 : 4 , 14 : 5 , 17 : 6 , 20 : 5 , 23 : 4 , 26 : 3 , 29 : 2 , 32 : 1 }) >>> d6 . lt ( d6 ) # how often a first six-sided die shows a face less than a second H ({ False : 21 , True : 15 }) >>> abs ( d6 - d6 ) # subtract the least of two six-sided dice from the greatest H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) 1 2 3 4 5 6 >>> from dyce import P >>> p_2d6 = 2 @P ( d6 ) # a pool of two six-sided dice >>> p_2d6 . h () # pools can be collapsed into histograms H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> p_2d6 == 2 @d6 # pools and histograms are comparable True By providing an optional argument to the P.h method , one can \u201ctake\u201d individual dice from pools, ordered least to greatest. (The H.format method provides rudimentary visualization for convenience.) 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( 0 ) # take the lowest die of 2d6 H ({ 1 : 11 , 2 : 9 , 3 : 7 , 4 : 5 , 5 : 3 , 6 : 1 }) >>> print ( p_2d6 . h ( 0 ) . format ( width = 65 )) avg | 2.53 std | 1.40 var | 1.97 1 | 30.56 % | ############### 2 | 25.00 % | ############ 3 | 19.44 % | ######### 4 | 13.89 % | ###### 5 | 8.33 % | #### 6 | 2.78 % | # 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_2d6 . h ( - 1 ) # take the highest die of 2d6 H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( 0 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v - 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Lowest\" , ... ) # doctest: +SKIP >>> outcomes , probabilities = p_2d6 . h ( - 1 ) . distribution_xy () >>> matplotlib . pyplot . bar ( ... [ v + 0.125 for v in outcomes ], ... probabilities , ... alpha = 0.75 , ... width = 0.5 , ... label = \"Highest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( r \"Taking the lowest or highest die of 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP H objects and P objects can generate random rolls. 1 2 3 >>> d6 = H ( 6 ) >>> d6 . roll () # doctest: +SKIP 4 1 2 3 4 >>> d10 = H ( 10 ) - 1 >>> p_6d10 = 6 @P ( d10 ) >>> p_6d10 . roll () # doctest: +SKIP ( 0 , 1 , 2 , 3 , 5 , 7 ) See the tutorials on counting and rolling , as well as the API guide for much more thorough treatments, including detailed examples.","title":"A taste"},{"location":"#design-philosophy","text":"dyce is fairly low-level by design, prioritizing ergonomics and composability. It explicitly avoids stochastic simulation, but instead determines outcomes through enumeration and discrete computation. That\u2019s a highfalutin way of saying it doesn\u2019t guess. It knows , even if knowing is harder or more limiting. Which, if we possess a modicum of humility, it often is. Quote \u201cIt\u2019s frightening to think that you might not know something, but more frightening to think that, by and large, the world is run by people who have faith that they know exactly what is going on.\u201d \u2014Amos Tversky Because dyce exposes Python primitives rather than defining a dedicated grammar and interpreter, one can more easily integrate it with other tools. 1 It can be installed and run anywhere 2 , and modified as desired. On its own, dyce is completely adequate for casual tinkering. However, it really shines when used in larger contexts such as with Matplotlib or Jupyter or embedded in a special-purpose application. In an intentional departure from RFC 1925, \u00a7 2.2 , dyce includes some conveniences, such as minor computation optimizations (e.g., the H.lowest_terms method , various other shorthands, etc.) and formatting conveniences (e.g., the H.distribution , H.distribution_xy , and H.format methods).","title":"Design philosophy"},{"location":"#comparison-to-alternatives","text":"The following is a best-effort 3 summary of the differences between various available tools in this space. Consider exploring the applications and translations for added color. dyce Bogosian et al. dice_roll.py Karonen python-dice Robson et al. AnyDice Flick d20 Curse LLC DnDice \u201cLordSembor\u201d dice Clements et al. dice-notation Garrido Latest release 2021 N/A 2021 Unknown 2021 2016 2021 2021 Actively maintained and documented \u2705 \u26a0\ufe0f 4 \u2705 \u2705 \u2705 \u274c \u2705 \u274c Suitable as a dependency in other projects \u2705 \u26a0\ufe0f 5 \u2705 \u274c \u2705 \u26a0\ufe0f 5 \u2705 \u274c Discrete outcome enumeration \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c Arbitrary expressions \u2705 \u26a0\ufe0f 6 \u2705 \u2705 \u2705 \u26a0\ufe0f 7 \u274c \u274c Arbitrary dice definitions \u2705 \u2705 \u2705 \u2705 \u274c \u274c \u274c \u274c Integrates with other tools \u2705 \u2705 \u26a0\ufe0f 8 \u274c \u26a0\ufe0f 8 \u2705 \u26a0\ufe0f 8 \u26a0\ufe0f 8 Open source (can inspect) \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 Permissive licensing (can use and extend) \u2705 \u2705 \u2705 N/A \u2705 \u2705 \u2705 \u2705","title":"Comparison to alternatives"},{"location":"#license","text":"dyce is licensed under the MIT License . See the included LICENSE file for details. Source code is available on GitHub .","title":"License"},{"location":"#installation","text":"Installation can be performed via PyPI . 1 2 % pip install dyce ... Alternately, you can download the source and install manually. 1 2 3 4 5 % git clone https://github.com/posita/dyce.git ... % cd dyce % python -m pip install . # -or- python -c 'from setuptools import setup ; setup()' install . ...","title":"Installation"},{"location":"#requirements","text":"dyce requires a relatively modern version of Python: CPython (3.7+) PyPy (CPython 3.7+ compatible) It has the following runtime dependencies: numerary dyce will opportunistically use the following, if available at runtime: beartype for yummy runtime type-checking goodness (0.8+) matplotlib for visualizing histograms and pools numpy to supply dyce with an alternate random number generator implementation dyce leverages numerary for its opportunistic use of beartype . If you use beartype for type checking your code that interacts with dyce , but don\u2019t want dyce or numerary to use it internally (e.g., for performance reasons), disable it with numerary \u2019s NUMERARY_BEARTYPE environment variable . See the hacking quick-start for additional development and testing dependencies. You won\u2019t find any lexers, parsers, or tokenizers in dyce \u2019s core, other than straight-up Python. That being said, you can always \u201croll\u201d your own (see what we did there?) and lean on dyce underneath. It doesn\u2019t mind. It actually kind of likes it . \u21a9 Okay, maybe not literally anywhere, but you\u2019d be surprised . Void where prohibited. Certain restrictions apply. Do not taunt Happy Fun Ball . \u21a9 I have attempted to ensure the above is reasonably accurate, but please consider contributing an issue if you observe discrepancies. \u21a9 Actively maintained, but sparsely documented. The author has expressed a desire to release a more polished version. \u21a9 Source can be downloaded and incorporated directly, but there is no packaging, versioning, or dependency tracking. \u21a9 \u21a9 Callers must perform their own arithmetic and characterize results in terms of a lightweight die primitive, which may be less accessible to the novice. That being said, the library is remarkably powerful, given its size. \u21a9 Limited arithmetic operations are available. The library also provides game-specific functions. \u21a9 Results only. Input is limited to specialized grammar. \u21a9 \u21a9 \u21a9 \u21a9","title":"Requirements"},{"location":"contrib/","text":"Contributing to dyce There are many ways you can contribute. You have only but to try. Filing issues You can file new issues as you find them. Please try to avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful. Hacking quick-start An easy way to bootstrap an isolated development environment is: 1 2 3 4 5 6 7 8 9 10 % git clone --recurse-submodules https://github.com/posita/dyce.git \u2026 % cd dyce % /path/to/python -m venv .venv \u2026 % . .venv/bin/activate % pip install --upgrade --editable '.[dev]' \u2026 % python -m pre_commit install \u2026 Substitute your preferred virtual environment process for venv . The [dev] variant includes additional dependencies necessary for development and testing. See the [options.extras_require] section in setup.cfg . Unit tests are run with pytest via Tox . 1 2 3 4 % cd \u2026/path/to/dyce % . .venv/bin/activate % tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] \u2026 Special considerations for regenerating class diagrams We use Pyreverse to generate class diagrams. Pyreverse is not very flexible with respect to what it includes. We use PyGraphviz to get rid of unwanted entries from the .dot file generated by Pyreverse. This is because the pure-Python alternative we use elsewhere does not support editing . PyGraphviz has some special needs when it comes to installation. This dumpster fire is complicated and fragile. 1 Depending on your configuration, PyGraphviz may not be able to find the native Graphviz library it needs. This can often be remedied by setting the appropriate gcc environment variables . 1 CPATH = /opt/local/include LIBRARY_PATH = /optlocal/lib tox -e check-classdiagrams Submission guidelines If you are willing and able, consider submitting a pull request with a fix. See the docs if you\u2019re not already familiar with pull requests. dyce releases from master (although not always immediately), so a lot of these workflows are helpful. There are only a few additional guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file. 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub \u2013 [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Do your best to follow the source conventions as you observe them. If it\u2019s important to you, Existing comments are wrapped at 88 characters per line to match Black\u2019s default. (Don\u2019t spend too much effort on strict conformance, though. I can clean things up later if they really bother me.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in tests . If you want feedback on a work-in-progress, consider \u201cmentioning\u201d me ( @posita ), and describe specifically how I can help. Consider prefixing your pull request\u2019s title with something like, \u201c NEED FEEDBACK \u2013 \u201d. If your pull request is still in progress, but you are not blocked on anything, consider using the draft feature . Once you are ready for a merge, resolve any conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) If your pull request started out as a draft, promote it by requesting a review. Consider prefixing the pull request\u2019s title to something like, \u201c READY FOR MERGE \u2013 \u201d. I will try to get to it as soon as I can. It is uncanny how often those two properties are found together. \u21a9","title":"Contributing"},{"location":"contrib/#contributing-to-dyce","text":"There are many ways you can contribute. You have only but to try.","title":"Contributing to dyce"},{"location":"contrib/#filing-issues","text":"You can file new issues as you find them. Please try to avoid duplicating issues. \u201cWriting Effective Bug Reports\u201d by Elisabeth Hendrickson (PDF) may be helpful.","title":"Filing issues"},{"location":"contrib/#hacking-quick-start","text":"An easy way to bootstrap an isolated development environment is: 1 2 3 4 5 6 7 8 9 10 % git clone --recurse-submodules https://github.com/posita/dyce.git \u2026 % cd dyce % /path/to/python -m venv .venv \u2026 % . .venv/bin/activate % pip install --upgrade --editable '.[dev]' \u2026 % python -m pre_commit install \u2026 Substitute your preferred virtual environment process for venv . The [dev] variant includes additional dependencies necessary for development and testing. See the [options.extras_require] section in setup.cfg . Unit tests are run with pytest via Tox . 1 2 3 4 % cd \u2026/path/to/dyce % . .venv/bin/activate % tox [ TOX_ARGS... [ -- PYTEST_ARGS... ]] \u2026 Special considerations for regenerating class diagrams We use Pyreverse to generate class diagrams. Pyreverse is not very flexible with respect to what it includes. We use PyGraphviz to get rid of unwanted entries from the .dot file generated by Pyreverse. This is because the pure-Python alternative we use elsewhere does not support editing . PyGraphviz has some special needs when it comes to installation. This dumpster fire is complicated and fragile. 1 Depending on your configuration, PyGraphviz may not be able to find the native Graphviz library it needs. This can often be remedied by setting the appropriate gcc environment variables . 1 CPATH = /opt/local/include LIBRARY_PATH = /optlocal/lib tox -e check-classdiagrams","title":"Hacking quick-start"},{"location":"contrib/#submission-guidelines","text":"If you are willing and able, consider submitting a pull request with a fix. See the docs if you\u2019re not already familiar with pull requests. dyce releases from master (although not always immediately), so a lot of these workflows are helpful. There are only a few additional guidelines: If it is not already present, please add your name (and optionally your email, GitHub username, website address, or other contact information) to the LICENSE file. 1 2 3 ... * [ Matt Bogosian ]( mailto:matt@bogosian.net?Subject=dyce ); GitHub \u2013 [ **@posita** ](https://github.com/posita) ... Use Black to format your changes. Do your best to follow the source conventions as you observe them. If it\u2019s important to you, Existing comments are wrapped at 88 characters per line to match Black\u2019s default. (Don\u2019t spend too much effort on strict conformance, though. I can clean things up later if they really bother me.) Provide tests where feasible and appropriate. At the very least, existing tests should not fail. (There are exceptions, but if there is any doubt, they probably do not apply.) Unit tests live in tests . If you want feedback on a work-in-progress, consider \u201cmentioning\u201d me ( @posita ), and describe specifically how I can help. Consider prefixing your pull request\u2019s title with something like, \u201c NEED FEEDBACK \u2013 \u201d. If your pull request is still in progress, but you are not blocked on anything, consider using the draft feature . Once you are ready for a merge, resolve any conflicts, squash your commits, and provide a useful commit message. ( This and this may be helpful.) If your pull request started out as a draft, promote it by requesting a review. Consider prefixing the pull request\u2019s title to something like, \u201c READY FOR MERGE \u2013 \u201d. I will try to get to it as soon as I can. It is uncanny how often those two properties are found together. \u21a9","title":"Submission guidelines"},{"location":"countin/","text":"dyce provides two core primitives for enumeration 1 . 1 >>> from dyce import H , P H objects represent histograms for modeling discrete outcomes. They encode finite discrete probability distributions as integer counts without any denominator. P objects represent pools (ordered sequences) of histograms. If all you need is to aggregate outcomes (sums) from rolling a bunch of dice (or perform calculations on aggregate outcomes), H objects are probably sufficient. If you need to select certain histograms from a group prior to computing aggregate outcomes (e.g., taking the highest and lowest of each possible roll of n dice), that\u2019s where P objects come in. As a wise person whose name has been lost to history once said: \u201cLanguage is imperfect. If at all possible, shut up and point.\u201d So with that illuminating (or perhaps impenetrable) introduction out of the way, let\u2019s dive into some examples! Basic examples A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H ( n ) is shorthand for explicitly enumerating outcomes \\([{{1} .. {n}}]\\) , each with a frequency of 1. 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P ( n , ... ) is shorthand for P ( H ( n ), ... ) . The above can be expressed more succinctly. 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case, Sicherman dice ) can be compared to histograms. 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. Histograms provide rudimentary formatting for convenience. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # The Miwin-Distribution is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 >>> miwin_iii = H (( 1 , 2 , 5 , 6 , 7 , 9 )) >>> miwin_iv = H (( 1 , 3 , 4 , 5 , 8 , 9 )) >>> miwin_v = H (( 2 , 3 , 4 , 6 , 7 , 8 )) >>> miwin_iii + miwin_iv + miwin_v H ({ 4 : 1 , 5 : 2 , 6 : 3 , 7 : 4 , 8 : 7 , ... , 22 : 7 , 23 : 4 , 24 : 3 , 25 : 2 , 26 : 1 }) >>> print (( miwin_iii + miwin_iv + miwin_v ) . format ( scaled = True , width = 65 )) avg | 15.00 std | 4.47 var | 20.00 4 | 0.46 % | ## 5 | 0.93 % | ##### 6 | 1.39 % | ####### 7 | 1.85 % | ########## 8 | 3.24 % | ################## 9 | 4.17 % | ####################### 10 | 4.63 % | ########################## 11 | 5.09 % | ############################ 12 | 7.87 % | ############################################ 13 | 8.80 % | ################################################# 14 | 8.33 % | ############################################### 15 | 6.48 % | #################################### 16 | 8.33 % | ############################################### 17 | 8.80 % | ################################################# 18 | 7.87 % | ############################################ 19 | 5.09 % | ############################ 20 | 4.63 % | ########################## 21 | 4.17 % | ####################### 22 | 3.24 % | ################## 23 | 1.85 % | ########## 24 | 1.39 % | ####### 25 | 0.93 % | ##### 26 | 0.46 % | ## One way to model the outcomes of subtracting the lesser of two six-sided dice from the greater is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms. 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest with negative values counting from the right, as one would expect (i.e., [ 0 ] , [ 1 ] , \u2026, [ - 2 ] , [ - 1 ] ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable. 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool. 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 2 ] P ( 4 , 6 , 8 ) A brute-force way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . is_even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( f \" { n : >2 } d6: { all_even [ 1 ] / sum ( all_even . counts ()) : >6.2% } \" ) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher on any single die when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( f \" { n : >2 } d6-exploding: { at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()) : >6.2% } \" ) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 % Visualization H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib . 1 2 3 4 5 6 7 8 >>> outcomes , probabilities = ( 2 @H ( 6 )) . distribution_xy () >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Distribution for 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.viz provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ). 1 2 3 >>> from dyce.viz import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position. 1 2 3 4 5 6 7 8 >>> d20 = H ( 20 ) >>> plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), inner_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring can also be used to compare two histograms directly. Ever been curious how your four shiny new fudge dice stack up against your trusty ol\u2019 double six-siders? Well wonder no more! The dyce abides. 1 2 3 4 >>> df_4 = 4 @H (( - 1 , 0 , 1 )) >>> d6_2 = 2 @H ( 6 ) >>> plot_burst ( df_4 , d6_2 , alpha = 0.9 ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Advanced exercise \u2013 modeling Risis Risus and its many community-developed alternative rules not only make for entertaining reading, but are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from typing import List , Tuple >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names : List [ str ] = [] ... rows : List [ Tuple [ float , ... ]] = [] ... for us in range ( them , them + num_rows ): ... row_names . append ( f \" { us } d6 \u2026\" ) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . distribution_xy ()[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( f \"\u2026 vs { them } d6\" ) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... f \" { rows [ y ][ x ] : .0% } \" , ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib . pyplot . show presents: Modeling entire multi-round combats With a little elbow finger grease, we can roll up our \u2026 erm \u2026 fingerless gloves and even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> from typing import Callable , Dict , Tuple >>> def risus_combat_driver ( ... us : int , # number of dice we still have ... them : int , # number of dice they still have ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... already_solved : Dict [ Tuple [ int , int ], H ] = {} ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in already_solved : return already_solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( _ : H , outcome ) -> H : ... if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die ... else : return H ({}) # ignore (immediately re-roll) all ties ... ... already_solved [( us , them )] = this_round . substitute ( _next_round ) ... return already_solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } There\u2019s lot going on there. Let\u2019s dissect it. 1 2 3 4 5 6 def risus_combat_driver ( us : int , # number of dice we still have them : int , # number of dice they still have us_vs_them_func : Callable [[ int , int ], H ], ) -> H : ... Our \u201cdriver\u201d takes three arguments: How many dice we have left ( us ); How many dice the opposition has left ( them ); and A resolution function ( us_vs_them_func ) that takes counts of each party\u2019s remaining dice and returns a histogram encoding the probability of winning or losing a single round akin to the H.vs method : An outcome of - 1 signals the likelihood of the opposition\u2019s victory An outcome of 1 signals the likelihood of our victory. An outcome of 0 signals the likelihood of a tie. This is intentional, since we\u2019re going to leverage that very method later. 6 7 8 9 10 if us < 0 or them < 0 : raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) if us == 0 and them == 0 : return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start already_solved : Dict [ Tuple [ int , int ], H ] = {} We make some preliminary checks that guard access to our recursive implementation so that it can be a little cleaner. We also set up a dict to keep track of results we\u2018ve already computed. For example, we might compute a case where we lose a die, then our opposition loses a die. We arrive at a similar case where our opposition loses a die, then we lose a die. Both cases are similar from that point on. We\u2019ll keep track of those, so we don\u2019t have to recompute them. 12 13 def _resolve ( us : int , them : int ) -> H : ... 27 return _resolve ( us , them ) Skipping over its implementation for now, we define a our recursive implementation ( _resolve ) and then call it with our initial arguments. 13 14 15 16 def _resolve ( us : int , them : int ) -> H : if ( us , them ) in already_solved : return already_solved [( us , them )] elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win Getting back to that implementation, these are our base cases. First we check to see if we\u2019ve already solved for this case (memoization), in which case we can just return it. Then we check whether either party has run out of dice, in which case the combat is over. If we have none of those cases, we get to work. Note In this function, we do not check for the case where both parties are at zero. Because only one party can lose a die during each round, the only way both parties can be at zero simultaneously is if they both started at zero. Since we guarded against that case in the enclosing function, we don\u2019t have to worry about that here. Either us is zero, them is zero, or neither is zero. 17 this_round = us_vs_them_func ( us , them ) Then, we compute the outcomes for this round using the provided resolution function. 19 20 def _next_round ( _ : H , outcome ) -> H : ... 24 25 already_solved [( us , them )] = this_round . substitute ( _next_round ) return already_solved [( us , them )] Keeping in mind that we\u2019re inside our recursive implementation, we define a substitution function specifically for use with H.substitute . This allows us to take our computation for this round, and \u201cfold in\u201d subsequent rounds. We keep track of the result in our memoization dict before returning it. 19 20 21 22 def _next_round ( _ : H , outcome ) -> H : if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die else : return H ({}) # ignore (immediately re-roll) all ties Our substitution function is pretty straightforward. Where we are asked whether we want to provide a substitution for a round we lost, we lose a die and recurse. Where we are asked for a substitution for a round we won, our opposition loses a die and we recurse. We ignore ties (simulating that we re-roll them in place until they are no longer ties). 32 33 34 35 ... risus_combat_driver ( u , t , lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ) ... At this point, we can define a simple lambda that wraps H.vs and submit it to our driver to enumerate resolution outcomes from various starting positions. Note This is a complicated example that involves some fairly sophisticated programming techniques (recursion, memoization, closures, etc.). The point is not to suggest that such techniques are required to be productive. However, it is useful to show that dyce is flexible enough to model these types of outcomes in a couple dozen lines of code. It is high-level enough to lean on for nuanced number crunching without a lot of detailed knowledge, while still being low-level enough that authors knowledgeable of advanced programming techniques are not precluded from using them. Modeling different combat resolution methods Using our risus_combat_driver from above, we can craft a alternative resolution function to model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d for resolving ties. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath Rule: tie goes to the party with fewer dice in this round ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional work. This is for two reasons. First, with one narrow exception , dyce only provides a mechanism to substitute outcomes, not counts. This means we can\u2019t arbitrarily increase the likelihood of achieving a particular outcome through substitution. Second, dyce \u2019s substitution mechanism only resolves outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough. Both of these limitations can be circumvented where infinite series can be computed and encoded as histograms. For this mechanic, we can observe that a single six-sided die ( 1d6 ) has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes one can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue. 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem. \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{1}{2} \\] \\[ \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{3}{5} \\] Well, butter my butt and call me a biscuit! Math really is fun! \ud83e\uddc8 \ud83e\udd20 \ud83e\uddee Info The Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader \u2026 at least one with nothing more pressing to do. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above. We can also deploy a trick using partial to parameterize use of the Goliath Rule. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 1 : 3 , 0 : 2 }) # 3 dubyas, 2 doughnuts >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"- - - - - - - With Goliath Rule - - - - - - Without Goliath Rule - - - -\" ) ... for u in range ( t , t + 3 ): ... goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... no_goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = False )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { goliath_results } { no_goliath_results } \" ) - - - - - - - With Goliath Rule - - - - - - Without Goliath Rule - - - - 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } { ... , - 1 : 14.38 % , 1 : 85.62 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } { ... , - 1 : 1.99 % , 1 : 98.01 % } - - - - - - - With Goliath Rule - - - - - - Without Goliath Rule - - - - 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } { ... , - 1 : 16.44 % , 1 : 83.56 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } { ... , - 1 : 2.86 % , 1 : 97.14 % } Time to get meta-evil on those outcomes! Thanks to numerary , dyce offers best-effort support for arbitrary number-like outcomes, including primitives from symbolic expression packages such as SymPy . 1 2 3 4 5 >>> import sympy.abc >>> d6x = H ( 6 ) + sympy . abc . x >>> d8y = H ( 8 ) + sympy . abc . y >>> P ( d6x , d8y , d6x ) . h () H ({ 2 * x + y + 3 : 1 , 2 * x + y + 4 : 3 , 2 * x + y + 5 : 6 , ... , 2 * x + y + 18 : 6 , 2 * x + y + 19 : 3 , 2 * x + y + 20 : 1 }) Note Be aware that, depending on implementation, performance can suffer quite a bit when using symbolic primitives. For histograms and pools, dyce remains opinionated about ordering. For non-critical contexts where relative values are indeterminate, dyce will attempt a \u201cnatural\u201d ordering based on the string representation of each outcome. This is to accommodate symbolic expressions whose relative values are often unknowable. 1 2 3 4 5 6 >>> expr = sympy . abc . x < sympy . abc . x * 3 ; expr x < 3 * x >>> bool ( expr ) # nope Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational SymPy does not even attempt simple relative comparisons between symbolic expressions, even where they are unambiguously resolvable. Instead, it relies on the caller to invoke its proprietary solver APIs. 1 2 3 4 5 6 7 >>> bool ( sympy . abc . x < sympy . abc . x + 1 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> import sympy.solvers.inequalities >>> sympy . solvers . inequalities . reduce_inequalities ( sympy . abc . x < sympy . abc . x + 1 , [ sympy . abc . x ]) True dyce , of course, is happily ignorant of all that keenness. (As it should be.) In practice, that means that certain operations won\u2019t work with symbolic expressions where correctness depends on ordering outcomes according to relative value (e.g., dice selection from pools). Flattening pools works. 1 2 3 4 5 >>> d3x = H ( 3 ) * sympy . abc . x ; d3x H ({ 2 * x : 1 , 3 * x : 1 , x : 1 }) >>> p = P ( d3x / 3 , ( d3x + 1 ) / 3 , ( d3x + 2 ) / 3 ) >>> p . h () H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Selecting the \u201clowest\u201d die doesn\u2019t. 1 2 3 4 >>> p . h ( 0 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational Selecting all dice works, since it\u2019s equivalent to flattening (no sorting is required). 1 2 >>> p . h ( slice ( None )) H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Enumerating rolls doesn\u2019t, even where there is no selection, because each roll\u2019s outcomes are sorted least-to-greatest. 1 2 3 4 >>> list ( p . rolls_with_counts ()) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational P.roll \u201cworks\u201d (i.e., falls back to natural ordering of outcomes), but that is a deliberate compromise of convenience. 1 2 >>> p . roll () # doctest: +SKIP ( 2 * x / 3 , 2 * x / 3 + 1 / 3 , x / 3 + 2 / 3 ) P.umap can help pave the way back to concrete outcomes. 1 2 3 4 5 >>> f = lambda outcome : outcome . subs ({ sympy . abc . x : sympy . Rational ( 1 , 3 )}) >>> p . umap ( f ) P ( H ({ 1 / 9 : 1 , 2 / 9 : 1 , 1 / 3 : 1 }), H ({ 4 / 9 : 1 , 5 / 9 : 1 , 2 / 3 : 1 }), H ({ 7 / 9 : 1 , 8 / 9 : 1 , 1 : 1 })) >>> p . umap ( f ) . h ( - 1 ) H ({ 7 / 9 : 9 , 8 / 9 : 9 , 1 : 9 }) Further exploration Consider delving into some applications and translations for more sophisticated examples, or jump right into the API . dyce also provides additional primitives ( R objects and their kin) which are useful for producing weighted randomized rolls without the overhead of enumeration. These are covered seperately . \u21a9","title":"Countin\u2019 with histograms and pools"},{"location":"countin/#basic-examples","text":"A six-sided die can be modeled as: 1 2 >>> H ( 6 ) H ( 6 ) H ( n ) is shorthand for explicitly enumerating outcomes \\([{{1} .. {n}}]\\) , each with a frequency of 1. 1 2 >>> H ( 6 ) == H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) True Tuples with repeating outcomes are accumulated. A six-sided \u201c2, 3, 3, 4, 4, 5\u201d die can be modeled as: 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) A fudge die can be modeled as: 1 2 >>> H (( - 1 , 0 , 1 )) H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) Python\u2019s matrix multiplication operator ( @ ) is used to express the number of a particular die (roughly equivalent to the \u201c d \u201d operator in common notations). The outcomes of rolling two six-sided dice ( 2d6 ) are: 1 2 >>> 2 @H ( 6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) A pool of two six-sided dice is: 1 2 >>> 2 @P ( H ( 6 )) P ( 6 , 6 ) Where n is an integer, P ( n , ... ) is shorthand for P ( H ( n ), ... ) . The above can be expressed more succinctly. 1 2 >>> 2 @P ( 6 ) P ( 6 , 6 ) Pools (in this case, Sicherman dice ) can be compared to histograms. 1 2 3 >>> d_sicherman = P ( H (( 1 , 2 , 2 , 3 , 3 , 4 )), H (( 1 , 3 , 4 , 5 , 6 , 8 ))) >>> d_sicherman == 2 @H ( 6 ) True Both histograms and pools support arithmetic operations. 3\u00d7(2d6+4) is: 1 2 >>> 3 * ( 2 @H ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) The results show there is one way to make 18 , two ways to make 21 , three ways to make 24 , etc. Histograms provide rudimentary formatting for convenience. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> print (( 2 @H ( 6 )) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # The Miwin-Distribution is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 >>> miwin_iii = H (( 1 , 2 , 5 , 6 , 7 , 9 )) >>> miwin_iv = H (( 1 , 3 , 4 , 5 , 8 , 9 )) >>> miwin_v = H (( 2 , 3 , 4 , 6 , 7 , 8 )) >>> miwin_iii + miwin_iv + miwin_v H ({ 4 : 1 , 5 : 2 , 6 : 3 , 7 : 4 , 8 : 7 , ... , 22 : 7 , 23 : 4 , 24 : 3 , 25 : 2 , 26 : 1 }) >>> print (( miwin_iii + miwin_iv + miwin_v ) . format ( scaled = True , width = 65 )) avg | 15.00 std | 4.47 var | 20.00 4 | 0.46 % | ## 5 | 0.93 % | ##### 6 | 1.39 % | ####### 7 | 1.85 % | ########## 8 | 3.24 % | ################## 9 | 4.17 % | ####################### 10 | 4.63 % | ########################## 11 | 5.09 % | ############################ 12 | 7.87 % | ############################################ 13 | 8.80 % | ################################################# 14 | 8.33 % | ############################################### 15 | 6.48 % | #################################### 16 | 8.33 % | ############################################### 17 | 8.80 % | ################################################# 18 | 7.87 % | ############################################ 19 | 5.09 % | ############################ 20 | 4.63 % | ########################## 21 | 4.17 % | ####################### 22 | 3.24 % | ################## 23 | 1.85 % | ########## 24 | 1.39 % | ####### 25 | 0.93 % | ##### 26 | 0.46 % | ## One way to model the outcomes of subtracting the lesser of two six-sided dice from the greater is: 1 2 >>> abs ( H ( 6 ) - H ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Arithmetic operations implicitly \u201cflatten\u201d pools into histograms. 1 2 3 4 >>> 3 * ( 2 @P ( 6 ) + 4 ) H ({ 18 : 1 , 21 : 2 , 24 : 3 , 27 : 4 , 30 : 5 , 33 : 6 , 36 : 5 , 39 : 4 , 42 : 3 , 45 : 2 , 48 : 1 }) >>> abs ( P ( 6 ) - P ( 6 )) H ({ 0 : 6 , 1 : 10 , 2 : 8 , 3 : 6 , 4 : 4 , 5 : 2 }) Histograms should be sufficient for most calculations. However, pools are useful for \u201ctaking\u201d (selecting) only some of each roll\u2019s outcomes. This is done by providing one or more index arguments to the P.h method or the P.rolls_with_counts method . Indexes can be integers, slices, or a mix thereof. Outcome indexes are ordered from least to greatest with negative values counting from the right, as one would expect (i.e., [ 0 ] , [ 1 ] , \u2026, [ - 2 ] , [ - 1 ] ). Summing the least two faces when rolling three six-sided dice would be: 1 2 3 4 >>> 3 @P ( 6 ) P ( 6 , 6 , 6 ) >>> ( 3 @P ( 6 )) . h ( 0 , 1 ) # see warning below about parentheses H ({ 2 : 16 , 3 : 27 , 4 : 34 , 5 : 36 , 6 : 34 , 7 : 27 , 8 : 19 , 9 : 12 , 10 : 7 , 11 : 3 , 12 : 1 }) Mind your parentheses Parentheses are needed in the above example because @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 >>> 2 @P ( 6 ) . h ( 1 ) # equivalent to 2@(P(6).h(1)) Traceback ( most recent call last ): ... IndexError : tuple index out of range >>> ( 2 @P ( 6 )) . h ( 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) Taking the least, middle, or greatest face when rolling three six-sided dice would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_3d6 = 3 @P ( 6 ) >>> p_3d6 . h ( 0 ) H ({ 1 : 91 , 2 : 61 , 3 : 37 , 4 : 19 , 5 : 7 , 6 : 1 }) >>> print ( p_3d6 . h ( 0 ) . format ( width = 65 )) avg | 2.04 std | 1.14 var | 1.31 1 | 42.13 % | ##################### 2 | 28.24 % | ############## 3 | 17.13 % | ######## 4 | 8.80 % | #### 5 | 3.24 % | # 6 | 0.46 % | 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 1 ) H ({ 1 : 16 , 2 : 40 , 3 : 52 , 4 : 52 , 5 : 40 , 6 : 16 }) >>> print ( p_3d6 . h ( 1 ) . format ( width = 65 )) avg | 3.50 std | 1.37 var | 1.88 1 | 7.41 % | ### 2 | 18.52 % | ######### 3 | 24.07 % | ############ 4 | 24.07 % | ############ 5 | 18.52 % | ######### 6 | 7.41 % | ### 1 2 3 4 5 6 7 8 9 10 11 12 >>> p_3d6 . h ( 2 ) H ({ 1 : 1 , 2 : 7 , 3 : 19 , 4 : 37 , 5 : 61 , 6 : 91 }) >>> print ( p_3d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.96 std | 1.14 var | 1.31 1 | 0.46 % | 2 | 3.24 % | # 3 | 8.80 % | #### 4 | 17.13 % | ######## 5 | 28.24 % | ############## 6 | 42.13 % | ##################### Summing the greatest and the least faces when rolling a typical six-die polygonal set would be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> d10 = H ( 10 ) - 1 ; d10 # a common \u201cd10\u201d with faces [0 .. 9] H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> h = P ( 4 , 6 , 8 , d10 , 12 , 20 ) . h ( 0 , - 1 ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 13.48 std | 4.40 var | 19.39 1 | 0.00 % | 2 | 0.01 % | 3 | 0.06 % | 4 | 0.30 % | # 5 | 0.92 % | ##### 6 | 2.03 % | ########### 7 | 3.76 % | #################### 8 | 5.57 % | ############################## 9 | 7.78 % | ########################################### 10 | 8.99 % | ################################################## 11 | 8.47 % | ############################################### 12 | 8.64 % | ################################################ 13 | 8.66 % | ################################################ 14 | 6.64 % | #################################### 15 | 5.62 % | ############################### 16 | 5.16 % | ############################ 17 | 5.00 % | ########################### 18 | 5.00 % | ########################### 19 | 5.00 % | ########################### 20 | 5.00 % | ########################### 21 | 4.50 % | ######################### 22 | 2.01 % | ########### 23 | 0.73 % | #### 24 | 0.18 % | Pools are ordered and iterable. 1 2 >>> list ( 2 @P ( 8 , 4 , 6 )) [ H ( 4 ), H ( 4 ), H ( 6 ), H ( 6 ), H ( 8 ), H ( 8 )] Indexing selects particular histograms into a new pool. 1 2 3 4 5 6 >>> 2 @P ( 8 , 4 , 6 ) P ( 4 , 4 , 6 , 6 , 8 , 8 ) >>> ( 2 @P ( 8 , 4 , 6 ))[: 2 ] P ( 4 , 4 ) >>> ( 2 @P ( 8 , 4 , 6 ))[:: 2 ] P ( 4 , 6 , 8 ) A brute-force way to enumerate all possible rolls is: 1 2 3 >>> import itertools >>> list ( itertools . product ( * P ( - 3 , 3 ))) [( - 3 , 1 ), ( - 3 , 2 ), ( - 3 , 3 ), ( - 2 , 1 ), ( - 2 , 2 ), ( - 2 , 3 ), ( - 1 , 1 ), ( - 1 , 2 ), ( - 1 , 3 )] Both histograms and pools support various comparison operations as well as substitution. The odds of observing all even faces when rolling \\(n\\) six-sided dice, for \\(n\\) in \\([1..6]\\) is: 1 2 3 4 5 6 7 8 9 10 11 >>> d6_even = H ( 6 ) . is_even () >>> for n in range ( 6 , 0 , - 1 ): ... number_of_evens_in_nd6 = n @d6_even ... all_even = number_of_evens_in_nd6 . eq ( n ) ... print ( f \" { n : >2 } d6: { all_even [ 1 ] / sum ( all_even . counts ()) : >6.2% } \" ) 6 d6 : 1.56 % 5 d6 : 3.12 % 4 d6 : 6.25 % 3 d6 : 12.50 % 2 d6 : 25.00 % 1 d6 : 50.00 % The odds of scoring at least one nine or higher on any single die when rolling \\(n\\) \u201c exploding \u201d six-sided dice, for \\(n\\) in \\([1..10]\\) is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> exploding_d6 = H ( 6 ) . explode ( max_depth = 2 ) >>> for n in range ( 10 , 0 , - 1 ): ... d6e_ge_9 = exploding_d6 . ge ( 9 ) ... number_of_nines_or_higher_in_nd6e = n @d6e_ge_9 ... at_least_one_9 = number_of_nines_or_higher_in_nd6e . ge ( 1 ) ... print ( f \" { n : >2 } d6-exploding: { at_least_one_9 [ 1 ] / sum ( at_least_one_9 . counts ()) : >6.2% } \" ) 10 d6 - exploding : 69.21 % 9 d6 - exploding : 65.36 % 8 d6 - exploding : 61.03 % 7 d6 - exploding : 56.15 % 6 d6 - exploding : 50.67 % 5 d6 - exploding : 44.51 % 4 d6 - exploding : 37.57 % 3 d6 - exploding : 29.77 % 2 d6 - exploding : 20.99 % 1 d6 - exploding : 11.11 %","title":"Basic examples"},{"location":"countin/#visualization","text":"H objects provide a distribution method and a distribution_xy method to ease integration with plotting packages like matplotlib . 1 2 3 4 5 6 7 8 >>> outcomes , probabilities = ( 2 @H ( 6 )) . distribution_xy () >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . bar ( ... [ str ( v ) for v in outcomes ], ... probabilities , ... ) # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Distribution for 2d6\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP dyce.viz provides some experimental, rudimentary conveniences if it detects that matplotlib is installed (e.g., via Jupyter ). 1 2 3 >>> from dyce.viz import plot_burst >>> fig , ax = plot_burst ( 2 @H ( 6 )) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring and corresponding labels can be overridden for interesting, at-a-glance displays. Overrides apply counter-clockwise, starting from the 12 o\u2018clock position. 1 2 3 4 5 6 7 8 >>> d20 = H ( 20 ) >>> plot_burst ( d20 , outer = ( ... ( \"crit. fail.\" , d20 . le ( 1 )[ 1 ]), ... ( \"fail.\" , d20 . within ( 2 , 14 )[ 0 ]), ... ( \"succ.\" , d20 . within ( 15 , 19 )[ 0 ]), ... ( \"crit. succ.\" , d20 . ge ( 20 )[ 1 ]), ... ), inner_color = \"RdYlBu_r\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP The outer ring can also be used to compare two histograms directly. Ever been curious how your four shiny new fudge dice stack up against your trusty ol\u2019 double six-siders? Well wonder no more! The dyce abides. 1 2 3 4 >>> df_4 = 4 @H (( - 1 , 0 , 1 )) >>> d6_2 = 2 @H ( 6 ) >>> plot_burst ( df_4 , d6_2 , alpha = 0.9 ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Visualization"},{"location":"countin/#advanced-exercise-modeling-risis","text":"Risus and its many community-developed alternative rules not only make for entertaining reading, but are fertile ground for stressing ergonomics and capabilities of any discrete outcome modeling tool. We can easily model its opposed combat system for various starting configurations through the first round. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> for them in range ( 3 , 6 ): ... print ( \"---\" ) ... for us in range ( them , them + 3 ): ... first_round = ( us @H ( 6 )) . vs ( them @H ( 6 )) # -1 is a loss, 0 is a tie, 1 is a win ... results = first_round . format ( width = 0 ) ... print ( f \" { us } d6 vs { them } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 45.36 % , 0 : 9.28 % , 1 : 45.36 % } 4 d6 vs 3 d6 : { ... , - 1 : 19.17 % , 0 : 6.55 % , 1 : 74.28 % } 5 d6 vs 3 d6 : { ... , - 1 : 6.07 % , 0 : 2.99 % , 1 : 90.93 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 45.95 % , 0 : 8.09 % , 1 : 45.95 % } 5 d6 vs 4 d6 : { ... , - 1 : 22.04 % , 0 : 6.15 % , 1 : 71.81 % } 6 d6 vs 4 d6 : { ... , - 1 : 8.34 % , 0 : 3.26 % , 1 : 88.40 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 46.37 % , 0 : 7.27 % , 1 : 46.37 % } 6 d6 vs 5 d6 : { ... , - 1 : 24.24 % , 0 : 5.79 % , 1 : 69.96 % } 7 d6 vs 5 d6 : { ... , - 1 : 10.36 % , 0 : 3.40 % , 1 : 86.24 % } This highlights the mechanic\u2019s notorious \u201cdeath spiral\u201d, which we can visualize as a heat map. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 >>> from typing import List , Tuple >>> col_names = [ \"Loss\" , \"Tie\" , \"Win\" ] # mapping from [-1, 0, 1], respectively >>> col_ticks = list ( range ( len ( col_names ))) >>> num_rows = 3 >>> fig , axes = matplotlib . pyplot . subplots ( 1 , num_rows ) # doctest: +SKIP >>> for i , them in enumerate ( range ( 3 , 3 + num_rows )): ... ax = axes [ i ] # doctest: +SKIP ... row_names : List [ str ] = [] ... rows : List [ Tuple [ float , ... ]] = [] ... for us in range ( them , them + num_rows ): ... row_names . append ( f \" { us } d6 \u2026\" ) ... rows . append (( us @H ( 6 )) . vs ( them @H ( 6 )) . distribution_xy ()[ - 1 ]) ... _ = ax . imshow ( rows ) # doctest: +SKIP ... ax . set_title ( f \"\u2026 vs { them } d6\" ) # doctest: +SKIP ... ax . set_xticks ( col_ticks ) # doctest: +SKIP ... ax . set_xticklabels ( col_names , rotation = 90 ) # doctest: +SKIP ... ax . set_yticks ( list ( range ( len ( rows )))) # doctest: +SKIP ... ax . set_yticklabels ( row_names ) # doctest: +SKIP ... for y in range ( len ( row_names )): ... for x in range ( len ( col_names )): ... _ = ax . text ( ... x , y , ... f \" { rows [ y ][ x ] : .0% } \" , ... ha = \"center\" , va = \"center\" , color = \"w\" , ... ) # doctest: +SKIP >>> fig . tight_layout () # doctest: +SKIP Calling matplotlib . pyplot . show presents:","title":"Advanced exercise \u2013 modeling Risis"},{"location":"countin/#modeling-entire-multi-round-combats","text":"With a little elbow finger grease, we can roll up our \u2026 erm \u2026 fingerless gloves and even model various starting configurations through to completion to get a better sense of the impact of any initial disparity (in this case, applying dynamic programming to avoid redundant computations). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 >>> from typing import Callable , Dict , Tuple >>> def risus_combat_driver ( ... us : int , # number of dice we still have ... them : int , # number of dice they still have ... us_vs_them_func : Callable [[ int , int ], H ], ... ) -> H : ... if us < 0 or them < 0 : ... raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) ... if us == 0 and them == 0 : ... return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start ... already_solved : Dict [ Tuple [ int , int ], H ] = {} ... ... def _resolve ( us : int , them : int ) -> H : ... if ( us , them ) in already_solved : return already_solved [( us , them )] ... elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win ... elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win ... this_round = us_vs_them_func ( us , them ) ... ... def _next_round ( _ : H , outcome ) -> H : ... if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die ... elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die ... else : return H ({}) # ignore (immediately re-roll) all ties ... ... already_solved [( us , them )] = this_round . substitute ( _next_round ) ... return already_solved [( us , them )] ... ... return _resolve ( us , them ) >>> for t in range ( 3 , 6 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( ... u , t , ... lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ... ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } 5 d6 vs 3 d6 : { ... , - 1 : 0.66 % , 1 : 99.34 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 12.25 % , 1 : 87.75 % } 6 d6 vs 4 d6 : { ... , - 1 : 1.07 % , 1 : 98.93 % } --- 5 d6 vs 5 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 6 d6 vs 5 d6 : { ... , - 1 : 13.66 % , 1 : 86.34 % } 7 d6 vs 5 d6 : { ... , - 1 : 1.49 % , 1 : 98.51 % } There\u2019s lot going on there. Let\u2019s dissect it. 1 2 3 4 5 6 def risus_combat_driver ( us : int , # number of dice we still have them : int , # number of dice they still have us_vs_them_func : Callable [[ int , int ], H ], ) -> H : ... Our \u201cdriver\u201d takes three arguments: How many dice we have left ( us ); How many dice the opposition has left ( them ); and A resolution function ( us_vs_them_func ) that takes counts of each party\u2019s remaining dice and returns a histogram encoding the probability of winning or losing a single round akin to the H.vs method : An outcome of - 1 signals the likelihood of the opposition\u2019s victory An outcome of 1 signals the likelihood of our victory. An outcome of 0 signals the likelihood of a tie. This is intentional, since we\u2019re going to leverage that very method later. 6 7 8 9 10 if us < 0 or them < 0 : raise ValueError ( f \"cannot have negative numbers (us: { us } , them: { them } )\" ) if us == 0 and them == 0 : return H ({ 0 : 1 }) # should not happen unless combat(0, 0) is called from the start already_solved : Dict [ Tuple [ int , int ], H ] = {} We make some preliminary checks that guard access to our recursive implementation so that it can be a little cleaner. We also set up a dict to keep track of results we\u2018ve already computed. For example, we might compute a case where we lose a die, then our opposition loses a die. We arrive at a similar case where our opposition loses a die, then we lose a die. Both cases are similar from that point on. We\u2019ll keep track of those, so we don\u2019t have to recompute them. 12 13 def _resolve ( us : int , them : int ) -> H : ... 27 return _resolve ( us , them ) Skipping over its implementation for now, we define a our recursive implementation ( _resolve ) and then call it with our initial arguments. 13 14 15 16 def _resolve ( us : int , them : int ) -> H : if ( us , them ) in already_solved : return already_solved [( us , them )] elif us == 0 : return H ({ - 1 : 1 }) # we are out of dice, they win elif them == 0 : return H ({ 1 : 1 }) # they are out of dice, we win Getting back to that implementation, these are our base cases. First we check to see if we\u2019ve already solved for this case (memoization), in which case we can just return it. Then we check whether either party has run out of dice, in which case the combat is over. If we have none of those cases, we get to work. Note In this function, we do not check for the case where both parties are at zero. Because only one party can lose a die during each round, the only way both parties can be at zero simultaneously is if they both started at zero. Since we guarded against that case in the enclosing function, we don\u2019t have to worry about that here. Either us is zero, them is zero, or neither is zero. 17 this_round = us_vs_them_func ( us , them ) Then, we compute the outcomes for this round using the provided resolution function. 19 20 def _next_round ( _ : H , outcome ) -> H : ... 24 25 already_solved [( us , them )] = this_round . substitute ( _next_round ) return already_solved [( us , them )] Keeping in mind that we\u2019re inside our recursive implementation, we define a substitution function specifically for use with H.substitute . This allows us to take our computation for this round, and \u201cfold in\u201d subsequent rounds. We keep track of the result in our memoization dict before returning it. 19 20 21 22 def _next_round ( _ : H , outcome ) -> H : if outcome < 0 : return _resolve ( us - 1 , them ) # we lost this round, and one die elif outcome > 0 : return _resolve ( us , them - 1 ) # they lost this round, and one die else : return H ({}) # ignore (immediately re-roll) all ties Our substitution function is pretty straightforward. Where we are asked whether we want to provide a substitution for a round we lost, we lose a die and recurse. Where we are asked for a substitution for a round we won, our opposition loses a die and we recurse. We ignore ties (simulating that we re-roll them in place until they are no longer ties). 32 33 34 35 ... risus_combat_driver ( u , t , lambda u , t : ( u @H ( 6 )) . vs ( t @H ( 6 )) ) ... At this point, we can define a simple lambda that wraps H.vs and submit it to our driver to enumerate resolution outcomes from various starting positions. Note This is a complicated example that involves some fairly sophisticated programming techniques (recursion, memoization, closures, etc.). The point is not to suggest that such techniques are required to be productive. However, it is useful to show that dyce is flexible enough to model these types of outcomes in a couple dozen lines of code. It is high-level enough to lean on for nuanced number crunching without a lot of detailed knowledge, while still being low-level enough that authors knowledgeable of advanced programming techniques are not precluded from using them.","title":"Modeling entire multi-round combats"},{"location":"countin/#modeling-different-combat-resolution-methods","text":"Using our risus_combat_driver from above, we can craft a alternative resolution function to model the less death-spirally \u201cBest of Set\u201d alternative mechanic from The Risus Companion with the optional \u201cGoliath Rule\u201d for resolving ties. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> def deadly_combat_vs ( us : int , them : int ) -> H : ... best_us = ( us @P ( 6 )) . h ( - 1 ) ... best_them = ( them @P ( 6 )) . h ( - 1 ) ... h = best_us . vs ( best_them ) ... # Goliath Rule: tie goes to the party with fewer dice in this round ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"---\" ) ... for u in range ( t , t + 3 ): ... results = risus_combat_driver ( u , t , deadly_combat_vs ) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { results } \" ) --- 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 36.00 % , 1 : 64.00 % } 5 d6 vs 3 d6 : { ... , - 1 : 23.23 % , 1 : 76.77 % } --- 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 40.67 % , 1 : 59.33 % } 6 d6 vs 4 d6 : { ... , - 1 : 30.59 % , 1 : 69.41 % } Modeling the \u201c Evens Up \u201d alternative dice mechanic is currently beyond the capabilities of dyce without additional work. This is for two reasons. First, with one narrow exception , dyce only provides a mechanism to substitute outcomes, not counts. This means we can\u2019t arbitrarily increase the likelihood of achieving a particular outcome through substitution. Second, dyce \u2019s substitution mechanism only resolves outcomes through a fixed number of iterations (not an infinite series). Most of the time, this is good enough. Both of these limitations can be circumvented where infinite series can be computed and encoded as histograms. For this mechanic, we can observe that a single six-sided die ( 1d6 ) has a \\(\\frac{1}{2}\\) chance of coming up even, thereby earning a \u201csuccess\u201d. We can also observe that it has a \\(\\frac{1}{6}\\) chance of showing a six, earning an additional roll. That second roll has a \\(\\frac{1}{2}\\) chance of coming up even, as well as a \\(\\frac{1}{6}\\) chance of earning another roll, and so on. In other words, the number of successes one can expect to roll are: \\[ \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{1}{6} \\left( \\frac{1}{2} + \\ldots \\right) \\right) \\right) \\] Or, in the alternative: \\[ \\frac{1}{2} + \\frac{1}{2}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6} + \\frac{1}{2}\\frac{1}{6}\\frac{1}{6}\\frac{1}{6} + \\ldots \\] Or simply: \\[ \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\ldots \\] So what is that? We probably don\u2019t know unless we do math for a living, or at least as an active hobby. (The author does neither, which is partially what motivated the creation of this library.) Computing the value to the first hundred iterations offers a clue. 1 2 >>> 1 / 2 * sum ( 1 / ( 6 ** i ) for i in range ( 100 )) 0.59999999999999975575093458246556110680103302001953125 It appears convergent around \\(\\frac{3}{5}\\) . Let\u2019s see if we can validate that. An article from MathIsFun.com provides useful guidance. The section on geometric series is easily adapted to our problem. \\[ \\begin{matrix} S & = & \\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{{2} \\times {6}^{3}} + \\frac{1}{{2} \\times {6}^{4}} + \\ldots \\\\ & = & \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ \\begin{matrix} \\frac{1}{6}S & = & \\frac{1}{6}\\frac{1}{{2} \\times {6}^{0}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{1}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{2}} + \\frac{1}{6}\\frac{1}{{2} \\times {6}^{3}} + \\ldots \\\\ & = & \\underbrace{ \\frac{1}{12} + \\frac{1}{72} + \\frac{1}{432} + \\frac{1}{2\\,592} + \\ldots } \\\\ \\end{matrix} \\] \\[ S = \\overbrace{ \\frac{1}{2} } + \\underbrace{ \\frac{1}{6}S } \\] \\[ S - \\frac{1}{6}S = \\frac{1}{2} \\] \\[ \\frac{5}{6}S = \\frac{1}{2} \\] \\[ S = \\frac{3}{5} \\] Well, butter my butt and call me a biscuit! Math really is fun! \ud83e\uddc8 \ud83e\udd20 \ud83e\uddee Info The Archimedean visualization technique mentioned in the aforementioned article also adapts well to this case. It involves no algebra and is left as an exercise to the reader \u2026 at least one with nothing more pressing to do. Armed with this knowledge, we can now model \u201cEvens Up\u201d using our risus_combat_driver from above. We can also deploy a trick using partial to parameterize use of the Goliath Rule. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> from functools import partial >>> d6_evens_exploding_on_six = H ({ 1 : 3 , 0 : 2 }) # 3 dubyas, 2 doughnuts >>> def evens_up_vs ( us : int , them : int , goliath : bool = False ) -> H : ... h = ( us @d6_evens_exploding_on_six ) . vs ( them @d6_evens_exploding_on_six ) ... if goliath : ... h = h . substitute ( lambda h , outcome : ( us < them ) - ( us > them ) if outcome == 0 else outcome ) ... return h >>> for t in range ( 3 , 5 ): ... print ( \"- - - - - - - With Goliath Rule - - - - - - Without Goliath Rule - - - -\" ) ... for u in range ( t , t + 3 ): ... goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = True )) . format ( width = 0 ) ... no_goliath_results = risus_combat_driver ( u , t , partial ( evens_up_vs , goliath = False )) . format ( width = 0 ) ... print ( f \" { u } d6 vs { t } d6: { goliath_results } { no_goliath_results } \" ) - - - - - - - With Goliath Rule - - - - - - Without Goliath Rule - - - - 3 d6 vs 3 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 4 d6 vs 3 d6 : { ... , - 1 : 27.49 % , 1 : 72.51 % } { ... , - 1 : 14.38 % , 1 : 85.62 % } 5 d6 vs 3 d6 : { ... , - 1 : 9.27 % , 1 : 90.73 % } { ... , - 1 : 1.99 % , 1 : 98.01 % } - - - - - - - With Goliath Rule - - - - - - Without Goliath Rule - - - - 4 d6 vs 4 d6 : { ... , - 1 : 50.00 % , 1 : 50.00 % } { ... , - 1 : 50.00 % , 1 : 50.00 % } 5 d6 vs 4 d6 : { ... , - 1 : 28.50 % , 1 : 71.50 % } { ... , - 1 : 16.44 % , 1 : 83.56 % } 6 d6 vs 4 d6 : { ... , - 1 : 10.50 % , 1 : 89.50 % } { ... , - 1 : 2.86 % , 1 : 97.14 % }","title":"Modeling different combat resolution methods"},{"location":"countin/#time-to-get-meta-evil-on-those-outcomes","text":"Thanks to numerary , dyce offers best-effort support for arbitrary number-like outcomes, including primitives from symbolic expression packages such as SymPy . 1 2 3 4 5 >>> import sympy.abc >>> d6x = H ( 6 ) + sympy . abc . x >>> d8y = H ( 8 ) + sympy . abc . y >>> P ( d6x , d8y , d6x ) . h () H ({ 2 * x + y + 3 : 1 , 2 * x + y + 4 : 3 , 2 * x + y + 5 : 6 , ... , 2 * x + y + 18 : 6 , 2 * x + y + 19 : 3 , 2 * x + y + 20 : 1 }) Note Be aware that, depending on implementation, performance can suffer quite a bit when using symbolic primitives. For histograms and pools, dyce remains opinionated about ordering. For non-critical contexts where relative values are indeterminate, dyce will attempt a \u201cnatural\u201d ordering based on the string representation of each outcome. This is to accommodate symbolic expressions whose relative values are often unknowable. 1 2 3 4 5 6 >>> expr = sympy . abc . x < sympy . abc . x * 3 ; expr x < 3 * x >>> bool ( expr ) # nope Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational SymPy does not even attempt simple relative comparisons between symbolic expressions, even where they are unambiguously resolvable. Instead, it relies on the caller to invoke its proprietary solver APIs. 1 2 3 4 5 6 7 >>> bool ( sympy . abc . x < sympy . abc . x + 1 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational >>> import sympy.solvers.inequalities >>> sympy . solvers . inequalities . reduce_inequalities ( sympy . abc . x < sympy . abc . x + 1 , [ sympy . abc . x ]) True dyce , of course, is happily ignorant of all that keenness. (As it should be.) In practice, that means that certain operations won\u2019t work with symbolic expressions where correctness depends on ordering outcomes according to relative value (e.g., dice selection from pools). Flattening pools works. 1 2 3 4 5 >>> d3x = H ( 3 ) * sympy . abc . x ; d3x H ({ 2 * x : 1 , 3 * x : 1 , x : 1 }) >>> p = P ( d3x / 3 , ( d3x + 1 ) / 3 , ( d3x + 2 ) / 3 ) >>> p . h () H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Selecting the \u201clowest\u201d die doesn\u2019t. 1 2 3 4 >>> p . h ( 0 ) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational Selecting all dice works, since it\u2019s equivalent to flattening (no sorting is required). 1 2 >>> p . h ( slice ( None )) H ({ 2 * x + 1 : 7 , 3 * x + 1 : 1 , 4 * x / 3 + 1 : 3 , 5 * x / 3 + 1 : 6 , 7 * x / 3 + 1 : 6 , 8 * x / 3 + 1 : 3 , x + 1 : 1 }) Enumerating rolls doesn\u2019t, even where there is no selection, because each roll\u2019s outcomes are sorted least-to-greatest. 1 2 3 4 >>> list ( p . rolls_with_counts ()) Traceback ( most recent call last ): ... TypeError : cannot determine truth value of Relational P.roll \u201cworks\u201d (i.e., falls back to natural ordering of outcomes), but that is a deliberate compromise of convenience. 1 2 >>> p . roll () # doctest: +SKIP ( 2 * x / 3 , 2 * x / 3 + 1 / 3 , x / 3 + 2 / 3 ) P.umap can help pave the way back to concrete outcomes. 1 2 3 4 5 >>> f = lambda outcome : outcome . subs ({ sympy . abc . x : sympy . Rational ( 1 , 3 )}) >>> p . umap ( f ) P ( H ({ 1 / 9 : 1 , 2 / 9 : 1 , 1 / 3 : 1 }), H ({ 4 / 9 : 1 , 5 / 9 : 1 , 2 / 3 : 1 }), H ({ 7 / 9 : 1 , 8 / 9 : 1 , 1 : 1 })) >>> p . umap ( f ) . h ( - 1 ) H ({ 7 / 9 : 9 , 8 / 9 : 9 , 1 : 9 })","title":"Time to get meta-evil on those outcomes!"},{"location":"countin/#further-exploration","text":"Consider delving into some applications and translations for more sophisticated examples, or jump right into the API . dyce also provides additional primitives ( R objects and their kin) which are useful for producing weighted randomized rolls without the overhead of enumeration. These are covered seperately . \u21a9","title":"Further exploration"},{"location":"dyce.h/","text":"dyce . h package reference HableOpsMixin A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HableT protocol . The P class derives from this class. Info See HableT for notes on pronunciation. __slots__ : Union [ str , Iterable [ str ]] special __abs__ ( self : HableT ) -> H special Shorthand for operator . __abs__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __abs__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__abs__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __abs__ ( self . h ()) __add__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __add__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __add__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( self . h (), other ) __and__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H special Shorthand for operator . __and__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __and__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( self . h (), other ) __floordiv__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __floordiv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __floordiv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( self . h (), other ) __invert__ ( self : HableT ) -> H special Shorthand for operator . __invert__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __invert__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__invert__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __invert__ ( self . h ()) __mod__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __mod__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mod__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( self . h (), other ) __mul__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __mul__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mul__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( self . h (), other ) __neg__ ( self : HableT ) -> H special Shorthand for operator . __neg__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __neg__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__neg__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __neg__ ( self . h ()) __or__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H special Shorthand for operator . __or__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __or__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( self . h (), other ) __pos__ ( self : HableT ) -> H special Shorthand for operator . __pos__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __pos__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pos__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pos__ ( self . h ()) __pow__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __pow__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __pow__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( self . h (), other ) __radd__ ( self : HableT , other : RealLikeSCU ) -> H special Shorthand for operator . __add__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __radd__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( other , self . h ()) __rand__ ( self : HableT , other : SupportsIntSCU ) -> H special Shorthand for operator . __and__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rand__ ( self : HableT , other : SupportsIntSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( other , self . h ()) __rfloordiv__ ( self : HableT , other : RealLikeSCU ) -> H special Shorthand for operator . __floordiv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rfloordiv__ ( self : HableT , other : RealLikeSCU ) -> H : # type: ignore r \"\"\" Shorthand for ``#!python operator.__floordiv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( other , self . h ()) __rmod__ ( self : HableT , other : RealLikeSCU ) -> H special Shorthand for operator . __mod__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmod__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( other , self . h ()) __rmul__ ( self : HableT , other : RealLikeSCU ) -> H special Shorthand for operator . __mul__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmul__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( other , self . h ()) __ror__ ( self : HableT , other : SupportsIntSCU ) -> H special Shorthand for operator . __or__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __ror__ ( self : HableT , other : SupportsIntSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( other , self . h ()) __rpow__ ( self : HableT , other : RealLikeSCU ) -> H special Shorthand for operator . __pow__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rpow__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( other , self . h ()) __rsub__ ( self : HableT , other : RealLikeSCU ) -> H special Shorthand for operator . __sub__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rsub__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( other , self . h ()) __rtruediv__ ( self : HableT , other : RealLikeSCU ) -> H special Shorthand for operator . __truediv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rtruediv__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( other , self . h ()) __rxor__ ( self : HableT , other : SupportsIntSCU ) -> H special Shorthand for operator . __xor__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rxor__ ( self : HableT , other : SupportsIntSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( other , self . h ()) __sub__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __sub__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __sub__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( self . h (), other ) __truediv__ ( self : HableT , other : _OperandT ) -> H special Shorthand for operator . __truediv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __truediv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( self . h (), other ) __xor__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H special Shorthand for operator . __xor__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __xor__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( self . h (), other ) eq ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . eq ( other ) . See the h method and H.eq . Source code in dyce/h.py @beartype def eq ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().eq(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other ) explode ( self : HableT , max_depth : SupportsIntSCU = 1 ) -> H Shorthand for self . h () . explode ( max_depth ) . See the h method and H.explode . Source code in dyce/h.py @beartype def explode ( self : HableT , max_depth : SupportsIntSCU = 1 ) -> H : r \"\"\" Shorthand for ``#!python self.h().explode(max_depth)``. See the [``h`` method][dyce.h.HableT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth ) ge ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . ge ( other ) . See the h method and H.ge . Source code in dyce/h.py @beartype def ge ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ge(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other ) gt ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . gt ( other ) . See the h method and H.gt . Source code in dyce/h.py @beartype def gt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().gt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other ) is_even ( self : HableT ) -> H Shorthand for self . h () . is_even () . See the h method and H.is_even . Source code in dyce/h.py @beartype def is_even ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_even()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_even``][dyce.h.H.is_even]. \"\"\" return self . h () . is_even () is_odd ( self : HableT ) -> H Shorthand for self . h () . is_odd () . See the h method and H.is_odd . Source code in dyce/h.py @beartype def is_odd ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_odd()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_odd``][dyce.h.H.is_odd]. \"\"\" return self . h () . is_odd () le ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . le ( other ) . See the h method and H.le . Source code in dyce/h.py @beartype def le ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().le(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other ) lt ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . lt ( other ) . See the h method and H.lt . Source code in dyce/h.py @beartype def lt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().lt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other ) ne ( self : HableT , other : _OperandT ) -> H Shorthand for self . h () . ne ( other ) . See the h method and H.ne . Source code in dyce/h.py @beartype def ne ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ne(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other ) substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = < function coalesce_replace at 0x10697bf70 > , max_depth : SupportsIntSCU = 1 ) -> H Shorthand for self . h () . substitute ( expand , coalesce , max_depth ) . See the h method and H.substitute . Source code in dyce/h.py @beartype def substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsIntSCU = 1 , ) -> H : r \"\"\" Shorthand for ``#!python self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.h.HableT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth ) within ( self : HableT , lo : RealLikeSCU , hi : RealLikeSCU , other : _OperandT = 0 ) -> H Shorthand for self . h () . within ( lo , hi , other ) . See the h method and H.within . Source code in dyce/h.py @beartype def within ( self : HableT , lo : RealLikeSCU , hi : RealLikeSCU , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``#!python self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other ) HableT ( Protocol ) A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users. Info The intended pronunciation of Hable is AYCH-uh-bul 1 (i.e., H -able). Yes, that is a clumsy attempt at verbing . (You could totally H that, dude!) However, if you prefer something else (e.g. HAY-bul or AYCH-AY-bul ), no one is going to judge you. (Well, they might , but they shouldn\u2019t .) We all know what you mean. World Book Online (WBO) style pronunciation respelling . \u21a9 __slots__ : Union [ str , Iterable [ str ]] special __init__ ( self , * args , ** kwargs ) special Source code in dyce/h.py def _no_init ( self , * args , ** kwargs ): raise TypeError ( 'Protocols cannot be instantiated' ) __subclasshook__ ( other ) special Source code in dyce/h.py def _proto_hook ( other ): if not cls . __dict__ . get ( '_is_protocol' , False ): return NotImplemented # First, perform various sanity checks. if not getattr ( cls , '_is_runtime_protocol' , False ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Instance and class checks can only be used with\" \" @runtime_checkable protocols\" ) if not _is_callable_members_only ( cls ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Protocols with non-method members\" \" don't support issubclass()\" ) if not isinstance ( other , type ): # Same error message as for issubclass(1, int). raise TypeError ( 'issubclass() arg 1 must be a class' ) # Second, perform the actual structural compatibility check. for attr in _get_protocol_attrs ( cls ): for base in other . __mro__ : # Check if the members appears in the class dictionary... if attr in base . __dict__ : if base . __dict__ [ attr ] is None : return NotImplemented break # ...or in annotations, if it is a sub-protocol. annotations = getattr ( base , '__annotations__' , {}) if ( isinstance ( annotations , collections . abc . Mapping ) and attr in annotations and issubclass ( other , Generic ) and other . _is_protocol ): break else : return NotImplemented return True h ( self ) -> H Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ... coalesce_replace ( h : H , outcome : RealLikeSCU ) -> H Default behavior for H.substitute . Returns h unmodified ( outcome is ignored). Source code in dyce/h.py def coalesce_replace ( h : H , outcome : RealLikeSCU ) -> H : r \"\"\" Default behavior for [``H.substitute``][dyce.h.H.substitute]. Returns *h* unmodified (*outcome* is ignored). \"\"\" return h sum_h ( hs : Iterable [ H ]) Shorthand for H ({}) if h_sum == 0 else sum ( hs ) . This is to ensure that summing zero or more histograms always returns a histograms. Source code in dyce/h.py @beartype def sum_h ( hs : Iterable [ H ]): \"\"\" Shorthand for ``#!python H({}) if h_sum == 0 else sum(hs)``. This is to ensure that summing zero or more histograms always returns a histograms. \"\"\" h_sum = sum ( hs ) return H ({}) if h_sum == 0 else h_sum","title":"<tt>dyce.h</tt>"},{"location":"dyce.h/#dyceh-package-reference","text":"","title":"dyce.h package reference"},{"location":"dyce.h/#dyce.h.HableOpsMixin","text":"A \u201cmix-in\u201d class providing arithmetic operations for implementers of the HableT protocol . The P class derives from this class. Info See HableT for notes on pronunciation.","title":"HableOpsMixin"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__slots__","text":"","title":"__slots__"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__abs__","text":"Shorthand for operator . __abs__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __abs__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__abs__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __abs__ ( self . h ())","title":"__abs__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__add__","text":"Shorthand for operator . __add__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __add__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( self . h (), other )","title":"__add__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__and__","text":"Shorthand for operator . __and__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __and__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( self . h (), other )","title":"__and__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__floordiv__","text":"Shorthand for operator . __floordiv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __floordiv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__floordiv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( self . h (), other )","title":"__floordiv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__invert__","text":"Shorthand for operator . __invert__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __invert__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__invert__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __invert__ ( self . h ())","title":"__invert__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__mod__","text":"Shorthand for operator . __mod__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mod__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( self . h (), other )","title":"__mod__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__mul__","text":"Shorthand for operator . __mul__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __mul__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( self . h (), other )","title":"__mul__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__neg__","text":"Shorthand for operator . __neg__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __neg__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__neg__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __neg__ ( self . h ())","title":"__neg__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__or__","text":"Shorthand for operator . __or__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __or__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( self . h (), other )","title":"__or__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__pos__","text":"Shorthand for operator . __pos__ ( self . h ()) . See the h method . Source code in dyce/h.py @beartype def __pos__ ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pos__(self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pos__ ( self . h ())","title":"__pos__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__pow__","text":"Shorthand for operator . __pow__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __pow__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( self . h (), other )","title":"__pow__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__radd__","text":"Shorthand for operator . __add__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __radd__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__add__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __add__ ( other , self . h ())","title":"__radd__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rand__","text":"Shorthand for operator . __and__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rand__ ( self : HableT , other : SupportsIntSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__and__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __and__ ( other , self . h ())","title":"__rand__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rfloordiv__","text":"Shorthand for operator . __floordiv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rfloordiv__ ( self : HableT , other : RealLikeSCU ) -> H : # type: ignore r \"\"\" Shorthand for ``#!python operator.__floordiv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __floordiv__ ( other , self . h ())","title":"__rfloordiv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rmod__","text":"Shorthand for operator . __mod__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmod__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__mod__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mod__ ( other , self . h ())","title":"__rmod__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rmul__","text":"Shorthand for operator . __mul__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rmul__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__mul__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __mul__ ( other , self . h ())","title":"__rmul__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__ror__","text":"Shorthand for operator . __or__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __ror__ ( self : HableT , other : SupportsIntSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__or__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __or__ ( other , self . h ())","title":"__ror__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rpow__","text":"Shorthand for operator . __pow__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rpow__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__pow__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __pow__ ( other , self . h ())","title":"__rpow__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rsub__","text":"Shorthand for operator . __sub__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rsub__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( other , self . h ())","title":"__rsub__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rtruediv__","text":"Shorthand for operator . __truediv__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rtruediv__ ( self : HableT , other : RealLikeSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( other , self . h ())","title":"__rtruediv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__rxor__","text":"Shorthand for operator . __xor__ ( other , self . h ()) . See the h method . Source code in dyce/h.py @beartype def __rxor__ ( self : HableT , other : SupportsIntSCU ) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(other, self.h())``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( other , self . h ())","title":"__rxor__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__sub__","text":"Shorthand for operator . __sub__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __sub__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__sub__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __sub__ ( self . h (), other )","title":"__sub__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__truediv__","text":"Shorthand for operator . __truediv__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __truediv__ ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python operator.__truediv__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __truediv__ ( self . h (), other )","title":"__truediv__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.__xor__","text":"Shorthand for operator . __xor__ ( self . h (), other ) . See the h method . Source code in dyce/h.py @beartype def __xor__ ( self : HableT , other : Union [ SupportsIntSCU , H , HableT ]) -> H : r \"\"\" Shorthand for ``#!python operator.__xor__(self.h(), other)``. See the [``h`` method][dyce.h.HableT.h]. \"\"\" return __xor__ ( self . h (), other )","title":"__xor__()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.eq","text":"Shorthand for self . h () . eq ( other ) . See the h method and H.eq . Source code in dyce/h.py @beartype def eq ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().eq(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.eq``][dyce.h.H.eq]. \"\"\" return self . h () . eq ( other )","title":"eq()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.explode","text":"Shorthand for self . h () . explode ( max_depth ) . See the h method and H.explode . Source code in dyce/h.py @beartype def explode ( self : HableT , max_depth : SupportsIntSCU = 1 ) -> H : r \"\"\" Shorthand for ``#!python self.h().explode(max_depth)``. See the [``h`` method][dyce.h.HableT.h] and [``H.explode``][dyce.h.H.explode]. \"\"\" return self . h () . explode ( max_depth )","title":"explode()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.ge","text":"Shorthand for self . h () . ge ( other ) . See the h method and H.ge . Source code in dyce/h.py @beartype def ge ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ge(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ge``][dyce.h.H.ge]. \"\"\" return self . h () . ge ( other )","title":"ge()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.gt","text":"Shorthand for self . h () . gt ( other ) . See the h method and H.gt . Source code in dyce/h.py @beartype def gt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().gt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.gt``][dyce.h.H.gt]. \"\"\" return self . h () . gt ( other )","title":"gt()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.is_even","text":"Shorthand for self . h () . is_even () . See the h method and H.is_even . Source code in dyce/h.py @beartype def is_even ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_even()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_even``][dyce.h.H.is_even]. \"\"\" return self . h () . is_even ()","title":"is_even()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.is_odd","text":"Shorthand for self . h () . is_odd () . See the h method and H.is_odd . Source code in dyce/h.py @beartype def is_odd ( self : HableT ) -> H : r \"\"\" Shorthand for ``#!python self.h().is_odd()``. See the [``h`` method][dyce.h.HableT.h] and [``H.is_odd``][dyce.h.H.is_odd]. \"\"\" return self . h () . is_odd ()","title":"is_odd()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.le","text":"Shorthand for self . h () . le ( other ) . See the h method and H.le . Source code in dyce/h.py @beartype def le ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().le(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.le``][dyce.h.H.le]. \"\"\" return self . h () . le ( other )","title":"le()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.lt","text":"Shorthand for self . h () . lt ( other ) . See the h method and H.lt . Source code in dyce/h.py @beartype def lt ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().lt(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.lt``][dyce.h.H.lt]. \"\"\" return self . h () . lt ( other )","title":"lt()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.ne","text":"Shorthand for self . h () . ne ( other ) . See the h method and H.ne . Source code in dyce/h.py @beartype def ne ( self : HableT , other : _OperandT ) -> H : r \"\"\" Shorthand for ``#!python self.h().ne(other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.ne``][dyce.h.H.ne]. \"\"\" return self . h () . ne ( other )","title":"ne()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.substitute","text":"Shorthand for self . h () . substitute ( expand , coalesce , max_depth ) . See the h method and H.substitute . Source code in dyce/h.py @beartype def substitute ( self : HableT , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsIntSCU = 1 , ) -> H : r \"\"\" Shorthand for ``#!python self.h().substitute(expand, coalesce, max_depth)``. See the [``h`` method][dyce.h.HableT.h] and [``H.substitute``][dyce.h.H.substitute]. \"\"\" return self . h () . substitute ( expand , coalesce , max_depth )","title":"substitute()"},{"location":"dyce.h/#dyce.h.HableOpsMixin.within","text":"Shorthand for self . h () . within ( lo , hi , other ) . See the h method and H.within . Source code in dyce/h.py @beartype def within ( self : HableT , lo : RealLikeSCU , hi : RealLikeSCU , other : _OperandT = 0 ) -> H : r \"\"\" Shorthand for ``#!python self.h().within(lo, hi, other)``. See the [``h`` method][dyce.h.HableT.h] and [``H.within``][dyce.h.H.within]. \"\"\" return self . h () . within ( lo , hi , other )","title":"within()"},{"location":"dyce.h/#dyce.h.HableT","text":"A protocol whose implementer can be expressed as (or reduced to) an H object by calling its h method . Currently, only the P class implements this protocol, but this affords an integration point for dyce users. Info The intended pronunciation of Hable is AYCH-uh-bul 1 (i.e., H -able). Yes, that is a clumsy attempt at verbing . (You could totally H that, dude!) However, if you prefer something else (e.g. HAY-bul or AYCH-AY-bul ), no one is going to judge you. (Well, they might , but they shouldn\u2019t .) We all know what you mean. World Book Online (WBO) style pronunciation respelling . \u21a9","title":"HableT"},{"location":"dyce.h/#dyce.h.HableT.__slots__","text":"","title":"__slots__"},{"location":"dyce.h/#dyce.h.HableT.__init__","text":"Source code in dyce/h.py def _no_init ( self , * args , ** kwargs ): raise TypeError ( 'Protocols cannot be instantiated' )","title":"__init__()"},{"location":"dyce.h/#dyce.h.HableT.__subclasshook__","text":"Source code in dyce/h.py def _proto_hook ( other ): if not cls . __dict__ . get ( '_is_protocol' , False ): return NotImplemented # First, perform various sanity checks. if not getattr ( cls , '_is_runtime_protocol' , False ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Instance and class checks can only be used with\" \" @runtime_checkable protocols\" ) if not _is_callable_members_only ( cls ): if _allow_reckless_class_cheks (): return NotImplemented raise TypeError ( \"Protocols with non-method members\" \" don't support issubclass()\" ) if not isinstance ( other , type ): # Same error message as for issubclass(1, int). raise TypeError ( 'issubclass() arg 1 must be a class' ) # Second, perform the actual structural compatibility check. for attr in _get_protocol_attrs ( cls ): for base in other . __mro__ : # Check if the members appears in the class dictionary... if attr in base . __dict__ : if base . __dict__ [ attr ] is None : return NotImplemented break # ...or in annotations, if it is a sub-protocol. annotations = getattr ( base , '__annotations__' , {}) if ( isinstance ( annotations , collections . abc . Mapping ) and attr in annotations and issubclass ( other , Generic ) and other . _is_protocol ): break else : return NotImplemented return True","title":"__subclasshook__()"},{"location":"dyce.h/#dyce.h.HableT.h","text":"Express its implementer as an H object . Source code in dyce/h.py def h ( self ) -> H : r \"\"\" Express its implementer as an [``H`` object][dyce.h.H]. \"\"\" ...","title":"h()"},{"location":"dyce.h/#dyce.h.coalesce_replace","text":"Default behavior for H.substitute . Returns h unmodified ( outcome is ignored). Source code in dyce/h.py def coalesce_replace ( h : H , outcome : RealLikeSCU ) -> H : r \"\"\" Default behavior for [``H.substitute``][dyce.h.H.substitute]. Returns *h* unmodified (*outcome* is ignored). \"\"\" return h","title":"coalesce_replace()"},{"location":"dyce.h/#dyce.h.sum_h","text":"Shorthand for H ({}) if h_sum == 0 else sum ( hs ) . This is to ensure that summing zero or more histograms always returns a histograms. Source code in dyce/h.py @beartype def sum_h ( hs : Iterable [ H ]): \"\"\" Shorthand for ``#!python H({}) if h_sum == 0 else sum(hs)``. This is to ensure that summing zero or more histograms always returns a histograms. \"\"\" h_sum = sum ( hs ) return H ({}) if h_sum == 0 else h_sum","title":"sum_h()"},{"location":"dyce/","text":"dyce package reference dyce provides several core primitives: H \u2013 histograms (outcomes or individual dice) P \u2013 collections of histograms (pools) R \u2013 scalars, histograms, pools, operators, etc. for assembling roller trees (see dyce.r for details) H ( Mapping , Generic ) An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode finite discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, a denominator is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derived, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ). 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed. 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative). 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps. 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes. 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand. 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes. 1 2 >>> len ( 2 @d6 ) 11 The total property can be used to compute the total number of combinations and each outcome\u2019s probability. 1 2 3 4 5 >>> from fractions import Fraction >>> ( 2 @d6 ) . total 36 >>> [( outcome , Fraction ( count , ( 2 @d6 ) . total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ) ; d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method . 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands. 1 2 >>> d6 . ge ( 4 ) == d6 . ge ( 4 ) . lowest_terms () True __slots__ : Union [ str , Iterable [ str ]] special total : int property readonly Experimental This propertyshould be considered experimental and may change or disappear in future versions. Equivalent to sum ( self . counts ()) . __abs__ ( self ) -> H special Source code in dyce/h.py @beartype def __abs__ ( self ) -> H : return self . umap ( __abs__ ) __add__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __add__ ( self , other : _OperandT ) -> H : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented __and__ ( self , other : Union [ SupportsIntSCU , 'H' , 'HableT' ]) -> H special Source code in dyce/h.py @beartype def __and__ ( self , other : Union [ SupportsIntSCU , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __eq__ ( self , other ) -> bool special Source code in dyce/h.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __eq__ ( self , other . h ()) elif isinstance ( other , H ): return __eq__ ( self . lowest_terms () . _h , other . lowest_terms () . _h ) else : return super () . __eq__ ( other ) __floordiv__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __floordiv__ ( self , other : _OperandT ) -> H : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented __getitem__ ( self , key : RealLikeSCU ) -> int special Source code in dyce/h.py @beartype def __getitem__ ( self , key : RealLikeSCU ) -> int : return __getitem__ ( self . _h , key ) __hash__ ( self ) -> int special Return hash(self). Source code in dyce/h.py @beartype def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ())) __init__ ( self , items : _SourceT ) -> None special Initializer. Source code in dyce/h.py @beartype def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ RealLikeSCU ] = counter () if isinstance ( items , MappingC ): items = items . items () if isinstance ( items , SupportsIntSCT ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , RealLikeSCT ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) # type: ignore else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HableT ): tmp . update ( items . h ()) elif isinstance ( items , IterableC ): # items is either an Iterable[RealLikeSCU] or an Iterable[Tuple[RealLikeSCU, # SupportsIntSCU]] (although this technically supports # Iterable[Union[RealLikeSCU, Tuple[RealLikeSCU, SupportsIntSCU]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 } __invert__ ( self ) -> H special Source code in dyce/h.py @beartype def __invert__ ( self ) -> H : return self . umap ( __invert__ ) __iter__ ( self ) -> Iterator [ RealLikeSCU ] special Source code in dyce/h.py @beartype def __iter__ ( self ) -> Iterator [ RealLikeSCU ]: return iter ( self . _h ) __len__ ( self ) -> int special Source code in dyce/h.py @beartype def __len__ ( self ) -> int : return len ( self . _h ) __matmul__ ( self , other : SupportsIntSCU ) -> H special Source code in dyce/h.py @beartype def __matmul__ ( self , other : SupportsIntSCU ) -> H : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return sum_h ( repeat ( self , other )) __mod__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __mod__ ( self , other : _OperandT ) -> H : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented __mul__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __mul__ ( self , other : _OperandT ) -> H : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented __ne__ ( self , other ) -> bool special Source code in dyce/h.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __ne__ ( self , other . h ()) elif isinstance ( other , H ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) __neg__ ( self ) -> H special Source code in dyce/h.py @beartype def __neg__ ( self ) -> H : return self . umap ( __neg__ ) __or__ ( self , other : Union [ SupportsIntSCU , 'H' , 'HableT' ]) -> H special Source code in dyce/h.py @beartype def __or__ ( self , other : Union [ SupportsIntSCU , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __pos__ ( self ) -> H special Source code in dyce/h.py @beartype def __pos__ ( self ) -> H : return self . umap ( __pos__ ) __pow__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __pow__ ( self , other : _OperandT ) -> H : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented __radd__ ( self , other : RealLikeSCU ) -> H special Source code in dyce/h.py @beartype def __radd__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented __rand__ ( self , other : SupportsIntSCU ) -> H special Source code in dyce/h.py @beartype def __rand__ ( self , other : SupportsIntSCU ) -> H : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented __repr__ ( self ) -> str special Source code in dyce/h.py @beartype def __repr__ ( self ) -> str : if self . _simple_init is not None : arg = str ( self . _simple_init ) else : arg = dict . __repr__ ( self . _h ) return f \" { type ( self ) . __name__ } ( { arg } )\" __rfloordiv__ ( self , other : RealLikeSCU ) -> H special Source code in dyce/h.py @beartype def __rfloordiv__ ( self , other : RealLikeSCU ) -> H : # type: ignore try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented __rmatmul__ ( self , other : SupportsIntSCU ) -> H special Source code in dyce/h.py @beartype def __rmatmul__ ( self , other : SupportsIntSCU ) -> H : return self . __matmul__ ( other ) __rmod__ ( self , other : RealLikeSCU ) -> H special Source code in dyce/h.py @beartype def __rmod__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented __rmul__ ( self , other : RealLikeSCU ) -> H special Source code in dyce/h.py @beartype def __rmul__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented __ror__ ( self , other : SupportsIntSCU ) -> H special Source code in dyce/h.py @beartype def __ror__ ( self , other : SupportsIntSCU ) -> H : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented __rpow__ ( self , other : RealLikeSCU ) -> H special Source code in dyce/h.py @beartype def __rpow__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented __rsub__ ( self , other : RealLikeSCU ) -> H special Source code in dyce/h.py @beartype def __rsub__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented __rtruediv__ ( self , other : RealLikeSCU ) -> H special Source code in dyce/h.py @beartype def __rtruediv__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented __rxor__ ( self , other : SupportsIntSCU ) -> H special Source code in dyce/h.py @beartype def __rxor__ ( self , other : SupportsIntSCU ) -> H : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented __sub__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __sub__ ( self , other : _OperandT ) -> H : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented __truediv__ ( self , other : _OperandT ) -> H special Source code in dyce/h.py @beartype def __truediv__ ( self , other : _OperandT ) -> H : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented __xor__ ( self , other : Union [ SupportsIntSCU , 'H' , 'HableT' ]) -> H special Source code in dyce/h.py @beartype def __xor__ ( self , other : Union [ SupportsIntSCU , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __xor__ , other ) except NotImplementedError : return NotImplemented accumulate ( self , other : _SourceT ) -> H Accumulates counts. 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py @beartype def accumulate ( self , other : _SourceT ) -> H : r \"\"\" Accumulates counts. ``` python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , MappingC ): other = other . items () elif not isinstance ( other , IterableC ): other = cast ( Iterable [ RealLikeSCU ], ( other ,)) return type ( self )( chain ( self . items (), cast ( Iterable , other ))) counts ( self ) -> ValuesView [ int ] More descriptive synonym for the values method . Source code in dyce/h.py @beartype def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . _h . values () distribution ( self , fill_items : Optional [ _MappingT ] = None , rational_t : _RationalInitializerT [ _T ] = < class ' fractions . Fraction '>) -> Iterator[Tuple[RealLikeSCU, _T]] Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. 1 2 3 4 5 >>> h = H (( 1 , 2 , 3 , 3 , 4 , 4 , 5 , 6 )) >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . ge ( 3 ) . distribution ()) [( False , Fraction ( 1 , 4 )), ( True , Fraction ( 3 , 4 ))] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes. 1 2 3 4 >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . distribution ( fill_items = { 0 : 0 , 7 : 0 })) [( 0 , Fraction ( 0 , 1 )), ( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 )), ( 7 , Fraction ( 0 , 1 ))] Experimental The rational_t argument to this method should be considered experimental and may change or disappear in future versions. If provided, rational_t must be a callable that takes two int s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. 1 2 >>> list ( h . distribution ( rational_t = lambda n , d : f \" { n } / { d } \" )) [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '2/8' ), ( 4 , '2/8' ), ( 5 , '1/8' ), ( 6 , '1/8' )] 1 2 3 >>> import sympy >>> list ( h . distribution ( rational_t = sympy . Rational )) [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> list ( h . distribution ( rational_t = lambda n , d : sage . rings . rational . Rational (( n , d )))) # doctest: +SKIP [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] Note The arguments passed to rational_t are not reduced to the lowest terms. The rational_t argument is a convenience. Iteration or comprehension can be used to accomplish something similar. 1 2 >>> [( outcome , f \" { probability . numerator } / { probability . denominator } \" ) for outcome , probability in ( h ) . distribution ()] [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '1/4' ), ( 4 , '1/4' ), ( 5 , '1/8' ), ( 6 , '1/8' )] Many number implementations can convert directly from fractions . Fraction s. 1 2 3 >>> import sympy.abc >>> [( outcome , sympy . Rational ( probability )) for outcome , probability in ( h + sympy . abc . x ) . distribution ()] [( x + 1 , 1 / 8 ), ( x + 2 , 1 / 8 ), ( x + 3 , 1 / 4 ), ( x + 4 , 1 / 4 ), ( x + 5 , 1 / 8 ), ( x + 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> [( outcome , sage . rings . rational . Rational ( probability )) for outcome , probability in h . distribution ()] # doctest: +SKIP [( 1 , 1 / 6 ), ( 2 , 1 / 6 ), ( 3 , 1 / 3 ), ( 4 , 1 / 3 ), ( 5 , 1 / 6 ), ( 6 , 1 / 6 )] Source code in dyce/h.py @experimental @beartype def distribution ( self , fill_items : Optional [ _MappingT ] = None , # TODO(posita): See <https://github.com/python/mypy/issues/10854> for context on # all the @overload work-around nonsense above and remove those once that issue # is addressed. rational_t : _RationalInitializerT [ _T ] = cast ( _RationalInitializerT , Fraction ), ) -> Iterator [ Tuple [ RealLikeSCU , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. ``` python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes. ``` python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` !!! warning \"Experimental\" The *rational_t* argument to this method should be considered experimental and may change or disappear in future versions. If provided, *rational_t* must be a callable that takes two ``#!python int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. ``` python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] ``` ``` python >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` !!! note The arguments passed to *rational_t* are not reduced to the lowest terms. The *rational_t* argument is a convenience. Iteration or comprehension can be used to accomplish something similar. ``` python >>> [(outcome, f\"{probability.numerator}/{probability.denominator}\") for outcome, probability in (h).distribution()] [(1, '1/8'), (2, '1/8'), (3, '1/4'), (4, '1/4'), (5, '1/8'), (6, '1/8')] ``` Many number implementations can convert directly from ``#!python fractions.Fraction``s. ``` python >>> import sympy.abc >>> [(outcome, sympy.Rational(probability)) for outcome, probability in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> [(outcome, sage.rings.rational.Rational(probability)) for outcome, probability in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) ) distribution_xy ( self , fill_items : Optional [ _MappingT ] = None ) -> Tuple [ Tuple [ RealLikeSCU , ... ], Tuple [ float , ... ]] Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method and ensures the values are float s. 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , Fraction ( 1 , 6 )), ( 2 , Fraction ( 1 , 6 )), ( 3 , Fraction ( 1 , 6 )), ( 4 , Fraction ( 1 , 6 )), ( 5 , Fraction ( 1 , 6 )), ( 6 , Fraction ( 1 , 6 ))] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py @beartype def distribution_xy ( self , fill_items : Optional [ _MappingT ] = None , ) -> Tuple [ Tuple [ RealLikeSCU , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``#!python float``s. ``` python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" # TODO(posita): See <https://github.com/python/typing/issues/193> return tuple ( # type: ignore zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) ) eq ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __eq__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map and umap methods. Source code in dyce/h.py @beartype def eq ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__eq__, other).umap(bool)``. ``` python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __eq__ , other ) . umap ( bool ) exactly_k_times_in_n ( self , outcome : RealLikeSCU , n : SupportsIntSCU , k : SupportsIntSCU ) -> int Experimental This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where outcome appears exactly k times among n @self . 1 2 3 4 5 6 >>> H ( 6 ) . exactly_k_times_in_n ( outcome = 5 , n = 4 , k = 2 ) 150 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 2 , n = 3 , k = 3 ) 1 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 4 , n = 3 , k = 3 ) 8 Source code in dyce/h.py @experimental @beartype def exactly_k_times_in_n ( self , outcome : RealLikeSCU , n : SupportsIntSCU , k : SupportsIntSCU , ) -> int : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``#!python n@self``. ``` python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) return comb ( n , k ) * c_outcome ** k * ( self . total - c_outcome ) ** ( n - k ) explode ( self , max_depth : SupportsIntSCU = 1 ) -> H Shorthand for self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , operator . __add__ , max_depth ) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py @beartype def explode ( self , max_depth : SupportsIntSCU = 1 ) -> H : r \"\"\" Shorthand for ``#!python self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.__add__, max_depth)``. ``` python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , __add__ , max_depth , ) format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsIntSCU = 88 , scaled : bool = False , tick : str = '#' , sep : str = ' \\n ' ) -> str Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( f \" { ' 65 chars wide -->|' : ->65 } \" ) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py @beartype def format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsIntSCU = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ``` python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ``` python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``#!python True``, horizontal bars are scaled to *width*. ``` python >>> h = (2@H(6)).ge(7) >>> print(f\"{' 65 chars wide -->|':->65}\") ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : RealLikeSCU = float ( self . mean ()) except TypeError : mu = self . mean () if width <= 0 : def _parts () -> Iterator [ str ]: yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 @beartype def lines () -> Iterator [ str ]: yield f \"avg | { mu : 7.2f } \" try : std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except TypeError : pass if self : outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( lines ()) ge ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __ge__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map and umap methods. Source code in dyce/h.py @beartype def ge ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ge__, other).umap(bool)``. ``` python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ge__ , other ) . umap ( bool ) gt ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __gt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def gt ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__gt__, other).umap(bool)``. ``` python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __gt__ , other ) . umap ( bool ) is_even ( self ) -> H Equivalent to self . umap ( dyce . types . is_even ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py @beartype def is_even ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_even)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_even ) is_odd ( self ) -> H Equivalent to self . umap ( dyce . types . is_odd ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py @beartype def is_odd ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_odd)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_odd ) items ( self ) -> ItemsView [ RealLikeSCU , int ] D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py @beartype def items ( self ) -> ItemsView [ RealLikeSCU , int ]: # TODO(posita): See <https://github.com/python/typeshed/issues/5808> return self . _h . items () # type: ignore keys ( self ) -> KeysView [ RealLikeSCU ] D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py @beartype def keys ( self ) -> KeysView [ RealLikeSCU ]: return self . outcomes () le ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __le__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def le ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__le__, other).umap(bool)``. ``` python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __le__ , other ) . umap ( bool ) lowest_terms ( self ) -> H Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )) ; df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d6avg = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d6avg H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d6avg . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py @beartype def lowest_terms ( self ) -> H : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ``` python >>> df = H((-1, -1, 0, 0, 1, 1)) ; df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ``` python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return type ( self )( self . _lowest_terms ()) lt ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __lt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map and umap methods. Source code in dyce/h.py @beartype def lt ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__lt__, other).umap(bool)``. ``` python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __lt__ , other ) . umap ( bool ) map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT ) -> H Applies bin_op to each outcome of the histogram as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . __add__ , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . __add__ , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . __pow__ , 2 ) H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 }) >>> d6 . map ( operator . __pow__ , 2 ) == d6 ** 2 True 1 2 3 4 >>> d6 . map ( operator . __gt__ , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . __gt__ , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT , ) -> H : r \"\"\" Applies *bin_op* to each outcome of the histogram as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> d6 = H(6) >>> d6.map(operator.__add__, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.__add__, d6) == d6 + d6 True ``` ``` python >>> d6.map(operator.__pow__, 2) H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1}) >>> d6.map(operator.__pow__, 2) == d6 ** 2 True ``` ``` python >>> d6.map(operator.__gt__, 3) H({False: 3, True: 3}) >>> d6.map(operator.__gt__, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( right_operand , HableT ): right_operand = right_operand . h () if isinstance ( right_operand , H ): return type ( self )( ( bin_op ( s , o ), self [ s ] * right_operand [ o ]) for s , o in product ( self , right_operand ) ) else : return type ( self )( ( bin_op ( outcome , right_operand ), count ) for outcome , count in self . items () ) mean ( self ) -> RealLikeSCU Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py @beartype def mean ( self ) -> RealLikeSCU : r \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 ) ne ( self , other : _OperandT ) -> H Shorthand for self . map ( operator . __ne__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map and umap methods. Source code in dyce/h.py @beartype def ne ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ne__, other).umap(bool)``. ``` python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ne__ , other ) . umap ( bool ) order_stat_for_n_at_pos ( self , n : SupportsIntSCU , pos : SupportsIntSCU ) -> H Experimental This method should be considered experimental and may change or disappear in future versions. Shorthand for self . order_stat_func_for_n ( n )( pos ) . Source code in dyce/h.py @experimental @beartype def order_stat_for_n_at_pos ( self , n : SupportsIntSCU , pos : SupportsIntSCU ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Shorthand for ``#!python self.order_stat_func_for_n(n)(pos)``. \"\"\" return self . order_stat_func_for_n ( n )( pos ) order_stat_func_for_n ( self , n : SupportsIntSCU ) -> Callable [[ SupportsIntSCU ], 'H' ] Experimental This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument ( pos ) and computes the probability distribution for each outcome appearing in that position among n @self . 1 2 3 4 >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> order_stat_for_5d6avg = d6avg . order_stat_func_for_n ( 5 ) >>> order_stat_for_5d6avg ( 3 ) # counts where outcome appears at index 3 H ({ 2 : 26 , 3 : 1432 , 4 : 4792 , 5 : 1526 }) The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where 2 appears at the fourth (index 3 ) position, 1432 ways where 3 appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. 1 2 3 4 >>> from dyce import P >>> p_5d6avg = 5 @P ( d6avg ) >>> sum ( count for roll , count in p_5d6avg . rolls_with_counts () if roll [ 3 ] == 5 ) 1526 This method exists in addition to the H.order_stat_for_n_at_pos method because computing the betas for each outcome in n is unnecessary for each pos . Where different pos values are needed for the same n (e.g., in a loop) and where n is large, that overhead can be significant. The returned function caches those betas for n such that repeated querying or results at pos can be computed much faster. 1 2 3 4 5 6 7 In [ 2 ]: % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 100 , i ) for i in range ( 10 )] 1.61 s \u00b1 31.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 3 ]: %% timeit ... : order_stat_for_100d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 100 ) ... : [ order_stat_for_100d6_at_pos ( i ) for i in range ( 10 )] 170 ms \u00b1 3.41 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Source code in dyce/h.py @experimental @beartype def order_stat_func_for_n ( self , n : SupportsIntSCU ) -> Callable [[ SupportsIntSCU ], \"H\" ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``#!python n@self``. ``` python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``#!python 2`` appears at the fourth (index ``#!python 3``) position, 1432 ways where ``#!python 3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. ``` python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster. ``` python In [2]: %timeit [H(6).order_stat_for_n_at_pos(100, i) for i in range(10)] 1.61 s \u00b1 31.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [3]: %%timeit ...: order_stat_for_100d6_at_pos = H(6).order_stat_func_for_n(100) ...: [order_stat_for_100d6_at_pos(i) for i in range(10)] 170 ms \u00b1 3.41 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) ``` \"\"\" betas_by_outcome : Dict [ RealLikeSCU , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ RealLikeSCU , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) @beartype def order_stat_for_n_at_pos ( pos : SupportsIntSCU ) -> H : return type ( self )( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos outcomes ( self ) -> KeysView [ RealLikeSCU ] More descriptive synonym for the keys method . Source code in dyce/h.py @beartype def outcomes ( self ) -> KeysView [ RealLikeSCU ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" # TODO(posita): See <https://github.com/python/typeshed/issues/5808> return self . _h . keys () # type: ignore rmap ( self , left_operand : RealLikeSCU , bin_op : _BinaryOperatorT ) -> H Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . rmap ( 2 , operator . __pow__ ) H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 }) >>> d6 . rmap ( 2 , operator . __pow__ ) == 2 ** d6 True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/h.py @beartype def rmap ( self , left_operand : RealLikeSCU , bin_op : _BinaryOperatorT , ) -> H : r \"\"\" Analogous to the [``map`` method][dyce.h.H.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> d6 = H(6) >>> d6.rmap(2, operator.__pow__) H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1}) >>> d6.rmap(2, operator.__pow__) == 2 ** d6 True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.h.H.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" return type ( self )( ( bin_op ( left_operand , outcome ), count ) for outcome , count in self . items () ) roll ( self ) -> RealLikeSCU Returns a (weighted) random outcome, sorted. Source code in dyce/h.py @beartype def roll ( self ) -> RealLikeSCU : r \"\"\" Returns a (weighted) random outcome, sorted. \"\"\" return ( rng . RNG . choices ( population = tuple ( self . outcomes ()), weights = tuple ( self . counts ()), k = 1 , )[ 0 ] if self else 0 ) stdev ( self , mu : Optional [ RealLikeSCU ] = None ) -> RealLikeSCU Shorthand for math . sqrt ( self . variance ( mu )) . Source code in dyce/h.py @beartype def stdev ( self , mu : Optional [ RealLikeSCU ] = None ) -> RealLikeSCU : r \"\"\" Shorthand for ``#!python math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu )) substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = < function coalesce_replace at 0x10697bf70 > , max_depth : SupportsIntSCU = 1 ) -> H Calls expand on each outcome, recursively up to max_depth times. If expand returns a number, it replaces the outcome. If it returns an H object , coalesce is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. See coalesce_replace and the lowest_terms method . This method can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution. 1 2 3 4 5 6 7 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , outcome : - h if outcome == 4 else outcome ) ; sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( count for outcome , count in orig . items () if outcome == 4 ) / orig . total 0.4 >>> sum ( count for outcome , count in sub . items () if outcome < 0 ) / sub . total 0.4 An important exception If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. 1 2 >>> H ( 6 ) . substitute ( lambda h , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda h , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . __add__ , max_depth = 6 ) >>> h_even = h . is_even () >>> print ( f \" { h_even [ 1 ] / h_even . total : .3% } \" ) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | Source code in dyce/h.py @beartype def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsIntSCU = 1 , ) -> H : r \"\"\" Calls *expand* on each outcome, recursively up to *max_depth* times. If *expand* returns a number, it replaces the outcome. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. See [``coalesce_replace``][dyce.h.coalesce_replace] and the [``lowest_terms`` method][dyce.h.H.lowest_terms]. This method can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ``` python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution. ``` python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, outcome: -h if outcome == 4 else outcome) ; sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(count for outcome, count in orig.items() if outcome == 4) / orig.total 0.4 >>> sum(count for outcome, count in sub.items() if outcome < 0) / sub.total 0.4 ``` !!! note \"An important exception\" If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. ``` python >>> H(6).substitute(lambda h, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda h, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``#!python substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ``` python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.__add__, max_depth=6) >>> h_even = h.is_even() >>> print(f\"{h_even[1] / h_even.total:.3%}\") 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. ``` python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=65, scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` \"\"\" max_depth = as_int ( max_depth ) if max_depth < 0 : raise ValueError ( \"max_depth cannot be negative\" ) def _substitute ( h : H , depth : int = 0 ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ RealLikeSCU , int , int ]] = [] for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , outcome ) # Account for the impact of expansion on peers expanded_scalar = expanded . total if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) else : items_for_reassembly . append (( expanded , count , 1 )) return type ( self )( ( # Apply the total_scalar, but factor out this item's contribution ( outcome , count * total_scalar // s ) for outcome , count , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self ) umap ( self , un_op : _UnaryOperatorT ) -> H Applies un_op to each outcome of the histogram. 1 2 3 >>> import operator >>> H ( 6 ) . umap ( operator . __neg__ ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> H : r \"\"\" Applies *un_op* to each outcome of the histogram. ``` python >>> import operator >>> H(6).umap(operator.__neg__) H(-6) ``` ``` python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = type ( self )(( un_op ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : simple_init = un_op ( self . _simple_init ) if isinstance ( simple_init , SupportsIntSCT ): h_simple = type ( self )( simple_init ) if h_simple == h : return h_simple return h values ( self ) -> ValuesView [ int ] D.values() -> an object providing a view on D's values Source code in dyce/h.py @beartype def values ( self ) -> ValuesView [ int ]: return self . counts () variance ( self , mu : Optional [ RealLikeSCU ] = None ) -> RealLikeSCU Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py @beartype def variance ( self , mu : Optional [ RealLikeSCU ] = None ) -> RealLikeSCU : r \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 ) vs ( self , other : _OperandT ) -> H Compares the histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self . within ( 0 , 0 , other ) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py @beartype def vs ( self , other : _OperandT ) -> H : r \"\"\" Compares the histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``#!python self.within(0, 0, other)``. ``` python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other ) within ( self , lo : RealLikeSCU , hi : RealLikeSCU , other : _OperandT = 0 ) -> H Computes the difference between the histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py @beartype def within ( self , lo : RealLikeSCU , hi : RealLikeSCU , other : _OperandT = 0 ) -> H : r \"\"\" Computes the difference between the histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ``` python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other ) P ( Sequence , Generic , HableOpsMixin ) An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). 1 2 3 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True This class implements the HableT protocol and derives from the HableOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using arithmetic operations. 1 2 >>> - p_d6 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) To perform arithmetic on individual H objects in a pool without flattening, use the map , rmap , and umap methods. 1 2 3 >>> import operator >>> P ( 4 , 6 , 8 ) . umap ( operator . __neg__ ) P ( - 8 , - 6 , - 4 ) 1 2 >>> P ( 4 , 6 ) . map ( operator . __pow__ , 2 ) P ( H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 }), H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 })) 1 2 >>> P ( 4 , 6 ) . rmap ( 2 , operator . __pow__ ) P ( H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 }), H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 })) Comparisons with H objects work as expected. 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram. 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering. 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HableT protocol , the h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ### __slots__ : Union [ str , Iterable [ str ]] special is_homogeneous : bool property readonly Experimental This property should be considered experimental and may change or disappear in future versions. A flag indicating whether the pool\u2019s population of histograms is homogeneous. 1 2 3 4 >>> P ( 6 , 6 ) . is_homogeneous True >>> P ( 4 , 6 , 8 ) . is_homogeneous False __eq__ ( self , other ) -> bool special Source code in dyce/p.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , P ): return __eq__ ( self . _hs , other . _hs ) else : return NotImplemented __getitem__ ( self , key : _GetItemT ) -> Union [ H , 'P' ] special Source code in dyce/p.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( self , key : _GetItemT ) -> Union [ H , \"P\" ]: # type: ignore if isinstance ( key , slice ): return P ( * self . _hs [ key ]) else : return self . _hs [ __index__ ( key )] __init__ ( self , * args : Union [ SupportsIntSCU , 'P' , H ]) -> None special Initializer. Source code in dyce/p.py @beartype def __init__ ( self , * args : Union [ SupportsIntSCU , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs () -> Iterator [ H ]: for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h elif isinstance ( a , SupportsIntSCT ): yield H ( a ) else : raise ValueError ( f \"unrecognized initializer { args } \" ) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs ) __iter__ ( self ) -> Iterator [ H ] special Source code in dyce/p.py @beartype def __iter__ ( self ) -> Iterator [ H ]: return iter ( self . _hs ) __len__ ( self ) -> int special Source code in dyce/p.py @beartype def __len__ ( self ) -> int : return len ( self . _hs ) __matmul__ ( self , other : SupportsIntSCU ) -> P special Source code in dyce/p.py @beartype def __matmul__ ( self , other : SupportsIntSCU ) -> P : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return P ( * chain . from_iterable ( repeat ( self , other ))) __ne__ ( self , other ) -> bool special Source code in dyce/p.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , P ): return __ne__ ( self . _hs , other . _hs ) else : return NotImplemented __repr__ ( self ) -> str special Source code in dyce/p.py @beartype def __repr__ ( self ) -> str : def _parts () -> Iterator [ str ]: for h in self : yield ( str ( h . _simple_init ) if h . _simple_init is not None else repr ( h )) args = \", \" . join ( _parts ()) return f \" { type ( self ) . __name__ } ( { args } )\" __rmatmul__ ( self , other : SupportsIntSCU ) -> P special Source code in dyce/p.py @beartype def __rmatmul__ ( self , other : SupportsIntSCU ) -> P : return self . __matmul__ ( other ) appearances_in_rolls ( self , outcome : RealLikeSCU ) -> H Experimental This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H (( sum ( 1 for v in roll if v == outcome ), count ) for roll , count in self . rolls_with_counts ()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being almost twice (about \\(\\frac{7}{4}\\) ) as efficient as the boolean accumulation technique for larger sets. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 In [ 3 ]: % timeit 3 @d4_eq3 + 2 @d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 4 ]: % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 402 \u00b5s \u00b1 5.59 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 5 ]: % timeit 9 @d4_eq3 + 6 @d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 6 ]: % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 597 \u00b5s \u00b1 9.46 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 7 ]: % timeit 90 @d4_eq3 + 60 @d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 8 ]: % timeit P ( 90 @P ( 4 ), 60 @P ( 6 )) . appearances_in_rolls ( 3 ) 7.5 ms \u00b1 84.6 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) In [ 9 ]: % timeit 900 @d4_eq3 + 600 @d6_eq3 3.34 s \u00b1 19.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 10 ]: % timeit P ( 900 @P ( 4 ), 600 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.93 s \u00b1 14.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py @experimental @beartype def appearances_in_rolls ( self , outcome : RealLikeSCU ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``#!python H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ``` python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ``` python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being almost twice (about $\\frac{7}{4}$) as efficient as the boolean accumulation technique for larger sets. ``` python In [3]: %timeit 3@d4_eq3 + 2@d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [4]: %timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3) 402 \u00b5s \u00b1 5.59 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [5]: %timeit 9@d4_eq3 + 6@d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [6]: %timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3) 597 \u00b5s \u00b1 9.46 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [7]: %timeit 90@d4_eq3 + 60@d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [8]: %timeit P(90@P(4), 60@P(6)).appearances_in_rolls(3) 7.5 ms \u00b1 84.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) In [9]: %timeit 900@d4_eq3 + 600@d6_eq3 3.34 s \u00b1 19.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [10]: %timeit P(900@P(4), 600@P(6)).appearances_in_rolls(3) 1.93 s \u00b1 14.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" group_counters : List [ Counter [ RealLikeSCU ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ RealLikeSCU ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_h ( H ( group_counter ) for group_counter in group_counters ) h ( self , * which : _GetItemT ) -> H Roughly equivalent to H (( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which )) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HableT protocol . 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( width = 65 , scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d6avg + d6avg True Source code in dyce/p.py @beartype def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``#!python H((sum(roll), count) for roll, count in self.rolls_with_counts(*which))`` with some short-circuit optimizations. When provided no arguments, ``#!python h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HableT`` protocol][dyce.h.HableT]. ``` python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ``` python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ``` python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(width=65, scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_h ( self ) map ( self , op : _BinaryOperatorT , right_operand : _OperandT ) -> P Shorthand for P ( * ( h . map ( op , right_operand ) for h in self )) . See the H.map method . 1 2 3 4 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . map ( operator . __mul__ , - 1 ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) Source code in dyce/p.py @beartype def map ( self , op : _BinaryOperatorT , right_operand : _OperandT , ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.map(op, right_operand) for h in self))``. See the [``H.map`` method][dyce.h.H.map]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.map(operator.__mul__, -1) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) ``` \"\"\" return P ( * ( h . map ( op , right_operand ) for h in self )) rmap ( self , left_operand : RealLikeSCU , op : _BinaryOperatorT ) -> P Shorthand for P ( * ( h . rmap ( left_operand , op ) for h in self )) . See the H.rmap method . 1 2 3 4 5 >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( Fraction ) . rmap ( 1 , operator . __truediv__ ) P ( H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 }), H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 })) Source code in dyce/p.py @beartype def rmap ( self , left_operand : RealLikeSCU , op : _BinaryOperatorT , ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.rmap(left_operand, op) for h in self))``. See the [``H.rmap`` method][dyce.h.H.rmap]. ``` python >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(Fraction).rmap(1, operator.__truediv__) P(H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1}), H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1})) ``` \"\"\" return P ( * ( h . rmap ( left_operand , op ) for h in self )) roll ( self ) -> _RollT Returns (weighted) random outcomes from contained histograms. On ordering This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. Source code in dyce/p.py @beartype def roll ( self ) -> _RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. !!! note \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self )) rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ] Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, ( 1 , 2 ) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d6avg + d6avg True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable. 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted. 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) . \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n @P ( H ( m )) . Enumerating combinations with replacements would yield all unique rolls. (( 1 , 1 , \u2026 , 1 ), ( 1 , 1 , \u2026 , 2 ), \u2026 , ( 1 , 1 , \u2026 , m ), \u2026 , ( m - 1 , m , \u2026 , m ), ( m , m , \u2026 , m )) To determine the count for a particular roll ( a , b , \u2026 , n ) , we compute the multinomial coefficient for that roll and multiply by the scalar H ( m )[ a ] * H ( m )[ b ] * \u2026 * H ( m )[ n ] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Source code in dyce/p.py @beartype def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed for more flexible selections. ``` python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. ``` python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ``` python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``#!python (1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ``` python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. ``` python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable. ``` python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted. ``` python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ``` python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$. $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``#!python n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls. ``#!python ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``#!python (a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``#!python H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ```ipython In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count umap ( self , op : _UnaryOperatorT ) -> P Shorthand for P ( * ( h . umap ( op ) for h in self )) . See the H.umap method . 1 2 3 4 5 6 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( operator . __neg__ ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) >>> p_3d6 . umap ( operator . __abs__ ) P ( H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 })) Source code in dyce/p.py @beartype def umap ( self , op : _UnaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.umap(op) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(operator.__neg__) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) >>> p_3d6.umap(operator.__abs__) P(H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1})) ``` \"\"\" return P ( * ( h . umap ( op ) for h in self ))","title":"<tt>dyce</tt>"},{"location":"dyce/#dyce-package-reference","text":"dyce provides several core primitives: H \u2013 histograms (outcomes or individual dice) P \u2013 collections of histograms (pools) R \u2013 scalars, histograms, pools, operators, etc. for assembling roller trees (see dyce.r for details)","title":"dyce package reference"},{"location":"dyce/#dyce.h.H","text":"An immutable mapping for use as a histogram which supports arithmetic operations. This is useful for modeling discrete outcomes, like individual dice. H objects encode finite discrete probability distributions as integer counts without any denominator. Info The lack of an explicit denominator is intentional and has two benefits. First, a denominator is redundant. Without it, one never has to worry about probabilities summing to one (e.g., via miscalculation, floating point error, etc.). Second (and perhaps more importantly), sometimes one wants to have an insight into non-reduced counts, not just probabilities. If needed, probabilities can always be derived, as shown below. The initializer takes a single parameter, items . In its most explicit form, items maps outcome values to counts. Modeling a single six-sided die ( 1d6 ) can be expressed as: 1 2 >>> from dyce import H >>> d6 = H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 }) An iterable of pairs can also be used (similar to dict ). 1 2 >>> d6 == H ((( 1 , 1 ), ( 2 , 1 ), ( 3 , 1 ), ( 4 , 1 ), ( 5 , 1 ), ( 6 , 1 ))) True Two shorthands are provided. If items is an iterable of numbers, counts of 1 are assumed. 1 2 >>> d6 == H (( 1 , 2 , 3 , 4 , 5 , 6 )) True Repeated items are accumulated, as one would expect. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) If items is an integer, it is shorthand for creating a sequential range \\([{1} .. {items}]\\) (or \\([{items} .. {-1}]\\) if items is negative). 1 2 >>> d6 == H ( 6 ) True Histograms are maps, so we can test equivalence against other maps. 1 2 >>> H ( 6 ) == { 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 } True Simple indexes can be used to look up an outcome\u2019s count. 1 2 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 ))[ 3 ] 2 Most arithmetic operators are supported and do what one would expect. If the operand is a number, the operator applies to the outcomes. 1 2 >>> d6 + 4 H ({ 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 , 10 : 1 }) 1 2 3 4 5 6 >>> d6 * - 1 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) >>> d6 * - 1 == - d6 True >>> d6 * - 1 == H ( - 6 ) True If the operand is another histogram, combinations are computed. Modeling the sum of two six-sided dice ( 2d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> d6 + d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> print (( d6 + d6 ) . format ( width = 65 )) avg | 7.00 std | 2.42 var | 5.83 2 | 2.78 % | # 3 | 5.56 % | ## 4 | 8.33 % | #### 5 | 11.11 % | ##### 6 | 13.89 % | ###### 7 | 16.67 % | ######## 8 | 13.89 % | ###### 9 | 11.11 % | ##### 10 | 8.33 % | #### 11 | 5.56 % | ## 12 | 2.78 % | # To sum \\({n}\\) identical histograms, the matrix multiplication operator ( @ ) provides a shorthand. 1 2 >>> 3 @d6 == d6 + d6 + d6 True The len built-in function can be used to show the number of distinct outcomes. 1 2 >>> len ( 2 @d6 ) 11 The total property can be used to compute the total number of combinations and each outcome\u2019s probability. 1 2 3 4 5 >>> from fractions import Fraction >>> ( 2 @d6 ) . total 36 >>> [( outcome , Fraction ( count , ( 2 @d6 ) . total )) for outcome , count in ( 2 @d6 ) . items ()] [( 2 , Fraction ( 1 , 36 )), ( 3 , Fraction ( 1 , 18 )), ( 4 , Fraction ( 1 , 12 )), ( 5 , Fraction ( 1 , 9 )), ( 6 , Fraction ( 5 , 36 )), ( 7 , Fraction ( 1 , 6 )), ... , ( 12 , Fraction ( 1 , 36 ))] Histograms provide common comparators (e.g., eq ne , etc.). One way to count how often a first six-sided die shows a different face than a second is: 1 2 3 4 5 6 7 8 >>> d6 . ne ( d6 ) H ({ False : 6 , True : 30 }) >>> print ( d6 . ne ( d6 ) . format ( width = 65 )) avg | 0.83 std | 0.37 var | 0.14 0 | 16.67 % | ######## 1 | 83.33 % | ######################################### Or, how often a first six-sided die shows a face less than a second is: 1 2 3 4 5 6 7 8 >>> d6 . lt ( d6 ) H ({ False : 21 , True : 15 }) >>> print ( d6 . lt ( d6 ) . format ( width = 65 )) avg | 0.42 std | 0.49 var | 0.24 0 | 58.33 % | ############################# 1 | 41.67 % | #################### Or how often at least one 2 will show when rolling four six-sided dice: 1 2 3 4 5 6 7 8 9 10 11 12 >>> d6_eq2 = d6 . eq ( 2 ) ; d6_eq2 # how often a 2 shows on a single six-sided die H ({ False : 5 , True : 1 }) >>> 4 @d6_eq2 # count of 2s showing on 4d6 H ({ 0 : 625 , 1 : 500 , 2 : 150 , 3 : 20 , 4 : 1 }) >>> ( 4 @d6_eq2 ) . ge ( 1 ) # how often that count is at least one H ({ False : 625 , True : 671 }) >>> print (( 4 @d6_eq2 ) . ge ( 1 ) . format ( width = 65 )) avg | 0.52 std | 0.50 var | 0.25 0 | 48.23 % | ######################## 1 | 51.77 % | ######################### Mind your parentheses Parentheses are often necessary to enforce the desired order of operations. This is most often an issue with the @ operator, because it behaves differently than the d operator in most dedicated grammars. More specifically, in Python, @ has a lower precedence than . and [ \u2026 ] . 1 2 3 4 5 6 7 8 >>> 2 @d6 [ 7 ] # type: ignore Traceback ( most recent call last ): ... KeyError : 7 >>> 2 @d6 . le ( 7 ) # probably not what was intended H ({ 2 : 36 }) >>> 2 @d6 . le ( 7 ) == 2 @ ( d6 . le ( 7 )) True 1 2 3 4 5 6 >>> ( 2 @d6 )[ 7 ] 6 >>> ( 2 @d6 ) . le ( 7 ) H ({ False : 15 , True : 21 }) >>> 2 @d6 . le ( 7 ) == ( 2 @d6 ) . le ( 7 ) False Counts are generally accumulated without reduction. To reduce, call the lowest_terms method . 1 2 3 4 >>> d6 . ge ( 4 ) H ({ False : 3 , True : 3 }) >>> d6 . ge ( 4 ) . lowest_terms () H ({ False : 1 , True : 1 }) Testing equivalence implicitly performs reductions of operands. 1 2 >>> d6 . ge ( 4 ) == d6 . ge ( 4 ) . lowest_terms () True","title":"H"},{"location":"dyce/#dyce.h.H.__slots__","text":"","title":"__slots__"},{"location":"dyce/#dyce.h.H.total","text":"Experimental This propertyshould be considered experimental and may change or disappear in future versions. Equivalent to sum ( self . counts ()) .","title":"total"},{"location":"dyce/#dyce.h.H.__abs__","text":"Source code in dyce/h.py @beartype def __abs__ ( self ) -> H : return self . umap ( __abs__ )","title":"__abs__()"},{"location":"dyce/#dyce.h.H.__add__","text":"Source code in dyce/h.py @beartype def __add__ ( self , other : _OperandT ) -> H : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented","title":"__add__()"},{"location":"dyce/#dyce.h.H.__and__","text":"Source code in dyce/h.py @beartype def __and__ ( self , other : Union [ SupportsIntSCU , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__and__()"},{"location":"dyce/#dyce.h.H.__eq__","text":"Source code in dyce/h.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __eq__ ( self , other . h ()) elif isinstance ( other , H ): return __eq__ ( self . lowest_terms () . _h , other . lowest_terms () . _h ) else : return super () . __eq__ ( other )","title":"__eq__()"},{"location":"dyce/#dyce.h.H.__floordiv__","text":"Source code in dyce/h.py @beartype def __floordiv__ ( self , other : _OperandT ) -> H : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented","title":"__floordiv__()"},{"location":"dyce/#dyce.h.H.__getitem__","text":"Source code in dyce/h.py @beartype def __getitem__ ( self , key : RealLikeSCU ) -> int : return __getitem__ ( self . _h , key )","title":"__getitem__()"},{"location":"dyce/#dyce.h.H.__hash__","text":"Return hash(self). Source code in dyce/h.py @beartype def __hash__ ( self ) -> int : return hash ( frozenset ( self . _lowest_terms ()))","title":"__hash__()"},{"location":"dyce/#dyce.h.H.__init__","text":"Initializer. Source code in dyce/h.py @beartype def __init__ ( self , items : _SourceT ) -> None : r \"Initializer.\" super () . __init__ () self . _simple_init : Optional [ int ] = None tmp : Counter [ RealLikeSCU ] = counter () if isinstance ( items , MappingC ): items = items . items () if isinstance ( items , SupportsIntSCT ): if items != 0 : self . _simple_init = as_int ( items ) outcome_range = range ( self . _simple_init , 0 , 1 if self . _simple_init < 0 else - 1 , # count toward zero ) if isinstance ( items , RealLikeSCT ): outcome_type = type ( items ) tmp . update ({ outcome_type ( i ): 1 for i in outcome_range }) # type: ignore else : tmp . update ({ i : 1 for i in outcome_range }) elif isinstance ( items , HableT ): tmp . update ( items . h ()) elif isinstance ( items , IterableC ): # items is either an Iterable[RealLikeSCU] or an Iterable[Tuple[RealLikeSCU, # SupportsIntSCU]] (although this technically supports # Iterable[Union[RealLikeSCU, Tuple[RealLikeSCU, SupportsIntSCU]]]) for item in items : if isinstance ( item , tuple ): outcome , count = item tmp [ outcome ] += as_int ( count ) else : tmp [ item ] += 1 else : raise ValueError ( f \"unrecognized initializer { items } \" ) # Sort and omit zero counts. As of Python 3.7, insertion order of keys is # preserved. self . _h : _MappingT = { outcome : tmp [ outcome ] for outcome in sorted_outcomes ( tmp ) if tmp [ outcome ] != 0 }","title":"__init__()"},{"location":"dyce/#dyce.h.H.__invert__","text":"Source code in dyce/h.py @beartype def __invert__ ( self ) -> H : return self . umap ( __invert__ )","title":"__invert__()"},{"location":"dyce/#dyce.h.H.__iter__","text":"Source code in dyce/h.py @beartype def __iter__ ( self ) -> Iterator [ RealLikeSCU ]: return iter ( self . _h )","title":"__iter__()"},{"location":"dyce/#dyce.h.H.__len__","text":"Source code in dyce/h.py @beartype def __len__ ( self ) -> int : return len ( self . _h )","title":"__len__()"},{"location":"dyce/#dyce.h.H.__matmul__","text":"Source code in dyce/h.py @beartype def __matmul__ ( self , other : SupportsIntSCU ) -> H : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return sum_h ( repeat ( self , other ))","title":"__matmul__()"},{"location":"dyce/#dyce.h.H.__mod__","text":"Source code in dyce/h.py @beartype def __mod__ ( self , other : _OperandT ) -> H : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented","title":"__mod__()"},{"location":"dyce/#dyce.h.H.__mul__","text":"Source code in dyce/h.py @beartype def __mul__ ( self , other : _OperandT ) -> H : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented","title":"__mul__()"},{"location":"dyce/#dyce.h.H.__ne__","text":"Source code in dyce/h.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , HableT ): return __ne__ ( self , other . h ()) elif isinstance ( other , H ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other )","title":"__ne__()"},{"location":"dyce/#dyce.h.H.__neg__","text":"Source code in dyce/h.py @beartype def __neg__ ( self ) -> H : return self . umap ( __neg__ )","title":"__neg__()"},{"location":"dyce/#dyce.h.H.__or__","text":"Source code in dyce/h.py @beartype def __or__ ( self , other : Union [ SupportsIntSCU , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__or__()"},{"location":"dyce/#dyce.h.H.__pos__","text":"Source code in dyce/h.py @beartype def __pos__ ( self ) -> H : return self . umap ( __pos__ )","title":"__pos__()"},{"location":"dyce/#dyce.h.H.__pow__","text":"Source code in dyce/h.py @beartype def __pow__ ( self , other : _OperandT ) -> H : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented","title":"__pow__()"},{"location":"dyce/#dyce.h.H.__radd__","text":"Source code in dyce/h.py @beartype def __radd__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented","title":"__radd__()"},{"location":"dyce/#dyce.h.H.__rand__","text":"Source code in dyce/h.py @beartype def __rand__ ( self , other : SupportsIntSCU ) -> H : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rand__()"},{"location":"dyce/#dyce.h.H.__repr__","text":"Source code in dyce/h.py @beartype def __repr__ ( self ) -> str : if self . _simple_init is not None : arg = str ( self . _simple_init ) else : arg = dict . __repr__ ( self . _h ) return f \" { type ( self ) . __name__ } ( { arg } )\"","title":"__repr__()"},{"location":"dyce/#dyce.h.H.__rfloordiv__","text":"Source code in dyce/h.py @beartype def __rfloordiv__ ( self , other : RealLikeSCU ) -> H : # type: ignore try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented","title":"__rfloordiv__()"},{"location":"dyce/#dyce.h.H.__rmatmul__","text":"Source code in dyce/h.py @beartype def __rmatmul__ ( self , other : SupportsIntSCU ) -> H : return self . __matmul__ ( other )","title":"__rmatmul__()"},{"location":"dyce/#dyce.h.H.__rmod__","text":"Source code in dyce/h.py @beartype def __rmod__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented","title":"__rmod__()"},{"location":"dyce/#dyce.h.H.__rmul__","text":"Source code in dyce/h.py @beartype def __rmul__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented","title":"__rmul__()"},{"location":"dyce/#dyce.h.H.__ror__","text":"Source code in dyce/h.py @beartype def __ror__ ( self , other : SupportsIntSCU ) -> H : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__ror__()"},{"location":"dyce/#dyce.h.H.__rpow__","text":"Source code in dyce/h.py @beartype def __rpow__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented","title":"__rpow__()"},{"location":"dyce/#dyce.h.H.__rsub__","text":"Source code in dyce/h.py @beartype def __rsub__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented","title":"__rsub__()"},{"location":"dyce/#dyce.h.H.__rtruediv__","text":"Source code in dyce/h.py @beartype def __rtruediv__ ( self , other : RealLikeSCU ) -> H : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented","title":"__rtruediv__()"},{"location":"dyce/#dyce.h.H.__rxor__","text":"Source code in dyce/h.py @beartype def __rxor__ ( self , other : SupportsIntSCU ) -> H : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rxor__()"},{"location":"dyce/#dyce.h.H.__sub__","text":"Source code in dyce/h.py @beartype def __sub__ ( self , other : _OperandT ) -> H : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented","title":"__sub__()"},{"location":"dyce/#dyce.h.H.__truediv__","text":"Source code in dyce/h.py @beartype def __truediv__ ( self , other : _OperandT ) -> H : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented","title":"__truediv__()"},{"location":"dyce/#dyce.h.H.__xor__","text":"Source code in dyce/h.py @beartype def __xor__ ( self , other : Union [ SupportsIntSCU , \"H\" , \"HableT\" ]) -> H : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __xor__ , other ) except NotImplementedError : return NotImplemented","title":"__xor__()"},{"location":"dyce/#dyce.h.H.accumulate","text":"Accumulates counts. 1 2 >>> H ( 4 ) . accumulate ( H ( 6 )) H ({ 1 : 2 , 2 : 2 , 3 : 2 , 4 : 2 , 5 : 1 , 6 : 1 }) Source code in dyce/h.py @beartype def accumulate ( self , other : _SourceT ) -> H : r \"\"\" Accumulates counts. ``` python >>> H(4).accumulate(H(6)) H({1: 2, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1}) ``` \"\"\" if isinstance ( other , MappingC ): other = other . items () elif not isinstance ( other , IterableC ): other = cast ( Iterable [ RealLikeSCU ], ( other ,)) return type ( self )( chain ( self . items (), cast ( Iterable , other )))","title":"accumulate()"},{"location":"dyce/#dyce.h.H.counts","text":"More descriptive synonym for the values method . Source code in dyce/h.py @beartype def counts ( self ) -> ValuesView [ int ]: r \"\"\" More descriptive synonym for the [``values`` method][dyce.h.H.values]. \"\"\" return self . _h . values ()","title":"counts()"},{"location":"dyce/#dyce.h.H.distribution","text":"Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. 1 2 3 4 5 >>> h = H (( 1 , 2 , 3 , 3 , 4 , 4 , 5 , 6 )) >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . ge ( 3 ) . distribution ()) [( False , Fraction ( 1 , 4 )), ( True , Fraction ( 3 , 4 ))] If provided, fill_items supplies defaults for any \u201cmissing\u201d outcomes. 1 2 3 4 >>> list ( h . distribution ()) [( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 ))] >>> list ( h . distribution ( fill_items = { 0 : 0 , 7 : 0 })) [( 0 , Fraction ( 0 , 1 )), ( 1 , Fraction ( 1 , 8 )), ( 2 , Fraction ( 1 , 8 )), ( 3 , Fraction ( 1 , 4 )), ( 4 , Fraction ( 1 , 4 )), ( 5 , Fraction ( 1 , 8 )), ( 6 , Fraction ( 1 , 8 )), ( 7 , Fraction ( 0 , 1 ))] Experimental The rational_t argument to this method should be considered experimental and may change or disappear in future versions. If provided, rational_t must be a callable that takes two int s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. 1 2 >>> list ( h . distribution ( rational_t = lambda n , d : f \" { n } / { d } \" )) [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '2/8' ), ( 4 , '2/8' ), ( 5 , '1/8' ), ( 6 , '1/8' )] 1 2 3 >>> import sympy >>> list ( h . distribution ( rational_t = sympy . Rational )) [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> list ( h . distribution ( rational_t = lambda n , d : sage . rings . rational . Rational (( n , d )))) # doctest: +SKIP [( 1 , 1 / 8 ), ( 2 , 1 / 8 ), ( 3 , 1 / 4 ), ( 4 , 1 / 4 ), ( 5 , 1 / 8 ), ( 6 , 1 / 8 )] Note The arguments passed to rational_t are not reduced to the lowest terms. The rational_t argument is a convenience. Iteration or comprehension can be used to accomplish something similar. 1 2 >>> [( outcome , f \" { probability . numerator } / { probability . denominator } \" ) for outcome , probability in ( h ) . distribution ()] [( 1 , '1/8' ), ( 2 , '1/8' ), ( 3 , '1/4' ), ( 4 , '1/4' ), ( 5 , '1/8' ), ( 6 , '1/8' )] Many number implementations can convert directly from fractions . Fraction s. 1 2 3 >>> import sympy.abc >>> [( outcome , sympy . Rational ( probability )) for outcome , probability in ( h + sympy . abc . x ) . distribution ()] [( x + 1 , 1 / 8 ), ( x + 2 , 1 / 8 ), ( x + 3 , 1 / 4 ), ( x + 4 , 1 / 4 ), ( x + 5 , 1 / 8 ), ( x + 6 , 1 / 8 )] 1 2 3 >>> import sage.rings.rational # doctest: +SKIP >>> [( outcome , sage . rings . rational . Rational ( probability )) for outcome , probability in h . distribution ()] # doctest: +SKIP [( 1 , 1 / 6 ), ( 2 , 1 / 6 ), ( 3 , 1 / 3 ), ( 4 , 1 / 3 ), ( 5 , 1 / 6 ), ( 6 , 1 / 6 )] Source code in dyce/h.py @experimental @beartype def distribution ( self , fill_items : Optional [ _MappingT ] = None , # TODO(posita): See <https://github.com/python/mypy/issues/10854> for context on # all the @overload work-around nonsense above and remove those once that issue # is addressed. rational_t : _RationalInitializerT [ _T ] = cast ( _RationalInitializerT , Fraction ), ) -> Iterator [ Tuple [ RealLikeSCU , _T ]]: r \"\"\" Presentation helper function returning an iterator for each outcome/count or outcome/probability pair. ``` python >>> h = H((1, 2, 3, 3, 4, 4, 5, 6)) >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.ge(3).distribution()) [(False, Fraction(1, 4)), (True, Fraction(3, 4))] ``` If provided, *fill_items* supplies defaults for any \u201cmissing\u201d outcomes. ``` python >>> list(h.distribution()) [(1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8))] >>> list(h.distribution(fill_items={0: 0, 7: 0})) [(0, Fraction(0, 1)), (1, Fraction(1, 8)), (2, Fraction(1, 8)), (3, Fraction(1, 4)), (4, Fraction(1, 4)), (5, Fraction(1, 8)), (6, Fraction(1, 8)), (7, Fraction(0, 1))] ``` !!! warning \"Experimental\" The *rational_t* argument to this method should be considered experimental and may change or disappear in future versions. If provided, *rational_t* must be a callable that takes two ``#!python int``s (a numerator and denominator) and returns an instance of a desired (but otherwise arbitrary) type. ``` python >>> list(h.distribution(rational_t=lambda n, d: f\"{n}/{d}\")) [(1, '1/8'), (2, '1/8'), (3, '2/8'), (4, '2/8'), (5, '1/8'), (6, '1/8')] ``` ``` python >>> import sympy >>> list(h.distribution(rational_t=sympy.Rational)) [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> list(h.distribution(rational_t=lambda n, d: sage.rings.rational.Rational((n, d)))) # doctest: +SKIP [(1, 1/8), (2, 1/8), (3, 1/4), (4, 1/4), (5, 1/8), (6, 1/8)] ``` !!! note The arguments passed to *rational_t* are not reduced to the lowest terms. The *rational_t* argument is a convenience. Iteration or comprehension can be used to accomplish something similar. ``` python >>> [(outcome, f\"{probability.numerator}/{probability.denominator}\") for outcome, probability in (h).distribution()] [(1, '1/8'), (2, '1/8'), (3, '1/4'), (4, '1/4'), (5, '1/8'), (6, '1/8')] ``` Many number implementations can convert directly from ``#!python fractions.Fraction``s. ``` python >>> import sympy.abc >>> [(outcome, sympy.Rational(probability)) for outcome, probability in (h + sympy.abc.x).distribution()] [(x + 1, 1/8), (x + 2, 1/8), (x + 3, 1/4), (x + 4, 1/4), (x + 5, 1/8), (x + 6, 1/8)] ``` ``` python >>> import sage.rings.rational # doctest: +SKIP >>> [(outcome, sage.rings.rational.Rational(probability)) for outcome, probability in h.distribution()] # doctest: +SKIP [(1, 1/6), (2, 1/6), (3, 1/3), (4, 1/3), (5, 1/6), (6, 1/6)] ``` \"\"\" if fill_items is None : fill_items = {} combined = dict ( chain ( fill_items . items (), self . items ())) total = sum ( combined . values ()) or 1 return ( ( outcome , rational_t ( combined [ outcome ], total )) for outcome in sorted_outcomes ( combined ) )","title":"distribution()"},{"location":"dyce/#dyce.h.H.distribution_xy","text":"Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the distribution method and ensures the values are float s. 1 2 3 4 >>> list ( H ( 6 ) . distribution ()) [( 1 , Fraction ( 1 , 6 )), ( 2 , Fraction ( 1 , 6 )), ( 3 , Fraction ( 1 , 6 )), ( 4 , Fraction ( 1 , 6 )), ( 5 , Fraction ( 1 , 6 )), ( 6 , Fraction ( 1 , 6 ))] >>> H ( 6 ) . distribution_xy () (( 1 , 2 , 3 , 4 , 5 , 6 ), ( 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 , 0.16666666 )) Source code in dyce/h.py @beartype def distribution_xy ( self , fill_items : Optional [ _MappingT ] = None , ) -> Tuple [ Tuple [ RealLikeSCU , ... ], Tuple [ float , ... ]]: r \"\"\" Presentation helper function returning an iterator for a \u201czipped\u201d arrangement of the output from the [``distribution`` method][dyce.h.H.distribution] and ensures the values are ``#!python float``s. ``` python >>> list(H(6).distribution()) [(1, Fraction(1, 6)), (2, Fraction(1, 6)), (3, Fraction(1, 6)), (4, Fraction(1, 6)), (5, Fraction(1, 6)), (6, Fraction(1, 6))] >>> H(6).distribution_xy() ((1, 2, 3, 4, 5, 6), (0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666, 0.16666666)) ``` \"\"\" # TODO(posita): See <https://github.com/python/typing/issues/193> return tuple ( # type: ignore zip ( * ( ( outcome , float ( probability )) for outcome , probability in self . distribution ( fill_items ) ) ) )","title":"distribution_xy()"},{"location":"dyce/#dyce.h.H.eq","text":"Shorthand for self . map ( operator . __eq__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . eq ( 3 ) H ({ False : 5 , True : 1 }) See the map and umap methods. Source code in dyce/h.py @beartype def eq ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__eq__, other).umap(bool)``. ``` python >>> H(6).eq(3) H({False: 5, True: 1}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __eq__ , other ) . umap ( bool )","title":"eq()"},{"location":"dyce/#dyce.h.H.exactly_k_times_in_n","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where outcome appears exactly k times among n @self . 1 2 3 4 5 6 >>> H ( 6 ) . exactly_k_times_in_n ( outcome = 5 , n = 4 , k = 2 ) 150 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 2 , n = 3 , k = 3 ) 1 >>> H (( 2 , 3 , 3 , 4 , 4 , 5 )) . exactly_k_times_in_n ( outcome = 4 , n = 3 , k = 3 ) 8 Source code in dyce/h.py @experimental @beartype def exactly_k_times_in_n ( self , outcome : RealLikeSCU , n : SupportsIntSCU , k : SupportsIntSCU , ) -> int : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Computes and returns the probability distribution where *outcome* appears exactly *k* times among ``#!python n@self``. ``` python >>> H(6).exactly_k_times_in_n(outcome=5, n=4, k=2) 150 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=2, n=3, k=3) 1 >>> H((2, 3, 3, 4, 4, 5)).exactly_k_times_in_n(outcome=4, n=3, k=3) 8 ``` \"\"\" n = as_int ( n ) k = as_int ( k ) assert k <= n c_outcome = self . get ( outcome , 0 ) return comb ( n , k ) * c_outcome ** k * ( self . total - c_outcome ) ** ( n - k )","title":"exactly_k_times_in_n()"},{"location":"dyce/#dyce.h.H.explode","text":"Shorthand for self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , operator . __add__ , max_depth ) . 1 2 >>> H ( 6 ) . explode ( max_depth = 2 ) H ({ 1 : 36 , 2 : 36 , 3 : 36 , 4 : 36 , 5 : 36 , 7 : 6 , 8 : 6 , 9 : 6 , 10 : 6 , 11 : 6 , 13 : 1 , 14 : 1 , 15 : 1 , 16 : 1 , 17 : 1 , 18 : 1 }) See the substitute method . Source code in dyce/h.py @beartype def explode ( self , max_depth : SupportsIntSCU = 1 ) -> H : r \"\"\" Shorthand for ``#!python self.substitute(lambda h, outcome: h if outcome == max(h) else outcome, operator.__add__, max_depth)``. ``` python >>> H(6).explode(max_depth=2) H({1: 36, 2: 36, 3: 36, 4: 36, 5: 36, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1}) ``` See the [``substitute`` method][dyce.h.H.substitute]. \"\"\" return self . substitute ( lambda h , outcome : h if outcome == max ( h ) else outcome , __add__ , max_depth , )","title":"explode()"},{"location":"dyce/#dyce.h.H.format","text":"Returns a formatted string representation of the histogram. If provided, fill_items supplies defaults for any missing outcomes. If width is greater than zero, a horizontal bar ASCII graph is printed using tick and sep (which are otherwise ignored if width is zero or less). 1 2 >>> print ( H ( 6 ) . format ( width = 0 )) { avg : 3.50 , 1 : 16.67 % , 2 : 16.67 % , 3 : 16.67 % , 4 : 16.67 % , 5 : 16.67 % , 6 : 16.67 % } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 >>> print (( 2 @H ( 6 )) . format ( fill_items = { i : 0 for i in range ( 1 , 21 )}, width = 65 , tick = \"@\" )) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00 % | 2 | 2.78 % |@ 3 | 5.56 % |@@ 4 | 8.33 % |@@@@ 5 | 11.11 % |@@@@@ 6 | 13.89 % |@@@@@@ 7 | 16.67 % |@@@@@@@@ 8 | 13.89 % |@@@@@@ 9 | 11.11 % |@@@@@ 10 | 8.33 % |@@@@ 11 | 5.56 % |@@ 12 | 2.78 % |@ 13 | 0.00 % | 14 | 0.00 % | 15 | 0.00 % | 16 | 0.00 % | 17 | 0.00 % | 18 | 0.00 % | 19 | 0.00 % | 20 | 0.00 % | If scaled is True , horizontal bars are scaled to width . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> h = ( 2 @H ( 6 )) . ge ( 7 ) >>> print ( f \" { ' 65 chars wide -->|' : ->65 } \" ) ---------------------------------------------- 65 chars wide -->| >>> print ( h . format ( width = 65 , scaled = False )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | #################### 1 | 58.33 % | ############################# >>> print ( h . format ( width = 65 , scaled = True )) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67 % | ################################### 1 | 58.33 % | ################################################## Source code in dyce/h.py @beartype def format ( self , fill_items : Optional [ _MappingT ] = None , width : SupportsIntSCU = _ROW_WIDTH , scaled : bool = False , tick : str = \"#\" , sep : str = os . linesep , ) -> str : r \"\"\" Returns a formatted string representation of the histogram. If provided, *fill_items* supplies defaults for any missing outcomes. If *width* is greater than zero, a horizontal bar ASCII graph is printed using *tick* and *sep* (which are otherwise ignored if *width* is zero or less). ``` python >>> print(H(6).format(width=0)) {avg: 3.50, 1: 16.67%, 2: 16.67%, 3: 16.67%, 4: 16.67%, 5: 16.67%, 6: 16.67%} ``` ``` python >>> print((2@H(6)).format(fill_items={i: 0 for i in range(1, 21)}, width=65, tick=\"@\")) avg | 7.00 std | 2.42 var | 5.83 1 | 0.00% | 2 | 2.78% |@ 3 | 5.56% |@@ 4 | 8.33% |@@@@ 5 | 11.11% |@@@@@ 6 | 13.89% |@@@@@@ 7 | 16.67% |@@@@@@@@ 8 | 13.89% |@@@@@@ 9 | 11.11% |@@@@@ 10 | 8.33% |@@@@ 11 | 5.56% |@@ 12 | 2.78% |@ 13 | 0.00% | 14 | 0.00% | 15 | 0.00% | 16 | 0.00% | 17 | 0.00% | 18 | 0.00% | 19 | 0.00% | 20 | 0.00% | ``` If *scaled* is ``#!python True``, horizontal bars are scaled to *width*. ``` python >>> h = (2@H(6)).ge(7) >>> print(f\"{' 65 chars wide -->|':->65}\") ---------------------------------------------- 65 chars wide -->| >>> print(h.format(width=65, scaled=False)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |#################### 1 | 58.33% |############################# >>> print(h.format(width=65, scaled=True)) avg | 0.58 std | 0.49 var | 0.24 0 | 41.67% |################################### 1 | 58.33% |################################################## ``` \"\"\" width = as_int ( width ) # We convert various values herein to native ints and floats because number # tower implementations sometimes neglect to implement __format__ properly (or # at all). (I'm looking at you, sage.rings.\u2026!) try : mu : RealLikeSCU = float ( self . mean ()) except TypeError : mu = self . mean () if width <= 0 : def _parts () -> Iterator [ str ]: yield f \"avg: { mu : .2f } \" for ( outcome , probability , ) in self . distribution ( fill_items ): probability_f = float ( probability ) yield f \" { outcome } : { probability_f : 7.2% } \" return \"{\" + \", \" . join ( _parts ()) + \"}\" else : w = width - 15 @beartype def lines () -> Iterator [ str ]: yield f \"avg | { mu : 7.2f } \" try : std = float ( self . stdev ( mu )) var = float ( self . variance ( mu )) yield f \"std | { std : 7.2f } \" yield f \"var | { var : 7.2f } \" except TypeError : pass if self : outcomes , probabilities = self . distribution_xy ( fill_items ) tick_scale = max ( probabilities ) if scaled else 1.0 for outcome , probability in zip ( outcomes , probabilities ): try : outcome_str = f \" { outcome : 3 } \" except ( TypeError , ValueError ): outcome_str = str ( outcome ) outcome_str = f \" { outcome_str : >3 } \" ticks = tick * int ( w * probability / tick_scale ) probability_f = float ( probability ) yield f \" { outcome_str } | { probability_f : 7.2% } | { ticks } \" return sep . join ( lines ())","title":"format()"},{"location":"dyce/#dyce.h.H.ge","text":"Shorthand for self . map ( operator . __ge__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ge ( 3 ) H ({ False : 2 , True : 4 }) See the map and umap methods. Source code in dyce/h.py @beartype def ge ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ge__, other).umap(bool)``. ``` python >>> H(6).ge(3) H({False: 2, True: 4}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ge__ , other ) . umap ( bool )","title":"ge()"},{"location":"dyce/#dyce.h.H.gt","text":"Shorthand for self . map ( operator . __gt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . gt ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def gt ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__gt__, other).umap(bool)``. ``` python >>> H(6).gt(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __gt__ , other ) . umap ( bool )","title":"gt()"},{"location":"dyce/#dyce.h.H.is_even","text":"Equivalent to self . umap ( dyce . types . is_even ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_even () H ({ False : 2 , True : 4 }) See the umap method . Source code in dyce/h.py @beartype def is_even ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_even)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_even() H({False: 2, True: 4}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_even )","title":"is_even()"},{"location":"dyce/#dyce.h.H.is_odd","text":"Equivalent to self . umap ( dyce . types . is_odd ) . 1 2 >>> H (( - 4 , - 2 , 0 , 1 , 2 , 3 )) . is_odd () H ({ False : 4 , True : 2 }) See the umap method . Source code in dyce/h.py @beartype def is_odd ( self ) -> H : r \"\"\" Equivalent to ``#!python self.umap(dyce.types.is_odd)``. ``` python >>> H((-4, -2, 0, 1, 2, 3)).is_odd() H({False: 4, True: 2}) ``` See the [``umap`` method][dyce.h.H.umap]. \"\"\" return self . umap ( is_odd )","title":"is_odd()"},{"location":"dyce/#dyce.h.H.items","text":"D.items() -> a set-like object providing a view on D's items Source code in dyce/h.py @beartype def items ( self ) -> ItemsView [ RealLikeSCU , int ]: # TODO(posita): See <https://github.com/python/typeshed/issues/5808> return self . _h . items () # type: ignore","title":"items()"},{"location":"dyce/#dyce.h.H.keys","text":"D.keys() -> a set-like object providing a view on D's keys Source code in dyce/h.py @beartype def keys ( self ) -> KeysView [ RealLikeSCU ]: return self . outcomes ()","title":"keys()"},{"location":"dyce/#dyce.h.H.le","text":"Shorthand for self . map ( operator . __le__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . le ( 3 ) H ({ False : 3 , True : 3 }) See the map and umap methods. Source code in dyce/h.py @beartype def le ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__le__, other).umap(bool)``. ``` python >>> H(6).le(3) H({False: 3, True: 3}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __le__ , other ) . umap ( bool )","title":"le()"},{"location":"dyce/#dyce.h.H.lowest_terms","text":"Computes and returns a histogram whose counts share a greatest common divisor of 1. 1 2 3 4 >>> df = H (( - 1 , - 1 , 0 , 0 , 1 , 1 )) ; df H ({ - 1 : 2 , 0 : 2 , 1 : 2 }) >>> df . lowest_terms () H ({ - 1 : 1 , 0 : 1 , 1 : 1 }) 1 2 3 4 >>> d6avg = H (( 2 , 2 , 3 , 3 , 3 , 3 , 4 , 4 , 4 , 4 , 5 , 5 )) ; d6avg H ({ 2 : 2 , 3 : 4 , 4 : 4 , 5 : 2 }) >>> d6avg . lowest_terms () H ({ 2 : 1 , 3 : 2 , 4 : 2 , 5 : 1 }) Source code in dyce/h.py @beartype def lowest_terms ( self ) -> H : r \"\"\" Computes and returns a histogram whose counts share a greatest common divisor of 1. ``` python >>> df = H((-1, -1, 0, 0, 1, 1)) ; df H({-1: 2, 0: 2, 1: 2}) >>> df.lowest_terms() H({-1: 1, 0: 1, 1: 1}) ``` ``` python >>> d6avg = H((2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5)) ; d6avg H({2: 2, 3: 4, 4: 4, 5: 2}) >>> d6avg.lowest_terms() H({2: 1, 3: 2, 4: 2, 5: 1}) ``` \"\"\" return type ( self )( self . _lowest_terms ())","title":"lowest_terms()"},{"location":"dyce/#dyce.h.H.lt","text":"Shorthand for self . map ( operator . __lt__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . lt ( 3 ) H ({ False : 4 , True : 2 }) See the map and umap methods. Source code in dyce/h.py @beartype def lt ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__lt__, other).umap(bool)``. ``` python >>> H(6).lt(3) H({False: 4, True: 2}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __lt__ , other ) . umap ( bool )","title":"lt()"},{"location":"dyce/#dyce.h.H.map","text":"Applies bin_op to each outcome of the histogram as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . map ( operator . __add__ , d6 ) H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) >>> d6 . map ( operator . __add__ , d6 ) == d6 + d6 True 1 2 3 4 >>> d6 . map ( operator . __pow__ , 2 ) H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 }) >>> d6 . map ( operator . __pow__ , 2 ) == d6 ** 2 True 1 2 3 4 >>> d6 . map ( operator . __gt__ , 3 ) H ({ False : 3 , True : 3 }) >>> d6 . map ( operator . __gt__ , 3 ) == d6 . gt ( 3 ) True Source code in dyce/h.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _OperandT , ) -> H : r \"\"\" Applies *bin_op* to each outcome of the histogram as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> d6 = H(6) >>> d6.map(operator.__add__, d6) H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) >>> d6.map(operator.__add__, d6) == d6 + d6 True ``` ``` python >>> d6.map(operator.__pow__, 2) H({1: 1, 4: 1, 9: 1, 16: 1, 25: 1, 36: 1}) >>> d6.map(operator.__pow__, 2) == d6 ** 2 True ``` ``` python >>> d6.map(operator.__gt__, 3) H({False: 3, True: 3}) >>> d6.map(operator.__gt__, 3) == d6.gt(3) True ``` \"\"\" if isinstance ( right_operand , HableT ): right_operand = right_operand . h () if isinstance ( right_operand , H ): return type ( self )( ( bin_op ( s , o ), self [ s ] * right_operand [ o ]) for s , o in product ( self , right_operand ) ) else : return type ( self )( ( bin_op ( outcome , right_operand ), count ) for outcome , count in self . items () )","title":"map()"},{"location":"dyce/#dyce.h.H.mean","text":"Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). Source code in dyce/h.py @beartype def mean ( self ) -> RealLikeSCU : r \"\"\" Returns the mean of the weighted outcomes (or 0.0 if there are no outcomes). \"\"\" numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += outcome * count denominator += count return numerator / ( denominator or 1 )","title":"mean()"},{"location":"dyce/#dyce.h.H.ne","text":"Shorthand for self . map ( operator . __ne__ , other ) . umap ( bool ) . 1 2 >>> H ( 6 ) . ne ( 3 ) H ({ False : 1 , True : 5 }) See the map and umap methods. Source code in dyce/h.py @beartype def ne ( self , other : _OperandT , ) -> H : r \"\"\" Shorthand for ``#!python self.map(operator.__ne__, other).umap(bool)``. ``` python >>> H(6).ne(3) H({False: 1, True: 5}) ``` See the [``map``][dyce.h.H.map] and [``umap``][dyce.h.H.umap] methods. \"\"\" return self . map ( __ne__ , other ) . umap ( bool )","title":"ne()"},{"location":"dyce/#dyce.h.H.order_stat_for_n_at_pos","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Shorthand for self . order_stat_func_for_n ( n )( pos ) . Source code in dyce/h.py @experimental @beartype def order_stat_for_n_at_pos ( self , n : SupportsIntSCU , pos : SupportsIntSCU ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Shorthand for ``#!python self.order_stat_func_for_n(n)(pos)``. \"\"\" return self . order_stat_func_for_n ( n )( pos )","title":"order_stat_for_n_at_pos()"},{"location":"dyce/#dyce.h.H.order_stat_func_for_n","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument ( pos ) and computes the probability distribution for each outcome appearing in that position among n @self . 1 2 3 4 >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> order_stat_for_5d6avg = d6avg . order_stat_func_for_n ( 5 ) >>> order_stat_for_5d6avg ( 3 ) # counts where outcome appears at index 3 H ({ 2 : 26 , 3 : 1432 , 4 : 4792 , 5 : 1526 }) The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where 2 appears at the fourth (index 3 ) position, 1432 ways where 3 appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. 1 2 3 4 >>> from dyce import P >>> p_5d6avg = 5 @P ( d6avg ) >>> sum ( count for roll , count in p_5d6avg . rolls_with_counts () if roll [ 3 ] == 5 ) 1526 This method exists in addition to the H.order_stat_for_n_at_pos method because computing the betas for each outcome in n is unnecessary for each pos . Where different pos values are needed for the same n (e.g., in a loop) and where n is large, that overhead can be significant. The returned function caches those betas for n such that repeated querying or results at pos can be computed much faster. 1 2 3 4 5 6 7 In [ 2 ]: % timeit [ H ( 6 ) . order_stat_for_n_at_pos ( 100 , i ) for i in range ( 10 )] 1.61 s \u00b1 31.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 3 ]: %% timeit ... : order_stat_for_100d6_at_pos = H ( 6 ) . order_stat_func_for_n ( 100 ) ... : [ order_stat_for_100d6_at_pos ( i ) for i in range ( 10 )] 170 ms \u00b1 3.41 ms per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) Source code in dyce/h.py @experimental @beartype def order_stat_func_for_n ( self , n : SupportsIntSCU ) -> Callable [[ SupportsIntSCU ], \"H\" ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Returns a function that takes a single argument (*pos*) and computes the probability distribution for each outcome appearing in that position among ``#!python n@self``. ``` python >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> order_stat_for_5d6avg = d6avg.order_stat_func_for_n(5) >>> order_stat_for_5d6avg(3) # counts where outcome appears at index 3 H({2: 26, 3: 1432, 4: 4792, 5: 1526}) ``` The results show that, when rolling five six-sided \u201caveraging\u201d dice and sorting each roll, there are 26 ways where ``#!python 2`` appears at the fourth (index ``#!python 3``) position, 1432 ways where ``#!python 3`` appears at the fourth position, etc. This can be verified independently using the computationally expensive method of enumerating rolls and counting those that meet the criteria. ``` python >>> from dyce import P >>> p_5d6avg = 5@P(d6avg) >>> sum(count for roll, count in p_5d6avg.rolls_with_counts() if roll[3] == 5) 1526 ``` This method exists in addition to the [``H.order_stat_for_n_at_pos`` method][dyce.h.H.order_stat_for_n_at_pos] because computing the betas for each outcome in *n* is unnecessary for each *pos*. Where different *pos* values are needed for the same *n* (e.g., in a loop) and where *n* is large, that overhead can be significant. The returned function caches those betas for *n* such that repeated querying or results at *pos* can be computed much faster. ``` python In [2]: %timeit [H(6).order_stat_for_n_at_pos(100, i) for i in range(10)] 1.61 s \u00b1 31.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [3]: %%timeit ...: order_stat_for_100d6_at_pos = H(6).order_stat_func_for_n(100) ...: [order_stat_for_100d6_at_pos(i) for i in range(10)] 170 ms \u00b1 3.41 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) ``` \"\"\" betas_by_outcome : Dict [ RealLikeSCU , Tuple [ H , H ]] = {} for outcome in self . outcomes (): betas_by_outcome [ outcome ] = ( n @ self . le ( outcome ), n @ self . lt ( outcome ), ) def _gen_h_items_at_pos ( pos : int ) -> Iterator [ Tuple [ RealLikeSCU , int ]]: for outcome , ( h_le , h_lt ) in betas_by_outcome . items (): yield ( outcome , h_le . gt ( pos ) . get ( True , 0 ) - h_lt . gt ( pos ) . get ( True , 0 ), ) @beartype def order_stat_for_n_at_pos ( pos : SupportsIntSCU ) -> H : return type ( self )( _gen_h_items_at_pos ( as_int ( pos ))) return order_stat_for_n_at_pos","title":"order_stat_func_for_n()"},{"location":"dyce/#dyce.h.H.outcomes","text":"More descriptive synonym for the keys method . Source code in dyce/h.py @beartype def outcomes ( self ) -> KeysView [ RealLikeSCU ]: r \"\"\" More descriptive synonym for the [``keys`` method][dyce.h.H.keys]. \"\"\" # TODO(posita): See <https://github.com/python/typeshed/issues/5808> return self . _h . keys () # type: ignore","title":"outcomes()"},{"location":"dyce/#dyce.h.H.rmap","text":"Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 >>> import operator >>> d6 = H ( 6 ) >>> d6 . rmap ( 2 , operator . __pow__ ) H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 }) >>> d6 . rmap ( 2 , operator . __pow__ ) == 2 ** d6 True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/h.py @beartype def rmap ( self , left_operand : RealLikeSCU , bin_op : _BinaryOperatorT , ) -> H : r \"\"\" Analogous to the [``map`` method][dyce.h.H.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> d6 = H(6) >>> d6.rmap(2, operator.__pow__) H({2: 1, 4: 1, 8: 1, 16: 1, 32: 1, 64: 1}) >>> d6.rmap(2, operator.__pow__) == 2 ** d6 True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.h.H.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" return type ( self )( ( bin_op ( left_operand , outcome ), count ) for outcome , count in self . items () )","title":"rmap()"},{"location":"dyce/#dyce.h.H.roll","text":"Returns a (weighted) random outcome, sorted. Source code in dyce/h.py @beartype def roll ( self ) -> RealLikeSCU : r \"\"\" Returns a (weighted) random outcome, sorted. \"\"\" return ( rng . RNG . choices ( population = tuple ( self . outcomes ()), weights = tuple ( self . counts ()), k = 1 , )[ 0 ] if self else 0 )","title":"roll()"},{"location":"dyce/#dyce.h.H.stdev","text":"Shorthand for math . sqrt ( self . variance ( mu )) . Source code in dyce/h.py @beartype def stdev ( self , mu : Optional [ RealLikeSCU ] = None ) -> RealLikeSCU : r \"\"\" Shorthand for ``#!python math.sqrt(self.variance(mu))``. \"\"\" return sqrt ( self . variance ( mu ))","title":"stdev()"},{"location":"dyce/#dyce.h.H.substitute","text":"Calls expand on each outcome, recursively up to max_depth times. If expand returns a number, it replaces the outcome. If it returns an H object , coalesce is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for coalesce is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. See coalesce_replace and the lowest_terms method . This method can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: 1 2 3 4 5 >>> def reroll_one ( h : H , outcome ): ... return h if outcome == 1 else outcome >>> H ( 6 ) . substitute ( reroll_one ) H ({ 1 : 1 , 2 : 7 , 3 : 7 , 4 : 7 , 5 : 7 , 6 : 7 }) See the explode method for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution. 1 2 3 4 5 6 7 >>> orig = H ({ 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 }) >>> sub = orig . substitute ( lambda h , outcome : - h if outcome == 4 else outcome ) ; sub H ({ - 4 : 8 , - 3 : 6 , - 2 : 4 , - 1 : 2 , 1 : 5 , 2 : 10 , 3 : 15 }) >>> sum ( count for outcome , count in orig . items () if outcome == 4 ) / orig . total 0.4 >>> sum ( count for outcome , count in sub . items () if outcome < 0 ) / sub . total 0.4 An important exception If coalesce returns the empty histogram ( H({}) ), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. 1 2 >>> H ( 6 ) . substitute ( lambda h , outcome : H ({}) if outcome == 6 else outcome ) H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 }) This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. 1 2 3 4 5 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . vs ( d8_2 ) H ({ - 1 : 4553 , 0 : 1153 , 1 : 8118 }) >>> d6_3 . vs ( d8_2 ) . substitute ( lambda h , outcome : H ({}) if outcome == 0 else outcome ) H ({ - 1 : 4553 , 1 : 8118 }) Because it delegates to a callback for refereeing substitution decisions, substitute is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: Start with a total of zero. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> def reroll_greatest_on_d4_d6 ( h : H , outcome ): ... if outcome == max ( h ): ... if h == d6 : return d4 ... if h == d4 : return d6 ... return outcome >>> import operator >>> h = d6 . substitute ( reroll_greatest_on_d4_d6 , operator . __add__ , max_depth = 6 ) >>> h_even = h . is_even () >>> print ( f \" { h_even [ 1 ] / h_even . total : .3% } \" ) 39.131 % Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being more likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 >>> bonus = 1 >>> dmg_dice = H ( 8 ) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H ( 20 ) >>> def dmg_from_attack_roll ( h : H , outcome ): ... if outcome == 20 : ... return crit ... elif outcome >= target : ... return dmg ... else : ... return 0 >>> h = d20 . substitute ( dmg_from_attack_roll ) >>> print ( h . format ( width = 65 , scaled = True )) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00 % | ################################################## 2 | 3.75 % | ## 3 | 3.83 % | ## 4 | 3.91 % | ### 5 | 3.98 % | ### 6 | 4.06 % | ### 7 | 4.14 % | ### 8 | 4.22 % | ### 9 | 4.30 % | ### 10 | 0.62 % | 11 | 0.55 % | 12 | 0.47 % | 13 | 0.39 % | 14 | 0.31 % | 15 | 0.23 % | 16 | 0.16 % | 17 | 0.08 % | Source code in dyce/h.py @beartype def substitute ( self , expand : _ExpandT , coalesce : _CoalesceT = coalesce_replace , max_depth : SupportsIntSCU = 1 , ) -> H : r \"\"\" Calls *expand* on each outcome, recursively up to *max_depth* times. If *expand* returns a number, it replaces the outcome. If it returns an [``H`` object][dyce.h.H], *coalesce* is called on the outcome and the expanded histogram, and the returned histogram is folded into result. The default behavior for *coalesce* is to replace the outcome with the expanded histogram. Returned histograms are always reduced to their lowest terms. See [``coalesce_replace``][dyce.h.coalesce_replace] and the [``lowest_terms`` method][dyce.h.H.lowest_terms]. This method can be used to model complex rules. The following models re-rolling a face of 1 on the first roll: ``` python >>> def reroll_one(h: H, outcome): ... return h if outcome == 1 else outcome >>> H(6).substitute(reroll_one) H({1: 1, 2: 7, 3: 7, 4: 7, 5: 7, 6: 7}) ``` See the [``explode`` method][dyce.h.H.explode] for a common shorthand for \u201cexploding\u201d dice (i.e., where, if the greatest face come up, the die is re-rolled and the result is added to a running sum). In nearly all cases, when a histogram is substituted for an outcome, it takes on the substituted outcome\u2019s \u201cscale\u201d. In other words, the sum of the counts of the replacement retains the same proportion as the replaced outcome in relation to other outcomes. This becomes clearer when there is no overlap between the original histogram and the substitution. ``` python >>> orig = H({1: 1, 2: 2, 3: 3, 4: 4}) >>> sub = orig.substitute(lambda h, outcome: -h if outcome == 4 else outcome) ; sub H({-4: 8, -3: 6, -2: 4, -1: 2, 1: 5, 2: 10, 3: 15}) >>> sum(count for outcome, count in orig.items() if outcome == 4) / orig.total 0.4 >>> sum(count for outcome, count in sub.items() if outcome < 0) / sub.total 0.4 ``` !!! note \"An important exception\" If *coalesce* returns the empty histogram (``H({})``), the corresponding outcome and its counts are omitted from the result without substitution or scaling. A silly example is modeling a d5 by indefinitely re-rolling a d6 until something other than a 6 comes up. ``` python >>> H(6).substitute(lambda h, outcome: H({}) if outcome == 6 else outcome) H({1: 1, 2: 1, 3: 1, 4: 1, 5: 1}) ``` This technique is more useful when modeling re-rolling certain derived outcomes, like ties in a contest. ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.vs(d8_2) H({-1: 4553, 0: 1153, 1: 8118}) >>> d6_3.vs(d8_2).substitute(lambda h, outcome: H({}) if outcome == 0 else outcome) H({-1: 4553, 1: 8118}) ``` Because it delegates to a callback for refereeing substitution decisions, ``#!python substitute`` is quite flexible and well suited to modeling (or at least approximating) logical progressions. Consider the following rules: 1. Start with a total of zero. 2. Roll a six-sided die. Add the face to the total. If the face was a six, go to step 3. Otherwise stop. 3. Roll a four-sided die. Add the face to the total. If the face was a four, go to step 2. Otherwise stop. What is the likelihood of an even final tally? This can be approximated by: ``` python >>> d4, d6 = H(4), H(6) >>> def reroll_greatest_on_d4_d6(h: H, outcome): ... if outcome == max(h): ... if h == d6: return d4 ... if h == d4: return d6 ... return outcome >>> import operator >>> h = d6.substitute(reroll_greatest_on_d4_d6, operator.__add__, max_depth=6) >>> h_even = h.is_even() >>> print(f\"{h_even[1] / h_even.total:.3%}\") 39.131% ``` Surprised? Because both six and four are even numbers, the only way we keep rolling is if the total is even. You might think this would lead to evens being *more* likely. However, we only care about the final tally and the rules direct us to re-roll certain evens (nudging us toward an odd number more often than not). We can also use this method to model expected damage from a single attack in d20-like role playing games. ``` python >>> bonus = 1 >>> dmg_dice = H(8) >>> dmg = dmg_dice + bonus >>> crit = dmg + dmg_dice >>> target = 15 - bonus >>> d20 = H(20) >>> def dmg_from_attack_roll(h: H, outcome): ... if outcome == 20: ... return crit ... elif outcome >= target: ... return dmg ... else: ... return 0 >>> h = d20.substitute(dmg_from_attack_roll) >>> print(h.format(width=65, scaled=True)) avg | 2.15 std | 3.40 var | 11.55 0 | 65.00% |################################################## 2 | 3.75% |## 3 | 3.83% |## 4 | 3.91% |### 5 | 3.98% |### 6 | 4.06% |### 7 | 4.14% |### 8 | 4.22% |### 9 | 4.30% |### 10 | 0.62% | 11 | 0.55% | 12 | 0.47% | 13 | 0.39% | 14 | 0.31% | 15 | 0.23% | 16 | 0.16% | 17 | 0.08% | ``` \"\"\" max_depth = as_int ( max_depth ) if max_depth < 0 : raise ValueError ( \"max_depth cannot be negative\" ) def _substitute ( h : H , depth : int = 0 ) -> H : assert coalesce is not None if depth == max_depth : return h total_scalar = 1 items_for_reassembly : List [ Tuple [ RealLikeSCU , int , int ]] = [] for outcome , count in h . items (): expanded = expand ( h , outcome ) if isinstance ( expanded , H ): # Keep expanding deeper, if we can expanded = _substitute ( expanded , depth + 1 ) # Coalesce the result expanded = coalesce ( expanded , outcome ) # Account for the impact of expansion on peers expanded_scalar = expanded . total if expanded_scalar : total_scalar *= expanded_scalar # Account for the impact of the original count on the result, but # keep track of the impact on peers so we can factor it out for # these items later items_for_reassembly . extend ( ( exp_f , exp_c * count , expanded_scalar ) for exp_f , exp_c in expanded . items () ) else : items_for_reassembly . append (( expanded , count , 1 )) return type ( self )( ( # Apply the total_scalar, but factor out this item's contribution ( outcome , count * total_scalar // s ) for outcome , count , s in items_for_reassembly ) ) . lowest_terms () return _substitute ( self )","title":"substitute()"},{"location":"dyce/#dyce.h.H.umap","text":"Applies un_op to each outcome of the histogram. 1 2 3 >>> import operator >>> H ( 6 ) . umap ( operator . __neg__ ) H ( - 6 ) 1 2 >>> H ( 4 ) . umap ( lambda outcome : ( - outcome ) ** outcome ) H ({ - 27 : 1 , - 1 : 1 , 4 : 1 , 256 : 1 }) Source code in dyce/h.py @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> H : r \"\"\" Applies *un_op* to each outcome of the histogram. ``` python >>> import operator >>> H(6).umap(operator.__neg__) H(-6) ``` ``` python >>> H(4).umap(lambda outcome: (-outcome) ** outcome) H({-27: 1, -1: 1, 4: 1, 256: 1}) ``` \"\"\" h = type ( self )(( un_op ( outcome ), count ) for outcome , count in self . items ()) if self . _simple_init is not None : simple_init = un_op ( self . _simple_init ) if isinstance ( simple_init , SupportsIntSCT ): h_simple = type ( self )( simple_init ) if h_simple == h : return h_simple return h","title":"umap()"},{"location":"dyce/#dyce.h.H.values","text":"D.values() -> an object providing a view on D's values Source code in dyce/h.py @beartype def values ( self ) -> ValuesView [ int ]: return self . counts ()","title":"values()"},{"location":"dyce/#dyce.h.H.variance","text":"Returns the variance of the weighted outcomes. If provided, mu is used as the mean (to avoid duplicate computation). Source code in dyce/h.py @beartype def variance ( self , mu : Optional [ RealLikeSCU ] = None ) -> RealLikeSCU : r \"\"\" Returns the variance of the weighted outcomes. If provided, *mu* is used as the mean (to avoid duplicate computation). \"\"\" mu = mu if mu else self . mean () numerator : float denominator : float numerator = denominator = 0 for outcome , count in self . items (): numerator += ( outcome - mu ) ** 2 * count denominator += count return numerator / ( denominator or 1 )","title":"variance()"},{"location":"dyce/#dyce.h.H.vs","text":"Compares the histogram with other . -1 represents where other is greater. 0 represents where they are equal. 1 represents where other is less. Shorthand for self . within ( 0 , 0 , other ) . 1 2 3 4 >>> H ( 6 ) . vs ( H ( 4 )) H ({ - 1 : 6 , 0 : 4 , 1 : 14 }) >>> H ( 6 ) . vs ( H ( 4 )) == H ( 6 ) . within ( 0 , 0 , H ( 4 )) True See the within method . Source code in dyce/h.py @beartype def vs ( self , other : _OperandT ) -> H : r \"\"\" Compares the histogram with *other*. -1 represents where *other* is greater. 0 represents where they are equal. 1 represents where *other* is less. Shorthand for ``#!python self.within(0, 0, other)``. ``` python >>> H(6).vs(H(4)) H({-1: 6, 0: 4, 1: 14}) >>> H(6).vs(H(4)) == H(6).within(0, 0, H(4)) True ``` See the [``within`` method][dyce.h.H.within]. \"\"\" return self . within ( 0 , 0 , other )","title":"vs()"},{"location":"dyce/#dyce.h.H.within","text":"Computes the difference between the histogram and other . -1 represents where that difference is less than lo . 0 represents where that difference between lo and hi (inclusive). 1 represents where that difference is greater than hi . 1 2 3 4 5 6 7 8 9 10 >>> d6_2 = 2 @H ( 6 ) >>> d6_2 . within ( 7 , 9 ) H ({ - 1 : 15 , 0 : 15 , 1 : 6 }) >>> print ( d6_2 . within ( 7 , 9 ) . format ( width = 65 )) avg | - 0.25 std | 0.72 var | 0.52 - 1 | 41.67 % | #################### 0 | 41.67 % | #################### 1 | 16.67 % | ######## 1 2 3 4 5 6 7 8 9 10 >>> d6_3 , d8_2 = 3 @H ( 6 ), 2 @H ( 8 ) >>> d6_3 . within ( - 1 , 1 , d8_2 ) # 3d6 w/in 1 of 2d8 H ({ - 1 : 3500 , 0 : 3412 , 1 : 6912 }) >>> print ( d6_3 . within ( - 1 , 1 , d8_2 ) . format ( width = 65 )) avg | 0.25 std | 0.83 var | 0.69 - 1 | 25.32 % | ############ 0 | 24.68 % | ############ 1 | 50.00 % | ######################### Source code in dyce/h.py @beartype def within ( self , lo : RealLikeSCU , hi : RealLikeSCU , other : _OperandT = 0 ) -> H : r \"\"\" Computes the difference between the histogram and *other*. -1 represents where that difference is less than *lo*. 0 represents where that difference between *lo* and *hi* (inclusive). 1 represents where that difference is greater than *hi*. ``` python >>> d6_2 = 2@H(6) >>> d6_2.within(7, 9) H({-1: 15, 0: 15, 1: 6}) >>> print(d6_2.within(7, 9).format(width=65)) avg | -0.25 std | 0.72 var | 0.52 -1 | 41.67% |#################### 0 | 41.67% |#################### 1 | 16.67% |######## ``` ``` python >>> d6_3, d8_2 = 3@H(6), 2@H(8) >>> d6_3.within(-1, 1, d8_2) # 3d6 w/in 1 of 2d8 H({-1: 3500, 0: 3412, 1: 6912}) >>> print(d6_3.within(-1, 1, d8_2).format(width=65)) avg | 0.25 std | 0.83 var | 0.69 -1 | 25.32% |############ 0 | 24.68% |############ 1 | 50.00% |######################### ``` \"\"\" return self . map ( _within ( lo , hi ), other )","title":"within()"},{"location":"dyce/#dyce.p.P","text":"An immutable pool (ordered sequence) supporting group operations for zero or more H objects (provided or created from the initializer \u2019s args parameter). 1 2 3 >>> from dyce import P >>> p_d6 = P ( 6 ) ; p_d6 # shorthand for P(H(6)) P ( 6 ) 1 2 3 4 5 6 >>> P ( p_d6 , p_d6 ) # 2d6 P ( 6 , 6 ) >>> 2 @p_d6 # also 2d6 P ( 6 , 6 ) >>> 2 @ ( 2 @p_d6 ) == 4 @p_d6 True 1 2 3 4 >>> p = P ( 4 , P ( 6 , P ( 8 , P ( 10 , P ( 12 , P ( 20 )))))) ; p P ( 4 , 6 , 8 , 10 , 12 , 20 ) >>> sum ( p . roll ()) in p . h () True This class implements the HableT protocol and derives from the HableOpsMixin class , which means it can be \u201cflattened\u201d into a single histogram, either explicitly via the h method , or implicitly by using arithmetic operations. 1 2 >>> - p_d6 H ({ - 6 : 1 , - 5 : 1 , - 4 : 1 , - 3 : 1 , - 2 : 1 , - 1 : 1 }) 1 2 >>> p_d6 + p_d6 H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) 1 2 >>> 2 * P ( 8 ) - 1 H ({ 1 : 1 , 3 : 1 , 5 : 1 , 7 : 1 , 9 : 1 , 11 : 1 , 13 : 1 , 15 : 1 }) To perform arithmetic on individual H objects in a pool without flattening, use the map , rmap , and umap methods. 1 2 3 >>> import operator >>> P ( 4 , 6 , 8 ) . umap ( operator . __neg__ ) P ( - 8 , - 6 , - 4 ) 1 2 >>> P ( 4 , 6 ) . map ( operator . __pow__ , 2 ) P ( H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 }), H ({ 1 : 1 , 4 : 1 , 9 : 1 , 16 : 1 , 25 : 1 , 36 : 1 })) 1 2 >>> P ( 4 , 6 ) . rmap ( 2 , operator . __pow__ ) P ( H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 }), H ({ 2 : 1 , 4 : 1 , 8 : 1 , 16 : 1 , 32 : 1 , 64 : 1 })) Comparisons with H objects work as expected. 1 2 3 >>> from dyce import H >>> 3 @p_d6 == H ( 6 ) + H ( 6 ) + H ( 6 ) True Indexing selects a contained histogram. 1 2 >>> P ( 4 , 6 , 8 )[ 0 ] H ( 4 ) Note that pools are opinionated about ordering. 1 2 3 4 >>> P ( 8 , 6 , 4 ) P ( 4 , 6 , 8 ) >>> P ( 8 , 6 , 4 )[ 0 ] == P ( 8 , 4 , 6 )[ 0 ] == H ( 4 ) True In an extension to (departure from) the HableT protocol , the h method \u2019s implementation also affords subsets of outcomes to be \u201ctaken\u201d (selected) by passing in selection criteria. Values are indexed from least to greatest. Negative indexes are supported and retain their idiomatic meaning. Modeling the sum of the greatest two faces of three six-sided dice ( 3d6 ) can be expressed as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> p_3d6 = 3 @p_d6 >>> p_3d6 . h ( - 2 , - 1 ) H ({ 2 : 1 , 3 : 3 , 4 : 7 , 5 : 12 , 6 : 19 , 7 : 27 , 8 : 34 , 9 : 36 , 10 : 34 , 11 : 27 , 12 : 16 }) >>> print ( p_3d6 . h ( - 2 , - 1 ) . format ( width = 65 )) avg | 8.46 std | 2.21 var | 4.91 2 | 0.46 % | 3 | 1.39 % | 4 | 3.24 % | # 5 | 5.56 % | ## 6 | 8.80 % | #### 7 | 12.50 % | ###### 8 | 15.74 % | ####### 9 | 16.67 % | ######## 10 | 15.74 % | ####### 11 | 12.50 % | ###### 12 | 7.41 % | ###","title":"P"},{"location":"dyce/#dyce.p.P.__slots__","text":"","title":"__slots__"},{"location":"dyce/#dyce.p.P.is_homogeneous","text":"Experimental This property should be considered experimental and may change or disappear in future versions. A flag indicating whether the pool\u2019s population of histograms is homogeneous. 1 2 3 4 >>> P ( 6 , 6 ) . is_homogeneous True >>> P ( 4 , 6 , 8 ) . is_homogeneous False","title":"is_homogeneous"},{"location":"dyce/#dyce.p.P.__eq__","text":"Source code in dyce/p.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , P ): return __eq__ ( self . _hs , other . _hs ) else : return NotImplemented","title":"__eq__()"},{"location":"dyce/#dyce.p.P.__getitem__","text":"Source code in dyce/p.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( self , key : _GetItemT ) -> Union [ H , \"P\" ]: # type: ignore if isinstance ( key , slice ): return P ( * self . _hs [ key ]) else : return self . _hs [ __index__ ( key )]","title":"__getitem__()"},{"location":"dyce/#dyce.p.P.__init__","text":"Initializer. Source code in dyce/p.py @beartype def __init__ ( self , * args : Union [ SupportsIntSCU , \"P\" , H ]) -> None : r \"Initializer.\" super () . __init__ () def _gen_hs () -> Iterator [ H ]: for a in args : if isinstance ( a , H ): yield a elif isinstance ( a , P ): for h in a . _hs : yield h elif isinstance ( a , SupportsIntSCT ): yield H ( a ) else : raise ValueError ( f \"unrecognized initializer { args } \" ) hs = list ( h for h in _gen_hs () if h ) try : hs . sort ( key = lambda h : tuple ( h . items ())) except TypeError : # This is for outcomes that don't support direct comparisons, like symbolic # representations hs . sort ( key = lambda h : str ( tuple ( h . items ()))) self . _hs = tuple ( hs )","title":"__init__()"},{"location":"dyce/#dyce.p.P.__iter__","text":"Source code in dyce/p.py @beartype def __iter__ ( self ) -> Iterator [ H ]: return iter ( self . _hs )","title":"__iter__()"},{"location":"dyce/#dyce.p.P.__len__","text":"Source code in dyce/p.py @beartype def __len__ ( self ) -> int : return len ( self . _hs )","title":"__len__()"},{"location":"dyce/#dyce.p.P.__matmul__","text":"Source code in dyce/p.py @beartype def __matmul__ ( self , other : SupportsIntSCU ) -> P : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return P ( * chain . from_iterable ( repeat ( self , other )))","title":"__matmul__()"},{"location":"dyce/#dyce.p.P.__ne__","text":"Source code in dyce/p.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , P ): return __ne__ ( self . _hs , other . _hs ) else : return NotImplemented","title":"__ne__()"},{"location":"dyce/#dyce.p.P.__repr__","text":"Source code in dyce/p.py @beartype def __repr__ ( self ) -> str : def _parts () -> Iterator [ str ]: for h in self : yield ( str ( h . _simple_init ) if h . _simple_init is not None else repr ( h )) args = \", \" . join ( _parts ()) return f \" { type ( self ) . __name__ } ( { args } )\"","title":"__repr__()"},{"location":"dyce/#dyce.p.P.__rmatmul__","text":"Source code in dyce/p.py @beartype def __rmatmul__ ( self , other : SupportsIntSCU ) -> P : return self . __matmul__ ( other )","title":"__rmatmul__()"},{"location":"dyce/#dyce.p.P.appearances_in_rolls","text":"Experimental This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times outcome appears, and the counts are the number of rolls where outcome appears precisely that number of times. Equivalent to H (( sum ( 1 for v in roll if v == outcome ), count ) for roll , count in self . rolls_with_counts ()) , but much more efficient. 1 2 3 4 5 >>> p_2d6 = P ( 6 , 6 ) >>> list ( p_2d6 . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 2 ), (( 1 , 3 ), 2 ), (( 1 , 4 ), 2 ), (( 1 , 5 ), 2 ), (( 1 , 6 ), 2 ), ... ] >>> p_2d6 . appearances_in_rolls ( 1 ) H ({ 0 : 25 , 1 : 10 , 2 : 1 }) 1 2 3 4 5 >>> # Least efficient, by far >>> d4 , d6 = H ( 4 ), H ( 6 ) >>> p_3d4_2d6 = P ( d4 , d4 , d4 , d6 , d6 ) >>> H (( sum ( 1 for v in roll if v == 3 ), count ) for roll , count in p_3d4_2d6 . rolls_with_counts ()) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 4 5 >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3 , d6_eq3 = d4 . eq ( 2 ), d6 . eq ( 2 ) >>> 3 @d4_eq3 + 2 @d6_eq3 H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) 1 2 3 >>> # Most efficient for large sets of dice >>> p_3d4_2d6 . appearances_in_rolls ( 3 ) H ({ 0 : 675 , 1 : 945 , 2 : 522 , 3 : 142 , 4 : 19 , 5 : 1 }) Based on some rudimentary testing, this method appears to converge on being almost twice (about \\(\\frac{7}{4}\\) ) as efficient as the boolean accumulation technique for larger sets. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 In [ 3 ]: % timeit 3 @d4_eq3 + 2 @d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 4 ]: % timeit P ( 3 @P ( 4 ), 2 @P ( 6 )) . appearances_in_rolls ( 3 ) 402 \u00b5s \u00b1 5.59 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 5 ]: % timeit 9 @d4_eq3 + 6 @d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 6 ]: % timeit P ( 9 @P ( 4 ), 6 @P ( 6 )) . appearances_in_rolls ( 3 ) 597 \u00b5s \u00b1 9.46 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 1000 loops each ) In [ 7 ]: % timeit 90 @d4_eq3 + 60 @d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) In [ 8 ]: % timeit P ( 90 @P ( 4 ), 60 @P ( 6 )) . appearances_in_rolls ( 3 ) 7.5 ms \u00b1 84.6 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 100 loops each ) In [ 9 ]: % timeit 900 @d4_eq3 + 600 @d6_eq3 3.34 s \u00b1 19.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In [ 10 ]: % timeit P ( 900 @P ( 4 ), 600 @P ( 6 )) . appearances_in_rolls ( 3 ) 1.93 s \u00b1 14.3 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) Source code in dyce/p.py @experimental @beartype def appearances_in_rolls ( self , outcome : RealLikeSCU ) -> H : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. While it does provide a performance improvement over other techniques, it is not significant for most applications, and rarely justifies the corresponding reduction in readability. Returns a histogram where the outcomes (keys) are the number of times *outcome* appears, and the counts are the number of rolls where *outcome* appears precisely that number of times. Equivalent to ``#!python H((sum(1 for v in roll if v == outcome), count) for roll, count in self.rolls_with_counts())``, but much more efficient. ``` python >>> p_2d6 = P(6, 6) >>> list(p_2d6.rolls_with_counts()) [((1, 1), 1), ((1, 2), 2), ((1, 3), 2), ((1, 4), 2), ((1, 5), 2), ((1, 6), 2), ...] >>> p_2d6.appearances_in_rolls(1) H({0: 25, 1: 10, 2: 1}) ``` ``` python >>> # Least efficient, by far >>> d4, d6 = H(4), H(6) >>> p_3d4_2d6 = P(d4, d4, d4, d6, d6) >>> H((sum(1 for v in roll if v == 3), count) for roll, count in p_3d4_2d6.rolls_with_counts()) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Pretty darned efficient, generalizable to other boolean inquiries, and >>> # arguably the most readable >>> d4_eq3, d6_eq3 = d4.eq(2), d6.eq(2) >>> 3@d4_eq3 + 2@d6_eq3 H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` ``` python >>> # Most efficient for large sets of dice >>> p_3d4_2d6.appearances_in_rolls(3) H({0: 675, 1: 945, 2: 522, 3: 142, 4: 19, 5: 1}) ``` Based on some rudimentary testing, this method appears to converge on being almost twice (about $\\frac{7}{4}$) as efficient as the boolean accumulation technique for larger sets. ``` python In [3]: %timeit 3@d4_eq3 + 2@d6_eq3 287 \u00b5s \u00b1 6.96 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [4]: %timeit P(3@P(4), 2@P(6)).appearances_in_rolls(3) 402 \u00b5s \u00b1 5.59 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [5]: %timeit 9@d4_eq3 + 6@d6_eq3 845 \u00b5s \u00b1 7.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [6]: %timeit P(9@P(4), 6@P(6)).appearances_in_rolls(3) 597 \u00b5s \u00b1 9.46 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) In [7]: %timeit 90@d4_eq3 + 60@d6_eq3 24.7 ms \u00b1 380 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [8]: %timeit P(90@P(4), 60@P(6)).appearances_in_rolls(3) 7.5 ms \u00b1 84.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) In [9]: %timeit 900@d4_eq3 + 600@d6_eq3 3.34 s \u00b1 19.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [10]: %timeit P(900@P(4), 600@P(6)).appearances_in_rolls(3) 1.93 s \u00b1 14.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" group_counters : List [ Counter [ RealLikeSCU ]] = [] for h , hs in groupby ( self ): group_counter : Counter [ RealLikeSCU ] = counter () n = sum ( 1 for _ in hs ) for k in range ( 0 , n + 1 ): group_counter [ k ] = h . exactly_k_times_in_n ( outcome , n , k ) * ( group_counter [ k ] if group_counter [ k ] else 1 ) group_counters . append ( group_counter ) return sum_h ( H ( group_counter ) for group_counter in group_counters )","title":"appearances_in_rolls()"},{"location":"dyce/#dyce.p.P.h","text":"Roughly equivalent to H (( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which )) with some short-circuit optimizations. When provided no arguments, h combines (or \u201cflattens\u201d) contained histograms in accordance with the HableT protocol . 1 2 >>> ( 2 @P ( 6 )) . h () H ({ 2 : 1 , 3 : 2 , 4 : 3 , 5 : 4 , 6 : 5 , 7 : 6 , 8 : 5 , 9 : 4 , 10 : 3 , 11 : 2 , 12 : 1 }) If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> p_2d6 = 2 @P ( 6 ) >>> p_2d6 . h ( - 1 ) H ({ 1 : 1 , 2 : 3 , 3 : 5 , 4 : 7 , 5 : 9 , 6 : 11 }) >>> print ( p_2d6 . h ( - 1 ) . format ( width = 65 )) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78 % | # 2 | 8.33 % | #### 3 | 13.89 % | ###### 4 | 19.44 % | ######### 5 | 25.00 % | ############ 6 | 30.56 % | ############### Taking the greatest two and least two faces of ten four-sided dice ( 10d4 ) can be modeled as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 >>> p_10d4 = 10 @P ( 4 ) >>> p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) H ({ 4 : 1 , 5 : 10 , 6 : 1012 , 7 : 5030 , 8 : 51973 , 9 : 168760 , 10 : 595004 , 11 : 168760 , 12 : 51973 , 13 : 5030 , 14 : 1012 , 15 : 10 , 16 : 1 }) >>> print ( p_10d4 . h ( slice ( 2 ), slice ( - 2 , None )) . format ( width = 65 , scaled = True )) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00 % | 5 | 0.00 % | 6 | 0.10 % | 7 | 0.48 % | 8 | 4.96 % | #### 9 | 16.09 % | ############## 10 | 56.74 % | ################################################## 11 | 16.09 % | ############## 12 | 4.96 % | #### 13 | 0.48 % | 14 | 0.10 % | 15 | 0.00 % | 16 | 0.00 % | Taking all outcomes exactly once is equivalent to summing the histograms in the pool. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> p . h ( slice ( None )) == p . h () == d6 + d6 + d6avg + d6avg True Source code in dyce/p.py @beartype def h ( self , * which : _GetItemT ) -> H : r \"\"\" Roughly equivalent to ``#!python H((sum(roll), count) for roll, count in self.rolls_with_counts(*which))`` with some short-circuit optimizations. When provided no arguments, ``#!python h`` combines (or \u201cflattens\u201d) contained histograms in accordance with the [``HableT`` protocol][dyce.h.HableT]. ``` python >>> (2@P(6)).h() H({2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 5, 9: 4, 10: 3, 11: 2, 12: 1}) ``` If one or more arguments are provided, this method sums subsets of outcomes those arguments identify for each roll. Outcomes are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed. Taking the greatest of two six-sided dice can be modeled as: ``` python >>> p_2d6 = 2@P(6) >>> p_2d6.h(-1) H({1: 1, 2: 3, 3: 5, 4: 7, 5: 9, 6: 11}) >>> print(p_2d6.h(-1).format(width=65)) avg | 4.47 std | 1.40 var | 1.97 1 | 2.78% |# 2 | 8.33% |#### 3 | 13.89% |###### 4 | 19.44% |######### 5 | 25.00% |############ 6 | 30.56% |############### ``` Taking the greatest two and least two faces of ten four-sided dice (``10d4``) can be modeled as: ``` python >>> p_10d4 = 10@P(4) >>> p_10d4.h(slice(2), slice(-2, None)) H({4: 1, 5: 10, 6: 1012, 7: 5030, 8: 51973, 9: 168760, 10: 595004, 11: 168760, 12: 51973, 13: 5030, 14: 1012, 15: 10, 16: 1}) >>> print(p_10d4.h(slice(2), slice(-2, None)).format(width=65, scaled=True)) avg | 10.00 std | 0.91 var | 0.84 4 | 0.00% | 5 | 0.00% | 6 | 0.10% | 7 | 0.48% | 8 | 4.96% |#### 9 | 16.09% |############## 10 | 56.74% |################################################## 11 | 16.09% |############## 12 | 4.96% |#### 13 | 0.48% | 14 | 0.10% | 15 | 0.00% | 16 | 0.00% | ``` Taking all outcomes exactly once is equivalent to summing the histograms in the pool. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> p.h(slice(None)) == p.h() == d6 + d6 + d6avg + d6avg True ``` \"\"\" if which : n = len ( self ) i = _analyze_selection ( n , which ) if i and i >= n : # The caller selected all dice in the pool exactly i // n times, so we # can short-circuit roll enumeration assert i % n == 0 return self . h () * ( i // n ) else : return H ( ( sum ( roll ), count ) for roll , count in self . rolls_with_counts ( * which ) ) else : # The caller offered no selection return sum_h ( self )","title":"h()"},{"location":"dyce/#dyce.p.P.map","text":"Shorthand for P ( * ( h . map ( op , right_operand ) for h in self )) . See the H.map method . 1 2 3 4 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . map ( operator . __mul__ , - 1 ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) Source code in dyce/p.py @beartype def map ( self , op : _BinaryOperatorT , right_operand : _OperandT , ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.map(op, right_operand) for h in self))``. See the [``H.map`` method][dyce.h.H.map]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.map(operator.__mul__, -1) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) ``` \"\"\" return P ( * ( h . map ( op , right_operand ) for h in self ))","title":"map()"},{"location":"dyce/#dyce.p.P.rmap","text":"Shorthand for P ( * ( h . rmap ( left_operand , op ) for h in self )) . See the H.rmap method . 1 2 3 4 5 >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( Fraction ) . rmap ( 1 , operator . __truediv__ ) P ( H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 }), H ({ Fraction ( - 1 , 1 ): 1 , Fraction ( - 1 , 3 ): 1 , Fraction ( 1 , 4 ): 1 , Fraction ( 1 , 2 ): 1 })) Source code in dyce/p.py @beartype def rmap ( self , left_operand : RealLikeSCU , op : _BinaryOperatorT , ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.rmap(left_operand, op) for h in self))``. See the [``H.rmap`` method][dyce.h.H.rmap]. ``` python >>> import operator >>> from fractions import Fraction >>> p_3d6 = 2@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(Fraction).rmap(1, operator.__truediv__) P(H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1}), H({Fraction(-1, 1): 1, Fraction(-1, 3): 1, Fraction(1, 4): 1, Fraction(1, 2): 1})) ``` \"\"\" return P ( * ( h . rmap ( left_operand , op ) for h in self ))","title":"rmap()"},{"location":"dyce/#dyce.p.P.roll","text":"Returns (weighted) random outcomes from contained histograms. On ordering This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. Source code in dyce/p.py @beartype def roll ( self ) -> _RollT : r \"\"\" Returns (weighted) random outcomes from contained histograms. !!! note \"On ordering\" This method \u201cworks\u201d (i.e., falls back to a \u201cnatural\u201d ordering of string representations) for outcomes whose relative values cannot be known (e.g., symbolic expressions). This is deliberate to allow random roll functionality where symbolic resolution is not needed or will happen later. \"\"\" return tuple ( sorted_outcomes ( h . roll () for h in self ))","title":"roll()"},{"location":"dyce/#dyce.p.P.rolls_with_counts","text":"Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index 0 ) to greatest (index - 1 or len ( self ) - 1 ). Identifiers can be int s or slice s, and can be mixed for more flexible selections. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> from collections import Counter >>> def accumulate_roll_counts ( counter , roll_counts ): ... for roll , count in roll_counts : ... counter [ roll ] += count ... return counter >>> p_6d6 = 6 @P ( 6 ) >>> every_other_d6 = accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( slice ( None , None , - 2 ))) ; every_other_d6 Counter ({( 6 , 4 , 2 ): 4110 , ( 6 , 5 , 3 ): 3390 , ( 6 , 4 , 3 ): 3330 , ... , ( 3 , 3 , 3 ): 13 , ( 2 , 2 , 2 ): 7 , ( 1 , 1 , 1 ): 1 }) >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( 5 , 3 , 1 )) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * range ( 5 , 0 , - 2 ))) == every_other_d6 True >>> accumulate_roll_counts ( Counter (), p_6d6 . rolls_with_counts ( * ( i for i in range ( 6 , 0 , - 1 ) if i % 2 == 1 ))) == every_other_d6 True One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. 1 2 3 4 5 6 7 8 >>> p_5d6 = 5 @P ( 6 ) >>> yhatzee_on_single_roll = H ( ... ( 1 if roll [ 0 ] == roll [ - 1 ] else 0 , count ) ... for roll , count ... in p_5d6 . rolls_with_counts () ... ) >>> print ( yhatzee_on_single_roll . format ( width = 0 )) { ... , 0 : 99.92 % , 1 : 0.08 % } In the general case, rolls may appear more than once. 1 2 >>> list ( P ( H ( 2 ), H ( 3 )) . rolls_with_counts ()) [(( 1 , 1 ), 1 ), (( 1 , 2 ), 1 ), (( 1 , 3 ), 1 ), (( 1 , 2 ), 1 ), (( 2 , 2 ), 1 ), (( 2 , 3 ), 1 )] In the above, ( 1 , 2 ) appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) 1 2 >>> list (( 2 @P ( H (( - 1 , 0 , 1 )))) . rolls_with_counts ()) [(( - 1 , - 1 ), 1 ), (( - 1 , 0 ), 2 ), (( - 1 , 1 ), 2 ), (( 0 , 0 ), 1 ), (( 0 , 1 ), 2 ), (( 1 , 1 ), 1 )] Either way, by summing and counting all rolls, we can confirm identity. 1 2 3 4 5 >>> d6 = H ( 6 ) >>> d6avg = H (( 2 , 3 , 3 , 4 , 4 , 5 )) >>> p = 2 @P ( d6 , d6avg ) >>> H (( sum ( roll ), count ) for roll , count in p . rolls_with_counts ()) == p . h () == d6 + d6 + d6avg + d6avg True This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. 1 2 3 4 >>> p_d3_d4 = P ( H ( 3 ), H ( 4 )) >>> # Select the second, first, then second (again) elements >>> list ( p_d3_d4 . rolls_with_counts ( - 1 , 0 , 1 )) [(( 1 , 1 , 1 ), 1 ), (( 2 , 1 , 2 ), 1 ), (( 3 , 1 , 3 ), 1 ), (( 4 , 1 , 4 ), 1 ), ... , (( 3 , 1 , 3 ), 1 ), (( 3 , 2 , 3 ), 1 ), (( 3 , 3 , 3 ), 1 ), (( 4 , 3 , 4 ), 1 )] Selecting the same outcomes, but in a different order is not immediately comparable. 1 2 3 4 >>> select_0_1 = list ( p_d3_d4 . rolls_with_counts ( 0 , 1 )) >>> select_1_0 = list ( p_d3_d4 . rolls_with_counts ( 1 , 0 )) >>> select_0_1 == select_1_0 False Equivalence can be tested when selected outcomes are sorted. 1 2 3 4 >>> sorted_0_1 = [( sorted ( roll ), count ) for roll , count in select_0_1 ] >>> sorted_1_0 = [( sorted ( roll ), count ) for roll , count in select_1_0 ] >>> sorted_0_1 == sorted_1_0 True They can also be summed and counted which is equivalent to calling the h method with identical selection arguments. 1 2 3 4 >>> summed_0_1 = H (( sum ( roll ), count ) for roll , count in select_0_1 ) >>> summed_1_0 = H (( sum ( roll ), count ) for roll , count in select_1_0 ) >>> summed_0_1 == summed_1_0 == p_d3_d4 . h ( 0 , 1 ) == p_d3_d4 . h ( 1 , 0 ) True About the implementation Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking \\(k\\) outcomes, where \\(k\\) selects fewer than all \\(n\\) outcomes a homogeneous pool benefits from Ilmari Karonen\u2019s optimization , which appears to scale geometrically with \\(k\\) times some factor of \\(n\\) (e.g., \\(\\log n\\) , but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for \\(k < n\\) . Where \\(k = n\\) , we leverage the multinomial coefficient , which appears to scale generally with \\(n\\) . \\[ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} \\] We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider n @P ( H ( m )) . Enumerating combinations with replacements would yield all unique rolls. (( 1 , 1 , \u2026 , 1 ), ( 1 , 1 , \u2026 , 2 ), \u2026 , ( 1 , 1 , \u2026 , m ), \u2026 , ( m - 1 , m , \u2026 , m ), ( m , m , \u2026 , m )) To determine the count for a particular roll ( a , b , \u2026 , n ) , we compute the multinomial coefficient for that roll and multiply by the scalar H ( m )[ a ] * H ( m )[ b ] * \u2026 * H ( m )[ n ] . (See this for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Source code in dyce/p.py @beartype def rolls_with_counts ( self , * which : _GetItemT ) -> Iterator [ _RollCountT ]: r \"\"\" Returns an iterator yielding 2-tuples (pairs) that, collectively, enumerate all possible outcomes for the pool. The first item in the 2-tuple is a sorted sequence of the outcomes for a distinct roll. The second is the count for that roll. Outcomes in each roll are ordered least to greatest. If one or more arguments are provided, this methods selects subsets of outcomes for each roll. Outcomes in each roll are ordered from least (index ``#!python 0``) to greatest (index ``#!python -1`` or ``#!python len(self) - 1``). Identifiers can be ``#!python int``s or ``#!python slice``s, and can be mixed for more flexible selections. ``` python >>> from collections import Counter >>> def accumulate_roll_counts(counter, roll_counts): ... for roll, count in roll_counts: ... counter[roll] += count ... return counter >>> p_6d6 = 6@P(6) >>> every_other_d6 = accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(slice(None, None, -2))) ; every_other_d6 Counter({(6, 4, 2): 4110, (6, 5, 3): 3390, (6, 4, 3): 3330, ..., (3, 3, 3): 13, (2, 2, 2): 7, (1, 1, 1): 1}) >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(5, 3, 1)) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*range(5, 0, -2))) == every_other_d6 True >>> accumulate_roll_counts(Counter(), p_6d6.rolls_with_counts(*(i for i in range(6, 0, -1) if i % 2 == 1))) == every_other_d6 True ``` One way to model the likelihood of achieving a \u201cYhatzee\u201d (i.e., where five six-sided dice show the same face) on a single roll by checking rolls for where the least and greatest outcomes are the same. ``` python >>> p_5d6 = 5@P(6) >>> yhatzee_on_single_roll = H( ... (1 if roll[0] == roll[-1] else 0, count) ... for roll, count ... in p_5d6.rolls_with_counts() ... ) >>> print(yhatzee_on_single_roll.format(width=0)) {..., 0: 99.92%, 1: 0.08%} ``` !!! note \"In the general case, rolls may appear more than once.\" ``` python >>> list(P(H(2), H(3)).rolls_with_counts()) [((1, 1), 1), ((1, 2), 1), ((1, 3), 1), ((1, 2), 1), ((2, 2), 1), ((2, 3), 1)] ``` In the above, ``#!python (1, 2)`` appears a total of two times, each with counts of one. However, if the pool is homogeneous (meaning it only contains identical histograms), rolls (before selection) are not repeated. (See the note on implementation below.) ``` python >>> list((2@P(H((-1, 0, 1)))).rolls_with_counts()) [((-1, -1), 1), ((-1, 0), 2), ((-1, 1), 2), ((0, 0), 1), ((0, 1), 2), ((1, 1), 1)] ``` Either way, by summing and counting all rolls, we can confirm identity. ``` python >>> d6 = H(6) >>> d6avg = H((2, 3, 3, 4, 4, 5)) >>> p = 2@P(d6, d6avg) >>> H((sum(roll), count) for roll, count in p.rolls_with_counts()) == p.h() == d6 + d6 + d6avg + d6avg True ``` This method does not try to outsmart callers by (mis)interpreting selection arguments. It honors selection identifier order and any redundancy. ``` python >>> p_d3_d4 = P(H(3), H(4)) >>> # Select the second, first, then second (again) elements >>> list(p_d3_d4.rolls_with_counts(-1, 0, 1)) [((1, 1, 1), 1), ((2, 1, 2), 1), ((3, 1, 3), 1), ((4, 1, 4), 1), ..., ((3, 1, 3), 1), ((3, 2, 3), 1), ((3, 3, 3), 1), ((4, 3, 4), 1)] ``` Selecting the same outcomes, but in a different order is not immediately comparable. ``` python >>> select_0_1 = list(p_d3_d4.rolls_with_counts(0, 1)) >>> select_1_0 = list(p_d3_d4.rolls_with_counts(1, 0)) >>> select_0_1 == select_1_0 False ``` Equivalence can be tested when selected outcomes are sorted. ``` python >>> sorted_0_1 = [(sorted(roll), count) for roll, count in select_0_1] >>> sorted_1_0 = [(sorted(roll), count) for roll, count in select_1_0] >>> sorted_0_1 == sorted_1_0 True ``` They can also be summed and counted which is equivalent to calling the [``h`` method][dyce.p.P.h] with identical selection arguments. ``` python >>> summed_0_1 = H((sum(roll), count) for roll, count in select_0_1) >>> summed_1_0 = H((sum(roll), count) for roll, count in select_1_0) >>> summed_0_1 == summed_1_0 == p_d3_d4.h(0, 1) == p_d3_d4.h(1, 0) True ``` !!! info \"About the implementation\" Enumeration is substantially more efficient for homogeneous pools than heterogeneous ones, because we are able to avoid the expensive enumeration of the Cartesian product using several techniques. Taking $k$ outcomes, where $k$ selects fewer than all $n$ outcomes a homogeneous pool benefits from [Ilmari Karonen\u2019s optimization](https://rpg.stackexchange.com/a/166663/71245), which appears to scale geometrically with $k$ times some factor of $n$ (e.g., $\\log n$, but I haven\u2019t bothered to figure that out yet), such that\u2014in observed testing, at least\u2014it is generally the fastest approach for $k < n$. Where $k = n$, we leverage the [*multinomial coefficient*](https://en.wikipedia.org/wiki/Permutation#Permutations_of_multisets), which appears to scale generally with $n$. $$ {{n} \\choose {{{k}_{1}},{{k}_{2}},\\ldots,{{k}_{m}}}} = {\\frac {{n}!} {{{k}_{1}}! {{k}_{2}}! \\cdots {{k}_{m}}!}} $$ We enumerate combinations with replacements, and then the compute the number of permutations with repetitions for each combination. Consider ``#!python n@P(H(m))``. Enumerating combinations with replacements would yield all unique rolls. ``#!python ((1, 1, \u2026, 1), (1, 1, \u2026, 2), \u2026, (1, 1, \u2026, m), \u2026, (m - 1, m, \u2026, m), (m, m, \u2026, m))`` To determine the count for a particular roll ``#!python (a, b, \u2026, n)``, we compute the multinomial coefficient for that roll and multiply by the scalar ``#!python H(m)[a] * H(m)[b] * \u2026 * H(m)[n]``. (See [this](https://www.lucamoroni.it/the-dice-roll-sum-problem/) for an in-depth exploration of the topic.) Further, this implementation attempts to optimize heterogeneous pools by breaking them into homogeneous groups before computing the Cartesian product of those sub-results. This approach allows homogeneous pools to be ordered without duplicates, where heterogeneous ones offer no such guarantees. As expected, this optimization allows the performance of arbitrary selection from mixed pools to sit between that of purely homogeneous and purely heterogeneous ones. Note, however, that all three appear to scale geometrically in some way. ```ipython In [1]: from dyce import H, P In [2]: for n in (6, 8): ...: p = n@P(6) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(6, 6, 6, 6, 6, 6)).h(slice(2)): 1.35 ms \u00b1 23.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(3)): 3.15 ms \u00b1 516 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(4)): 5.37 ms \u00b1 182 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6)).h(slice(5)): 10.5 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(4)): 5.58 ms \u00b1 25.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(5)): 9.81 ms \u00b1 171 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(6)): 14.7 ms \u00b1 430 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(6, 6, 6, 6, 6, 6, 6, 6)).h(slice(7)): 20.4 ms \u00b1 328 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) In [3]: for n in (3, 4): ...: p = P(n@P(6), *[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(2)): 16.1 ms \u00b1 1.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(3)): 39 ms \u00b1 602 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(4)): 40.3 ms \u00b1 3.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-2: 1, ..., 3: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6)).h(slice(5)): 46.2 ms \u00b1 7.43 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(4)): 538 ms \u00b1 9.46 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(5)): 534 ms \u00b1 30.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(6)): 536 ms \u00b1 13.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-3: 1, ..., 2: 1}), ..., H({0: 1, ..., 5: 1}), 6, 6, 6, 6)).h(slice(7)): 604 ms \u00b1 52.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) In [4]: for n in (6, 8): ...: p = P(*[H(6) - m for m in range(n, 0, -1)]) ...: for i in range(len(p) - 4, len(p)): ...: print(f\"({p}).h(slice({i})):\") ...: %timeit p.h(slice(i)) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(2)): 145 ms \u00b1 4.59 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(3)): 147 ms \u00b1 3.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 158 ms \u00b1 1.38 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-5: 1, ..., 0: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 147 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(4)): 6.09 s \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(5)): 6.11 s \u00b1 36.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(6)): 6.25 s \u00b1 47.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) (P(H({-7: 1, ..., -2: 1}), ..., H({0: 1, ..., 5: 1}))).h(slice(7)): 6.31 s \u00b1 42.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) ``` \"\"\" n = len ( self ) if not which : i : Optional [ int ] = n else : i = _analyze_selection ( n , which ) if i == 0 or n == 0 : rolls_with_counts_iter : Iterable [ _RollCountT ] = iter (()) else : groups = tuple (( h , sum ( 1 for _ in hs )) for h , hs in groupby ( self )) if len ( groups ) == 1 : # Based on cursory performance analysis, calling the homogeneous # implementation directly provides about a 15% performance savings over # merely falling through to _rwc_heterogeneous_h_groups. Maybe # itertools.product adds significant overhead? h , hn = groups [ 0 ] assert hn == n # Still in search of a better (i.e., more efficient) way: # https://math.stackexchange.com/questions/4173084/probability-distribution-of-k-1-k-2-cdots-k-m-selections-of-arbitrary-posi if i and abs ( i ) < n : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_karonen_partial_selection ( h , n , i , fill = 0 ) ) else : rolls_with_counts_iter = ( _rwc_homogeneous_n_h_using_multinomial_coefficient ( h , n ) ) else : rolls_with_counts_iter = _rwc_heterogeneous_h_groups ( groups , i ) for sorted_outcomes_for_roll , roll_count in rolls_with_counts_iter : if which : taken_outcomes = tuple ( getitems ( sorted_outcomes_for_roll , which )) else : taken_outcomes = sorted_outcomes_for_roll yield taken_outcomes , roll_count","title":"rolls_with_counts()"},{"location":"dyce/#dyce.p.P.umap","text":"Shorthand for P ( * ( h . umap ( op ) for h in self )) . See the H.umap method . 1 2 3 4 5 6 >>> import operator >>> p_3d6 = 3 @P ( H (( - 3 , - 1 , 2 , 4 ))) >>> p_3d6 . umap ( operator . __neg__ ) P ( H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 }), H ({ - 4 : 1 , - 2 : 1 , 1 : 1 , 3 : 1 })) >>> p_3d6 . umap ( operator . __abs__ ) P ( H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 }), H ({ 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 })) Source code in dyce/p.py @beartype def umap ( self , op : _UnaryOperatorT ) -> P : r \"\"\" Shorthand for ``#!python P(*(h.umap(op) for h in self))``. See the [``H.umap`` method][dyce.h.H.umap]. ``` python >>> import operator >>> p_3d6 = 3@P(H((-3, -1, 2, 4))) >>> p_3d6.umap(operator.__neg__) P(H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1}), H({-4: 1, -2: 1, 1: 1, 3: 1})) >>> p_3d6.umap(operator.__abs__) P(H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1}), H({1: 1, 2: 1, 3: 1, 4: 1})) ``` \"\"\" return P ( * ( h . umap ( op ) for h in self ))","title":"umap()"},{"location":"dyce.r/","text":"dyce . r package reference Experimental This package is an attempt to provide primitives for producing weighted randomized rolls without the overhead of enumeration. Rolls can be inspected to understand how specific values are derived. It should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Feedback, suggestions, and contributions are welcome and appreciated. Roller class hierarchy BasicOpRoller ( R ) A roller for applying op to some variation of outcomes from sources . Any RollOutcome s returned by op are used directly in the creation of a new Roll . __slots__ : Union [ str , Iterable [ str ]] special op : BasicOperatorT property readonly The operator this roller applies to its sources. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . op , other . op )) __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _op = op __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( op= { self . op !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) res = self . op ( self , ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), ) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , ) BinarySumOpRoller ( NarySumOpRoller ) An NarySumOpRoller for applying a binary operator bin_op to the sum of all outcomes from its left_source and the sum of all outcomes from its right_source . __slots__ : Union [ str , Iterable [ str ]] special bin_op : _RollOutcomeBinaryOperatorT property readonly The operator this roller applies to its sources. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . bin_op , other . bin_op )) __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: left_operand , right_operand = roll_outcomes return bin_op ( left_operand , right_operand ) super () . __init__ ( op = _op , sources = ( left_source , right_source ), annotation = annotation , ** kw ) self . _bin_op = bin_op __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : def _source_repr ( source : _SourceT ) -> str : return indent ( repr ( source ), \" \" ) . strip () left_source , right_source = self . sources return f \"\"\" { type ( self ) . __name__ } ( bin_op= { self . bin_op !r} , left_source= { _source_repr ( left_source ) } , right_source= { _source_repr ( right_source ) } , annotation= { self . annotation !r} , )\"\"\" NarySumOpRoller ( BasicOpRoller ) A BasicOpRoller for applying op to the sum of outcomes grouped by each of sources . __slots__ : Union [ str , Iterable [ str ]] special roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _sum_roll_outcomes_by_rolls () -> Iterator [ RollOutcome ]: for source_roll in source_rolls : if len ( source_roll ) == 1 and source_roll [ 0 ] . value is not None : yield from source_roll else : yield RollOutcome ( sum ( source_roll . outcomes ()), sources = source_roll ) res = self . op ( self , _sum_roll_outcomes_by_rolls ()) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , ) PoolRoller ( R ) A roller for rolling flattened \u201cpools\u201d from all sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 >>> PoolRoller (( ... PoolRoller (( ... ValueRoller ( 11 ), ... ValueRoller ( 12 ), ... )), ... PoolRoller (( ... PoolRoller (( ... ValueRoller ( 211 ), ... ValueRoller ( 212 ), ... )), ... PoolRoller (( ... ValueRoller ( 221 ), ... ValueRoller ( 222 ), ... )), ... )), ... ValueRoller ( 3 ), ... )) . roll () Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 11 , sources =... , ), RollOutcome ( value = 12 , sources =... , ), RollOutcome ( value = 211 , sources =... , ), RollOutcome ( value = 212 , sources =... , ), RollOutcome ( value = 221 , sources =... , ), RollOutcome ( value = 222 , sources =... , ), RollOutcome ( value = 3 , sources =... , ), ), source_rolls =... , ) __slots__ : Union [ str , Iterable [ str ]] special roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , ) R Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Where H objects and P objects are used primarily for enumerating weighted outcomes, R objects represent rollers. More specifically, they are immutable nodes assembled in tree-like structures to represent calculations. Unlike H or P objects, rollers generate rolls that conform to weighted outcomes without engaging in computationally expensive enumeration. Roller trees are typically composed from various R class methods and operators as well as arithmetic operations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> from dyce import H , P , R >>> d6 = H ( 6 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> (( 4 * r_d6 + 3 ) ** 2 % 5 ) . gt ( 2 ) BinarySumOpRoller ( bin_op =< function R . gt .< locals >. _gt at ...> , left_source = BinarySumOpRoller ( bin_op =< built - in function mod > , left_source = BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = BinarySumOpRoller ( bin_op =< built - in function add > , left_source = BinarySumOpRoller ( bin_op =< built - in function mul > , left_source = ValueRoller ( value = 4 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 3 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 5 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) Info No optimizations are made when initializing roller trees. They retain their exact structure, even where such structures could be trivially reduced. 1 2 3 4 5 6 7 >>> r_6 = R . from_value ( 6 ) >>> r_6_abs_3 = 3 @ abs ( r_6 ) >>> r_6_abs_6_abs_6_abs = R . from_sources ( abs ( r_6 ), abs ( r_6 ), abs ( r_6 )) >>> tuple ( r_6_abs_3 . roll () . outcomes ()), tuple ( r_6_abs_6_abs_6_abs . roll () . outcomes ()) # they generate the same rolls (( 6 , 6 , 6 ), ( 6 , 6 , 6 )) >>> r_6_abs_3 == r_6_abs_6_abs_6_abs # and yet, they're different animals False This is because the structure itself contains information that might be required by certain contexts. If such information loss is permissible and reduction is desirable, consider using histograms instead. Roller trees can can be queried via the roll method , which produces Roll objects . 1 2 3 4 5 >>> roll = r_d6 . roll () >>> tuple ( roll . outcomes ()) ( 4 ,) >>> roll . total () 4 1 2 3 4 >>> d6 + 3 H ({ 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> ( r_d6 + 3 ) . roll () . total () in ( d6 + 3 ) True Roll objects are much richer than mere sequences of outcomes. They are also tree-like structures that mirror the roller trees used to produce them, capturing references to rollers and the outcomes generated at each node. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 >>> roll = ( r_d6 + 3 ) . roll () >>> roll . total () 8 >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 8 , sources = ( RollOutcome ( value = 5 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 5 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Rollers afford optional annotations as a convenience to callers. They are taken into account when comparing roller trees, but otherwise ignored, internally. One use is to capture references to nodes in an abstract syntax tree generated from parsing a proprietary grammar. Any provided annotation can be retrieved using the annotation property . The annotate method can be used to apply an annotation to existing roller. The R class itself acts as a base from which several computation-specific implementations derive (such as expressing operands like outcomes or histograms, unary operations, binary operations, pools, etc.). __slots__ : Union [ str , Iterable [ str ]] special annotation : Any property readonly Any provided annotation. sources : Tuple [ _SourceT , ... ] property readonly The roller\u2019s direct sources (if any). __abs__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __abs__ ( self ) -> UnarySumOpRoller : return self . umap ( __abs__ ) __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented __and__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __and__ , other ) else : return self . map ( __and__ , as_int ( other )) except NotImplementedError : return NotImplemented __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , R ): return ( ( isinstance ( self , type ( other )) or isinstance ( other , type ( self ))) and __eq__ ( self . sources , other . sources ) # order matters and __eq__ ( self . annotation , other . annotation ) ) else : return super () . __eq__ ( other ) __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = '' , ** kw ) special Initializer. Source code in dyce/r.py @experimental @beartype def __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ () self . _sources = tuple ( sources ) self . _annotation = annotation __invert__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __invert__ ( self ) -> UnarySumOpRoller : return self . umap ( __invert__ ) __matmul__ ( self , other : SupportsIntSCU ) -> R special Source code in dyce/r.py @beartype def __matmul__ ( self , other : SupportsIntSCU ) -> R : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return RepeatRoller ( other , self ) __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented __ne__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , R ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other ) __neg__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __neg__ ( self ) -> UnarySumOpRoller : return self . umap ( __neg__ ) __or__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __or__ , other ) else : return self . map ( __or__ , as_int ( other )) except NotImplementedError : return NotImplemented __pos__ ( self ) -> UnarySumOpRoller special Source code in dyce/r.py @beartype def __pos__ ( self ) -> UnarySumOpRoller : return self . umap ( __pos__ ) __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented __radd__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented __rand__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __and__ ) except NotImplementedError : return NotImplemented __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" __rfloordiv__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : # type: ignore try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented __rmatmul__ ( self , other : SupportsIntSCU ) -> R special Source code in dyce/r.py @beartype def __rmatmul__ ( self , other : SupportsIntSCU ) -> R : return self . __matmul__ ( other ) __rmod__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented __rmul__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented __ror__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __or__ ) except NotImplementedError : return NotImplemented __rpow__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented __rsub__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented __rtruediv__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented __rxor__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __xor__ ) except NotImplementedError : return NotImplemented __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented __xor__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller special Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __xor__ , other ) else : return self . map ( __xor__ , as_int ( other )) except NotImplementedError : return NotImplemented annotate ( self , annotation : Any = '' ) -> R Generates a copy of the roller with the desired annotation. 1 2 3 4 >>> r_just_the_n_of_us = R . from_value ( 5 , annotation = \"But I'm 42!\" ) ; r_just_the_n_of_us ValueRoller ( value = 5 , annotation = \"But I'm 42!\" ) >>> r_just_the_n_of_us . annotate ( \"I'm a 42-year-old investment banker!\" ) ValueRoller ( value = 5 , annotation = \"I'm a 42-year-old investment banker!\" ) Source code in dyce/r.py @beartype def annotate ( self , annotation : Any = \"\" ) -> R : r \"\"\" Generates a copy of the roller with the desired annotation. ``` python >>> r_just_the_n_of_us = R.from_value(5, annotation=\"But I'm 42!\") ; r_just_the_n_of_us ValueRoller(value=5, annotation=\"But I'm 42!\") >>> r_just_the_n_of_us.annotate(\"I'm a 42-year-old investment banker!\") ValueRoller(value=5, annotation=\"I'm a 42-year-old investment banker!\") ``` \"\"\" r = copy ( self ) r . _annotation = annotation return r eq ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . eq ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def eq ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.eq(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _eq ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . eq ( right_operand ) return self . map ( _eq , other ) from_sources ( * sources : _SourceT , * , annotation : Any = '' ) -> PoolRoller classmethod Shorthand for cls . from_sources_iterable ( rs , annotation = annotation ) . See the from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def from_sources ( cls , * sources : _SourceT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable(rs, annotation=annotation)``. See the [``from_sources_iterable`` method][dyce.r.R.from_sources_iterable]. \"\"\" return cls . from_sources_iterable ( sources , annotation = annotation ) from_sources_iterable ( sources : Iterable [ _SourceT ], annotation : Any = '' ) -> PoolRoller classmethod Creates and returns a roller for \u201cpooling\u201d zero or more sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> r_pool = R . from_sources_iterable ( R . from_value ( h ) for h in ( H (( 1 , 2 )), H (( 3 , 4 )), H (( 5 , 6 )))) >>> roll = r_pool . roll () >>> tuple ( roll . outcomes ()) ( 2 , 4 , 6 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), RollOutcome ( value = 6 , sources = (), ), ), source_rolls =... , ) Source code in dyce/r.py @classmethod @beartype def from_sources_iterable ( cls , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Creates and returns a roller for \u201cpooling\u201d zero or more *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056341) -- END MONKEY PATCH --> ``` python >>> r_pool = R.from_sources_iterable(R.from_value(h) for h in (H((1, 2)), H((3, 4)), H((5, 6)))) >>> roll = r_pool.roll() >>> tuple(roll.outcomes()) (2, 4, 6) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=4, sources=(), ), RollOutcome( value=6, sources=(), ), ), source_rolls=..., ) ``` \"\"\" return PoolRoller ( sources , annotation = annotation ) from_value ( value : _ValueT , annotation : Any = '' ) -> ValueRoller classmethod Creates and returns a ValueRoller from value . 1 2 >>> R . from_value ( 6 ) ValueRoller ( value = 6 , annotation = '' ) 1 2 >>> R . from_value ( H ( 6 )) ValueRoller ( value = H ( 6 ), annotation = '' ) 1 2 >>> R . from_value ( P ( 6 , 6 )) ValueRoller ( value = P ( 6 , 6 ), annotation = '' ) Source code in dyce/r.py @classmethod @beartype def from_value ( cls , value : _ValueT , annotation : Any = \"\" , ) -> ValueRoller : r \"\"\" Creates and returns a [``ValueRoller``][dyce.r.ValueRoller] from *value*. ``` python >>> R.from_value(6) ValueRoller(value=6, annotation='') ``` ``` python >>> R.from_value(H(6)) ValueRoller(value=H(6), annotation='') ``` ``` python >>> R.from_value(P(6, 6)) ValueRoller(value=P(6, 6), annotation='') ``` \"\"\" return ValueRoller ( value , annotation = annotation ) from_values ( * values : _ValueT , * , annotation : Any = '' ) -> PoolRoller classmethod Shorthand for cls . from_values_iterable ( values , annotation = annotation ) . See the from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def from_values ( cls , * values : _ValueT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_values_iterable(values, annotation=annotation)``. See the [``from_values_iterable`` method][dyce.r.R.from_values_iterable]. \"\"\" return cls . from_values_iterable ( values , annotation = annotation ) from_values_iterable ( values : Iterable [ _ValueT ], annotation : Any = '' ) -> PoolRoller classmethod Shorthand for cls . from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def from_values_iterable ( cls , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``from_sources_iterable``][dyce.r.R.from_sources_iterable] methods. \"\"\" return cls . from_sources_iterable ( ( cls . from_value ( value ) for value in values ), annotation = annotation , ) ge ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . ge ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ge ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ge(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ge ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ge ( right_operand ) return self . map ( _ge , other ) gt ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . gt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def gt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.gt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _gt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . gt ( right_operand ) return self . map ( _gt , other ) is_even ( self ) -> UnarySumOpRoller Shorthand for: self . umap ( lambda operand : operand . is_even ()) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_even())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_even ( operand : RollOutcome ) -> RollOutcome : return operand . is_even () return self . umap ( _is_even ) is_odd ( self ) -> UnarySumOpRoller Shorthand for: self . umap ( lambda operand : operand . is_odd ()) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_odd())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_odd ( operand : RollOutcome ) -> RollOutcome : return operand . is_odd () return self . umap ( _is_odd ) le ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . le ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def le ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.le(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _le ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . le ( right_operand ) return self . map ( _le , other ) lt ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . lt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def lt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.lt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _lt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . lt ( right_operand ) return self . map ( _lt , other ) map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = '' ) -> BinarySumOpRoller Creates and returns a BinarySumOpRoller for applying bin_op to this roller and right_operand as its sources. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . map ( operator . __pow__ , 2 ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = H ( 6 ), annotation = '' ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) >>> r_bin_op == R . from_value ( H ( 6 )) ** 2 True Source code in dyce/r.py @beartype def map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Creates and returns a [``BinarySumOpRoller``][dyce.r.BinarySumOpRoller] for applying *bin_op* to this roller and *right_operand* as its sources. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).map(operator.__pow__, 2) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=H(6), annotation=''), right_source=ValueRoller(value=2, annotation=''), annotation='', ) >>> r_bin_op == R.from_value(H(6)) ** 2 True ``` \"\"\" if isinstance ( right_operand , RealLikeSCT ): right_operand = ValueRoller ( right_operand ) if isinstance ( right_operand , ( R , RollOutcome )): return BinarySumOpRoller ( bin_op , self , right_operand , annotation = annotation ) else : raise NotImplementedError ne ( self , other : _ROperandT ) -> BinarySumOpRoller Shorthand for self . map ( lambda left , right : left . ne ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ne ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ne(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ne ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ne ( right_operand ) return self . map ( _ne , other ) rmap ( self , left_operand : Union [ RealLikeSCU , 'RollOutcome' ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = '' ) -> BinarySumOpRoller Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . rmap ( 2 , operator . __pow__ ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = 2 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_bin_op == 2 ** R . from_value ( H ( 6 )) True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : Union [ RealLikeSCU , \"RollOutcome\" ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Analogous to the [``map`` method][dyce.r.R.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).rmap(2, operator.__pow__) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=2, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_bin_op == 2 ** R.from_value(H(6)) True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.R.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLikeSCT ): return BinarySumOpRoller ( bin_op , ValueRoller ( left_operand ), self , annotation = annotation ) elif isinstance ( left_operand , RollOutcome ): return BinarySumOpRoller ( bin_op , left_operand , self , annotation = annotation ) else : raise NotImplementedError roll ( self ) -> Roll Sub-classes should implement this method to return a new Roll object taking into account any sources . Note Implementors guarantee that all RollOutcome s in the returned Roll must be associated with a roll, including all roll outcomes\u2019 sources . Tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of None with the excluded roll outcome as its source. The RollOutcome.euthanize convenience method is provided for this purpose. See the section on \u201c Dropping dice from prior rolls \u2026 \u201d as well as the note in Roll.__init__ for additional color. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 >>> from itertools import chain >>> class AntonChigurhRoller ( R ): ... h_coin_toss = H (( 0 , 1 )) ... def roll ( self ) -> Roll : ... source_rolls = list ( self . source_rolls ()) ... def _roll_outcomes_gen (): ... for roll_outcome in chain . from_iterable ( source_rolls ): ... if roll_outcome . value is None : ... # Omit those already deceased ... continue ... elif self . h_coin_toss . roll (): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else : ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome . euthanize () ... return Roll ( self , roll_outcomes = _roll_outcomes_gen (), source_rolls = source_rolls ) >>> ac_r = AntonChigurhRoller ( sources = ( R . from_value ( 1 ), R . from_value ( 2 ), R . from_value ( 3 ))) >>> ac_r . roll () Roll ( r = AntonChigurhRoller ( sources = ( ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 2 , annotation = '' ), ValueRoller ( value = 3 , annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = 1 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 2 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Source code in dyce/r.py @abstractmethod def roll ( self ) -> Roll : r \"\"\" Sub-classes should implement this method to return a new [``Roll`` object][dyce.r.Roll] taking into account any [sources][dyce.r.R.sources]. !!! note Implementors guarantee that all [``RollOutcome``][dyce.r.RollOutcome]s in the returned [``Roll``][dyce.r.Roll] *must* be associated with a roll, *including all roll outcomes\u2019 [``sources``][dyce.r.RollOutcome.sources]*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633403927) -- END MONKEY PATCH --> !!! tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of ``#!python None`` with the excluded roll outcome as its source. The [``RollOutcome.euthanize``][dyce.r.RollOutcome.euthanize] convenience method is provided for this purpose. See the section on \u201c[Dropping dice from prior rolls \u2026](rollin.md#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8)\u201d as well as the note in [``Roll.__init__``][dyce.r.Roll.__init__] for additional color. ``` python >>> from itertools import chain >>> class AntonChigurhRoller(R): ... h_coin_toss = H((0, 1)) ... def roll(self) -> Roll: ... source_rolls = list(self.source_rolls()) ... def _roll_outcomes_gen(): ... for roll_outcome in chain.from_iterable(source_rolls): ... if roll_outcome.value is None: ... # Omit those already deceased ... continue ... elif self.h_coin_toss.roll(): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else: ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome.euthanize() ... return Roll(self, roll_outcomes=_roll_outcomes_gen(), source_rolls=source_rolls) >>> ac_r = AntonChigurhRoller(sources=(R.from_value(1), R.from_value(2), R.from_value(3))) >>> ac_r.roll() Roll( r=AntonChigurhRoller( sources=( ValueRoller(value=1, annotation=''), ValueRoller(value=2, annotation=''), ValueRoller(value=3, annotation=''), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=1, annotation=''), roll_outcomes=( RollOutcome( value=1, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=2, annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` \"\"\" ... select ( self , * which : _GetItemT , * , annotation : Any = '' ) -> SelectionRoller Shorthand for self . select_iterable ( which , annotation = annotation ) . See the select_iterable method . Source code in dyce/r.py @beartype def select ( self , * which : _GetItemT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python self.select_iterable(which, annotation=annotation)``. See the [``select_iterable`` method][dyce.r.R.select_iterable]. \"\"\" return self . select_iterable ( which , annotation = annotation ) select_from_sources ( which : Iterable [ _GetItemT ], * sources : _SourceT , * , annotation : Any = '' ) -> SelectionRoller classmethod Shorthand for cls . select_from_sources_iterable ( which , sources , annotation = annotation ) . See the select_from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_sources ( cls , which : Iterable [ _GetItemT ], * sources : _SourceT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable(which, sources, annotation=annotation)``. See the [``select_from_sources_iterable`` method][dyce.r.R.select_from_sources_iterable]. \"\"\" return cls . select_from_sources_iterable ( which , sources , annotation = annotation ) select_from_sources_iterable ( which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = '' ) -> SelectionRoller classmethod Creates and returns a SelectionRoller for applying selection which to sorted outcomes from sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_select = R . select_from_values ( ... ( 0 , - 1 , slice ( 3 , 6 ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), ... 5 , 4 , 6 , 3 , 7 , 2 , 8 , 1 , 9 , 0 , ... ) ; r_select SelectionRoller ( which = ( 0 , - 1 , slice ( 3 , 6 , None ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), sources = ( ValueRoller ( value = 5 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ... , ValueRoller ( value = 9 , annotation = '' ), ValueRoller ( value = 0 , annotation = '' ), ), annotation = '' , ) >>> tuple ( r_select . roll () . outcomes ()) ( 0 , 9 , 3 , 4 , 5 , 6 , 5 , 4 , 9 , 0 ) Source code in dyce/r.py @classmethod @beartype def select_from_sources_iterable ( cls , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Creates and returns a [``SelectionRoller``][dyce.r.SelectionRoller] for applying selection *which* to sorted outcomes from *sources*. ``` python >>> r_select = R.select_from_values( ... (0, -1, slice(3, 6), slice(6, 3, -1), -1, 0), ... 5, 4, 6, 3, 7, 2, 8, 1, 9, 0, ... ) ; r_select SelectionRoller( which=(0, -1, slice(3, 6, None), slice(6, 3, -1), -1, 0), sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_select.roll().outcomes()) (0, 9, 3, 4, 5, 6, 5, 4, 9, 0) ``` \"\"\" return SelectionRoller ( which , sources , annotation = annotation ) select_from_values ( which : Iterable [ _GetItemT ], * values : _ValueT , * , annotation : Any = '' ) -> SelectionRoller classmethod Shorthand for cls . select_from_values_iterable ( which , values , annotation = annotation ) . See the select_from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_values ( cls , which : Iterable [ _GetItemT ], * values : _ValueT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_values_iterable(which, values, annotation=annotation)``. See the [``select_from_values_iterable`` method][dyce.r.R.select_from_values_iterable]. \"\"\" return cls . select_from_values_iterable ( which , values , annotation = annotation ) select_from_values_iterable ( which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = '' ) -> SelectionRoller classmethod Shorthand for cls . select_from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and select_from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def select_from_values_iterable ( cls , which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``select_from_sources_iterable``][dyce.r.R.select_from_sources_iterable] methods. \"\"\" return cls . select_from_sources_iterable ( which , ( cls . from_value ( value ) for value in values ), annotation = annotation , ) select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = '' ) -> SelectionRoller Shorthand for type ( self ) . select_from_sources ( which , self , annotation = annotation ) . See the select_from_sources method . Source code in dyce/r.py @beartype def select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python type(self).select_from_sources(which, self, annotation=annotation)``. See the [``select_from_sources`` method][dyce.r.R.select_from_sources]. \"\"\" return type ( self ) . select_from_sources ( which , self , annotation = annotation ) source_rolls ( self ) -> Iterator [ 'Roll' ] Generates new rolls from all sources . Source code in dyce/r.py @beartype def source_rolls ( self ) -> Iterator [ \"Roll\" ]: r \"\"\" Generates new rolls from all [``sources``][dyce.r.R.sources]. \"\"\" for source in self . sources : yield source . roll () umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = '' ) -> UnarySumOpRoller Creates and returns a UnarySumOpRoller roller for applying un_op to this roller as its source. 1 2 3 4 5 6 7 8 9 >>> import operator >>> r_un_op = R . from_value ( H ( 6 )) . umap ( operator . __neg__ ) ; r_un_op UnarySumOpRoller ( un_op =< built - in function neg > , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_un_op == - R . from_value ( H ( 6 )) True Source code in dyce/r.py @beartype def umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = \"\" , ) -> UnarySumOpRoller : r \"\"\" Creates and returns a [``UnarySumOpRoller``][dyce.r.UnarySumOpRoller] roller for applying *un_op* to this roller as its source. ``` python >>> import operator >>> r_un_op = R.from_value(H(6)).umap(operator.__neg__) ; r_un_op UnarySumOpRoller( un_op=<built-in function neg>, source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_un_op == -R.from_value(H(6)) True ``` \"\"\" return UnarySumOpRoller ( un_op , self , annotation = annotation ) RepeatRoller ( R ) A roller to implement the __matmul__ operator. It is akin to a homogeneous PoolRoller containing n identical source s. 1 2 3 4 5 6 7 8 9 10 >>> d20 = H ( 20 ) >>> r_d20 = R . from_value ( d20 ) >>> r_d20_100 = 100 @r_d20 ; r_d20_100 RepeatRoller ( n = 100 , source = ValueRoller ( value = H ( 20 ), annotation = '' ), annotation = '' , ) >>> all ( outcome in d20 for outcome in r_d20_100 . roll () . outcomes ()) True __slots__ : Union [ str , Iterable [ str ]] special n : int property readonly The number of times to \u201crepeat\u201d the roller\u2019s sole source. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . n == other . n __init__ ( self , n : SupportsIntSCU , source : _SourceT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , n : SupportsIntSCU , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _n = as_int ( n ) __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( n= { self . n !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls : List [ Roll ] = [] for _ in range ( self . n ): source_rolls . extend ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , ) Roll ( Sequence , Generic ) Experimental This class should be considered experimental and may change or disappear in future versions. An immutable roll result (or \u201croll\u201d for short). More specifically, the result of calling the R.roll method . Rolls are sequences of RollOutcome objects that can be assembled into trees. __slots__ : Union [ str , Iterable [ str ]] special annotation : Any property readonly Shorthand for self . r . annotation . See the R.annotation property . r : R property readonly The roller that generated the roll. source_rolls : Tuple [ Roll , ... ] property readonly The source rolls from which this roll was generated. __getitem__ ( self , key : _GetItemT ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]] special Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( # type: ignore self , key : _GetItemT , ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]]: if isinstance ( key , slice ): return self . _roll_outcomes [ key ] else : return self . _roll_outcomes [ __index__ ( key )] __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ 'Roll' ] = ()) special Initializer. This initializer will associate each of roll_outcomes with the newly constructed roll if they do not already have a source_roll . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_4 = ValueRoller ( 4 ) >>> roll = r_4 . roll () >>> new_roll = Roll ( r_4 , roll ) ; new_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ) >>> roll [ 0 ] . source_roll == roll True >>> roll [ 0 ] . r == r_4 True Note Technically, this violates the immutability of roll outcomes. dyce does not generally contemplate creation of rolls or roll outcomes outside the womb of R.roll implementations. Roll and RollOutcome objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the RollOutcome.source_roll property . Source code in dyce/r.py @experimental @beartype def __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ \"Roll\" ] = (), ): r \"\"\" Initializer. This initializer will associate each of *roll_outcomes* with the newly constructed roll if they do not already have a [``source_roll``][dyce.r.RollOutcome.source_roll]. ``` python >>> r_4 = ValueRoller(4) >>> roll = r_4.roll() >>> new_roll = Roll(r_4, roll) ; new_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) >>> roll[0].source_roll == roll True >>> roll[0].r == r_4 True ``` !!! note Technically, this violates the immutability of roll outcomes. ``dyce`` does not generally contemplate creation of rolls or roll outcomes outside the womb of [``R.roll``][dyce.r.R.roll] implementations. [``Roll``][dyce.r.Roll] and [``RollOutcome``][dyce.r.RollOutcome] objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the [``RollOutcome.source_roll`` property][dyce.r.RollOutcome.source_roll]. \"\"\" super () . __init__ () self . _r = r self . _roll_outcomes = tuple ( roll_outcomes ) self . _source_rolls = tuple ( source_rolls ) for roll_outcome in self . _roll_outcomes : if not roll_outcome . _has_roll : roll_outcome . _roll = self __iter__ ( self ) -> Iterator [ RollOutcome ] special Source code in dyce/r.py @beartype def __iter__ ( self ) -> Iterator [ RollOutcome ]: return iter ( self . _roll_outcomes ) __len__ ( self ) -> int special Source code in dyce/r.py @beartype def __len__ ( self ) -> int : return len ( self . _roll_outcomes ) __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( r= { indent ( repr ( self . r ), \" \" ) . strip () } , roll_outcomes=( { _seq_repr ( self ) } ), source_rolls=( { _seq_repr ( self . source_rolls ) } ), )\"\"\" outcomes ( self ) -> Iterator [ RealLikeSCU ] Shorthand for ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) . Info Unlike H.roll and P.roll , these outcomes are not sorted. Instead, they retain the ordering from whence they came in the roller tree. 1 2 3 4 5 6 7 >>> r_3d6 = 3 @R . from_value ( H ( 6 )) >>> r_3d6_neg = 3 @- R . from_value ( H ( 6 )) >>> roll = R . from_sources ( r_3d6 , r_3d6_neg ) . roll () >>> tuple ( roll . outcomes ()) ( 1 , 3 , 1 , - 4 , - 6 , - 1 ) >>> len ( roll ) 6 Source code in dyce/r.py @beartype def outcomes ( self ) -> Iterator [ RealLikeSCU ]: r \"\"\" Shorthand for ``#!python (roll_outcome.value for roll_outcome in self if roll_outcome.value is not None)``. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056410) -- END MONKEY PATCH --> !!! info Unlike [``H.roll``][dyce.h.H.roll] and [``P.roll``][dyce.p.P.roll], these outcomes are *not* sorted. Instead, they retain the ordering from whence they came in the roller tree. ``` python >>> r_3d6 = 3@R.from_value(H(6)) >>> r_3d6_neg = 3@-R.from_value(H(6)) >>> roll = R.from_sources(r_3d6, r_3d6_neg).roll() >>> tuple(roll.outcomes()) (1, 3, 1, -4, -6, -1) >>> len(roll) 6 ``` \"\"\" return ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) total ( self ) -> RealLikeSCU Shorthand for sum ( self . outcomes ()) . Source code in dyce/r.py @beartype def total ( self ) -> RealLikeSCU : r \"\"\" Shorthand for ``#!python sum(self.outcomes())``. \"\"\" return sum ( self . outcomes ()) RollOutcome Experimental This class should be considered experimental and may change or disappear in future versions. A single, ( mostly ) immutable outcome generated by a roll. __slots__ : Union [ str , Iterable [ str ]] special annotation : Any property readonly Shorthand for self . source_roll . annotation . See the source_roll and Roll.annotation properties. r : R property readonly Shorthand for self . source_roll . r . See the source_roll and Roll.r properties. source_roll : Roll property readonly Returns the roll if one has been associated with this roll outcome. Usually that happens by submitting the roll outcome to the Roll.__init__ method inside a R.roll method implementation. Accessing this property before the roll outcome has been associated with a roll is considered a programming error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> ro = RollOutcome ( 4 ) >>> ro . source_roll Traceback ( most recent call last ): ... AssertionError : RollOutcome . source_roll accessed before associating the roll outcome with a roll ( usually via Roll . __init__ ) assert None is not None >>> roll = Roll ( R . from_value ( 4 ), roll_outcomes = ( ro ,)) >>> ro . source_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ) sources : Tuple [ RollOutcome , ... ] property readonly The source roll outcomes from which this roll outcome was generated. value : Optional [ RealLikeSCU ] property readonly The outcome value. A value of None is used to signal that a source\u2019s roll outcome was excluded by the roller. __abs__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __abs__ ( self ) -> RollOutcome : return self . umap ( __abs__ ) __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented __and__ ( self , other : Union [ 'RollOutcome' , SupportsIntSCU ]) -> RollOutcome special Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ \"RollOutcome\" , SupportsIntSCU ]) -> RollOutcome : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __eq__ ( self . value , other . value )) else : return super () . __eq__ ( other ) __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented __ge__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype def __ge__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ge__ ( self . value , other . value )) else : return NotImplemented __gt__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype def __gt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __gt__ ( self . value , other . value )) else : return NotImplemented __init__ ( self , value : Optional [ RealLikeSCU ], sources : Iterable [ 'RollOutcome' ] = ()) special Initializer. Source code in dyce/r.py @beartype def __init__ ( self , value : Optional [ RealLikeSCU ], sources : Iterable [ \"RollOutcome\" ] = (), ): r \"Initializer.\" super () . __init__ () self . _value = value self . _sources = tuple ( sources ) self . _roll : Optional [ Roll ] = None if self . _value is None and not self . _sources : raise ValueError ( \"value can only be None if sources is non-empty\" ) __invert__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __invert__ ( self ) -> RollOutcome : return self . umap ( __invert__ ) __le__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype def __le__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __le__ ( self . value , other . value )) else : return NotImplemented __lt__ ( self , other : _RollOutcomeOperandT ) -> bool special Source code in dyce/r.py @beartype def __lt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __lt__ ( self . value , other . value )) else : return NotImplemented __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented __ne__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ne__ ( self . value , other . value )) else : return super () . __ne__ ( other ) __neg__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __neg__ ( self ) -> RollOutcome : return self . umap ( __neg__ ) __or__ ( self , other : Union [ 'RollOutcome' , SupportsIntSCU ]) -> RollOutcome special Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ \"RollOutcome\" , SupportsIntSCU ]) -> RollOutcome : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented __pos__ ( self ) -> RollOutcome special Source code in dyce/r.py @beartype def __pos__ ( self ) -> RollOutcome : return self . umap ( __pos__ ) __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented __radd__ ( self , other : RealLikeSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented __rand__ ( self , other : SupportsIntSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsIntSCU ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( value= { repr ( self . value ) } , sources=( { _seq_repr ( self . sources ) } ), )\"\"\" __rfloordiv__ ( self , other : RealLikeSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLikeSCU ) -> RollOutcome : # type: ignore try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented __rmod__ ( self , other : RealLikeSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented __rmul__ ( self , other : RealLikeSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented __ror__ ( self , other : SupportsIntSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsIntSCU ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented __rpow__ ( self , other : RealLikeSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented __rsub__ ( self , other : RealLikeSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented __rtruediv__ ( self , other : RealLikeSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented __rxor__ ( self , other : SupportsIntSCU ) -> RollOutcome special Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsIntSCU ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome special Source code in dyce/r.py @beartype def __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented __xor__ ( self , other : Union [ 'RollOutcome' , SupportsIntSCU ]) -> RollOutcome special Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ \"RollOutcome\" , SupportsIntSCU ]) -> RollOutcome : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __xor__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __eq__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __eq__ ( self . value , other )), sources = ( self ,)) euthanize ( self ) -> RollOutcome Shorthand for self . umap ( lambda operand : None ) . 1 2 3 4 5 6 7 8 9 10 11 >>> two = RollOutcome ( 2 ) >>> two . euthanize () RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) See the umap method . Source code in dyce/r.py @beartype def euthanize ( self ) -> RollOutcome : r \"\"\" Shorthand for ``#!python self.umap(lambda operand: None)``. ``` python >>> two = RollOutcome(2) >>> two.euthanize() RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ) ``` See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" def _euthanize ( operand : Optional [ RealLikeSCU ]) -> Optional [ RealLikeSCU ]: return None return self . umap ( _euthanize ) ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __ge__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __ge__ ( self . value , other )), sources = ( self ,)) gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __gt__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __gt__ ( self . value , other )), sources = ( self ,)) is_even ( self ) -> RollOutcome Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_even ) is_odd ( self ) -> RollOutcome Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_odd ) le ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def le ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __le__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __le__ ( self . value , other )), sources = ( self ,)) lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __lt__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __lt__ ( self . value , other )), sources = ( self ,)) map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT ) -> RollOutcome Applies bin_op to the value of this roll outcome as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . map ( operator . __pow__ , 10 ) RollOutcome ( value = 1024 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . map ( operator . __pow__ , 10 ) == two ** 10 True Source code in dyce/r.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT , ) -> RollOutcome : r \"\"\" Applies *bin_op* to the value of this roll outcome as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.map(operator.__pow__, 10) RollOutcome( value=1024, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.map(operator.__pow__, 10) == two ** 10 True ``` \"\"\" if isinstance ( right_operand , RollOutcome ): sources : Tuple [ RollOutcome , ... ] = ( self , right_operand ) right_operand_value : Optional [ RealLikeSCU ] = right_operand . value else : sources = ( self ,) right_operand_value = right_operand if isinstance ( right_operand_value , RealLikeSCT ): return RollOutcome ( bin_op ( self . value , right_operand_value ), sources ) else : raise NotImplementedError ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome Source code in dyce/r.py @beartype def ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __ne__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __ne__ ( self . value , other )), sources = ( self ,)) rmap ( self , left_operand : RealLikeSCU , bin_op : _BinaryOperatorT ) -> RollOutcome Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . rmap ( 10 , operator . __pow__ ) RollOutcome ( value = 100 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . rmap ( 10 , operator . __pow__ ) == 10 ** two True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : RealLikeSCU , bin_op : _BinaryOperatorT , ) -> RollOutcome : r \"\"\" Analogous to the [``map`` method][dyce.r.RollOutcome.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.rmap(10, operator.__pow__) RollOutcome( value=100, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.rmap(10, operator.__pow__) == 10 ** two True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.RollOutcome.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLikeSCT ): return RollOutcome ( bin_op ( left_operand , self . value ), sources = ( self ,)) else : raise NotImplementedError umap ( self , un_op : _UnaryOperatorT ) -> RollOutcome Applies un_op to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two_neg = RollOutcome ( - 2 ) >>> two_neg . umap ( operator . __neg__ ) RollOutcome ( value = 2 , sources = ( RollOutcome ( value =- 2 , sources = (), ), ), ) >>> two_neg . umap ( operator . __neg__ ) == - two_neg True Source code in dyce/r.py @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> RollOutcome : r \"\"\" Applies *un_op* to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two_neg = RollOutcome(-2) >>> two_neg.umap(operator.__neg__) RollOutcome( value=2, sources=( RollOutcome( value=-2, sources=(), ), ), ) >>> two_neg.umap(operator.__neg__) == -two_neg True ``` \"\"\" return RollOutcome ( un_op ( self . value ), sources = ( self ,)) RollWalkerVisitor Experimental This function should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each Roll object found. __slots__ : Union [ str , Iterable [ str ]] special on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None Source code in dyce/r.py @abstractmethod def on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None : ... RollerWalkerVisitor Experimental This function should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each R object found. __slots__ : Union [ str , Iterable [ str ]] special on_roller ( self , r : R , parents : Iterator [ R ]) -> None Source code in dyce/r.py @abstractmethod def on_roller ( self , r : R , parents : Iterator [ R ]) -> None : ... SelectionRoller ( R ) A roller for sorting outcomes from its sources and applying a selector which . Roll outcomes in created rolls are ordered according to the selections which . However, those selections are interpreted as indexes in a sorted view of the source\u2019s roll outcomes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 >>> r_values = R . from_values ( 10000 , 1 , 1000 , 10 , 100 ) >>> outcomes = tuple ( r_values . roll () . outcomes ()) ; outcomes ( 10000 , 1 , 1000 , 10 , 100 ) >>> sorted_outcomes = tuple ( sorted ( outcomes )) ; sorted_outcomes ( 1 , 10 , 100 , 1000 , 10000 ) >>> which = ( 3 , 1 , 3 , 2 ) >>> tuple ( sorted_outcomes [ i ] for i in which ) ( 1000 , 10 , 1000 , 100 ) >>> r_select = r_values . select_iterable ( which ) ; r_select SelectionRoller ( which = ( 3 , 1 , 3 , 2 ), sources = ( PoolRoller ( sources = ( ValueRoller ( value = 10000 , annotation = '' ), ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 1000 , annotation = '' ), ValueRoller ( value = 10 , annotation = '' ), ValueRoller ( value = 100 , annotation = '' ), ), annotation = '' , ), ), annotation = '' , ) >>> roll = r_select . roll () >>> tuple ( roll . outcomes ()) ( 1000 , 10 , 1000 , 100 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 10 , sources = (), ), RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 100 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 10000 , sources = (), ), ), ), ), source_rolls =... , ) __slots__ : Union [ str , Iterable [ str ]] special which : Tuple [ _GetItemT , ... ] property readonly The selector this roller applies to the sorted outcomes of its sole source. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . which == other . which __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _which = tuple ( which ) __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( which= { self . which !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) roll_outcomes = list ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ) roll_outcomes . sort ( key = attrgetter ( \"value\" )) all_indexes = tuple ( range ( len ( roll_outcomes ))) selected_indexes = tuple ( getitems ( all_indexes , self . which )) def _selected_roll_outcomes (): for selected_index in selected_indexes : selected_roll_outcome = roll_outcomes [ selected_index ] assert selected_roll_outcome . value is not None yield selected_roll_outcome for excluded_index in set ( all_indexes ) - set ( selected_indexes ): yield roll_outcomes [ excluded_index ] . euthanize () return Roll ( self , roll_outcomes = _selected_roll_outcomes (), source_rolls = source_rolls , ) UnarySumOpRoller ( NarySumOpRoller ) An NarySumOpRoller for applying a unary operator un_op to the sum of all outcomes from its sole source . __slots__ : Union [ str , Iterable [ str ]] special un_op : _RollOutcomeUnaryOperatorT property readonly The operator this roller applies to its sources. __eq__ ( self , other ) -> bool special Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . un_op , other . un_op )) __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: ( operand ,) = roll_outcomes return un_op ( operand ) super () . __init__ ( op = _op , sources = ( source ,), annotation = annotation , ** kw ) self . _un_op = un_op __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( un_op= { self . un_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\" ValueRoller ( R ) A roller whose roll outcomes are derived from scalars, H objects , P objects , RollOutcome objects , or even Roll objects , instead of other source rollers. __slots__ : Union [ str , Iterable [ str ]] special value : _ValueT property readonly The value to be emitted by this roller via its ValueRoller.roll method . __init__ ( self , value : _ValueT , annotation : Any = '' , ** kw ) special Source code in dyce/r.py @beartype def __init__ ( self , value : _ValueT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = (), annotation = annotation , ** kw ) if isinstance ( value , P ) and not value . is_homogeneous : warnings . warn ( f \"using a heterogeneous pool ( { value } ) is not recommended where traceability is important\" , stacklevel = 2 , ) self . _value = value __repr__ ( self ) -> str special Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \" { type ( self ) . __name__ } (value= { self . value !r} , annotation= { self . annotation !r} )\" roll ( self ) -> Roll Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" if isinstance ( self . value , Roll ): return self . value elif isinstance ( self . value , RollOutcome ): return Roll ( self , roll_outcomes = ( self . value ,)) elif isinstance ( self . value , P ): return Roll ( self , roll_outcomes = ( RollOutcome ( outcome ) for outcome in self . value . roll ()), ) elif isinstance ( self . value , H ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value . roll ()),)) elif isinstance ( self . value , RealLikeSCT ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value ),)) else : assert False , f \"unrecognized value type { self . value !r} \" walk ( root : Union [ Roll , R , RollOutcome ], visitor : Union [ RollWalkerVisitor , RollerWalkerVisitor , RollOutcomeWalkerVisitor ]) -> None Experimental This function should be considered experimental and may change or disappear in future versions. Walks through root , calling visitor for each matching object. No ordering guarantees are made. On the current implementation walk performs a breadth-first traversal of root , assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. Source code in dyce/r.py @experimental @beartype def walk ( root : Union [ Roll , R , RollOutcome ], visitor : Union [ RollWalkerVisitor , RollerWalkerVisitor , RollOutcomeWalkerVisitor ], ) -> None : r \"\"\" !!! warning \"Experimental\" This function should be considered experimental and may change or disappear in future versions. Walks through *root*, calling *visitor* for each matching object. No ordering guarantees are made. !!! info \"On the current implementation\" ``#!python walk`` performs a breadth-first traversal of *root*, assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. \"\"\" rolls : Dict [ int , Roll ] = {} rollers : Dict [ int , R ] = {} roll_outcomes : Dict [ int , RollOutcome ] = {} roll_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roller_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roll_outcome_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) queue = deque (( root ,)) roll : Roll r : R roll_outcome : RollOutcome while queue : obj = queue . popleft () if isinstance ( obj , Roll ): roll = obj if id ( roll ) not in rolls : rolls [ id ( roll )] = roll queue . append ( roll . r ) for i , roll_outcome in enumerate ( roll ): queue . append ( roll_outcome ) for source_roll in roll . source_rolls : roll_parent_ids [ id ( source_roll )] . add ( id ( roll )) queue . append ( source_roll ) elif isinstance ( obj , R ): r = obj if id ( r ) not in rollers : rollers [ id ( r )] = r for source_r in r . sources : roller_parent_ids [ id ( source_r )] . add ( id ( r )) queue . append ( source_r ) elif isinstance ( obj , RollOutcome ): roll_outcome = obj if id ( roll_outcome ) not in roll_outcomes : roll_outcomes [ id ( roll_outcome )] = roll_outcome for source_roll_outcome in roll_outcome . sources : roll_outcome_parent_ids [ id ( source_roll_outcome )] . add ( id ( roll_outcome ) ) queue . append ( source_roll_outcome ) if rolls and isinstance ( visitor , RollWalkerVisitor ): for roll_id , roll in rolls . items (): visitor . on_roll ( roll , ( rolls [ i ] for i in roll_parent_ids [ roll_id ])) if rollers and isinstance ( visitor , RollerWalkerVisitor ): for r_id , r in rollers . items (): visitor . on_roller ( r , ( rollers [ i ] for i in roller_parent_ids [ r_id ])) if roll_outcomes and isinstance ( visitor , RollOutcomeWalkerVisitor ): for roll_outcome_id , roll_outcome in roll_outcomes . items (): visitor . on_roll_outcome ( roll_outcome , ( roll_outcomes [ i ] for i in roll_outcome_parent_ids [ roll_outcome_id ]), )","title":"<tt>dyce.r</tt>"},{"location":"dyce.r/#dycer-package-reference","text":"Experimental This package is an attempt to provide primitives for producing weighted randomized rolls without the overhead of enumeration. Rolls can be inspected to understand how specific values are derived. It should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Feedback, suggestions, and contributions are welcome and appreciated.","title":"dyce.r package reference"},{"location":"dyce.r/#roller-class-hierarchy","text":"","title":"Roller class hierarchy"},{"location":"dyce.r/#dyce.r.BasicOpRoller","text":"A roller for applying op to some variation of outcomes from sources . Any RollOutcome s returned by op are used directly in the creation of a new Roll .","title":"BasicOpRoller"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.BasicOpRoller.op","text":"The operator this roller applies to its sources.","title":"op"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . op , other . op ))","title":"__eq__()"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , op : BasicOperatorT , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _op = op","title":"__init__()"},{"location":"dyce.r/#dyce.r.BasicOpRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( op= { self . op !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.BasicOpRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) res = self . op ( self , ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), ) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller","text":"An NarySumOpRoller for applying a binary operator bin_op to the sum of all outcomes from its left_source and the sum of all outcomes from its right_source .","title":"BinarySumOpRoller"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.bin_op","text":"The operator this roller applies to its sources.","title":"bin_op"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . bin_op , other . bin_op ))","title":"__eq__()"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , bin_op : _RollOutcomeBinaryOperatorT , left_source : _SourceT , right_source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: left_operand , right_operand = roll_outcomes return bin_op ( left_operand , right_operand ) super () . __init__ ( op = _op , sources = ( left_source , right_source ), annotation = annotation , ** kw ) self . _bin_op = bin_op","title":"__init__()"},{"location":"dyce.r/#dyce.r.BinarySumOpRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : def _source_repr ( source : _SourceT ) -> str : return indent ( repr ( source ), \" \" ) . strip () left_source , right_source = self . sources return f \"\"\" { type ( self ) . __name__ } ( bin_op= { self . bin_op !r} , left_source= { _source_repr ( left_source ) } , right_source= { _source_repr ( right_source ) } , annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.NarySumOpRoller","text":"A BasicOpRoller for applying op to the sum of outcomes grouped by each of sources .","title":"NarySumOpRoller"},{"location":"dyce.r/#dyce.r.NarySumOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.NarySumOpRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) def _sum_roll_outcomes_by_rolls () -> Iterator [ RollOutcome ]: for source_roll in source_rolls : if len ( source_roll ) == 1 and source_roll [ 0 ] . value is not None : yield from source_roll else : yield RollOutcome ( sum ( source_roll . outcomes ()), sources = source_roll ) res = self . op ( self , _sum_roll_outcomes_by_rolls ()) if isinstance ( res , RollOutcome ): roll_outcomes = ( res ,) else : roll_outcomes = res # type: ignore # TODO(posita): WTF? return Roll ( self , roll_outcomes = roll_outcomes , source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.PoolRoller","text":"A roller for rolling flattened \u201cpools\u201d from all sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 >>> PoolRoller (( ... PoolRoller (( ... ValueRoller ( 11 ), ... ValueRoller ( 12 ), ... )), ... PoolRoller (( ... PoolRoller (( ... ValueRoller ( 211 ), ... ValueRoller ( 212 ), ... )), ... PoolRoller (( ... ValueRoller ( 221 ), ... ValueRoller ( 222 ), ... )), ... )), ... ValueRoller ( 3 ), ... )) . roll () Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 11 , sources =... , ), RollOutcome ( value = 12 , sources =... , ), RollOutcome ( value = 211 , sources =... , ), RollOutcome ( value = 212 , sources =... , ), RollOutcome ( value = 221 , sources =... , ), RollOutcome ( value = 222 , sources =... , ), RollOutcome ( value = 3 , sources =... , ), ), source_rolls =... , )","title":"PoolRoller"},{"location":"dyce.r/#dyce.r.PoolRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.PoolRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.R","text":"Experimental This class (and its descendants) should be considered experimental and may change or disappear in future versions. Where H objects and P objects are used primarily for enumerating weighted outcomes, R objects represent rollers. More specifically, they are immutable nodes assembled in tree-like structures to represent calculations. Unlike H or P objects, rollers generate rolls that conform to weighted outcomes without engaging in computationally expensive enumeration. Roller trees are typically composed from various R class methods and operators as well as arithmetic operations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 >>> from dyce import H , P , R >>> d6 = H ( 6 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> (( 4 * r_d6 + 3 ) ** 2 % 5 ) . gt ( 2 ) BinarySumOpRoller ( bin_op =< function R . gt .< locals >. _gt at ...> , left_source = BinarySumOpRoller ( bin_op =< built - in function mod > , left_source = BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = BinarySumOpRoller ( bin_op =< built - in function add > , left_source = BinarySumOpRoller ( bin_op =< built - in function mul > , left_source = ValueRoller ( value = 4 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 3 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 5 , annotation = '' ), annotation = '' , ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) Info No optimizations are made when initializing roller trees. They retain their exact structure, even where such structures could be trivially reduced. 1 2 3 4 5 6 7 >>> r_6 = R . from_value ( 6 ) >>> r_6_abs_3 = 3 @ abs ( r_6 ) >>> r_6_abs_6_abs_6_abs = R . from_sources ( abs ( r_6 ), abs ( r_6 ), abs ( r_6 )) >>> tuple ( r_6_abs_3 . roll () . outcomes ()), tuple ( r_6_abs_6_abs_6_abs . roll () . outcomes ()) # they generate the same rolls (( 6 , 6 , 6 ), ( 6 , 6 , 6 )) >>> r_6_abs_3 == r_6_abs_6_abs_6_abs # and yet, they're different animals False This is because the structure itself contains information that might be required by certain contexts. If such information loss is permissible and reduction is desirable, consider using histograms instead. Roller trees can can be queried via the roll method , which produces Roll objects . 1 2 3 4 5 >>> roll = r_d6 . roll () >>> tuple ( roll . outcomes ()) ( 4 ,) >>> roll . total () 4 1 2 3 4 >>> d6 + 3 H ({ 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }) >>> ( r_d6 + 3 ) . roll () . total () in ( d6 + 3 ) True Roll objects are much richer than mere sequences of outcomes. They are also tree-like structures that mirror the roller trees used to produce them, capturing references to rollers and the outcomes generated at each node. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 >>> roll = ( r_d6 + 3 ) . roll () >>> roll . total () 8 >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 8 , sources = ( RollOutcome ( value = 5 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 6 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 5 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Rollers afford optional annotations as a convenience to callers. They are taken into account when comparing roller trees, but otherwise ignored, internally. One use is to capture references to nodes in an abstract syntax tree generated from parsing a proprietary grammar. Any provided annotation can be retrieved using the annotation property . The annotate method can be used to apply an annotation to existing roller. The R class itself acts as a base from which several computation-specific implementations derive (such as expressing operands like outcomes or histograms, unary operations, binary operations, pools, etc.).","title":"R"},{"location":"dyce.r/#dyce.r.R.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.R.annotation","text":"Any provided annotation.","title":"annotation"},{"location":"dyce.r/#dyce.r.R.sources","text":"The roller\u2019s direct sources (if any).","title":"sources"},{"location":"dyce.r/#dyce.r.R.__abs__","text":"Source code in dyce/r.py @beartype def __abs__ ( self ) -> UnarySumOpRoller : return self . umap ( __abs__ )","title":"__abs__()"},{"location":"dyce.r/#dyce.r.R.__add__","text":"Source code in dyce/r.py @beartype def __add__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented","title":"__add__()"},{"location":"dyce.r/#dyce.r.R.__and__","text":"Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __and__ , other ) else : return self . map ( __and__ , as_int ( other )) except NotImplementedError : return NotImplemented","title":"__and__()"},{"location":"dyce.r/#dyce.r.R.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , R ): return ( ( isinstance ( self , type ( other )) or isinstance ( other , type ( self ))) and __eq__ ( self . sources , other . sources ) # order matters and __eq__ ( self . annotation , other . annotation ) ) else : return super () . __eq__ ( other )","title":"__eq__()"},{"location":"dyce.r/#dyce.r.R.__floordiv__","text":"Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented","title":"__floordiv__()"},{"location":"dyce.r/#dyce.r.R.__init__","text":"Initializer. Source code in dyce/r.py @experimental @beartype def __init__ ( self , sources : Iterable [ _SourceT ] = (), annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ () self . _sources = tuple ( sources ) self . _annotation = annotation","title":"__init__()"},{"location":"dyce.r/#dyce.r.R.__invert__","text":"Source code in dyce/r.py @beartype def __invert__ ( self ) -> UnarySumOpRoller : return self . umap ( __invert__ )","title":"__invert__()"},{"location":"dyce.r/#dyce.r.R.__matmul__","text":"Source code in dyce/r.py @beartype def __matmul__ ( self , other : SupportsIntSCU ) -> R : try : other = as_int ( other ) except TypeError : return NotImplemented if other < 0 : raise ValueError ( \"argument cannot be negative\" ) else : return RepeatRoller ( other , self )","title":"__matmul__()"},{"location":"dyce.r/#dyce.r.R.__mod__","text":"Source code in dyce/r.py @beartype def __mod__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented","title":"__mod__()"},{"location":"dyce.r/#dyce.r.R.__mul__","text":"Source code in dyce/r.py @beartype def __mul__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented","title":"__mul__()"},{"location":"dyce.r/#dyce.r.R.__ne__","text":"Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , R ): return not __eq__ ( self , other ) else : return super () . __ne__ ( other )","title":"__ne__()"},{"location":"dyce.r/#dyce.r.R.__neg__","text":"Source code in dyce/r.py @beartype def __neg__ ( self ) -> UnarySumOpRoller : return self . umap ( __neg__ )","title":"__neg__()"},{"location":"dyce.r/#dyce.r.R.__or__","text":"Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __or__ , other ) else : return self . map ( __or__ , as_int ( other )) except NotImplementedError : return NotImplemented","title":"__or__()"},{"location":"dyce.r/#dyce.r.R.__pos__","text":"Source code in dyce/r.py @beartype def __pos__ ( self ) -> UnarySumOpRoller : return self . umap ( __pos__ )","title":"__pos__()"},{"location":"dyce.r/#dyce.r.R.__pow__","text":"Source code in dyce/r.py @beartype def __pow__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented","title":"__pow__()"},{"location":"dyce.r/#dyce.r.R.__radd__","text":"Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented","title":"__radd__()"},{"location":"dyce.r/#dyce.r.R.__rand__","text":"Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __and__ ) except NotImplementedError : return NotImplemented","title":"__rand__()"},{"location":"dyce.r/#dyce.r.R.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.R.__rfloordiv__","text":"Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : # type: ignore try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented","title":"__rfloordiv__()"},{"location":"dyce.r/#dyce.r.R.__rmatmul__","text":"Source code in dyce/r.py @beartype def __rmatmul__ ( self , other : SupportsIntSCU ) -> R : return self . __matmul__ ( other )","title":"__rmatmul__()"},{"location":"dyce.r/#dyce.r.R.__rmod__","text":"Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented","title":"__rmod__()"},{"location":"dyce.r/#dyce.r.R.__rmul__","text":"Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented","title":"__rmul__()"},{"location":"dyce.r/#dyce.r.R.__ror__","text":"Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __or__ ) except NotImplementedError : return NotImplemented","title":"__ror__()"},{"location":"dyce.r/#dyce.r.R.__rpow__","text":"Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented","title":"__rpow__()"},{"location":"dyce.r/#dyce.r.R.__rsub__","text":"Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented","title":"__rsub__()"},{"location":"dyce.r/#dyce.r.R.__rtruediv__","text":"Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLikeSCU ) -> BinarySumOpRoller : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented","title":"__rtruediv__()"},{"location":"dyce.r/#dyce.r.R.__rxor__","text":"Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsIntSCU ) -> BinarySumOpRoller : try : return self . rmap ( as_int ( other ), __xor__ ) except NotImplementedError : return NotImplemented","title":"__rxor__()"},{"location":"dyce.r/#dyce.r.R.__sub__","text":"Source code in dyce/r.py @beartype def __sub__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented","title":"__sub__()"},{"location":"dyce.r/#dyce.r.R.__truediv__","text":"Source code in dyce/r.py @beartype def __truediv__ ( self , other : _ROperandT ) -> BinarySumOpRoller : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented","title":"__truediv__()"},{"location":"dyce.r/#dyce.r.R.__xor__","text":"Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ _SourceT , SupportsIntSCU ]) -> BinarySumOpRoller : try : if isinstance ( other , R ): return self . map ( __xor__ , other ) else : return self . map ( __xor__ , as_int ( other )) except NotImplementedError : return NotImplemented","title":"__xor__()"},{"location":"dyce.r/#dyce.r.R.annotate","text":"Generates a copy of the roller with the desired annotation. 1 2 3 4 >>> r_just_the_n_of_us = R . from_value ( 5 , annotation = \"But I'm 42!\" ) ; r_just_the_n_of_us ValueRoller ( value = 5 , annotation = \"But I'm 42!\" ) >>> r_just_the_n_of_us . annotate ( \"I'm a 42-year-old investment banker!\" ) ValueRoller ( value = 5 , annotation = \"I'm a 42-year-old investment banker!\" ) Source code in dyce/r.py @beartype def annotate ( self , annotation : Any = \"\" ) -> R : r \"\"\" Generates a copy of the roller with the desired annotation. ``` python >>> r_just_the_n_of_us = R.from_value(5, annotation=\"But I'm 42!\") ; r_just_the_n_of_us ValueRoller(value=5, annotation=\"But I'm 42!\") >>> r_just_the_n_of_us.annotate(\"I'm a 42-year-old investment banker!\") ValueRoller(value=5, annotation=\"I'm a 42-year-old investment banker!\") ``` \"\"\" r = copy ( self ) r . _annotation = annotation return r","title":"annotate()"},{"location":"dyce.r/#dyce.r.R.eq","text":"Shorthand for self . map ( lambda left , right : left . eq ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def eq ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.eq(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _eq ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . eq ( right_operand ) return self . map ( _eq , other )","title":"eq()"},{"location":"dyce.r/#dyce.r.R.from_sources","text":"Shorthand for cls . from_sources_iterable ( rs , annotation = annotation ) . See the from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def from_sources ( cls , * sources : _SourceT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable(rs, annotation=annotation)``. See the [``from_sources_iterable`` method][dyce.r.R.from_sources_iterable]. \"\"\" return cls . from_sources_iterable ( sources , annotation = annotation )","title":"from_sources()"},{"location":"dyce.r/#dyce.r.R.from_sources_iterable","text":"Creates and returns a roller for \u201cpooling\u201d zero or more sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> r_pool = R . from_sources_iterable ( R . from_value ( h ) for h in ( H (( 1 , 2 )), H (( 3 , 4 )), H (( 5 , 6 )))) >>> roll = r_pool . roll () >>> tuple ( roll . outcomes ()) ( 2 , 4 , 6 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), RollOutcome ( value = 6 , sources = (), ), ), source_rolls =... , ) Source code in dyce/r.py @classmethod @beartype def from_sources_iterable ( cls , sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Creates and returns a roller for \u201cpooling\u201d zero or more *sources*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056341) -- END MONKEY PATCH --> ``` python >>> r_pool = R.from_sources_iterable(R.from_value(h) for h in (H((1, 2)), H((3, 4)), H((5, 6)))) >>> roll = r_pool.roll() >>> tuple(roll.outcomes()) (2, 4, 6) >>> roll Roll( r=..., roll_outcomes=( RollOutcome( value=2, sources=(), ), RollOutcome( value=4, sources=(), ), RollOutcome( value=6, sources=(), ), ), source_rolls=..., ) ``` \"\"\" return PoolRoller ( sources , annotation = annotation )","title":"from_sources_iterable()"},{"location":"dyce.r/#dyce.r.R.from_value","text":"Creates and returns a ValueRoller from value . 1 2 >>> R . from_value ( 6 ) ValueRoller ( value = 6 , annotation = '' ) 1 2 >>> R . from_value ( H ( 6 )) ValueRoller ( value = H ( 6 ), annotation = '' ) 1 2 >>> R . from_value ( P ( 6 , 6 )) ValueRoller ( value = P ( 6 , 6 ), annotation = '' ) Source code in dyce/r.py @classmethod @beartype def from_value ( cls , value : _ValueT , annotation : Any = \"\" , ) -> ValueRoller : r \"\"\" Creates and returns a [``ValueRoller``][dyce.r.ValueRoller] from *value*. ``` python >>> R.from_value(6) ValueRoller(value=6, annotation='') ``` ``` python >>> R.from_value(H(6)) ValueRoller(value=H(6), annotation='') ``` ``` python >>> R.from_value(P(6, 6)) ValueRoller(value=P(6, 6), annotation='') ``` \"\"\" return ValueRoller ( value , annotation = annotation )","title":"from_value()"},{"location":"dyce.r/#dyce.r.R.from_values","text":"Shorthand for cls . from_values_iterable ( values , annotation = annotation ) . See the from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def from_values ( cls , * values : _ValueT , annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_values_iterable(values, annotation=annotation)``. See the [``from_values_iterable`` method][dyce.r.R.from_values_iterable]. \"\"\" return cls . from_values_iterable ( values , annotation = annotation )","title":"from_values()"},{"location":"dyce.r/#dyce.r.R.from_values_iterable","text":"Shorthand for cls . from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def from_values_iterable ( cls , values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> PoolRoller : r \"\"\" Shorthand for ``#!python cls.from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``from_sources_iterable``][dyce.r.R.from_sources_iterable] methods. \"\"\" return cls . from_sources_iterable ( ( cls . from_value ( value ) for value in values ), annotation = annotation , )","title":"from_values_iterable()"},{"location":"dyce.r/#dyce.r.R.ge","text":"Shorthand for self . map ( lambda left , right : left . ge ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ge ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ge(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ge ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ge ( right_operand ) return self . map ( _ge , other )","title":"ge()"},{"location":"dyce.r/#dyce.r.R.gt","text":"Shorthand for self . map ( lambda left , right : left . gt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def gt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.gt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _gt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . gt ( right_operand ) return self . map ( _gt , other )","title":"gt()"},{"location":"dyce.r/#dyce.r.R.is_even","text":"Shorthand for: self . umap ( lambda operand : operand . is_even ()) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_even())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_even ( operand : RollOutcome ) -> RollOutcome : return operand . is_even () return self . umap ( _is_even )","title":"is_even()"},{"location":"dyce.r/#dyce.r.R.is_odd","text":"Shorthand for: self . umap ( lambda operand : operand . is_odd ()) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> UnarySumOpRoller : r \"\"\" Shorthand for: ``#!python self.umap(lambda operand: operand.is_odd())``. See the [``umap`` method][dyce.r.R.umap]. \"\"\" def _is_odd ( operand : RollOutcome ) -> RollOutcome : return operand . is_odd () return self . umap ( _is_odd )","title":"is_odd()"},{"location":"dyce.r/#dyce.r.R.le","text":"Shorthand for self . map ( lambda left , right : left . le ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def le ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.le(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _le ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . le ( right_operand ) return self . map ( _le , other )","title":"le()"},{"location":"dyce.r/#dyce.r.R.lt","text":"Shorthand for self . map ( lambda left , right : left . lt ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def lt ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.lt(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _lt ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . lt ( right_operand ) return self . map ( _lt , other )","title":"lt()"},{"location":"dyce.r/#dyce.r.R.map","text":"Creates and returns a BinarySumOpRoller for applying bin_op to this roller and right_operand as its sources. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . map ( operator . __pow__ , 2 ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = H ( 6 ), annotation = '' ), right_source = ValueRoller ( value = 2 , annotation = '' ), annotation = '' , ) >>> r_bin_op == R . from_value ( H ( 6 )) ** 2 True Source code in dyce/r.py @beartype def map ( self , bin_op : _RollOutcomeBinaryOperatorT , right_operand : _ROperandT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Creates and returns a [``BinarySumOpRoller``][dyce.r.BinarySumOpRoller] for applying *bin_op* to this roller and *right_operand* as its sources. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).map(operator.__pow__, 2) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=H(6), annotation=''), right_source=ValueRoller(value=2, annotation=''), annotation='', ) >>> r_bin_op == R.from_value(H(6)) ** 2 True ``` \"\"\" if isinstance ( right_operand , RealLikeSCT ): right_operand = ValueRoller ( right_operand ) if isinstance ( right_operand , ( R , RollOutcome )): return BinarySumOpRoller ( bin_op , self , right_operand , annotation = annotation ) else : raise NotImplementedError","title":"map()"},{"location":"dyce.r/#dyce.r.R.ne","text":"Shorthand for self . map ( lambda left , right : left . ne ( right ), other ) . See the map method . Source code in dyce/r.py @beartype def ne ( self , other : _ROperandT ) -> BinarySumOpRoller : r \"\"\" Shorthand for ``#!python self.map(lambda left, right: left.ne(right), other)``. See the [``map`` method][dyce.r.R.map]. \"\"\" def _ne ( left_operand : RollOutcome , right_operand : RollOutcome ) -> RollOutcome : return left_operand . ne ( right_operand ) return self . map ( _ne , other )","title":"ne()"},{"location":"dyce.r/#dyce.r.R.rmap","text":"Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 >>> import operator >>> r_bin_op = R . from_value ( H ( 6 )) . rmap ( 2 , operator . __pow__ ) ; r_bin_op BinarySumOpRoller ( bin_op =< built - in function pow > , left_source = ValueRoller ( value = 2 , annotation = '' ), right_source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_bin_op == 2 ** R . from_value ( H ( 6 )) True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : Union [ RealLikeSCU , \"RollOutcome\" ], bin_op : _RollOutcomeBinaryOperatorT , annotation : Any = \"\" , ) -> BinarySumOpRoller : r \"\"\" Analogous to the [``map`` method][dyce.r.R.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> r_bin_op = R.from_value(H(6)).rmap(2, operator.__pow__) ; r_bin_op BinarySumOpRoller( bin_op=<built-in function pow>, left_source=ValueRoller(value=2, annotation=''), right_source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_bin_op == 2 ** R.from_value(H(6)) True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.R.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLikeSCT ): return BinarySumOpRoller ( bin_op , ValueRoller ( left_operand ), self , annotation = annotation ) elif isinstance ( left_operand , RollOutcome ): return BinarySumOpRoller ( bin_op , left_operand , self , annotation = annotation ) else : raise NotImplementedError","title":"rmap()"},{"location":"dyce.r/#dyce.r.R.roll","text":"Sub-classes should implement this method to return a new Roll object taking into account any sources . Note Implementors guarantee that all RollOutcome s in the returned Roll must be associated with a roll, including all roll outcomes\u2019 sources . Tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of None with the excluded roll outcome as its source. The RollOutcome.euthanize convenience method is provided for this purpose. See the section on \u201c Dropping dice from prior rolls \u2026 \u201d as well as the note in Roll.__init__ for additional color. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 >>> from itertools import chain >>> class AntonChigurhRoller ( R ): ... h_coin_toss = H (( 0 , 1 )) ... def roll ( self ) -> Roll : ... source_rolls = list ( self . source_rolls ()) ... def _roll_outcomes_gen (): ... for roll_outcome in chain . from_iterable ( source_rolls ): ... if roll_outcome . value is None : ... # Omit those already deceased ... continue ... elif self . h_coin_toss . roll (): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else : ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome . euthanize () ... return Roll ( self , roll_outcomes = _roll_outcomes_gen (), source_rolls = source_rolls ) >>> ac_r = AntonChigurhRoller ( sources = ( R . from_value ( 1 ), R . from_value ( 2 ), R . from_value ( 3 ))) >>> ac_r . roll () Roll ( r = AntonChigurhRoller ( sources = ( ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 2 , annotation = '' ), ValueRoller ( value = 3 , annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = 2 , sources = (), ), RollOutcome ( value = 3 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = 1 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 2 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 2 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 3 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 3 , sources = (), ), ), source_rolls = (), ), ), ) Source code in dyce/r.py @abstractmethod def roll ( self ) -> Roll : r \"\"\" Sub-classes should implement this method to return a new [``Roll`` object][dyce.r.Roll] taking into account any [sources][dyce.r.R.sources]. !!! note Implementors guarantee that all [``RollOutcome``][dyce.r.RollOutcome]s in the returned [``Roll``][dyce.r.Roll] *must* be associated with a roll, *including all roll outcomes\u2019 [``sources``][dyce.r.RollOutcome.sources]*. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633403927) -- END MONKEY PATCH --> !!! tip Show that roll outcomes from source rolls are excluded by creating a new roll outcome with a value of ``#!python None`` with the excluded roll outcome as its source. The [``RollOutcome.euthanize``][dyce.r.RollOutcome.euthanize] convenience method is provided for this purpose. See the section on \u201c[Dropping dice from prior rolls \u2026](rollin.md#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8)\u201d as well as the note in [``Roll.__init__``][dyce.r.Roll.__init__] for additional color. ``` python >>> from itertools import chain >>> class AntonChigurhRoller(R): ... h_coin_toss = H((0, 1)) ... def roll(self) -> Roll: ... source_rolls = list(self.source_rolls()) ... def _roll_outcomes_gen(): ... for roll_outcome in chain.from_iterable(source_rolls): ... if roll_outcome.value is None: ... # Omit those already deceased ... continue ... elif self.h_coin_toss.roll(): ... # This one lives. Wrap the old outcome in a new one with the same value. ... yield roll_outcome ... else: ... # This one dies here. Wrap the old outcome in a new one with a value of None. ... yield roll_outcome.euthanize() ... return Roll(self, roll_outcomes=_roll_outcomes_gen(), source_rolls=source_rolls) >>> ac_r = AntonChigurhRoller(sources=(R.from_value(1), R.from_value(2), R.from_value(3))) >>> ac_r.roll() Roll( r=AntonChigurhRoller( sources=( ValueRoller(value=1, annotation=''), ValueRoller(value=2, annotation=''), ValueRoller(value=3, annotation=''), ), annotation='', ), roll_outcomes=( RollOutcome( value=None, sources=( RollOutcome( value=1, sources=(), ), ), ), RollOutcome( value=2, sources=(), ), RollOutcome( value=3, sources=(), ), ), source_rolls=( Roll( r=ValueRoller(value=1, annotation=''), roll_outcomes=( RollOutcome( value=1, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=2, annotation=''), roll_outcomes=( RollOutcome( value=2, sources=(), ), ), source_rolls=(), ), Roll( r=ValueRoller(value=3, annotation=''), roll_outcomes=( RollOutcome( value=3, sources=(), ), ), source_rolls=(), ), ), ) ``` \"\"\" ...","title":"roll()"},{"location":"dyce.r/#dyce.r.R.select","text":"Shorthand for self . select_iterable ( which , annotation = annotation ) . See the select_iterable method . Source code in dyce/r.py @beartype def select ( self , * which : _GetItemT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python self.select_iterable(which, annotation=annotation)``. See the [``select_iterable`` method][dyce.r.R.select_iterable]. \"\"\" return self . select_iterable ( which , annotation = annotation )","title":"select()"},{"location":"dyce.r/#dyce.r.R.select_from_sources","text":"Shorthand for cls . select_from_sources_iterable ( which , sources , annotation = annotation ) . See the select_from_sources_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_sources ( cls , which : Iterable [ _GetItemT ], * sources : _SourceT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable(which, sources, annotation=annotation)``. See the [``select_from_sources_iterable`` method][dyce.r.R.select_from_sources_iterable]. \"\"\" return cls . select_from_sources_iterable ( which , sources , annotation = annotation )","title":"select_from_sources()"},{"location":"dyce.r/#dyce.r.R.select_from_sources_iterable","text":"Creates and returns a SelectionRoller for applying selection which to sorted outcomes from sources . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_select = R . select_from_values ( ... ( 0 , - 1 , slice ( 3 , 6 ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), ... 5 , 4 , 6 , 3 , 7 , 2 , 8 , 1 , 9 , 0 , ... ) ; r_select SelectionRoller ( which = ( 0 , - 1 , slice ( 3 , 6 , None ), slice ( 6 , 3 , - 1 ), - 1 , 0 ), sources = ( ValueRoller ( value = 5 , annotation = '' ), ValueRoller ( value = 4 , annotation = '' ), ... , ValueRoller ( value = 9 , annotation = '' ), ValueRoller ( value = 0 , annotation = '' ), ), annotation = '' , ) >>> tuple ( r_select . roll () . outcomes ()) ( 0 , 9 , 3 , 4 , 5 , 6 , 5 , 4 , 9 , 0 ) Source code in dyce/r.py @classmethod @beartype def select_from_sources_iterable ( cls , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Creates and returns a [``SelectionRoller``][dyce.r.SelectionRoller] for applying selection *which* to sorted outcomes from *sources*. ``` python >>> r_select = R.select_from_values( ... (0, -1, slice(3, 6), slice(6, 3, -1), -1, 0), ... 5, 4, 6, 3, 7, 2, 8, 1, 9, 0, ... ) ; r_select SelectionRoller( which=(0, -1, slice(3, 6, None), slice(6, 3, -1), -1, 0), sources=( ValueRoller(value=5, annotation=''), ValueRoller(value=4, annotation=''), ..., ValueRoller(value=9, annotation=''), ValueRoller(value=0, annotation=''), ), annotation='', ) >>> tuple(r_select.roll().outcomes()) (0, 9, 3, 4, 5, 6, 5, 4, 9, 0) ``` \"\"\" return SelectionRoller ( which , sources , annotation = annotation )","title":"select_from_sources_iterable()"},{"location":"dyce.r/#dyce.r.R.select_from_values","text":"Shorthand for cls . select_from_values_iterable ( which , values , annotation = annotation ) . See the select_from_values_iterable method . Source code in dyce/r.py @classmethod @beartype def select_from_values ( cls , which : Iterable [ _GetItemT ], * values : _ValueT , annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_values_iterable(which, values, annotation=annotation)``. See the [``select_from_values_iterable`` method][dyce.r.R.select_from_values_iterable]. \"\"\" return cls . select_from_values_iterable ( which , values , annotation = annotation )","title":"select_from_values()"},{"location":"dyce.r/#dyce.r.R.select_from_values_iterable","text":"Shorthand for cls . select_from_sources_iterable (( cls . from_value ( value ) for value in values ), annotation = annotation ) . See the from_value and select_from_sources_iterable methods. Source code in dyce/r.py @classmethod @beartype def select_from_values_iterable ( cls , which : Iterable [ _GetItemT ], values : Iterable [ _ValueT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python cls.select_from_sources_iterable((cls.from_value(value) for value in values), annotation=annotation)``. See the [``from_value``][dyce.r.R.from_value] and [``select_from_sources_iterable``][dyce.r.R.select_from_sources_iterable] methods. \"\"\" return cls . select_from_sources_iterable ( which , ( cls . from_value ( value ) for value in values ), annotation = annotation , )","title":"select_from_values_iterable()"},{"location":"dyce.r/#dyce.r.R.select_iterable","text":"Shorthand for type ( self ) . select_from_sources ( which , self , annotation = annotation ) . See the select_from_sources method . Source code in dyce/r.py @beartype def select_iterable ( self , which : Iterable [ _GetItemT ], annotation : Any = \"\" , ) -> SelectionRoller : r \"\"\" Shorthand for ``#!python type(self).select_from_sources(which, self, annotation=annotation)``. See the [``select_from_sources`` method][dyce.r.R.select_from_sources]. \"\"\" return type ( self ) . select_from_sources ( which , self , annotation = annotation )","title":"select_iterable()"},{"location":"dyce.r/#dyce.r.R.source_rolls","text":"Generates new rolls from all sources . Source code in dyce/r.py @beartype def source_rolls ( self ) -> Iterator [ \"Roll\" ]: r \"\"\" Generates new rolls from all [``sources``][dyce.r.R.sources]. \"\"\" for source in self . sources : yield source . roll ()","title":"source_rolls()"},{"location":"dyce.r/#dyce.r.R.umap","text":"Creates and returns a UnarySumOpRoller roller for applying un_op to this roller as its source. 1 2 3 4 5 6 7 8 9 >>> import operator >>> r_un_op = R . from_value ( H ( 6 )) . umap ( operator . __neg__ ) ; r_un_op UnarySumOpRoller ( un_op =< built - in function neg > , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) >>> r_un_op == - R . from_value ( H ( 6 )) True Source code in dyce/r.py @beartype def umap ( self , un_op : _RollOutcomeUnaryOperatorT , annotation : Any = \"\" , ) -> UnarySumOpRoller : r \"\"\" Creates and returns a [``UnarySumOpRoller``][dyce.r.UnarySumOpRoller] roller for applying *un_op* to this roller as its source. ``` python >>> import operator >>> r_un_op = R.from_value(H(6)).umap(operator.__neg__) ; r_un_op UnarySumOpRoller( un_op=<built-in function neg>, source=ValueRoller(value=H(6), annotation=''), annotation='', ) >>> r_un_op == -R.from_value(H(6)) True ``` \"\"\" return UnarySumOpRoller ( un_op , self , annotation = annotation )","title":"umap()"},{"location":"dyce.r/#dyce.r.RepeatRoller","text":"A roller to implement the __matmul__ operator. It is akin to a homogeneous PoolRoller containing n identical source s. 1 2 3 4 5 6 7 8 9 10 >>> d20 = H ( 20 ) >>> r_d20 = R . from_value ( d20 ) >>> r_d20_100 = 100 @r_d20 ; r_d20_100 RepeatRoller ( n = 100 , source = ValueRoller ( value = H ( 20 ), annotation = '' ), annotation = '' , ) >>> all ( outcome in d20 for outcome in r_d20_100 . roll () . outcomes ()) True","title":"RepeatRoller"},{"location":"dyce.r/#dyce.r.RepeatRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RepeatRoller.n","text":"The number of times to \u201crepeat\u201d the roller\u2019s sole source.","title":"n"},{"location":"dyce.r/#dyce.r.RepeatRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . n == other . n","title":"__eq__()"},{"location":"dyce.r/#dyce.r.RepeatRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , n : SupportsIntSCU , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = ( source ,), annotation = annotation , ** kw ) self . _n = as_int ( n )","title":"__init__()"},{"location":"dyce.r/#dyce.r.RepeatRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( n= { self . n !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.RepeatRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls : List [ Roll ] = [] for _ in range ( self . n ): source_rolls . extend ( self . source_rolls ()) return Roll ( self , roll_outcomes = ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.Roll","text":"Experimental This class should be considered experimental and may change or disappear in future versions. An immutable roll result (or \u201croll\u201d for short). More specifically, the result of calling the R.roll method . Rolls are sequences of RollOutcome objects that can be assembled into trees.","title":"Roll"},{"location":"dyce.r/#dyce.r.Roll.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.Roll.annotation","text":"Shorthand for self . r . annotation . See the R.annotation property .","title":"annotation"},{"location":"dyce.r/#dyce.r.Roll.r","text":"The roller that generated the roll.","title":"r"},{"location":"dyce.r/#dyce.r.Roll.source_rolls","text":"The source rolls from which this roll was generated.","title":"source_rolls"},{"location":"dyce.r/#dyce.r.Roll.__getitem__","text":"Source code in dyce/r.py @beartype # TODO(posita): See <https://github.com/python/mypy/issues/8393> # TODO(posita): See <https://github.com/beartype/beartype/issues/39#issuecomment-871914114> et seq. def __getitem__ ( # type: ignore self , key : _GetItemT , ) -> Union [ RollOutcome , Tuple [ RollOutcome , ... ]]: if isinstance ( key , slice ): return self . _roll_outcomes [ key ] else : return self . _roll_outcomes [ __index__ ( key )]","title":"__getitem__()"},{"location":"dyce.r/#dyce.r.Roll.__init__","text":"Initializer. This initializer will associate each of roll_outcomes with the newly constructed roll if they do not already have a source_roll . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 >>> r_4 = ValueRoller ( 4 ) >>> roll = r_4 . roll () >>> new_roll = Roll ( r_4 , roll ) ; new_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ) >>> roll [ 0 ] . source_roll == roll True >>> roll [ 0 ] . r == r_4 True Note Technically, this violates the immutability of roll outcomes. dyce does not generally contemplate creation of rolls or roll outcomes outside the womb of R.roll implementations. Roll and RollOutcome objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the RollOutcome.source_roll property . Source code in dyce/r.py @experimental @beartype def __init__ ( self , r : R , roll_outcomes : Iterable [ RollOutcome ], source_rolls : Iterable [ \"Roll\" ] = (), ): r \"\"\" Initializer. This initializer will associate each of *roll_outcomes* with the newly constructed roll if they do not already have a [``source_roll``][dyce.r.RollOutcome.source_roll]. ``` python >>> r_4 = ValueRoller(4) >>> roll = r_4.roll() >>> new_roll = Roll(r_4, roll) ; new_roll Roll( r=ValueRoller(value=4, annotation=''), roll_outcomes=( RollOutcome( value=4, sources=(), ), ), source_rolls=(), ) >>> roll[0].source_roll == roll True >>> roll[0].r == r_4 True ``` !!! note Technically, this violates the immutability of roll outcomes. ``dyce`` does not generally contemplate creation of rolls or roll outcomes outside the womb of [``R.roll``][dyce.r.R.roll] implementations. [``Roll``][dyce.r.Roll] and [``RollOutcome``][dyce.r.RollOutcome] objects generally mate for life, being created exclusively for (and in close proximity to) one another. A roll manipulating a roll outcome\u2019s internal state post initialization may seem unseemly, but that intimacy is a fundamental part of their primordial ritual. That being said, you\u2019re an adult. Do what you want. Just know that if you\u2019re going to create your own roll outcomes and pimp them out all over town, they might pick something up along the way. See also the [``RollOutcome.source_roll`` property][dyce.r.RollOutcome.source_roll]. \"\"\" super () . __init__ () self . _r = r self . _roll_outcomes = tuple ( roll_outcomes ) self . _source_rolls = tuple ( source_rolls ) for roll_outcome in self . _roll_outcomes : if not roll_outcome . _has_roll : roll_outcome . _roll = self","title":"__init__()"},{"location":"dyce.r/#dyce.r.Roll.__iter__","text":"Source code in dyce/r.py @beartype def __iter__ ( self ) -> Iterator [ RollOutcome ]: return iter ( self . _roll_outcomes )","title":"__iter__()"},{"location":"dyce.r/#dyce.r.Roll.__len__","text":"Source code in dyce/r.py @beartype def __len__ ( self ) -> int : return len ( self . _roll_outcomes )","title":"__len__()"},{"location":"dyce.r/#dyce.r.Roll.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( r= { indent ( repr ( self . r ), \" \" ) . strip () } , roll_outcomes=( { _seq_repr ( self ) } ), source_rolls=( { _seq_repr ( self . source_rolls ) } ), )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.Roll.outcomes","text":"Shorthand for ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None ) . Info Unlike H.roll and P.roll , these outcomes are not sorted. Instead, they retain the ordering from whence they came in the roller tree. 1 2 3 4 5 6 7 >>> r_3d6 = 3 @R . from_value ( H ( 6 )) >>> r_3d6_neg = 3 @- R . from_value ( H ( 6 )) >>> roll = R . from_sources ( r_3d6 , r_3d6_neg ) . roll () >>> tuple ( roll . outcomes ()) ( 1 , 3 , 1 , - 4 , - 6 , - 1 ) >>> len ( roll ) 6 Source code in dyce/r.py @beartype def outcomes ( self ) -> Iterator [ RealLikeSCU ]: r \"\"\" Shorthand for ``#!python (roll_outcome.value for roll_outcome in self if roll_outcome.value is not None)``. <!-- BEGIN MONKEY PATCH -- For deterministic outcomes >>> import random >>> from dyce import rng >>> rng.RNG = random.Random(1633056410) -- END MONKEY PATCH --> !!! info Unlike [``H.roll``][dyce.h.H.roll] and [``P.roll``][dyce.p.P.roll], these outcomes are *not* sorted. Instead, they retain the ordering from whence they came in the roller tree. ``` python >>> r_3d6 = 3@R.from_value(H(6)) >>> r_3d6_neg = 3@-R.from_value(H(6)) >>> roll = R.from_sources(r_3d6, r_3d6_neg).roll() >>> tuple(roll.outcomes()) (1, 3, 1, -4, -6, -1) >>> len(roll) 6 ``` \"\"\" return ( roll_outcome . value for roll_outcome in self if roll_outcome . value is not None )","title":"outcomes()"},{"location":"dyce.r/#dyce.r.Roll.total","text":"Shorthand for sum ( self . outcomes ()) . Source code in dyce/r.py @beartype def total ( self ) -> RealLikeSCU : r \"\"\" Shorthand for ``#!python sum(self.outcomes())``. \"\"\" return sum ( self . outcomes ())","title":"total()"},{"location":"dyce.r/#dyce.r.RollOutcome","text":"Experimental This class should be considered experimental and may change or disappear in future versions. A single, ( mostly ) immutable outcome generated by a roll.","title":"RollOutcome"},{"location":"dyce.r/#dyce.r.RollOutcome.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RollOutcome.annotation","text":"Shorthand for self . source_roll . annotation . See the source_roll and Roll.annotation properties.","title":"annotation"},{"location":"dyce.r/#dyce.r.RollOutcome.r","text":"Shorthand for self . source_roll . r . See the source_roll and Roll.r properties.","title":"r"},{"location":"dyce.r/#dyce.r.RollOutcome.source_roll","text":"Returns the roll if one has been associated with this roll outcome. Usually that happens by submitting the roll outcome to the Roll.__init__ method inside a R.roll method implementation. Accessing this property before the roll outcome has been associated with a roll is considered a programming error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> ro = RollOutcome ( 4 ) >>> ro . source_roll Traceback ( most recent call last ): ... AssertionError : RollOutcome . source_roll accessed before associating the roll outcome with a roll ( usually via Roll . __init__ ) assert None is not None >>> roll = Roll ( R . from_value ( 4 ), roll_outcomes = ( ro ,)) >>> ro . source_roll Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), )","title":"source_roll"},{"location":"dyce.r/#dyce.r.RollOutcome.sources","text":"The source roll outcomes from which this roll outcome was generated.","title":"sources"},{"location":"dyce.r/#dyce.r.RollOutcome.value","text":"The outcome value. A value of None is used to signal that a source\u2019s roll outcome was excluded by the roller.","title":"value"},{"location":"dyce.r/#dyce.r.RollOutcome.__abs__","text":"Source code in dyce/r.py @beartype def __abs__ ( self ) -> RollOutcome : return self . umap ( __abs__ )","title":"__abs__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__add__","text":"Source code in dyce/r.py @beartype def __add__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __add__ , other ) except NotImplementedError : return NotImplemented","title":"__add__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__and__","text":"Source code in dyce/r.py @beartype def __and__ ( self , other : Union [ \"RollOutcome\" , SupportsIntSCU ]) -> RollOutcome : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __and__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__and__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __eq__ ( self . value , other . value )) else : return super () . __eq__ ( other )","title":"__eq__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__floordiv__","text":"Source code in dyce/r.py @beartype def __floordiv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __floordiv__ , other ) except NotImplementedError : return NotImplemented","title":"__floordiv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__ge__","text":"Source code in dyce/r.py @beartype def __ge__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ge__ ( self . value , other . value )) else : return NotImplemented","title":"__ge__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__gt__","text":"Source code in dyce/r.py @beartype def __gt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __gt__ ( self . value , other . value )) else : return NotImplemented","title":"__gt__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__init__","text":"Initializer. Source code in dyce/r.py @beartype def __init__ ( self , value : Optional [ RealLikeSCU ], sources : Iterable [ \"RollOutcome\" ] = (), ): r \"Initializer.\" super () . __init__ () self . _value = value self . _sources = tuple ( sources ) self . _roll : Optional [ Roll ] = None if self . _value is None and not self . _sources : raise ValueError ( \"value can only be None if sources is non-empty\" )","title":"__init__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__invert__","text":"Source code in dyce/r.py @beartype def __invert__ ( self ) -> RollOutcome : return self . umap ( __invert__ )","title":"__invert__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__le__","text":"Source code in dyce/r.py @beartype def __le__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __le__ ( self . value , other . value )) else : return NotImplemented","title":"__le__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__lt__","text":"Source code in dyce/r.py @beartype def __lt__ ( self , other : _RollOutcomeOperandT ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __lt__ ( self . value , other . value )) else : return NotImplemented","title":"__lt__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__mod__","text":"Source code in dyce/r.py @beartype def __mod__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mod__ , other ) except NotImplementedError : return NotImplemented","title":"__mod__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__mul__","text":"Source code in dyce/r.py @beartype def __mul__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __mul__ , other ) except NotImplementedError : return NotImplemented","title":"__mul__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__ne__","text":"Source code in dyce/r.py @beartype def __ne__ ( self , other ) -> bool : if isinstance ( other , RollOutcome ): return bool ( __ne__ ( self . value , other . value )) else : return super () . __ne__ ( other )","title":"__ne__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__neg__","text":"Source code in dyce/r.py @beartype def __neg__ ( self ) -> RollOutcome : return self . umap ( __neg__ )","title":"__neg__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__or__","text":"Source code in dyce/r.py @beartype def __or__ ( self , other : Union [ \"RollOutcome\" , SupportsIntSCU ]) -> RollOutcome : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __or__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__or__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__pos__","text":"Source code in dyce/r.py @beartype def __pos__ ( self ) -> RollOutcome : return self . umap ( __pos__ )","title":"__pos__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__pow__","text":"Source code in dyce/r.py @beartype def __pow__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __pow__ , other ) except NotImplementedError : return NotImplemented","title":"__pow__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__radd__","text":"Source code in dyce/r.py @beartype def __radd__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __add__ ) except NotImplementedError : return NotImplemented","title":"__radd__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rand__","text":"Source code in dyce/r.py @beartype def __rand__ ( self , other : SupportsIntSCU ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __and__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rand__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( value= { repr ( self . value ) } , sources=( { _seq_repr ( self . sources ) } ), )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rfloordiv__","text":"Source code in dyce/r.py @beartype def __rfloordiv__ ( self , other : RealLikeSCU ) -> RollOutcome : # type: ignore try : return self . rmap ( other , __floordiv__ ) except NotImplementedError : return NotImplemented","title":"__rfloordiv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rmod__","text":"Source code in dyce/r.py @beartype def __rmod__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __mod__ ) except NotImplementedError : return NotImplemented","title":"__rmod__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rmul__","text":"Source code in dyce/r.py @beartype def __rmul__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __mul__ ) except NotImplementedError : return NotImplemented","title":"__rmul__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__ror__","text":"Source code in dyce/r.py @beartype def __ror__ ( self , other : SupportsIntSCU ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __or__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__ror__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rpow__","text":"Source code in dyce/r.py @beartype def __rpow__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __pow__ ) except NotImplementedError : return NotImplemented","title":"__rpow__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rsub__","text":"Source code in dyce/r.py @beartype def __rsub__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __sub__ ) except NotImplementedError : return NotImplemented","title":"__rsub__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rtruediv__","text":"Source code in dyce/r.py @beartype def __rtruediv__ ( self , other : RealLikeSCU ) -> RollOutcome : try : return self . rmap ( other , __truediv__ ) except NotImplementedError : return NotImplemented","title":"__rtruediv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__rxor__","text":"Source code in dyce/r.py @beartype def __rxor__ ( self , other : SupportsIntSCU ) -> RollOutcome : try : return self . rmap ( as_int ( other ), __xor__ ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__rxor__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__sub__","text":"Source code in dyce/r.py @beartype def __sub__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __sub__ , other ) except NotImplementedError : return NotImplemented","title":"__sub__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__truediv__","text":"Source code in dyce/r.py @beartype def __truediv__ ( self , other : _RollOutcomeOperandT ) -> RollOutcome : try : return self . map ( __truediv__ , other ) except NotImplementedError : return NotImplemented","title":"__truediv__()"},{"location":"dyce.r/#dyce.r.RollOutcome.__xor__","text":"Source code in dyce/r.py @beartype def __xor__ ( self , other : Union [ \"RollOutcome\" , SupportsIntSCU ]) -> RollOutcome : try : if isinstance ( other , SupportsIntSCT ): other = as_int ( other ) return self . map ( __xor__ , other ) except ( NotImplementedError , TypeError ): return NotImplemented","title":"__xor__()"},{"location":"dyce.r/#dyce.r.RollOutcome.eq","text":"Source code in dyce/r.py @beartype def eq ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __eq__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __eq__ ( self . value , other )), sources = ( self ,))","title":"eq()"},{"location":"dyce.r/#dyce.r.RollOutcome.euthanize","text":"Shorthand for self . umap ( lambda operand : None ) . 1 2 3 4 5 6 7 8 9 10 11 >>> two = RollOutcome ( 2 ) >>> two . euthanize () RollOutcome ( value = None , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) See the umap method . Source code in dyce/r.py @beartype def euthanize ( self ) -> RollOutcome : r \"\"\" Shorthand for ``#!python self.umap(lambda operand: None)``. ``` python >>> two = RollOutcome(2) >>> two.euthanize() RollOutcome( value=None, sources=( RollOutcome( value=2, sources=(), ), ), ) ``` See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" def _euthanize ( operand : Optional [ RealLikeSCU ]) -> Optional [ RealLikeSCU ]: return None return self . umap ( _euthanize )","title":"euthanize()"},{"location":"dyce.r/#dyce.r.RollOutcome.ge","text":"Source code in dyce/r.py @beartype def ge ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __ge__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __ge__ ( self . value , other )), sources = ( self ,))","title":"ge()"},{"location":"dyce.r/#dyce.r.RollOutcome.gt","text":"Source code in dyce/r.py @beartype def gt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __gt__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __gt__ ( self . value , other )), sources = ( self ,))","title":"gt()"},{"location":"dyce.r/#dyce.r.RollOutcome.is_even","text":"Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_even ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_even )","title":"is_even()"},{"location":"dyce.r/#dyce.r.RollOutcome.is_odd","text":"Shorthand for: self . umap ( dyce . types . is_even ) . See the umap method . Source code in dyce/r.py @beartype def is_odd ( self ) -> RollOutcome : r \"\"\" Shorthand for: ``#!python self.umap(dyce.types.is_even)``. See the [``umap`` method][dyce.r.RollOutcome.umap]. \"\"\" return self . umap ( is_odd )","title":"is_odd()"},{"location":"dyce.r/#dyce.r.RollOutcome.le","text":"Source code in dyce/r.py @beartype def le ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __le__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __le__ ( self . value , other )), sources = ( self ,))","title":"le()"},{"location":"dyce.r/#dyce.r.RollOutcome.lt","text":"Source code in dyce/r.py @beartype def lt ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __lt__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __lt__ ( self . value , other )), sources = ( self ,))","title":"lt()"},{"location":"dyce.r/#dyce.r.RollOutcome.map","text":"Applies bin_op to the value of this roll outcome as the left operand and right_operand as the right. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . map ( operator . __pow__ , 10 ) RollOutcome ( value = 1024 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . map ( operator . __pow__ , 10 ) == two ** 10 True Source code in dyce/r.py @beartype def map ( self , bin_op : _BinaryOperatorT , right_operand : _RollOutcomeOperandT , ) -> RollOutcome : r \"\"\" Applies *bin_op* to the value of this roll outcome as the left operand and *right_operand* as the right. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.map(operator.__pow__, 10) RollOutcome( value=1024, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.map(operator.__pow__, 10) == two ** 10 True ``` \"\"\" if isinstance ( right_operand , RollOutcome ): sources : Tuple [ RollOutcome , ... ] = ( self , right_operand ) right_operand_value : Optional [ RealLikeSCU ] = right_operand . value else : sources = ( self ,) right_operand_value = right_operand if isinstance ( right_operand_value , RealLikeSCT ): return RollOutcome ( bin_op ( self . value , right_operand_value ), sources ) else : raise NotImplementedError","title":"map()"},{"location":"dyce.r/#dyce.r.RollOutcome.ne","text":"Source code in dyce/r.py @beartype def ne ( self , other : _RollOutcomeOperandT ) -> RollOutcome : if isinstance ( other , RollOutcome ): return RollOutcome ( bool ( __ne__ ( self . value , other . value )), sources = ( self , other ) ) else : return RollOutcome ( bool ( __ne__ ( self . value , other )), sources = ( self ,))","title":"ne()"},{"location":"dyce.r/#dyce.r.RollOutcome.rmap","text":"Analogous to the map method , but where the caller supplies left_operand . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two = RollOutcome ( 2 ) >>> two . rmap ( 10 , operator . __pow__ ) RollOutcome ( value = 100 , sources = ( RollOutcome ( value = 2 , sources = (), ), ), ) >>> two . rmap ( 10 , operator . __pow__ ) == 10 ** two True Note The positions of left_operand and bin_op are different from map method . This is intentional and serves as a reminder of operand ordering. Source code in dyce/r.py @beartype def rmap ( self , left_operand : RealLikeSCU , bin_op : _BinaryOperatorT , ) -> RollOutcome : r \"\"\" Analogous to the [``map`` method][dyce.r.RollOutcome.map], but where the caller supplies *left_operand*. ``` python >>> import operator >>> two = RollOutcome(2) >>> two.rmap(10, operator.__pow__) RollOutcome( value=100, sources=( RollOutcome( value=2, sources=(), ), ), ) >>> two.rmap(10, operator.__pow__) == 10 ** two True ``` !!! note The positions of *left_operand* and *bin_op* are different from [``map`` method][dyce.r.RollOutcome.map]. This is intentional and serves as a reminder of operand ordering. \"\"\" if isinstance ( left_operand , RealLikeSCT ): return RollOutcome ( bin_op ( left_operand , self . value ), sources = ( self ,)) else : raise NotImplementedError","title":"rmap()"},{"location":"dyce.r/#dyce.r.RollOutcome.umap","text":"Applies un_op to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> import operator >>> two_neg = RollOutcome ( - 2 ) >>> two_neg . umap ( operator . __neg__ ) RollOutcome ( value = 2 , sources = ( RollOutcome ( value =- 2 , sources = (), ), ), ) >>> two_neg . umap ( operator . __neg__ ) == - two_neg True Source code in dyce/r.py @beartype def umap ( self , un_op : _UnaryOperatorT , ) -> RollOutcome : r \"\"\" Applies *un_op* to the value of this roll outcome. Shorthands exist for many arithmetic operators and comparators. ``` python >>> import operator >>> two_neg = RollOutcome(-2) >>> two_neg.umap(operator.__neg__) RollOutcome( value=2, sources=( RollOutcome( value=-2, sources=(), ), ), ) >>> two_neg.umap(operator.__neg__) == -two_neg True ``` \"\"\" return RollOutcome ( un_op ( self . value ), sources = ( self ,))","title":"umap()"},{"location":"dyce.r/#dyce.r.RollWalkerVisitor","text":"Experimental This function should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each Roll object found.","title":"RollWalkerVisitor"},{"location":"dyce.r/#dyce.r.RollWalkerVisitor.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RollWalkerVisitor.on_roll","text":"Source code in dyce/r.py @abstractmethod def on_roll ( self , roll : Roll , parents : Iterator [ Roll ]) -> None : ...","title":"on_roll()"},{"location":"dyce.r/#dyce.r.RollerWalkerVisitor","text":"Experimental This function should be considered experimental and may change or disappear in future versions. Abstract visitor interface for use with walk called for each R object found.","title":"RollerWalkerVisitor"},{"location":"dyce.r/#dyce.r.RollerWalkerVisitor.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.RollerWalkerVisitor.on_roller","text":"Source code in dyce/r.py @abstractmethod def on_roller ( self , r : R , parents : Iterator [ R ]) -> None : ...","title":"on_roller()"},{"location":"dyce.r/#dyce.r.SelectionRoller","text":"A roller for sorting outcomes from its sources and applying a selector which . Roll outcomes in created rolls are ordered according to the selections which . However, those selections are interpreted as indexes in a sorted view of the source\u2019s roll outcomes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 >>> r_values = R . from_values ( 10000 , 1 , 1000 , 10 , 100 ) >>> outcomes = tuple ( r_values . roll () . outcomes ()) ; outcomes ( 10000 , 1 , 1000 , 10 , 100 ) >>> sorted_outcomes = tuple ( sorted ( outcomes )) ; sorted_outcomes ( 1 , 10 , 100 , 1000 , 10000 ) >>> which = ( 3 , 1 , 3 , 2 ) >>> tuple ( sorted_outcomes [ i ] for i in which ) ( 1000 , 10 , 1000 , 100 ) >>> r_select = r_values . select_iterable ( which ) ; r_select SelectionRoller ( which = ( 3 , 1 , 3 , 2 ), sources = ( PoolRoller ( sources = ( ValueRoller ( value = 10000 , annotation = '' ), ValueRoller ( value = 1 , annotation = '' ), ValueRoller ( value = 1000 , annotation = '' ), ValueRoller ( value = 10 , annotation = '' ), ValueRoller ( value = 100 , annotation = '' ), ), annotation = '' , ), ), annotation = '' , ) >>> roll = r_select . roll () >>> tuple ( roll . outcomes ()) ( 1000 , 10 , 1000 , 100 ) >>> roll Roll ( r =... , roll_outcomes = ( RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 10 , sources = (), ), RollOutcome ( value = 1000 , sources = (), ), RollOutcome ( value = 100 , sources = (), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 1 , sources = (), ), ), ), RollOutcome ( value = None , sources = ( RollOutcome ( value = 10000 , sources = (), ), ), ), ), source_rolls =... , )","title":"SelectionRoller"},{"location":"dyce.r/#dyce.r.SelectionRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.SelectionRoller.which","text":"The selector this roller applies to the sorted outcomes of its sole source.","title":"which"},{"location":"dyce.r/#dyce.r.SelectionRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and self . which == other . which","title":"__eq__()"},{"location":"dyce.r/#dyce.r.SelectionRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , which : Iterable [ _GetItemT ], sources : Iterable [ _SourceT ], annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = sources , annotation = annotation , ** kw ) self . _which = tuple ( which )","title":"__init__()"},{"location":"dyce.r/#dyce.r.SelectionRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \"\"\" { type ( self ) . __name__ } ( which= { self . which !r} , sources=( { _seq_repr ( self . sources ) } ), annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.SelectionRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" source_rolls = list ( self . source_rolls ()) roll_outcomes = list ( roll_outcome for roll_outcome in chain . from_iterable ( source_rolls ) if roll_outcome . value is not None ) roll_outcomes . sort ( key = attrgetter ( \"value\" )) all_indexes = tuple ( range ( len ( roll_outcomes ))) selected_indexes = tuple ( getitems ( all_indexes , self . which )) def _selected_roll_outcomes (): for selected_index in selected_indexes : selected_roll_outcome = roll_outcomes [ selected_index ] assert selected_roll_outcome . value is not None yield selected_roll_outcome for excluded_index in set ( all_indexes ) - set ( selected_indexes ): yield roll_outcomes [ excluded_index ] . euthanize () return Roll ( self , roll_outcomes = _selected_roll_outcomes (), source_rolls = source_rolls , )","title":"roll()"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller","text":"An NarySumOpRoller for applying a unary operator un_op to the sum of all outcomes from its sole source .","title":"UnarySumOpRoller"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.un_op","text":"The operator this roller applies to its sources.","title":"un_op"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__eq__","text":"Source code in dyce/r.py @beartype def __eq__ ( self , other ) -> bool : return super () . __eq__ ( other ) and ( _callable_cmp ( self . un_op , other . un_op ))","title":"__eq__()"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , un_op : _RollOutcomeUnaryOperatorT , source : _SourceT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" def _op ( r : R , roll_outcomes : Iterable [ RollOutcome ], ) -> Union [ RollOutcome , Iterable [ RollOutcome ]]: ( operand ,) = roll_outcomes return un_op ( operand ) super () . __init__ ( op = _op , sources = ( source ,), annotation = annotation , ** kw ) self . _un_op = un_op","title":"__init__()"},{"location":"dyce.r/#dyce.r.UnarySumOpRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : ( source ,) = self . sources return f \"\"\" { type ( self ) . __name__ } ( un_op= { self . un_op !r} , source= { indent ( repr ( source ), \" \" ) . strip () } , annotation= { self . annotation !r} , )\"\"\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.ValueRoller","text":"A roller whose roll outcomes are derived from scalars, H objects , P objects , RollOutcome objects , or even Roll objects , instead of other source rollers.","title":"ValueRoller"},{"location":"dyce.r/#dyce.r.ValueRoller.__slots__","text":"","title":"__slots__"},{"location":"dyce.r/#dyce.r.ValueRoller.value","text":"The value to be emitted by this roller via its ValueRoller.roll method .","title":"value"},{"location":"dyce.r/#dyce.r.ValueRoller.__init__","text":"Source code in dyce/r.py @beartype def __init__ ( self , value : _ValueT , annotation : Any = \"\" , ** kw , ): r \"Initializer.\" super () . __init__ ( sources = (), annotation = annotation , ** kw ) if isinstance ( value , P ) and not value . is_homogeneous : warnings . warn ( f \"using a heterogeneous pool ( { value } ) is not recommended where traceability is important\" , stacklevel = 2 , ) self . _value = value","title":"__init__()"},{"location":"dyce.r/#dyce.r.ValueRoller.__repr__","text":"Source code in dyce/r.py @beartype def __repr__ ( self ) -> str : return f \" { type ( self ) . __name__ } (value= { self . value !r} , annotation= { self . annotation !r} )\"","title":"__repr__()"},{"location":"dyce.r/#dyce.r.ValueRoller.roll","text":"Source code in dyce/r.py @beartype def roll ( self ) -> Roll : r \"\"\"\"\"\" if isinstance ( self . value , Roll ): return self . value elif isinstance ( self . value , RollOutcome ): return Roll ( self , roll_outcomes = ( self . value ,)) elif isinstance ( self . value , P ): return Roll ( self , roll_outcomes = ( RollOutcome ( outcome ) for outcome in self . value . roll ()), ) elif isinstance ( self . value , H ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value . roll ()),)) elif isinstance ( self . value , RealLikeSCT ): return Roll ( self , roll_outcomes = ( RollOutcome ( self . value ),)) else : assert False , f \"unrecognized value type { self . value !r} \"","title":"roll()"},{"location":"dyce.r/#dyce.r.walk","text":"Experimental This function should be considered experimental and may change or disappear in future versions. Walks through root , calling visitor for each matching object. No ordering guarantees are made. On the current implementation walk performs a breadth-first traversal of root , assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. Source code in dyce/r.py @experimental @beartype def walk ( root : Union [ Roll , R , RollOutcome ], visitor : Union [ RollWalkerVisitor , RollerWalkerVisitor , RollOutcomeWalkerVisitor ], ) -> None : r \"\"\" !!! warning \"Experimental\" This function should be considered experimental and may change or disappear in future versions. Walks through *root*, calling *visitor* for each matching object. No ordering guarantees are made. !!! info \"On the current implementation\" ``#!python walk`` performs a breadth-first traversal of *root*, assembling a secondary index of referencing objects (parents). Visitors are called back grouped first by type, then by order encountered. \"\"\" rolls : Dict [ int , Roll ] = {} rollers : Dict [ int , R ] = {} roll_outcomes : Dict [ int , RollOutcome ] = {} roll_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roller_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) roll_outcome_parent_ids : DefaultDict [ int , Set [ int ]] = defaultdict ( set ) queue = deque (( root ,)) roll : Roll r : R roll_outcome : RollOutcome while queue : obj = queue . popleft () if isinstance ( obj , Roll ): roll = obj if id ( roll ) not in rolls : rolls [ id ( roll )] = roll queue . append ( roll . r ) for i , roll_outcome in enumerate ( roll ): queue . append ( roll_outcome ) for source_roll in roll . source_rolls : roll_parent_ids [ id ( source_roll )] . add ( id ( roll )) queue . append ( source_roll ) elif isinstance ( obj , R ): r = obj if id ( r ) not in rollers : rollers [ id ( r )] = r for source_r in r . sources : roller_parent_ids [ id ( source_r )] . add ( id ( r )) queue . append ( source_r ) elif isinstance ( obj , RollOutcome ): roll_outcome = obj if id ( roll_outcome ) not in roll_outcomes : roll_outcomes [ id ( roll_outcome )] = roll_outcome for source_roll_outcome in roll_outcome . sources : roll_outcome_parent_ids [ id ( source_roll_outcome )] . add ( id ( roll_outcome ) ) queue . append ( source_roll_outcome ) if rolls and isinstance ( visitor , RollWalkerVisitor ): for roll_id , roll in rolls . items (): visitor . on_roll ( roll , ( rolls [ i ] for i in roll_parent_ids [ roll_id ])) if rollers and isinstance ( visitor , RollerWalkerVisitor ): for r_id , r in rollers . items (): visitor . on_roller ( r , ( rollers [ i ] for i in roller_parent_ids [ r_id ])) if roll_outcomes and isinstance ( visitor , RollOutcomeWalkerVisitor ): for roll_outcome_id , roll_outcome in roll_outcomes . items (): visitor . on_roll_outcome ( roll_outcome , ( roll_outcomes [ i ] for i in roll_outcome_parent_ids [ roll_outcome_id ]), )","title":"walk()"},{"location":"dyce.viz/","text":"dyce . viz package reference Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Feedback, suggestions, and contributions are welcome and appreciated. display_burst ( ax : Axes , h_inner : H , outer : Optional [ Union [ H , Iterable [ LabelT ]]] = None , desc : Optional [ str ] = None , inner_color : str = 'RdYlGn_r' , outer_color : Optional [ str ] = None , text_color : str = 'black' , alpha : float = 0.5 ) -> None Experimental This method should be considered experimental and may change or disappear in future versions. Creates a dual, overlapping, cocentric pie chart in ax , which can be useful for visualizing relative probability distributions. See the visualization tutorial for examples. Source code in dyce/viz.py @experimental @beartype def display_burst ( ax : Axes , h_inner : H , outer : Optional [ Union [ H , Iterable [ LabelT ]]] = None , desc : Optional [ str ] = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : Optional [ str ] = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Creates a dual, overlapping, cocentric pie chart in *ax*, which can be useful for visualizing relative probability distributions. See the [visualization tutorial](countin.md#visualization) for examples. \"\"\" assert matplotlib inner_colors = graph_colors ( inner_color , h_inner , alpha ) if outer is None : outer = ( ( f \" { float ( v ) : .2% } \" if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . distribution () ) elif isinstance ( outer , H ): outer = (( str ( outcome ), count ) for outcome , count in outer . distribution ()) outer_labels , outer_values = list ( zip ( * outer )) outer_colors = graph_colors ( inner_color if outer_color is None else outer_color , outer_values , alpha , ) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.0 , labeldistance = 1.1 , startangle = 90 , colors = outer_colors , wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 0.9 , labeldistance = 0.8 , startangle = 90 , colors = inner_colors , textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.6 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" ) labels_cumulative ( h : H ) -> Iterator [ LabelT ] Experimental This method should be considered experimental and may change or disappear in future versions. Enumerates label, probability pairs for each outcome in h where each label contains several percentages. This can be useful for passing as the outer value to either display_burst or plot_burst . Source code in dyce/viz.py @experimental @beartype def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Enumerates label, probability pairs for each outcome in *h* where each label contains several percentages. This can be useful for passing as the *outer* value to either [``display_burst``][dyce.viz.display_burst] or [``plot_burst``][dyce.viz.plot_burst]. \"\"\" le_total , ge_total = 0.0 , 1.0 for outcome , probability in h . distribution (): le_total += probability label = f \" { outcome } { float ( probability ) : .2% } ; \u2265 { le_total : .2% } ; \u2264 { ge_total : .2% } \" ge_total -= probability yield ( label , probability ) plot_burst ( h_inner : H , outer : Optional [ Union [ H , Iterable [ LabelT ]]] = None , desc : Optional [ str ] = None , inner_color : str = 'RdYlGn_r' , outer_color : Optional [ str ] = None , text_color : str = 'black' , alpha : float = 0.5 ) -> Tuple [ Figure , Axes ] Experimental This method should be considered experimental and may change or disappear in future versions. Wrapper around display_burst that creates a figure, axis pair and calls matplotlib.pyplot.tight_layout on the result. Source code in dyce/viz.py @experimental @beartype def plot_burst ( h_inner : H , outer : Optional [ Union [ H , Iterable [ LabelT ]]] = None , desc : Optional [ str ] = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : Optional [ str ] = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ Figure , Axes ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Wrapper around [``display_burst``][dyce.viz.display_burst] that creates a figure, axis pair and calls [``matplotlib.pyplot.tight_layout``](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tight_layout.html) on the result. \"\"\" assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , inner_color , outer_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"<tt>dyce.viz</tt>"},{"location":"dyce.viz/#dyceviz-package-reference","text":"Experimental This package is an attempt to explore conveniences for integration with Matplotlib . It is an explicit departure from RFC 1925, \u00a7 2.2 and should be considered experimental. Be warned that future release may introduce incompatibilities or remove this package altogether. Feedback, suggestions, and contributions are welcome and appreciated.","title":"dyce.viz package reference"},{"location":"dyce.viz/#dyce.viz.display_burst","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Creates a dual, overlapping, cocentric pie chart in ax , which can be useful for visualizing relative probability distributions. See the visualization tutorial for examples. Source code in dyce/viz.py @experimental @beartype def display_burst ( ax : Axes , h_inner : H , outer : Optional [ Union [ H , Iterable [ LabelT ]]] = None , desc : Optional [ str ] = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : Optional [ str ] = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> None : r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Creates a dual, overlapping, cocentric pie chart in *ax*, which can be useful for visualizing relative probability distributions. See the [visualization tutorial](countin.md#visualization) for examples. \"\"\" assert matplotlib inner_colors = graph_colors ( inner_color , h_inner , alpha ) if outer is None : outer = ( ( f \" { float ( v ) : .2% } \" if v >= _HIDE_LIM else \"\" , v ) for _ , v in h_inner . distribution () ) elif isinstance ( outer , H ): outer = (( str ( outcome ), count ) for outcome , count in outer . distribution ()) outer_labels , outer_values = list ( zip ( * outer )) outer_colors = graph_colors ( inner_color if outer_color is None else outer_color , outer_values , alpha , ) if desc : ax . set_title ( desc , fontdict = { \"fontweight\" : \"bold\" }, pad = 24.0 ) ax . pie ( outer_values , labels = outer_labels , radius = 1.0 , labeldistance = 1.1 , startangle = 90 , colors = outer_colors , wedgeprops = dict ( width = 0.8 , edgecolor = text_color ), ) ax . pie ( h_inner . values (), labels = h_inner , radius = 0.9 , labeldistance = 0.8 , startangle = 90 , colors = inner_colors , textprops = dict ( color = text_color ), wedgeprops = dict ( width = 0.6 , edgecolor = text_color ), ) ax . set ( aspect = \"equal\" )","title":"display_burst()"},{"location":"dyce.viz/#dyce.viz.labels_cumulative","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Enumerates label, probability pairs for each outcome in h where each label contains several percentages. This can be useful for passing as the outer value to either display_burst or plot_burst . Source code in dyce/viz.py @experimental @beartype def labels_cumulative ( h : H , ) -> Iterator [ LabelT ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Enumerates label, probability pairs for each outcome in *h* where each label contains several percentages. This can be useful for passing as the *outer* value to either [``display_burst``][dyce.viz.display_burst] or [``plot_burst``][dyce.viz.plot_burst]. \"\"\" le_total , ge_total = 0.0 , 1.0 for outcome , probability in h . distribution (): le_total += probability label = f \" { outcome } { float ( probability ) : .2% } ; \u2265 { le_total : .2% } ; \u2264 { ge_total : .2% } \" ge_total -= probability yield ( label , probability )","title":"labels_cumulative()"},{"location":"dyce.viz/#dyce.viz.plot_burst","text":"Experimental This method should be considered experimental and may change or disappear in future versions. Wrapper around display_burst that creates a figure, axis pair and calls matplotlib.pyplot.tight_layout on the result. Source code in dyce/viz.py @experimental @beartype def plot_burst ( h_inner : H , outer : Optional [ Union [ H , Iterable [ LabelT ]]] = None , desc : Optional [ str ] = None , inner_color : str = DEFAULT_GRAPH_COLOR , outer_color : Optional [ str ] = None , text_color : str = DEFAULT_TEXT_COLOR , alpha : float = DEFAULT_GRAPH_ALPHA , ) -> Tuple [ Figure , Axes ]: r \"\"\" !!! warning \"Experimental\" This method should be considered experimental and may change or disappear in future versions. Wrapper around [``display_burst``][dyce.viz.display_burst] that creates a figure, axis pair and calls [``matplotlib.pyplot.tight_layout``](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tight_layout.html) on the result. \"\"\" assert matplotlib fig , ax = matplotlib . pyplot . subplots () display_burst ( ax , h_inner , outer , desc , inner_color , outer_color , text_color , alpha ) matplotlib . pyplot . tight_layout () return fig , ax","title":"plot_burst()"},{"location":"license/","text":"License and credits The MIT License (MIT) Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contributors The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub \u2013 @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"License"},{"location":"license/#license-and-credits","text":"","title":"License and credits"},{"location":"license/#the-mit-license-mit","text":"Copyright \u00a9 2015-2021 Matt Bogosian ( @posita ). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"license/#contributors","text":"The following individuals or entities have contributed to this software: Matt Bogosian ; GitHub \u2013 @posita Ilmari Karonen By adding your name to this list, you grant a nonexclusive, perpetual license to your contributions to this software under the same terms as its license, above. Further, you warrant that your contributions to this software are exclusively your own creations and no one else has any superior right or claim to them. Finally, you agree to indemnify and hold harmless this software\u2019s owner against any colorable claim of infringement by a third party for this software\u2019s owner\u2019s otherwise lawful use of your contribution, whether or not such use was contemplated by you at the time you made it.","title":"Contributors"},{"location":"notes/","text":"dyce release notes 0.4.1 Splits out protocol checking into its own fancy library: numerary ! Is now available on PyPI as dyce _ , thanks to the generosity of David Eyk ! Introduces experimental generic walk function and supporting visitor data structures. Uses pygraphviz to automate class diagram generation. (See the note on special considerations for regenerating class diagrams in the hacking quick start .) Introduces experimental use of numpy for RNG, if present. Migrates to using pyproject.toml and setup.cfg . Adds missing py.typed to ensure clients get type checking . (Whoops.) 0.4.0 Breaking changes Warning The following changes are not backward compatible. Please review before upgrading. Renames HAbleT and HAbleOpsMixin to HableT and HableOpsMixin . Uses alternate spellings. Removes deprecated non-flattening unary operation methods P.__neg__ and P.__pos__ . Uses, e.g., P . umap ( operator . __neg__ ) or P ( - h for h in p ) instead. Removes deprecated synonym methods H.even and H.odd . Uses H.is_even and H.is_odd instead. Removes deprecated synonym package dyce.plt . Uses dyce.viz instead. Removes special case handling of H({}) for addition and subtraction. Check for code that relied on, e.g., h + H ({}) resolving to h . It is probably not correct. If the behavior is desired, consider eliminating empty histograms before performing calculations. E.G., h1 + h2 if h2 else h1 . See also the sum_h function , which ensures the result is always a histogram: 1 2 3 4 5 >>> from dyce.h import sum_h >>> sum (()) 0 >>> sum_h (()) H ({}) Note, however, that sums including empty histograms will be always result in empty histograms: 1 2 3 4 >>> from dyce import H >>> hs = ( H ( 6 ), H ( 6 ), H ( 6 ), H ({})) >>> sum_h ( hs ) H ({}) If a different result was desired, adapting our advice from above would yield something like: 1 2 >>> sum_h ( h for h in hs if h ) H ({ 3 : 1 , 4 : 3 , 5 : 6 , 6 : 10 , ... , 16 : 6 , 17 : 3 , 18 : 1 }) Other changes Documentation overhaul including augmented examples and reorganized images and JavaScript. Fixes H({}).format() bug. Adds beartype runtime type checking. Maintains support for Python 3.7 (for now). 0.3.2 Emergency release to cover up address this embarrassment typo . \ud83d\ude2c\ud83d\ude05 0.3.1 Adds these release notes. Boosts isinstance performance with dyce \u2019s proprietary numeric Protocol s. Reinstates support for Python 3.7 (for now) . Adds H.is_even and H.is_odd . Deprecates synonym methods H.even and H.odd . Introduces experimental H.total property. Removes incorrectly non-flattening unary operation methods P . __abs__ and P . __invert__ . Deprecates non-flattening unary operation methods P . __neg__ and P . __pos__ . Renames experimental P . homogeneous property to P.is_homogeneous . Introduces experimental R and Roll primitives. Removes coerce parameter from H.map , H.rmap , and H.umap . Renames dyce . plt to dyce.viz . Deprecates synonym package dyce . plt . 0.3.0 dyce goes beta! Non-experimental features should be considered stable.","title":"Release notes"},{"location":"notes/#dyce-release-notes","text":"","title":"dyce release notes"},{"location":"notes/#041","text":"Splits out protocol checking into its own fancy library: numerary ! Is now available on PyPI as dyce _ , thanks to the generosity of David Eyk ! Introduces experimental generic walk function and supporting visitor data structures. Uses pygraphviz to automate class diagram generation. (See the note on special considerations for regenerating class diagrams in the hacking quick start .) Introduces experimental use of numpy for RNG, if present. Migrates to using pyproject.toml and setup.cfg . Adds missing py.typed to ensure clients get type checking . (Whoops.)","title":"0.4.1"},{"location":"notes/#040","text":"","title":"0.4.0"},{"location":"notes/#breaking-changes","text":"Warning The following changes are not backward compatible. Please review before upgrading. Renames HAbleT and HAbleOpsMixin to HableT and HableOpsMixin . Uses alternate spellings. Removes deprecated non-flattening unary operation methods P.__neg__ and P.__pos__ . Uses, e.g., P . umap ( operator . __neg__ ) or P ( - h for h in p ) instead. Removes deprecated synonym methods H.even and H.odd . Uses H.is_even and H.is_odd instead. Removes deprecated synonym package dyce.plt . Uses dyce.viz instead. Removes special case handling of H({}) for addition and subtraction. Check for code that relied on, e.g., h + H ({}) resolving to h . It is probably not correct. If the behavior is desired, consider eliminating empty histograms before performing calculations. E.G., h1 + h2 if h2 else h1 . See also the sum_h function , which ensures the result is always a histogram: 1 2 3 4 5 >>> from dyce.h import sum_h >>> sum (()) 0 >>> sum_h (()) H ({}) Note, however, that sums including empty histograms will be always result in empty histograms: 1 2 3 4 >>> from dyce import H >>> hs = ( H ( 6 ), H ( 6 ), H ( 6 ), H ({})) >>> sum_h ( hs ) H ({}) If a different result was desired, adapting our advice from above would yield something like: 1 2 >>> sum_h ( h for h in hs if h ) H ({ 3 : 1 , 4 : 3 , 5 : 6 , 6 : 10 , ... , 16 : 6 , 17 : 3 , 18 : 1 })","title":"Breaking changes"},{"location":"notes/#other-changes","text":"Documentation overhaul including augmented examples and reorganized images and JavaScript. Fixes H({}).format() bug. Adds beartype runtime type checking. Maintains support for Python 3.7 (for now).","title":"Other changes"},{"location":"notes/#032","text":"Emergency release to cover up address this embarrassment typo . \ud83d\ude2c\ud83d\ude05","title":"0.3.2"},{"location":"notes/#031","text":"Adds these release notes. Boosts isinstance performance with dyce \u2019s proprietary numeric Protocol s. Reinstates support for Python 3.7 (for now) . Adds H.is_even and H.is_odd . Deprecates synonym methods H.even and H.odd . Introduces experimental H.total property. Removes incorrectly non-flattening unary operation methods P . __abs__ and P . __invert__ . Deprecates non-flattening unary operation methods P . __neg__ and P . __pos__ . Renames experimental P . homogeneous property to P.is_homogeneous . Introduces experimental R and Roll primitives. Removes coerce parameter from H.map , H.rmap , and H.umap . Renames dyce . plt to dyce.viz . Deprecates synonym package dyce . plt .","title":"0.3.1"},{"location":"notes/#030","text":"dyce goes beta! Non-experimental features should be considered stable.","title":"0.3.0"},{"location":"rollin/","text":"Experimental This functionality should be considered experimental. Be warned that future release may introduce incompatibilities or remove it altogether. Feedback, suggestions, and contributions are welcome and appreciated. dyce provides additional primitives for generating and inspecting rolls of weighted random outcomes without requiring the overhead of enumeration. 1 >>> from dyce import R R objects represent rollers. Rollers produce Roll objects . Roll objects are sequences of RollOutcome objects , which represent weighted random values. Each object can be a node in a tree-like structure. Rollers, for example, can represent scalars, histograms, pools, operators, etc., and can be assembled into trees representing more complex calculations. Rolls can derive from other rolls, forming trees that are generally analogous to the roller trees that generated them. Similarly, roll outcomes can derive from other roll outcomes. The simplest roller we can create represents a single value. Each roll it generates has that value as its sole outcome. Let\u2019s see what that looks like (now with tasty entity relationship diagrams). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 >>> from dyce.r import ValueRoller >>> r_1 = ValueRoller ( 1 ) >>> roll = r_1 . roll () >>> roll . total () 1 >>> tuple ( roll . outcomes ()) ( 1 ,) >>> roll Roll ( r = ValueRoller ( value = 1 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 1 , sources = (), ), ), source_rolls = (), ) Hopefully, that\u2019s relatively straightforward. Let\u2019s look at some more substantial examples. Emulating a hundred-sided die using two ten-sided dice In many games it is common to emulate a hundred-sided die using a \u201cones\u201d ten-sided die (faces numbered \\([{{0}, {1}, \\ldots , {9}}]\\) ) and a \u201ctens\u201d ten-sided die (faces numbered \\([{{00}, {10}, \\ldots , {90}}]\\) ). Let\u2019s try to model that as a roller and use it to generate a roll. We start by creating two histograms 1 representing our two ten-sided dice ( d00 for our \u201ctens\u201d die and d10 for our \u201cones\u201c die). 1 2 3 >>> from dyce import H >>> d10 = H ( 10 ) - 1 >>> d00 = 10 * d10 Next, we create a roller using the R.from_values class method . 1 2 3 4 5 6 7 8 >>> r_d100 = R . from_values ( d00 , d10 ) ; r_d100 PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ) Well, wouldya look at that? That durned class method created a whole roller tree , which is actually three rollers. One ValueRoller for the d00 histogram; Another for the d10 histogram; and A PoolRoller for aggregating them both. Tip We could have also composed an identical tree using roller implementations from dyce.r instead of the R.from_values convenience method. 1 2 3 >>> from dyce.r import PoolRoller , ValueRoller >>> r_d100 == PoolRoller ( sources = ( ValueRoller ( d00 ), ValueRoller ( d10 ))) True Let\u2019s use our new roller to create a roll and retrieve its total. 1 2 3 >>> roll = r_d100 . roll () >>> roll . total () 69 No surprises there. Let\u2019s dig a little deeper and ask for the roll\u2019s outcome values. 1 2 >>> tuple ( roll . outcomes ()) ( 60 , 9 ) As we mentioned before, the top level of our roller tree is a PoolRoller , which aggregates (or \u201cpools\u201d) rolls from its sources. For our roll, the aggregated outcomes are 60 are 9 . What does our pooled roll look like? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 >>> roll Roll ( r = PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), RollOutcome ( value = 9 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 9 , sources = (), ), ), source_rolls = (), ), ), ) Let\u2019s break that down so it doesn\u2019t feel like trying to drink from a fire hose. Calling the R.roll method on our PoolRoller resulted in a Roll object . Actually, it resulted in a roll tree (analogous to our roller tree). Each Roll object in that tree has: A reference to the R object in the roller tree that generated it, retrieved via its r property ; Zero or more RollOutcome objects , retrieved by accessing the roll as a sequence (i.e., via __getitem__ , __len__ ); and Zero or more source rolls, retrieved via its source_rolls property . The RollOutcome objects also form trees (in our case, simple ones). Each one has: A single value, retrieved via its value property ; Zero or more source outcomes from which the value was derived, retrieved via its sources property ; and A reference back to the roll that generated it, retrieved via its source_roll property (omitted from the diagram for the sake of readability). Tip You might be wondering to yourself, \u201cSelf, one wonders, can one have a pool of pools?\u201d Such questions command the response, \u201cWhy the heck not? Try it!\u201d 1 2 3 4 5 6 >>> two_r_d100s = PoolRoller ( sources = ( r_d100 , r_d100 )) >>> roll_two = two_r_d100s . roll () >>> roll_two . total () 63 >>> tuple ( roll_two . outcomes ()) ( 40 , 2 , 20 , 1 ) So the answer is a resounding, \u201cOf course. What devious entity would prohibit such a thing? Please identify that creature so we may flog it until it achieves enlightenment,\u201d \u201cYes.\u201d Composing rollers with arithmetic Rollers support arithmetic operators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 >>> d12 = H ( 12 ) >>> r_d12_add_4 = ValueRoller ( d12 ) + 4 ; r_d12_add_4 BinarySumOpRoller ( bin_op =< built - in function add > , left_source = ValueRoller ( value = H ( 12 ), annotation = '' ), right_source = ValueRoller ( value = 4 , annotation = '' ), annotation = '' , ) >>> r_d12_add_4 . roll () Roll ( r = BinarySumOpRoller ( ... ), roll_outcomes = ( RollOutcome ( value = 11 , sources = ( RollOutcome ( value = 7 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 12 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 7 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ), ), ) Dropping dice from prior rolls \u2013 keeping the best three of 3d6 and 1d8 The trifecta of roller trees, roll trees, and outcome trees might appear complicated or redundant. Everything serves a purpose. 2 Consider excluding (or \u201cdropping\u201d) dice from a roll. How would we account for that? Let\u2019s see how to generate rolls that keep the best three outcomes from rolling three six-sided dice and one eight-sided die. We start by using the R.from_value class method to create ValueRoller s for histograms representing our six- and eight-sided dice. 1 2 3 4 5 6 >>> d6 = H ( 6 ) >>> d8 = H ( 8 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> r_d8 = R . from_value ( d8 ) ; r_d8 ValueRoller ( value = H ( 8 ), annotation = '' ) For homogeneous pools, we can use the matrix multiplication operator. 1 2 3 4 5 6 >>> r_3d6 = 3 @r_d6 ; r_3d6 RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) Finally, we\u2019ll create a SelectionRoller by calling the R.select_from_sources method on our other rollers. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> r_best_3_of_3d6_d8 = R . select_from_sources (( slice ( 1 , None ),), r_3d6 , r_d8 ) ; r_best_3_of_3d6_d8 SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ) Oh boy! Aren\u2019t you super excited to try this thing out? 1 2 3 >>> roll = r_best_3_of_3d6_d8 . roll () >>> tuple ( roll . outcomes ()) ( 1 , 5 , 6 ) There are indeed three values, despite starting with four dice. Given that the lowest value we see is a 1 , we might assume that the eliminated value is also a 1 . But, we all know what happens when one assumes. Recall that in roll trees, a roll may have references to other rolls (its \u201csource rolls\u201d) from which it derives. We should be able to get information about the dropped die by traversing that tree. Let\u2019s see if we can validate our assumption by looking at the outcomes from our roll\u2019s direct source. 1 2 3 >>> from itertools import chain >>> tuple ( chain . from_iterable ( source_roll . outcomes () for source_roll in roll . source_rolls )) ( 6 , 1 , 1 , 5 ) Yup! We were right! There\u2019s the other 1 , plain as day. Our work here is do\u2014 What? You want to know which die we eliminated? We can see that, too! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> roll Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 147 148 ), ) Oof. \u261d\ufe0f That was \u2026 a lot . Let\u2019s visualize! Holy entangled relationship diagrams, Batman! One thing you may notice about our top-level roll is that it has four outcomes. One of those kids is not like the others. Specifically, it has a value of None . That\u2019s our dropped outcome! 1 2 3 4 5 6 >>> len ( roll ) == 4 True >>> roll [ - 1 ] . value is None True >>> tuple ( roll_outcome . value for roll_outcome in roll ) ( 1 , 5 , 6 , None ) Info A roll outcome with a value of None is akin to a \u201ctombstone\u201d. It conveys one whose sources were present in immediately prior rolls but excluded from the current roll. Such roll outcomes must have at least one source. 1 2 3 4 5 >>> from dyce.r import RollOutcome >>> RollOutcome ( value = None ) Traceback ( most recent call last ): ... ValueError : value can only be None if sources is non - empty However, because such a roll signals its absence from the current roll, its value is not included by the Roll.outcomes method . We can programmatically verify that the excluded outcome originated from one of the six-sided dice. 1 2 3 4 5 6 7 >>> excluded = roll [ - 1 ] >>> excluded . value is None True >>> excluded . sources [ 0 ] . value 1 >>> excluded . sources [ 0 ] . r is r_d6 True We can also verify that the 5 came from the eight-sided die. 1 2 3 4 5 >>> five = roll [ 1 ] >>> five . value 5 >>> five . r is r_d8 True Alternatively, could have also used our old friend the P object to eliminate the RepeatRoller for a similar, but structurally simpler result. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from dyce import P >>> R . select_from_values (( slice ( 1 , None ),), 3 @P ( d6 ), d8 ) . roll () Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( ValueRoller ( value = P ( 6 , 6 , 6 ), annotation = '' ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 79 80 ), ) In this case, our results are still mostly traceable, since our pool is homogeneous. However, results from P.roll are sorted, meaning they lose association with their source histograms. This risks ambiguity. Consider: 1 2 >>> P ( 6 , 8 ) . roll () ( 4 , 6 ) Is the 4 from the d6 or d8 ? \ud83e\udd14\ud83d\udcad No one knows. 1 2 3 4 >>> R . from_value ( P ( 6 , 8 )) # doctest: +SKIP \u2026 : UserWarning : using a heterogeneous pool ( P ( 6 , 8 )) is not recommended where traceability is important ... ValueRoller ( value = P ( 6 , 8 ), annotation = '' ) Performance How much overhead do all these data structures contribute? It obviously depends on the complexity of the structure. Consider a simple example d20 + d12 + 4 . Let\u2019s do that 5,000 times, sort the results, and take every other one starting with the highest. We might use a pool, if we didn\u2019t care about traceability. 1 2 3 4 5 6 7 8 In [ 1 ]: from dyce import H , P , R In [ 2 ]: d20 , d12 = H ( 20 ), H ( 12 ) In [ 3 ]: p = 5000 @P ( d20 + d12 + 4 ) In [ 4 ]: % timeit p . roll ()[:: - 2 ] 26.3 ms \u00b1 520 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) That\u2019s not bad. What about rollers? 1 2 3 4 In [ 5 ]: r = ( 5000 @ ( R . select_from_values (( slice ( None , None , - 2 ),), d20 , d12 , 4 ))) In [ 6 ]: % timeit r . roll () 257 ms \u00b1 3.7 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In this particular case, our roller takes about ten times longer than our histogram pool. It is unsurprising that a simple roller is slower than a simple pool, at least in part because the math is deferred until R.roll time. In more sophisticated cases, rollers may be more competitive with (or even surpass) their histogram or pool analogies, especially when initialization time is taken into account. All that being said, for periodic rolls simulating handfuls (not thousands) of operations or dice, such performance disparities probably won\u2019t matter that much. Just use the primitives whose semantics work best for you. If ever performance becomes an issue, let us know , and we can collaborate on how to improve it. Further exploration Consider reviewing the roller API . If you\u2019re not already familiar with histograms, consider skimming the counting tutorial . \u21a9 We may still be discovering what those are. We have the utmost faith such purposes exist, even if they have yet to reveal themselves. If you discover one, consider contributing an example. \u21a9","title":"Rollin\u2019 with rollers and rolls"},{"location":"rollin/#emulating-a-hundred-sided-die-using-two-ten-sided-dice","text":"In many games it is common to emulate a hundred-sided die using a \u201cones\u201d ten-sided die (faces numbered \\([{{0}, {1}, \\ldots , {9}}]\\) ) and a \u201ctens\u201d ten-sided die (faces numbered \\([{{00}, {10}, \\ldots , {90}}]\\) ). Let\u2019s try to model that as a roller and use it to generate a roll. We start by creating two histograms 1 representing our two ten-sided dice ( d00 for our \u201ctens\u201d die and d10 for our \u201cones\u201c die). 1 2 3 >>> from dyce import H >>> d10 = H ( 10 ) - 1 >>> d00 = 10 * d10 Next, we create a roller using the R.from_values class method . 1 2 3 4 5 6 7 8 >>> r_d100 = R . from_values ( d00 , d10 ) ; r_d100 PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ) Well, wouldya look at that? That durned class method created a whole roller tree , which is actually three rollers. One ValueRoller for the d00 histogram; Another for the d10 histogram; and A PoolRoller for aggregating them both. Tip We could have also composed an identical tree using roller implementations from dyce.r instead of the R.from_values convenience method. 1 2 3 >>> from dyce.r import PoolRoller , ValueRoller >>> r_d100 == PoolRoller ( sources = ( ValueRoller ( d00 ), ValueRoller ( d10 ))) True Let\u2019s use our new roller to create a roll and retrieve its total. 1 2 3 >>> roll = r_d100 . roll () >>> roll . total () 69 No surprises there. Let\u2019s dig a little deeper and ask for the roll\u2019s outcome values. 1 2 >>> tuple ( roll . outcomes ()) ( 60 , 9 ) As we mentioned before, the top level of our roller tree is a PoolRoller , which aggregates (or \u201cpools\u201d) rolls from its sources. For our roll, the aggregated outcomes are 60 are 9 . What does our pooled roll look like? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 >>> roll Roll ( r = PoolRoller ( sources = ( ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), RollOutcome ( value = 9 , sources = (), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 10 : 1 , 20 : 1 , 30 : 1 , 40 : 1 , 50 : 1 , 60 : 1 , 70 : 1 , 80 : 1 , 90 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 60 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = H ({ 0 : 1 , 1 : 1 , 2 : 1 , 3 : 1 , 4 : 1 , 5 : 1 , 6 : 1 , 7 : 1 , 8 : 1 , 9 : 1 }), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 9 , sources = (), ), ), source_rolls = (), ), ), ) Let\u2019s break that down so it doesn\u2019t feel like trying to drink from a fire hose. Calling the R.roll method on our PoolRoller resulted in a Roll object . Actually, it resulted in a roll tree (analogous to our roller tree). Each Roll object in that tree has: A reference to the R object in the roller tree that generated it, retrieved via its r property ; Zero or more RollOutcome objects , retrieved by accessing the roll as a sequence (i.e., via __getitem__ , __len__ ); and Zero or more source rolls, retrieved via its source_rolls property . The RollOutcome objects also form trees (in our case, simple ones). Each one has: A single value, retrieved via its value property ; Zero or more source outcomes from which the value was derived, retrieved via its sources property ; and A reference back to the roll that generated it, retrieved via its source_roll property (omitted from the diagram for the sake of readability). Tip You might be wondering to yourself, \u201cSelf, one wonders, can one have a pool of pools?\u201d Such questions command the response, \u201cWhy the heck not? Try it!\u201d 1 2 3 4 5 6 >>> two_r_d100s = PoolRoller ( sources = ( r_d100 , r_d100 )) >>> roll_two = two_r_d100s . roll () >>> roll_two . total () 63 >>> tuple ( roll_two . outcomes ()) ( 40 , 2 , 20 , 1 ) So the answer is a resounding, \u201cOf course. What devious entity would prohibit such a thing? Please identify that creature so we may flog it until it achieves enlightenment,\u201d \u201cYes.\u201d","title":"Emulating a hundred-sided die using two ten-sided dice"},{"location":"rollin/#composing-rollers-with-arithmetic","text":"Rollers support arithmetic operators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 >>> d12 = H ( 12 ) >>> r_d12_add_4 = ValueRoller ( d12 ) + 4 ; r_d12_add_4 BinarySumOpRoller ( bin_op =< built - in function add > , left_source = ValueRoller ( value = H ( 12 ), annotation = '' ), right_source = ValueRoller ( value = 4 , annotation = '' ), annotation = '' , ) >>> r_d12_add_4 . roll () Roll ( r = BinarySumOpRoller ( ... ), roll_outcomes = ( RollOutcome ( value = 11 , sources = ( RollOutcome ( value = 7 , sources = (), ), RollOutcome ( value = 4 , sources = (), ), ), ), ), source_rolls = ( Roll ( r = ValueRoller ( value = H ( 12 ), annotation = '' ), roll_outcomes = ( RollOutcome ( value = 7 , sources = (), ), ), source_rolls = (), ), Roll ( r = ValueRoller ( value = 4 , annotation = '' ), roll_outcomes = ( RollOutcome ( value = 4 , sources = (), ), ), source_rolls = (), ), ), )","title":"Composing rollers with arithmetic"},{"location":"rollin/#dropping-dice-from-prior-rolls-keeping-the-best-three-of-3d6-and-1d8","text":"The trifecta of roller trees, roll trees, and outcome trees might appear complicated or redundant. Everything serves a purpose. 2 Consider excluding (or \u201cdropping\u201d) dice from a roll. How would we account for that? Let\u2019s see how to generate rolls that keep the best three outcomes from rolling three six-sided dice and one eight-sided die. We start by using the R.from_value class method to create ValueRoller s for histograms representing our six- and eight-sided dice. 1 2 3 4 5 6 >>> d6 = H ( 6 ) >>> d8 = H ( 8 ) >>> r_d6 = R . from_value ( d6 ) ; r_d6 ValueRoller ( value = H ( 6 ), annotation = '' ) >>> r_d8 = R . from_value ( d8 ) ; r_d8 ValueRoller ( value = H ( 8 ), annotation = '' ) For homogeneous pools, we can use the matrix multiplication operator. 1 2 3 4 5 6 >>> r_3d6 = 3 @r_d6 ; r_3d6 RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ) Finally, we\u2019ll create a SelectionRoller by calling the R.select_from_sources method on our other rollers. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> r_best_3_of_3d6_d8 = R . select_from_sources (( slice ( 1 , None ),), r_3d6 , r_d8 ) ; r_best_3_of_3d6_d8 SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ) Oh boy! Aren\u2019t you super excited to try this thing out? 1 2 3 >>> roll = r_best_3_of_3d6_d8 . roll () >>> tuple ( roll . outcomes ()) ( 1 , 5 , 6 ) There are indeed three values, despite starting with four dice. Given that the lowest value we see is a 1 , we might assume that the eliminated value is also a 1 . But, we all know what happens when one assumes. Recall that in roll trees, a roll may have references to other rolls (its \u201csource rolls\u201d) from which it derives. We should be able to get information about the dropped die by traversing that tree. Let\u2019s see if we can validate our assumption by looking at the outcomes from our roll\u2019s direct source. 1 2 3 >>> from itertools import chain >>> tuple ( chain . from_iterable ( source_roll . outcomes () for source_roll in roll . source_rolls )) ( 6 , 1 , 1 , 5 ) Yup! We were right! There\u2019s the other 1 , plain as day. Our work here is do\u2014 What? You want to know which die we eliminated? We can see that, too! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 >>> roll Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( RepeatRoller ( n = 3 , source = ValueRoller ( value = H ( 6 ), annotation = '' ), annotation = '' , ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 147 148 ), ) Oof. \u261d\ufe0f That was \u2026 a lot . Let\u2019s visualize! Holy entangled relationship diagrams, Batman! One thing you may notice about our top-level roll is that it has four outcomes. One of those kids is not like the others. Specifically, it has a value of None . That\u2019s our dropped outcome! 1 2 3 4 5 6 >>> len ( roll ) == 4 True >>> roll [ - 1 ] . value is None True >>> tuple ( roll_outcome . value for roll_outcome in roll ) ( 1 , 5 , 6 , None ) Info A roll outcome with a value of None is akin to a \u201ctombstone\u201d. It conveys one whose sources were present in immediately prior rolls but excluded from the current roll. Such roll outcomes must have at least one source. 1 2 3 4 5 >>> from dyce.r import RollOutcome >>> RollOutcome ( value = None ) Traceback ( most recent call last ): ... ValueError : value can only be None if sources is non - empty However, because such a roll signals its absence from the current roll, its value is not included by the Roll.outcomes method . We can programmatically verify that the excluded outcome originated from one of the six-sided dice. 1 2 3 4 5 6 7 >>> excluded = roll [ - 1 ] >>> excluded . value is None True >>> excluded . sources [ 0 ] . value 1 >>> excluded . sources [ 0 ] . r is r_d6 True We can also verify that the 5 came from the eight-sided die. 1 2 3 4 5 >>> five = roll [ 1 ] >>> five . value 5 >>> five . r is r_d8 True Alternatively, could have also used our old friend the P object to eliminate the RepeatRoller for a similar, but structurally simpler result. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from dyce import P >>> R . select_from_values (( slice ( 1 , None ),), 3 @P ( d6 ), d8 ) . roll () Roll ( r = SelectionRoller ( which = ( slice ( 1 , None , None ),), sources = ( ValueRoller ( value = P ( 6 , 6 , 6 ), annotation = '' ), ValueRoller ( value = H ( 8 ), annotation = '' ), ), annotation = '' , ), roll_outcomes = ( ... *snip* \u2702\ufe0f 79 80 ), ) In this case, our results are still mostly traceable, since our pool is homogeneous. However, results from P.roll are sorted, meaning they lose association with their source histograms. This risks ambiguity. Consider: 1 2 >>> P ( 6 , 8 ) . roll () ( 4 , 6 ) Is the 4 from the d6 or d8 ? \ud83e\udd14\ud83d\udcad No one knows. 1 2 3 4 >>> R . from_value ( P ( 6 , 8 )) # doctest: +SKIP \u2026 : UserWarning : using a heterogeneous pool ( P ( 6 , 8 )) is not recommended where traceability is important ... ValueRoller ( value = P ( 6 , 8 ), annotation = '' )","title":"Dropping dice from prior rolls \u2013 keeping the best three of 3d6 and 1d8"},{"location":"rollin/#performance","text":"How much overhead do all these data structures contribute? It obviously depends on the complexity of the structure. Consider a simple example d20 + d12 + 4 . Let\u2019s do that 5,000 times, sort the results, and take every other one starting with the highest. We might use a pool, if we didn\u2019t care about traceability. 1 2 3 4 5 6 7 8 In [ 1 ]: from dyce import H , P , R In [ 2 ]: d20 , d12 = H ( 20 ), H ( 12 ) In [ 3 ]: p = 5000 @P ( d20 + d12 + 4 ) In [ 4 ]: % timeit p . roll ()[:: - 2 ] 26.3 ms \u00b1 520 \u00b5s per loop ( mean \u00b1 std . dev . of 7 runs , 10 loops each ) That\u2019s not bad. What about rollers? 1 2 3 4 In [ 5 ]: r = ( 5000 @ ( R . select_from_values (( slice ( None , None , - 2 ),), d20 , d12 , 4 ))) In [ 6 ]: % timeit r . roll () 257 ms \u00b1 3.7 ms per loop ( mean \u00b1 std . dev . of 7 runs , 1 loop each ) In this particular case, our roller takes about ten times longer than our histogram pool. It is unsurprising that a simple roller is slower than a simple pool, at least in part because the math is deferred until R.roll time. In more sophisticated cases, rollers may be more competitive with (or even surpass) their histogram or pool analogies, especially when initialization time is taken into account. All that being said, for periodic rolls simulating handfuls (not thousands) of operations or dice, such performance disparities probably won\u2019t matter that much. Just use the primitives whose semantics work best for you. If ever performance becomes an issue, let us know , and we can collaborate on how to improve it.","title":"Performance"},{"location":"rollin/#further-exploration","text":"Consider reviewing the roller API . If you\u2019re not already familiar with histograms, consider skimming the counting tutorial . \u21a9 We may still be discovering what those are. We have the utmost faith such purposes exist, even if they have yet to reveal themselves. If you discover one, consider contributing an example. \u21a9","title":"Further exploration"},{"location":"translations/","text":"The following examples and translations are intended to showcase dyce \u2019s flexibility. If you have exposure to another tool , they may also help with transition. Modeling \u201c The Probability of 4d6, Drop the Lowest, Reroll 1s \u201d 1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H , P >>> res1 = 3 @ H ( 6 ) >>> p_4d6 = 4 @P ( 6 ) >>> res2 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : H ( 6 ) if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res3 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H (( 2 , 3 , 4 , 5 , 6 ))) >>> res4 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest >>> res5 = 2 @ H ( 6 ) + 6 >>> res6 = 4 @ H ( 4 ) + 2 Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res4 . distribution_xy (), ... marker = \"D\" , ... label = \"3d6\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res1 . distribution_xy (), ... marker = \"s\" , ... label = \"4d6 - discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res2 . distribution_xy (), ... marker = \"^\" , ... label = \"4d6 - re-roll first 1, discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res3 . distribution_xy (), ... marker = \"*\" , ... label = \"4d6 - re-roll all 1s (i.e., 4d5), discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res5 . distribution_xy (), ... marker = \"x\" , ... label = \"2d6 + 6\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res6 . distribution_xy (), ... marker = \"o\" , ... label = \"4d4 + 2\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Comparing various take-three-of-4d6 methods\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translating one example from markbrockettrobson/python_dice Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: 1 2 3 4 5 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = damage_half_on_save . distribution_xy () >>> matplotlib . pyplot . plot ( outcomes , probabilities , marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Expected outcomes for attack with saving throw for half damage\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP An alternative using the H.substitute method : 1 2 3 4 5 6 7 >>> import operator >>> save_roll . substitute ( ... lambda h , outcome : ... burning_arch_damage // 2 if operator . __ge__ ( outcome , 10 ) ... else burning_arch_damage ... ) == damage_half_on_save True More translations from markbrockettrobson/python_dice 1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_ = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_ . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> _ = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( _ . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> _ = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( _ . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % } Translations from LordSembor/DnDice Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { ... , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { ... , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 >>> import matplotlib # doctest: +SKIP >>> from dyce.viz import display_burst >>> ax_plot = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 0 )) # doctest: +SKIP >>> ax_burst = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 1 )) # doctest: +SKIP >>> label_sa = \"Normal attack\" >>> ax_plot . plot ( ... * single_attack . distribution_xy (), ... color = \"tab:green\" , ... label = label_sa , ... marker = \".\" , ... ) # doctest: +SKIP >>> label_gwf = \"\u201cGreat Weapon Fighting\u201d\" >>> ax_plot . plot ( ... * great_weapon_fighting . distribution_xy (), ... color = \"tab:blue\" , ... label = label_gwf , ... marker = \".\" , ... ) # doctest: +SKIP >>> ax_plot . legend () # doctest: +SKIP >>> ax_plot . set_title ( \"Comparing a normal attack to an enhanced one\" ) # doctest: +SKIP >>> display_burst ( ... ax_burst , ... h_inner = great_weapon_fighting , ... outer = single_attack , ... desc = f \" { label_sa } vs. { label_gwf } \" , ... inner_color = \"RdYlBu_r\" , ... outer_color = \"RdYlGn_r\" , ... alpha = 0.9 , ... ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( _ : H , outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = advantage . substitute ( crit ) Example 2 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * normal_hit . distribution_xy (), ... marker = \".\" , ... label = \"Normal hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * critical_hit . distribution_xy (), ... marker = \".\" , ... label = \"Critical hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * advantage_weighted . distribution_xy (), ... marker = \".\" , ... label = \"Advantage-weighted\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Modeling an advantage-weighted attack with critical hits\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c Roll and Keep in Anydice? \u201d Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: 1 2 3 4 5 6 7 8 9 10 11 >>> import matplotlib # doctest: +SKIP >>> for depth in range ( 6 ): ... res = ( 10 @ P ( H ( 10 ) . explode ( max_depth = depth ))) . h ( slice ( - 3 , None )) ... matplotlib . pyplot . plot ( ... * res . distribution_xy (), ... marker = \".\" , ... label = f \" { depth } rerolls\" , ... ) # doctest: +SKIP matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Modeling taking the three highest of ten exploding d10s\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c How do I count the number of duplicates in anydice? \u201d Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 11 >>> def dupes ( p : P ): ... for roll , count in p . rolls_with_counts (): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... # Outcomes are ordered, so we only have to look at one neighbor ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... yield dupes , count >>> res_15d6 = H ( dupes ( 15 @P ( 6 ))) >>> res_8d10 = H ( dupes ( 8 @P ( 10 ))) Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res_15d6 . distribution_xy (), ... marker = \"o\" , ... label = \"15d6\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res_8d10 . distribution_xy (), ... marker = \"o\" , ... label = \"8d10\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Chances of rolling $n$ duplicates\" ) # doctest: +SKIP Translation of \u201c How do I implement this specialized roll-and-keep mechanic in AnyDice? \u201d Source: 1 2 3 4 5 6 7 8 9 function: N:n of SIZE:n keep K:n extras add { result: [helper NdSIZE SIZE K] } function: helper ROLL:s SIZE:n K:n { COUNT: [count SIZE in ROLL] if COUNT > K { result: K*SIZE - K + COUNT } result: {1..K}@ROLL } Translation: 1 2 3 4 5 6 7 8 >>> def roll_and_keep ( p : P , k : int ): ... assert p . is_homogeneous ... max_d = max ( p [ - 1 ]) if p else 0 ... for roll , count in p . rolls_with_counts (): ... total = sum ( roll [ - k :]) + sum ( 1 for outcome in roll [: - k ] if outcome == max_d ) ... yield total , count >>> H ( roll_and_keep ( 6 @P ( 6 ), 3 )) H ({ 3 : 1 , 4 : 6 , 5 : 21 , 6 : 78 , 7 : 207 , ... , 17 : 5535 , 18 : 2500 , 19 : 375 , 20 : 30 , 21 : 1 }) Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> import matplotlib # doctest: +SKIP >>> d , k = 6 , 3 >>> for n in range ( k + 1 , k + 9 ): ... p = n @ P ( d ) ... res_roll_and_keep = H ( roll_and_keep ( p , k )) ... matplotlib . pyplot . plot ( ... * res_roll_and_keep . distribution_xy (), ... marker = \"o\" , ... label = f \" { n } d { d } keep { k } add +1\" , ... ) # doctest: +SKIP >>> for n in range ( k + 1 , k + 9 ): ... p = n @ P ( d ) ... res_normal = p . h ( slice ( - k , None )) ... matplotlib . pyplot . plot ( ... * res_normal . distribution_xy (), ... marker = \"s\" , ... label = f \" { n } d { d } keep { k } \" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Roll-and-keep mechanic comparison\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Translation of the accepted answer to \u201c Modelling [sic] opposed dice pools with a swap \u201d Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 >>> from itertools import product >>> def brawl ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... yield a_successes - b_successes , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 >>> res = H ( brawl ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> def brawl_w_optional_swap ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... yield result , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> res = H ( brawl_w_optional_swap ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = H ( brawl_w_optional_swap ( 4 @P ( 6 ), 4 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Applications and translations"},{"location":"translations/#modeling-the-probability-of-4d6-drop-the-lowest-reroll-1s","text":"1 2 3 4 5 6 7 8 9 10 11 >>> from dyce import H , P >>> res1 = 3 @ H ( 6 ) >>> p_4d6 = 4 @P ( 6 ) >>> res2 = p_4d6 . h ( slice ( 1 , None )) # discard the lowest die (index 0) >>> d6_reroll_first_one = H ( 6 ) . substitute ( lambda h , outcome : H ( 6 ) if outcome == 1 else outcome ) >>> p_4d6_reroll_first_one = ( 4 @P ( d6_reroll_first_one )) >>> res3 = p_4d6_reroll_first_one . h ( slice ( 1 , None )) # discard the lowest >>> p_4d6_reroll_all_ones = 4 @P ( H (( 2 , 3 , 4 , 5 , 6 ))) >>> res4 = p_4d6_reroll_all_ones . h ( slice ( 1 , None )) # discard the lowest >>> res5 = 2 @ H ( 6 ) + 6 >>> res6 = 4 @ H ( 4 ) + 2 Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res4 . distribution_xy (), ... marker = \"D\" , ... label = \"3d6\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res1 . distribution_xy (), ... marker = \"s\" , ... label = \"4d6 - discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res2 . distribution_xy (), ... marker = \"^\" , ... label = \"4d6 - re-roll first 1, discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res3 . distribution_xy (), ... marker = \"*\" , ... label = \"4d6 - re-roll all 1s (i.e., 4d5), discard lowest\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res5 . distribution_xy (), ... marker = \"x\" , ... label = \"2d6 + 6\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res6 . distribution_xy (), ... marker = \"o\" , ... label = \"4d4 + 2\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Comparing various take-three-of-4d6 methods\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Modeling \u201cThe Probability of 4d6, Drop the Lowest, Reroll 1s\u201d"},{"location":"translations/#translating-one-example-from-markbrockettrobsonpython_dice","text":"Source: 1 2 3 4 5 6 7 8 9 # \u2026 program = [ \"VAR save_roll = d20\" , \"VAR burning_arch_damage = 10d6 + 10\" , \"VAR pass_save = ( save_roll >= 10 ) \" , \"VAR damage_half_on_save = burning_arch_damage // (pass_save + 1)\" , \"damage_half_on_save\" ] # \u2026 Translation: 1 2 3 4 >>> save_roll = H ( 20 ) >>> burning_arch_damage = 10 @H ( 6 ) + 10 >>> pass_save = save_roll . ge ( 10 ) >>> damage_half_on_save = burning_arch_damage // ( pass_save + 1 ) Visualization: 1 2 3 4 5 >>> import matplotlib # doctest: +SKIP >>> outcomes , probabilities = damage_half_on_save . distribution_xy () >>> matplotlib . pyplot . plot ( outcomes , probabilities , marker = \".\" ) # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Expected outcomes for attack with saving throw for half damage\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP An alternative using the H.substitute method : 1 2 3 4 5 6 7 >>> import operator >>> save_roll . substitute ( ... lambda h , outcome : ... burning_arch_damage // 2 if operator . __ge__ ( outcome , 10 ) ... else burning_arch_damage ... ) == damage_half_on_save True","title":"Translating one example from markbrockettrobson/python_dice"},{"location":"translations/#more-translations-from-markbrockettrobsonpython_dice","text":"1 2 3 4 >>> # VAR name = 1 + 2d3 - 3 * 4d2 // 5 >>> name = 1 + ( 2 @H ( 3 )) - 3 * ( 4 @H ( 2 )) // 5 >>> print ( name . format ( width = 0 )) { avg : 1.75 , - 1 : 3.47 % , 0 : 13.89 % , 1 : 25.00 % , 2 : 29.17 % , 3 : 19.44 % , 4 : 8.33 % , 5 : 0.69 % } 1 2 3 4 >>> # VAR out = 3 * ( 1 + 1d4 ) >>> out = 3 * ( 1 + 2 @H ( 4 )) >>> print ( out . format ( width = 0 )) { avg : 18.00 , 9 : 6.25 % , 12 : 12.50 % , 15 : 18.75 % , 18 : 25.00 % , 21 : 18.75 % , 24 : 12.50 % , 27 : 6.25 % } 1 2 3 4 >>> # VAR g = (1d4 >= 2) AND !(1d20 == 2) >>> g = H ( 4 ) . ge ( 2 ) & H ( 20 ) . ne ( 2 ) >>> print ( g . format ( width = 0 )) { ... , False : 28.75 % , True : 71.25 % } 1 2 3 4 >>> # VAR h = (1d4 >= 2) OR !(1d20 == 2) >>> h = H ( 4 ) . ge ( 2 ) | H ( 20 ) . ne ( 2 ) >>> print ( h . format ( width = 0 )) { ... , False : 1.25 % , True : 98.75 % } 1 2 3 4 >>> # VAR abs = ABS( 1d6 - 1d6 ) >>> abs_ = abs ( H ( 6 ) - H ( 6 )) >>> print ( abs_ . format ( width = 0 )) { avg : 1.94 , 0 : 16.67 % , 1 : 27.78 % , 2 : 22.22 % , 3 : 16.67 % , 4 : 11.11 % , 5 : 5.56 % } 1 2 3 4 >>> # MAX(4d7, 2d10) >>> _ = P ( 4 @H ( 7 ), 2 @H ( 10 )) . h ( - 1 ) >>> print ( _ . format ( width = 0 )) { avg : 16.60 , 4 : 0.00 % , 5 : 0.02 % , 6 : 0.07 % , 7 : 0.21 % , ... , 25 : 0.83 % , 26 : 0.42 % , 27 : 0.17 % , 28 : 0.04 % } 1 2 3 4 >>> # MIN(50, d%) >>> _ = P ( H (( 50 ,)), P ( 100 )) . h ( 0 ) >>> print ( _ . format ( width = 0 )) { avg : 37.75 , 1 : 1.00 % , 2 : 1.00 % , 3 : 1.00 % , ... , 47 : 1.00 % , 48 : 1.00 % , 49 : 1.00 % , 50 : 51.00 % }","title":"More translations from markbrockettrobson/python_dice"},{"location":"translations/#translations-from-lordsembordndice","text":"Example 1 source: 1 2 3 4 5 6 7 8 9 10 11 from DnDice import d , gwf single_attack = 2 * d ( 6 ) + 5 # \u2026 great_weapon_fighting = gwf ( 2 * d ( 6 )) + 5 # \u2026 # comparison of the probability print ( single_attack . expectancies ()) print ( great_weapon_fighting . expectancies ()) # [ 0.03, 0.06, 0.08, 0.11, 0.14, 0.17, 0.14, ...] (single attack) # [0.003, 0.006, 0.03, 0.05, 0.10, 0.15, 0.17, ...] (gwf attack) # \u2026 Example 1 translation: 1 2 3 4 5 6 7 8 9 10 >>> single_attack = 2 @H ( 6 ) + 5 >>> def gwf ( h : H , outcome ): ... return h if outcome in ( 1 , 2 ) else outcome >>> great_weapon_fighting = 2 @ ( H ( 6 ) . substitute ( gwf )) + 5 # reroll either die if it is a one or two >>> print ( single_attack . format ( width = 0 )) { ... , 7 : 2.78 % , 8 : 5.56 % , 9 : 8.33 % , 10 : 11.11 % , 11 : 13.89 % , 12 : 16.67 % , 13 : 13.89 % , ... } >>> print ( great_weapon_fighting . format ( width = 0 )) { ... , 7 : 0.31 % , 8 : 0.62 % , 9 : 2.78 % , 10 : 4.94 % , 11 : 9.88 % , 12 : 14.81 % , 13 : 17.28 % , ... } Example 1 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 >>> import matplotlib # doctest: +SKIP >>> from dyce.viz import display_burst >>> ax_plot = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 0 )) # doctest: +SKIP >>> ax_burst = matplotlib . pyplot . subplot2grid (( 1 , 2 ), ( 0 , 1 )) # doctest: +SKIP >>> label_sa = \"Normal attack\" >>> ax_plot . plot ( ... * single_attack . distribution_xy (), ... color = \"tab:green\" , ... label = label_sa , ... marker = \".\" , ... ) # doctest: +SKIP >>> label_gwf = \"\u201cGreat Weapon Fighting\u201d\" >>> ax_plot . plot ( ... * great_weapon_fighting . distribution_xy (), ... color = \"tab:blue\" , ... label = label_gwf , ... marker = \".\" , ... ) # doctest: +SKIP >>> ax_plot . legend () # doctest: +SKIP >>> ax_plot . set_title ( \"Comparing a normal attack to an enhanced one\" ) # doctest: +SKIP >>> display_burst ( ... ax_burst , ... h_inner = great_weapon_fighting , ... outer = single_attack , ... desc = f \" { label_sa } vs. { label_gwf } \" , ... inner_color = \"RdYlBu_r\" , ... outer_color = \"RdYlGn_r\" , ... alpha = 0.9 , ... ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP Example 2 source: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from DnDice import d , advantage , plot normal_hit = 1 * d ( 12 ) + 5 critical_hit = 3 * d ( 12 ) + 5 result = d () for value , probability in advantage (): if value == 20 : result . layer ( critical_hit , weight = probability ) elif value + 5 >= 14 : result . layer ( normal_hit , weight = probability ) else : result . layer ( d ( 0 ), weight = probability ) result . normalizeExpectancies () # \u2026 Example 2 translation: 1 2 3 4 5 6 7 8 9 10 >>> normal_hit = H ( 12 ) + 5 >>> critical_hit = 3 @H ( 12 ) + 5 >>> advantage = ( 2 @P ( 20 )) . h ( - 1 ) >>> def crit ( _ : H , outcome ): ... if outcome == 20 : return critical_hit ... elif outcome + 5 >= 14 : return normal_hit ... else : return 0 >>> advantage_weighted = advantage . substitute ( crit ) Example 2 visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * normal_hit . distribution_xy (), ... marker = \".\" , ... label = \"Normal hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * critical_hit . distribution_xy (), ... marker = \".\" , ... label = \"Critical hit\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * advantage_weighted . distribution_xy (), ... marker = \".\" , ... label = \"Advantage-weighted\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Modeling an advantage-weighted attack with critical hits\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translations from LordSembor/DnDice"},{"location":"translations/#translation-of-the-accepted-answer-to-roll-and-keep-in-anydice","text":"Source: 1 output [highest 3 of 10d [explode d10]] named \"10k3\" Translation: 1 >>> res = ( 10 @P ( H ( 10 ) . explode ( max_depth = 3 ))) . h ( slice ( - 3 , None )) Visualization: 1 2 3 4 5 6 7 8 9 10 11 >>> import matplotlib # doctest: +SKIP >>> for depth in range ( 6 ): ... res = ( 10 @ P ( H ( 10 ) . explode ( max_depth = depth ))) . h ( slice ( - 3 , None )) ... matplotlib . pyplot . plot ( ... * res . distribution_xy (), ... marker = \".\" , ... label = f \" { depth } rerolls\" , ... ) # doctest: +SKIP matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Modeling taking the three highest of ten exploding d10s\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translation of the accepted answer to \u201cRoll and Keep in Anydice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-how-do-i-count-the-number-of-duplicates-in-anydice","text":"Source: 1 2 3 4 5 6 7 function: dupes in DICE:s { D: 0 loop X over {2..#DICE} { if ((X-1)@DICE = X@DICE) { D: D + 1} } result: D } Translation: 1 2 3 4 5 6 7 8 9 10 11 >>> def dupes ( p : P ): ... for roll , count in p . rolls_with_counts (): ... dupes = 0 ... for i in range ( 1 , len ( roll )): ... # Outcomes are ordered, so we only have to look at one neighbor ... if roll [ i ] == roll [ i - 1 ]: ... dupes += 1 ... yield dupes , count >>> res_15d6 = H ( dupes ( 15 @P ( 6 ))) >>> res_8d10 = H ( dupes ( 8 @P ( 10 ))) Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> import matplotlib # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res_15d6 . distribution_xy (), ... marker = \"o\" , ... label = \"15d6\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . plot ( ... * res_8d10 . distribution_xy (), ... marker = \"o\" , ... label = \"8d10\" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Chances of rolling $n$ duplicates\" ) # doctest: +SKIP","title":"Translation of the accepted answer to \u201cHow do I count the number of duplicates in anydice?\u201d"},{"location":"translations/#translation-of-how-do-i-implement-this-specialized-roll-and-keep-mechanic-in-anydice","text":"Source: 1 2 3 4 5 6 7 8 9 function: N:n of SIZE:n keep K:n extras add { result: [helper NdSIZE SIZE K] } function: helper ROLL:s SIZE:n K:n { COUNT: [count SIZE in ROLL] if COUNT > K { result: K*SIZE - K + COUNT } result: {1..K}@ROLL } Translation: 1 2 3 4 5 6 7 8 >>> def roll_and_keep ( p : P , k : int ): ... assert p . is_homogeneous ... max_d = max ( p [ - 1 ]) if p else 0 ... for roll , count in p . rolls_with_counts (): ... total = sum ( roll [ - k :]) + sum ( 1 for outcome in roll [: - k ] if outcome == max_d ) ... yield total , count >>> H ( roll_and_keep ( 6 @P ( 6 ), 3 )) H ({ 3 : 1 , 4 : 6 , 5 : 21 , 6 : 78 , 7 : 207 , ... , 17 : 5535 , 18 : 2500 , 19 : 375 , 20 : 30 , 21 : 1 }) Visualization: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 >>> import matplotlib # doctest: +SKIP >>> d , k = 6 , 3 >>> for n in range ( k + 1 , k + 9 ): ... p = n @ P ( d ) ... res_roll_and_keep = H ( roll_and_keep ( p , k )) ... matplotlib . pyplot . plot ( ... * res_roll_and_keep . distribution_xy (), ... marker = \"o\" , ... label = f \" { n } d { d } keep { k } add +1\" , ... ) # doctest: +SKIP >>> for n in range ( k + 1 , k + 9 ): ... p = n @ P ( d ) ... res_normal = p . h ( slice ( - k , None )) ... matplotlib . pyplot . plot ( ... * res_normal . distribution_xy (), ... marker = \"s\" , ... label = f \" { n } d { d } keep { k } \" , ... ) # doctest: +SKIP >>> matplotlib . pyplot . legend () # doctest: +SKIP >>> matplotlib . pyplot . title ( \"Roll-and-keep mechanic comparison\" ) # doctest: +SKIP >>> matplotlib . pyplot . show () # doctest: +SKIP","title":"Translation of \u201cHow do I implement this specialized roll-and-keep mechanic in AnyDice?\u201d"},{"location":"translations/#translation-of-the-accepted-answer-to-modelling-sic-opposed-dice-pools-with-a-swap","text":"Source of basic brawl : 1 2 3 4 5 6 7 8 9 function: brawl A:s vs B:s { SA: A >= 1@B SB: B >= 1@A if SA-SB=0 { result:(A > B) - (A < B) } result:SA-SB } output [brawl 3d6 vs 3d6] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 >>> from itertools import product >>> def brawl ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ - 1 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ - 1 ]) ... yield a_successes - b_successes , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 >>> res = H ( brawl ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 0.00 std | 1.73 var | 2.99 - 3 | 7.86 % | ### - 2 | 15.52 % | ####### - 1 | 16.64 % | ######## 0 | 19.96 % | ######### 1 | 16.64 % | ######## 2 | 15.52 % | ####### 3 | 7.86 % | ### Source of brawl with an optional dice swap: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function: set element I:n in SEQ:s to N:n { NEW: {} loop J over {1 .. #SEQ} { if I = J { NEW: {NEW, N} } else { NEW: {NEW, J@SEQ} } } result: NEW } function: brawl A:s vs B:s with optional swap { if #A@A >= 1@B { result: [brawl A vs B] } AX: [sort [set element #A in A to 1@B]] BX: [sort [set element 1 in B to #A@A]] result: [brawl AX vs BX] } output [brawl 3d6 vs 3d6 with optional swap] named \"A vs B Damage\" Translation: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> def brawl_w_optional_swap ( a : P , b : P ): ... for ( roll_a , count_a ), ( roll_b , count_b ) in product ( ... a . rolls_with_counts (), ... b . rolls_with_counts (), ... ): ... if roll_a [ 0 ] < roll_b [ - 1 ]: ... roll_a , roll_b = roll_a [ 1 :] + roll_b [ - 1 :], roll_a [: 1 ] + roll_b [: - 1 ] ... roll_a = tuple ( sorted ( roll_a , reverse = True )) ... roll_b = tuple ( sorted ( roll_b , reverse = True )) ... a_successes = sum ( 1 for v in roll_a if v >= roll_b [ 0 ]) ... b_successes = sum ( 1 for v in roll_b if v >= roll_a [ 0 ]) ... result = a_successes - b_successes or ( roll_a > roll_b ) - ( roll_a < roll_b ) ... yield result , count_a * count_b Rudimentary visualization using built-in methods: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 >>> res = H ( brawl_w_optional_swap ( 3 @P ( 6 ), 3 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.36 std | 0.88 var | 0.77 - 1 | 1.42 % | 0 | 0.59 % | 1 | 16.65 % | ######## 2 | 23.19 % | ########### 3 | 58.15 % | ############################# >>> res = H ( brawl_w_optional_swap ( 4 @P ( 6 ), 4 @P ( 6 ))) . lowest_terms () >>> print ( res . format ( width = 65 )) avg | 2.64 std | 1.28 var | 1.64 - 2 | 0.06 % | - 1 | 2.94 % | # 0 | 0.31 % | 1 | 18.16 % | ######### 2 | 19.97 % | ######### 3 | 25.19 % | ############ 4 | 33.37 % | ################","title":"Translation of the accepted answer to \u201cModelling [sic] opposed dice pools with a swap\u201d"}]}